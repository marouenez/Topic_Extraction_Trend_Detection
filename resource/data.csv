title|year|Abstract|Keywords|Keywords-Plus|Web-of-Science-Categories|Times-Cited|Usage-Count-Last-180-days|Usage-Count-Since-2013
Enhancing deep learning sentiment analysis with ensemble techniques in social applications|2017|Deep learning techniques for Sentiment Analysis have become very popular. They provide automatic feature extraction and both richer representation capabilities and better performance than traditional feature based techniques (i.e., surface methods). Traditional surface approaches are based on complex manually extracted features, and this extraction process is a fundamental question in feature driven methods. These long-established approaches can yield strong baselines, and their predictive capabilities can be used in conjunction with the arising deep learning methods. In this paper we seek to improve the performance of deep learning techniques integrating them with traditional surface approaches based on manually extracted features. The contributions of this paper are sixfold. First, we develop a deep learning based sentiment classifier using a word embeddings model and a linear machine learning algorithm. This classifier serves as a baseline to compare to subsequent results. Second, we propose two ensemble techniques which aggregate our baseline classifier with other surface classifiers widely used in Sentiment Analysis. Third, we also propose two models for combining both surface and deep features to merge information from several sources. Fourth, we introduce a taxonomy for classifying the different models found in the literature, as well as the ones we propose. Fifth, we conduct several experiments to compare the performance of these models with the deep learning baseline. For this, we use seven public datasets that were extracted from the microblogging and movie reviews domain. Finally, as a result, a statistical study confirms that the performance of these proposed models surpasses that of our original baseline on Fl-Score. (C) 2017 The Authors. Published by Elsevier Ltd.|Ensemble; Deep learning; Sentiment analysis; Machine learning; Natural language processing|CLASSIFICATION; POLARITY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|5|14|93
Impact of media richness and flow on e-learning technology acceptance|2009|Advances in e-learning technologies parallels a general increase in sophistication by computer users. The use of just one theory or model, such as the technology acceptance model, is no longer sufficient to study the intended use of e-learning systems. Rather, a combination of theories must be integrated in order to fully capture the complexity of e-learners, who are both system users and learners. The current research presents an integrated theoretical framework to study users' acceptance of streaming media for e-learning. Three streams of research provide the basis for this integrated framework: the technology acceptance model, flow theory and media richness theory. Students enrolled in an online section of an information systems course used one of three different combinations of text, streamed audio and streamed video. Regression analysis was used to test the hypotheses in this field experiment. Perceived ease of use was a predictor of perceived usefulness: both the perceived usefulness and the attitude of the user were predictors of intention to use. Richer content-presentation types were positively correlated with higher concentration levels but showed mixed results when correlated with perceived usefulness. Results from this study have practical implications for those interested in integrating streaming media into e-learning. (C) 2008 Elsevier Ltd. All rights reserved.|Distance education and telelearning; Teaching/learning strategies; Lifelong learning; Multimedia/hypermedia systems|INFORMATION-TECHNOLOGY; USER ACCEPTANCE; INTERNET; MODEL; USAGE; SATISFACTION; MULTIMEDIA; EXPERIENCE; INTENTION; BEHAVIOR|Computer Science, Interdisciplinary Applications; Education \& Educational Research|158|4|93
What's buzzing in the blizzard of buzz? Automotive component isolation in social media postings|2013|In the blizzard of social media postings, isolating what is important to a corporation is a huge challenge. In the consumer-related manufacturing industry, for instance, manufacturers and distributors are faced with an unrelenting, accumulating snow of millions of discussion forum postings. In this paper, we describe and evaluate text mining tools for categorizing this user-generated content and distilling valuable intelligence frozen in the mound of postings. Using the automotive industry as an example, we implement and tune the parameters of a text-mining model for component diagnostics from social media. Our model can automatically and accurately isolate the vehicle component that is the subject of a user discussion. The procedure described also rapidly identifies the most distinctive terms for each component category, which provides further marketing and competitive intelligence to manufacturers, distributors, service centers, and suppliers. (c) 2012 Elsevier B.V. All rights reserved.|Social media analytics; Diagnostics; Text mining; User-generated content (UGC)|CUSTOMER COMPLAINT MANAGEMENT; TEXT CATEGORIZATION; INFORMATION EXTRACTION; CLASSIFICATION; COMMUNITIES; ONLINE; DOCUMENTS; KNOWLEDGE; FRAMEWORK; REVIEWS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|28|3|90
Community of inquiry as a theoretical framework to foster ``epistemic engagement{''} and ``cognitive presence{''} in online education|2009|In this paper, several recent theoretical conceptions of technology-mediated education are examined and a study of 2159 online learners is presented. The study validates an instrument designed to measure teaching, social, and cognitive presence indicative of a community of learners within the community of inquiry (CoI) framework {[}Garrison, D. R., Anderson, T., \& Archer, W. (2000). Critical inquiry in a text-based environment: Computer conferencing in higher education. The Internet and Higher Education, 2, 1-19; Garrison, D. R., Anderson, T., \& Archer, W. (2001). Critical thinking, cognitive presence. and computer conferencing in distance education. American Journal of Distance Education, 15(1), 7-23]. Results indicate that the survey items cohere into interpretable factors that represent the intended constructs. Further it was determined through structural equation modeling that 70\% of the variance in the online students' levels of cognitive presence, a multivariate measure of learning, can be modeled based on their reports of their instructors' skills in fostering teaching presence and their own abilities to establish a sense of social presence. Additional analysis identifies more details of the relationship between learner understandings of teaching and social presence and its impact on their cognitive presence. Implications for online teaching, policy, and faculty development are discussed. (C) 2008 Elsevier Ltd. All rights reserved.|Online learning; Theory; Community of inquiry model; Teaching presence; Social presence; Cognitive presence; Study|GENDER|Computer Science, Interdisciplinary Applications; Education \& Educational Research|147|7|90
Exploring determinants of voting for the ``helpfulness{''} of online user reviews: A text mining approach|2011|The ``helpfulness{''} feature of online user reviews helps consumers cope with information overloads and facilitates decision-making. However, many online user reviews lack sufficient helpfulness votes for other users to evaluate their true helpfulness level. This study empirically examines the impact of the various features, that is, basic, stylistic, and semantic characteristics of online user reviews on the number of helpfulness votes those reviews receive. Text mining techniques are employed to extract semantic characteristics from review texts. Our findings show that the semantic characteristics are more influential than other characteristics in affecting how many helpfulness votes reviews receive. Our findings also suggest that reviews with extreme opinions receive more helpfulness votes than those with mixed or neutral opinions. This paper sheds light on the understanding of online users' helpfulness voting behavior and the design of a better helpfulness voting mechanism for online user review systems. (C) 2010 Elsevier B.V. All rights reserved.|Online user review; Helpfulness; Text mining; Ordinal logistic regression; Latent Semantic Analysis|WORD-OF-MOUTH; LATENT SEMANTIC ANALYSIS; INFORMATION-SYSTEMS; SALES; VARIABLES; DYNAMICS; INTERNET; MODEL|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|108|14|89
Predicting e-commerce company success by mining the text of its publicly-accessible website|2012|We analyze the impact of textual information from e-commerce companies' websites on their commercial success. The textual information is extracted from web content of e-commerce companies divided into the Top 100 worldwide most successful companies and into the Top 101 to 500 worldwide most successful companies. It is shown that latent semantic concepts extracted from the analysis of textual information can be adopted as success factors for a Top 100 e-commerce company classification. This contributes to the existing literature concerning e-commerce success factors. As evaluation, a regression model based on these concepts is built that is successful in predicting the commercial success of the Top 100 companies. These findings are valuable for e-commerce websites creation. (c) 2012 Elsevier Ltd. All rights reserved.|Success factor; E-commerce; LSI; Classification; Text mining; Website|INFORMATION-SYSTEMS EVALUATION; PURCHASING BEHAVIOR; WEB SITES; SATISFACTION; PERFORMANCE; METRICS; ACCEPTANCE; CUSTOMERS; RETRIEVAL; USABILITY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|29|0|87
Exploring the feasibility and accuracy of Latent Semantic Analysis based text mining techniques to detect similarity between patent documents and scientific publications|2010|In this study, we examine and validate the use of existing text mining techniques (based on the vector space model and latent semantic indexing) to detect similarities between patent documents and scientific publications. Clearly, experts involved in domain studies would benefit from techniques that allow similarity to be detected-and hence facilitate mapping, categorization and classification efforts. In addition, given current debates on the relevance and appropriateness of academic patenting, the ability to assess content-relatedness between sets of documents-in this case, patents and publications-might become relevant and useful. We list several options available to arrive at content based similarity measures. Different options of a vector space model and latent semantic indexing approach have been selected and applied to the publications and patents of a sample of academic inventors (n = 6). We also validated the outcomes by using independently obtained validation scores of human raters. While we conclude that text mining techniques can be valuable for detecting similarities between patents and publications, our findings also indicate that the various options available to arrive at similarity measures vary considerably in terms of accuracy: some generally accepted text mining options, like dimensionality reduction and LSA, do not yield the best results when working with smaller document sets. Implications and directions for further research are discussed.|Text mining; Latent Semantic Analysis; Science-technology linkages; Patent-publication pairs; Author-inventor relationships|COMBINING FULL-TEXT; INFORMATION-RETRIEVAL; SCIENCE; TECHNOLOGY; KNOWLEDGE; CLASSIFICATION; RESEARCHERS; PERFORMANCE; SPACE; RANK|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|26|3|87
Using `core documents' for detecting and labelling new emerging topics|2012|The notion of `core documents', first introduced in the context of co-citation analysis and later re-introduced for bibliographic coupling and extended to hybrid approaches, refers to the representation of the core of a document set according to given criteria. In the present study, core documents are used for the identification of new emerging topics. The proposed method proceeds from independent clustering of disciplines in different time windows. Cross-citations between core documents and clusters in different periods are used to detect new, exceptionally growing clusters or clusters with changing topics. Three paradigmatic types of new, emerging topics are distinguished. Methodology is illustrated using the example of four ISI subject categories selected from the life sciences, applied sciences and the social sciences.|Hybrid clustering; Bibliographic coupling; Text mining; Core documents; Emerging topics|COCITATION ANALYSIS; CITATION; SCIENCE; TEXT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|38|4|86
Detecting variation of emotions in online activities|2017|Online text sources form evolving large scale data repositories out of which valuable knowledge about human emotions can be derived. Beyond the primary emotions which refer to the global emotional signals, deeper understanding of a wider spectrum of emotions is important to detect online public views and attitudes. The present work is motivated by the need to test and provide a system that categorizes emotion in online activities. Such a system can be beneficial for online services, companies recommendations, and social support communities. The main contributions of this work are to: (a) detect primary emotions, social ones, and those that characterize general affective states from online text sources, (b) compare and validate different emotional analysis processes to highlight those that are most efficient, and (c) provide a proof of concept case study to monitor and validate online activity, both explicitly and implicitly. The proposed approaches are tested on three datasets collected from different sources, i.e., news agencies, Twitter, and Facebook, and on different languages, i.e., English and Greek. Study results demonstrate that the methodologies at hand succeed to detect a wider spectrum of emotions out of text sources. (C) 2017 Elsevier Ltd. All rights reserved.|Emotion detection; Machine learning; Lexicon-based approach; Hybrid process|SENTIMENT ANALYSIS; PERCEPTIONS; TRANSLATION; TEXT|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|1|83|83
Major trends in knowledge management research: a bibliometric study|2016|This study provides an overview of the knowledge management literature from 1980 through 2014. We employ bibliometric and text mining analyses on a sample of 500 most cited articles to examine the impact of factors such as number of authors, references, pages, and keywords on the number of citations that they received. We also investigate major trends in knowledge management literature including the contribution of different countries, variations across publication years, and identifying active research areas and major journal outlets. Our study serves as a resource for future studies by shedding light on how trends in knowledge management research have evolved over time and demonstrating the characteristics of the most cited articles in this literature. Specifically, our results reveal that the most cited articles are from United States and United Kingdom. The most prolific year in terms of the number of published articles is 2009 and in terms of the number of citations is 2012. We also found a positive relationship between the number of publications' keywords, references, and pages and the number of citations that they have received. Finally, the Journal of Knowledge Management has the largest share in publishing the most cited articles in this field.|Bibliometric; Citation analysis; Knowledge management; Research productivity|GOOGLE SCHOLAR; PART I; CITATION; SCIENCE; IMPACT; DISCIPLINE; AUTHORSHIP; DISCOURSES; JOURNALS; ARTICLES|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|12|13|83
Do fourth graders integrate text and picture in processing and learning from an illustrated science text? Evidence from eye-movement patterns|2013|This study used eye-tracking methodology in the school setting to examine fourth graders' online processing of text and graphics while reading an illustrated science text. We were interested in identifying patterns of visual behavior, which was examined considering individual differences in reading comprehension, prior knowledge, and spatial ability. We also investigated the outcomes of learning from text by measuring free recall, factual knowledge, and transfer of knowledge. For an important advancement of research in this area, the link between processing and learning was also examined. Forty-nine 4th graders participated in a pretest, immediate, and delayed posttest design. Results of a cluster analysis using indices of first- and second-pass eye-fixation, as well as integrative saccades revealed three patterns of visual behavior varying for the level of integration of text and picture. Significant associations between eye-tracking data and reading comprehension and prior knowledge emerged. Moreover, the three patterns of visual behavior were significantly related to students' performances in the various learning tasks at both testing times. The greater integrative processing of the illustrated text was associated with higher learning performances. The significance of the study for educational implications is outlined. (C) 2012 Elsevier Ltd. All rights reserved.|Text processing; Eye movements; Text and picture comprehension; Learning from text; Comprehension of science text|WORKING-MEMORY CAPACITY; PRIOR KNOWLEDGE; EXPOSITORY TEXT; MULTIPLE REPRESENTATIONS; COMPREHENSION PROCESSES; READING-COMPREHENSION; FIXATION PATTERNS; SCIENTIFIC TEXT; SPATIAL ABILITY; REFUTATION TEXT|Computer Science, Interdisciplinary Applications; Education \& Educational Research|58|5|83
Divergence and convergence: technology-relatedness evolution in solar energy industry|2013|Exploring and measuring technology-relatedness and its collateral technology divergence and convergence, would have far-reaching theoretical significance and academic value on the chain mode of technology development, and also on the mastery of the laws for technology evolution and progress. Taking the patentometric analysis of solar energy technology worldwide as a case, employing the methodology of technology co-classification analysis, choosing two indicators, namely, mean technology co-classification partners (MTCP) and mean technology co-classification index (MTCI), we have analyzed and measured the evolving process of technology-relatedness. The results not only demonstrate in a direct manner the continuously advancing character of solar energy technology in the tensions of technology divergence and convergence, but also reveal quantitatively that, due to the chain reaction of technology-relatedness, technology divergence and technology convergence would tend to evolve in parallel. Through these, it is indicated that technology divergence and technology convergence are two trends which would develop separately, react mutually, and serve as causation for each other, thus making chain progress and continuously pushing forward the innovation, creation and upgrading of technologies. This is a regular phenomenon on condition that the specific technology area is in a status of sustainable development. It still awaits further research on how to verify and reveal the general principles on the interaction between technology divergence and convergence by conducting empirical studies and combining patent analysis.|Technology divergence and convergence; Technology-relatedness; Solar energy industry; Patent analysis; Co-classification analysis; Jaccard index|CO-CLASSIFICATION ANALYSIS; POLYMERASE-CHAIN-REACTION; INTERFIRM COOPERATION; PATENT ANALYSIS; CAR RACE; FIRMS; DIVERSIFICATION; INDICATORS; PROGRAM; TEXT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|8|11|82
Automated news reading: Stock price prediction based on financial news using context-capturing features|2013|We examine whether stock price prediction based on textual information in financial news can be improved as previous approaches only yield prediction accuracies close to guessing probability. Accordingly, we enhance existing text mining methods by using more expressive features to represent text and by employing market feedback as part of our feature selection process. We show that a robust feature selection allows lifting classification accuracies significantly above previous approaches when combined with complex feature types. This is because our approach allows selecting semantically relevant features and thus, reduces the problem of over-fitting when applying a machine learning approach. We also demonstrate that our approach is highly profitable for trading in practice. The methodology can be transferred to any other application area providing textual information and corresponding effect data. (C) 2013 Elsevier B.V. All rights reserved.|Text mining; Financial news; Stock price prediction; Decision support|TEXTUAL ANALYSIS; SENTIMENT; INFORMATION; MANAGEMENT; MARKET; TALK|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|30|8|82
Knowledge mapping of the Iranian nanoscience and technology: a text mining approach|2012|Nanoscience and technology (NST) is a relatively new interdisciplinary scientific domain, and scholars from a broad range of different disciplines are contributing to it. However, there is an ambiguity in its structure and in the extent of multidisciplinary scientific collaboration of NST. This paper investigates the multidisciplinary patterns of Iranian research in NST based on a selection of 1,120 ISI-indexed articles published during 1974-2007. Using text mining techniques, 96 terms were identified as the main terms of the Iranian publications in NST. Then the scientific structure of the Iranian NST was mapped through multidimensional scaling, based upon the co-occurrence of the main terms in the academic publications. The results showed that the NST domain in Iranian publications has a multidisciplinary structure which is composed of different fields, such as pure physics, analytical chemistry, chemistry physics, material science and engineering, polymer science, biochemistry and new emerging topics.|Science map; Knowledge map; Nano science and technology; Text mining|CO-WORD ANALYSIS; NEURAL-NETWORK RESEARCH; SCIENCE-AND-TECHNOLOGY; NANOTECHNOLOGY LITERATURE; INFORMATION-SCIENCE; FIELD; SCIENTOMETRICS; EMERGENCE; MAPS; REPRESENTATIONS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|5|6|82
Understanding the evolving academic landscape of library and information science through faculty hiring data|2016|Using a 40-year (from 1975 to 2015) hiring dataset of 642 library and Information science (LIS) faculty members from 44 US universities, this research reveals the disciplinary characteristics of LIS through several key aspects including gender, rank, country, university, major, and research area. Results show that genders and ranks among LIS faculty members are evenly distributed; geographically, more than 90 \% of LIS faculty members received doctoral degrees in the US; meanwhile, 60 \% of LIS faculty received Ph.D. in LIS, followed by Computer Science and Education; in regards to research interests, Human-Computer interaction, Digital Librarianship, Knowledge Organization and Management, and Information Behavior are the most popular research areas among LIS faculty members. Through a series of dynamic analyses, this study shows that the educational background of LIS faculty members is becoming increasingly diverse; in addition, research areas such as Human-Computer interaction, Social Network Analysis, Services for Children and Youth, Information Literacy, Information Ethics and Policy, and Data and Text Mining, Natural Language Processing, Machine Learning have received an increasing popularity. Predictive analyses are performed to discover trends on majors and research areas. Results show that the growth rate of LIS faculty members is linearly distributed. In addition, among faculty member's Ph.D. majors, the share of LIS is decreasing while that the share of Computer Science is growing; among faculty members' research areas, the share of Human-Computer interaction is on the rise.|Library and information science education; Faculty hiring; Interdisciplinarity; Research areas|DEMOGRAPHIC INERTIA; NETWORK ANALYSIS; HIGHER-EDUCATION; REPRESENTATION; PLACEMENT; PAGERANK; PATTERNS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|16|81
Content-based author co-citation analysis|2014|Author co-citation analysis (ACA) has long been used as an effective method for identifying the intellectual structure of a research domain, but it relies on simple co-citation counting, which does not take the citation content into consideration. The present study proposes a new method for measuring the similarity between co-cited authors by considering author's citation content. We collected the full-text journal articles in the information science domain and extracted the citing sentences to calculate their similarity distances. We compared our method with traditional ACA and found out that our approach, while displaying a similar intellectual structure for the information science domain as the other baseline methods, also provides more details about the sub-disciplines in the domain than with traditional ACA. (C) 2013 Elsevier Ltd. All rights reserved.|Author co-citation analysis; Citation content analysis; Bibliometrics; Information science; Citation analysis|INTELLECTUAL STRUCTURE; ALL-AUTHOR; INFORMATION-SCIENCE; CITATION ANALYSIS; MANAGEMENT FIELD; PROXIMITY; WEB; PUBLICATIONS; NETWORKS; 1ST|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|23|4|81
Written corrective feedback for individual L2 writers|2013|In this study, the controversial issue of written corrective feedback (WCF) is examined through a longitudinal (16-week semester) multiple-case study approach. Ten L2 writers (from ``Generation 1.5{''} backgrounds) in a developmental. ESL Writing class at a U.S. university wrote four in-class texts, revised them after receiving WCF, and participated in retrospective interviews after each of the first three writing and revision sessions. Data collected included student background questionnaires (N = 10), four student texts (originals plus revisions) per participant (N = 40), recordings and field notes from interviews with participants (N = 30), and recordings and notes from an end-of-semester interview with the classroom teacher. Analyses focused primarily on students' descriptions of their own self-monitoring processes as they revised marked papers and wrote new texts and individual and contextual factors that appeared to influence their writing development. Students found the techniques used in the study (focused WCF, revision,. and one-to-one discussion about errors) useful, but formal knowledge of language rules played a limited and sometimes even counterproductive role in their self-editing and composing. Our findings suggest that teachers should take a more finely tuned approach to corrective feedback and that future research designs investigating WCF should go beyond consideration of only students' written products. (C) 2012 Elsevier Inc. All rights reserved.|Written corrective feedback; Error correction; Self-editing strategies; Teacher feedback; Generation 1.5|WRITING CONFERENCES; GRAMMAR-CORRECTION; LEARNERS; 2ND-LANGUAGE; PERFORMANCE; STUDENTS; ERRORS; ESL; ENGLISH; SELF|Linguistics|35|2|81
Discovering business intelligence from online product reviews: A rule-induction framework|2012|Online product reviews are a major source of business intelligence (BI) that helps managers and marketers understand customers' concerns and interests. The large volume of review data makes it difficult to manually analyze customers' concerns. Automated tools have emerged to facilitate this analysis, however most lack the capability of extracting the relationships between the reviews' rich expressions and the customer ratings. Managers and marketers often resort to manually read through voluminous reviews to find the relationships. To address these challenges, we propose the development of a new class of BI systems based on rough set theory, inductive rule learning, and information retrieval methods. We developed a new framework for designing BI systems that extract the relationship between the customer ratings and their reviews. Using reviews of different products from Amazon.com, we conducted both qualitative and quantitative experiments to evaluate the performance of a BI system developed based on the framework. The results indicate that the system achieved high accuracy and coverage related to rule quality, and produced interesting and informative rules with high support and confidence values. The findings have important implications for market sentiment analysis and e-commerce reputation management. (C) 2012 Elsevier Ltd. All rights reserved.|E-commerce; Online reviews; Data mining; Text mining; Association rule mining; Rough set theory; Business intelligence; Online reputation|CUSTOMER RELATIONSHIP MANAGEMENT; ROUGH SET-THEORY; RECOMMENDER SYSTEMS; KNOWLEDGE; CLASSIFICATION; INFORMATION; WEB; MODEL|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|24|2|81
Linguistic features for review helpfulness prediction|2015|Online reviews play a critical role in customer's purchase decision making process on the web. The reviews are often ranked based on user helpfulness votes to minimize the review information overload problem. This paper examines the factors that contribute towards helpfulness of online reviews and builds a predictive model. The proposed predictive model extracts novel linguistic category features by analysing the textual content of reviews. In addition, the model makes use of review metadata, subjectivity and readability related features for helpfulness prediction. Our experimental analysis on two real-life review datasets reveals that a hybrid set of features deliver the best predictive accuracy. We also show that the proposed linguistic category features are better predictors of review helpfulness for experience goods such as books, music, and video games. The findings of this study can provide new insights to e-commerce retailers for better organization and ranking of online reviews and help customers in making better product choices. (C) 2015 Elsevier Ltd. All rights reserved.|Review helpfulness; Linguistic category features; Sentiment analysis; Machine learning; Text mining|CONSUMER-BEHAVIOR|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|19|10|80
Pharmacovigilance from social media: mining adverse drug reaction mentions using sequence labeling with word embedding cluster features|2015|Objective Social media is becoming increasingly popular as a platform for sharing personal health-related information. This information can be utilized for public health monitoring tasks, particularly for pharmacovigilance, via the use of natural language processing (NLP) techniques. However, the language in social media is highly informal, and user-expressed medical concepts are often nontechnical, descriptive, and challenging to extract. There has been limited progress in addressing these challenges, and thus far, advanced machine learning-based NLP techniques have been underutilized. Our objective is to design a machine learning-based approach to extract mentions of adverse drug reactions (ADRs) from highly informal text in social media. Methods We introduce ADRMine, a machine learning-based concept extraction system that uses conditional random fields (CRFs). ADRMine utilizes a variety of features, including a novel feature for modeling words' semantic similarities. The similarities are modeled by clustering words based on unsupervised, pretrained word representation vectors (embeddings) generated from unlabeled user posts in social media using a deep learning technique. Results ADRMine outperforms several strong baseline systems in the ADR extraction task by achieving an F-measure of 0.82. Feature analysis demonstrates that the proposed word cluster features significantly improve extraction performance. Conclusion It is possible to extract complex medical concepts, with relatively high performance, from informal, user-generated content. Our approach is particularly scalable, suitable for social media mining, as it relies on large volumes of unlabeled data, thus diminishing the need for large, annotated training data sets.|adverse drug reaction; ADR; social media mining; pharmacovigilance; natural language processing; machine learning; deep learning word embeddings|WEB; EXTRACTION; DISCOVERY; AGREEMENT; DATABASE; TEXT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|48|15|79
Design and evaluation of instructor-based and peer-oriented attention guidance functionalities in an open source anchored discussion system|2014|Social interactions to supplement learning and asynchronous tools to facilitate exchange of quality ideas have gained much attention in information systems education. While various systems exist, students have difficulty with deep processing of complex instructional materials (e.g., concepts of a theory and pedagogical support mechanisms derived from a theory). This research proposes a theoretical framework that leverages attention guidance in a social constructivist approach to facilitate processing of central domain concepts, principles, and their interrelations. Using an open source anchored discussion system, we designed a set of instructor-based and peer-oriented attention guidance functionalities involving dynamic manipulation of text font size similar to tag clouds. We conducted an experimental study with two small groups of first-year doctoral students in a blended-learning classroom format. Students in the control group had no access to attention guidance functions. Students in the treatment group used instructor-based attention guidance functionality and then switched to peer-oriented attention guidance functionality. The evaluation compared focus, content, and sequential organization of students' online discussion messages with heat maps, content analysis, sequential analysis, and statistical discourse analysis to examine different facets of the phenomenon in a holistic way. The results show that in areas where students struggle to understand challenging concepts, instructor-based attention guidance functionality facilitated elaboration and negotiation of ideas, which is fundamental to higher order thinking. In addition, after switching to peer-oriented attention guidance functionality, students in the treatment group took the lead in pinpointing challenging concepts they did not previously understand. These findings indicate that instructor-based and peer-oriented attention guidance functionalities offer students an indirect way of focusing their attention on deep processing of challenging concepts in an inherently open learning environment. Implications for theory, software design, and future research are discussed. Published by Elsevier Ltd.|Anchored discussion system; Attention guidance; Social constructivism; Heat maps; Statistical discourse analysis|ONLINE LEARNING CONVERSATIONS; COGNITIVE LOAD; KNOWLEDGE ACQUISITION; SPLIT-ATTENTION; ENVIRONMENTS; DISCOURSE; ARGUMENTATION; TECHNOLOGY; ANIMATIONS; CONSTRUCTION|Computer Science, Interdisciplinary Applications; Education \& Educational Research|6|0|79
Detecting weak signals for long-term business opportunities using text mining of Web news|2012|In an uncertain business environment, competitive intelligence requires peripheral vision to scan and identify weak signals that can affect the future business environment. Weak signals are defined as imprecise and early indicators of impending important events or trends, which are considered key to formulating new potential business items. However, existing methods for discovering weak signals rely on the knowledge and expertise of experts, whose services are not widely available and tend to be costly. They may even provide different analysis results. Therefore, this paper presents a quantitative method that identifies weak signal topics by exploiting keyword-based text mining. The proposed method is illustrated using Web news articles related to solar cells. As a supportive tool for the expert-based approach, this method can be incorporated into long-term business planning processes to assist experts in identifying potential business items. (C) 2012 Elsevier Ltd. All rights reserved.|Weak signal; Future sign; Text mining; Web news; Peripheral vision; Business intelligence|DECISION-MAKING; TECHNOLOGY; NETWORKS; TRENDS; PATENTS|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|21|7|79
A survey of the applications of text mining in financial domain|2016|Text mining has found a variety of applications in diverse domains. Of late, prolific work is reported in using text mining techniques to solve problems in financial domain. The objective of this paper is to provide a state-of-the-art survey of various applications of Text mining to finance. These applications are categorized broadly into FOREX rate prediction, stock market prediction, customer relationship management (CRM) and cyber security. Since finance is a service industry, these problems are paramount in operational and customer growth aspects. We reviewed 89 research papers that appeared during the period 2000-2016, highlighted some of the issues, gaps, key challenges in this area and proposed some future research directions. Finally, this review can be extremely useful to budding researchers in this area, as many open problems are highlighted. (C) 2016 Elsevier B.V. All rights reserved.|Text mining; Financial applications; FOREX rate prediction; Stock market prediction; Customer relationship management; Cyber security|MACHINE LEARNING APPROACH; INTRUSION-DETECTION; SENTIMENT ANALYSIS; INFORMATION-CONTENT; MARKET PREDICTION; PHISHING ATTACKS; MACRO NEWS; CLASSIFICATION; SYSTEM; WEB|Computer Science, Artificial Intelligence|15|16|78
Emotion detection in suicide notes|2013|The success of suicide prevention, a major public health concern worldwide, hinges on adequate suicide risk assessment. Online platforms are increasingly used for expressing suicidal thoughts, but manual monitoring is unfeasible given the information overload experts are confronted with. We investigate whether the recent advances in natural language processing, and more specifically in sentiment mining, can be used to accurately pinpoint 15 different emotions, which might be indicative of suicidal behavior. A system for automatic emotion detection was built using binary support vector machine classifiers. We hypothesized that lexical and semantic features could be an adequate way to represent the data, as emotions seemed to be lexicalized consistently. The optimal feature combination for each of the different emotions was determined using bootstrap resampling. Spelling correction was applied to the input data, in order to reduce lexical variation. Classification performance varied between emotions, with scores up to 68.86\% F-score. F-scores above 40\% were achieved for six of the seven most frequent emotions: thankfulness, guilt, love, information, hopelessness and instructions. The most salient features are trigram and lemma bags-of-words and subjectivity clues. Spelling correction had a slightly positive effect on classification performance. We showed that fine-grained automatic emotion detection benefits from classifier optimization and a combined lexico-semantic feature representation. The modest performance improvements obtained through spelling correction might indicate the robustness of the system to noisy input text. We conclude that natural language processing techniques have future application potential for suicide prevention. (c) 2013 Elsevier Ltd. All rights reserved.|Natural language processing; Suicide; Emotion|RESOURCES; LANGUAGE|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|24|3|77
Evaluating sentiment in financial news articles|2012|Can the choice of words and tone used by the authors of financial news articles correlate to measurable stock price movements? If so, can the magnitude of price movement be predicted using these same variables? We investigate these questions using the Arizona Financial Text (AZFinText) system, a financial news article prediction system, and pair it with a sentiment analysis tool. Through our analysis, we found that subjective news articles were easier to predict in price direction (59.0\% versus 50.0\% of chance alone) and using a simple trading engine, subjective articles garnered a 3.30\% return. Looking further into the role of author tone in financial news articles, we found that articles with a negative sentiment were easiest to predict in price direction (50.9\% versus 50.0\% of chance alone) and a 3.04\% trading return. Investigating negative sentiment further, we found that our system was able to predict price decreases in articles of a positive sentiment 53.5\% of the time, and price increases in articles of a negative sentiment 52.4\% of the time. We believe that perhaps this result can be attributable to market traders behaving in a contrarian manner, e.g., see good news, sell; see bad news, buy. (C) 2012 Elsevier B.V. All rights reserved.|Business intelligence; Text mining; Financial prediction; Sentiment analysis|STOCK-MARKET; TALK; TEXT|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|53|6|77
What in Consumer Reviews Affects the Sales of Mobile Apps: A Multifacet Sentiment Analysis Approach|2016|With the rapid adoption of smartphones, developing mobile apps has become an attractive arena for entrepreneurs. Many factors drive the sales of mobile apps, one of which is online word of mouth (eWOM). This research examines the effect of textual consumer reviews on the sales of mobile apps. Noting the inconsistent findings on the effect of textual reviews in previous literature, this study inspects how the sentiments of different topics in online reviews affect app sales. We develop a multifacet sentiment analysis (MFSA) approach to measure the dimensions in consumer reviews. Specifically, we are interested in the comments on product quality and service quality in this research. Employing a real-world data set of seventy-nine paid and seventy free apps from an iOS app store, we found that although consumers' opinions on product quality occupies a larger portion of consumer reviews, their comments on service quality have a stronger unit effect on sales rankings. The empirical analysis illustrates the value of our proposed MFSA approach for better understanding of the effect of textual consumer reviews on mobile app success.|Consumer reviews; electronic word of mouth; eWoM; mobile app sales; opinion analysis; sentiment analysis; text mining|WORD-OF-MOUTH; ONLINE PRODUCT REVIEWS; INFORMATION-SYSTEMS SUCCESS; SERVICE QUALITY; MODERATING ROLE; COMMUNICATION; PERFORMANCE; MANAGEMENT; SOFTWARE; IMPACT|Business; Computer Science, Software Engineering|7|7|76
Identifying patent infringement using SAO based semantic technological similarities|2012|Companies should investigate possible patent infringement and cope with potential risks because patent litigation may have a tremendous financial impact. An important factor to identify the possibility of patent infringement is the technological similarity among patents, so this paper considered technological similarity as a criterion for judging the possibility of infringement. Technological similarities can be measured by transforming patent documents into abstracted forms which contain specific technological key-findings and structural relationships among technological components in the invention. Although keyword-based technological similarity has been widely adopted for patent analysis related research, it is inadequate for identifying patent infringement because a keyword vector cannot reflect specific technological key-findings and structural relationships among technological components. As a remedy, this paper exploited a subject-action-object (SAO) based semantic technological similarity. An SAO structure explicitly describes the structural relationships among technological components in the patent, and the set of SAO structures is considered to be a detailed picture of the inventor's expertise, which is the specific key-findings in the patent. Therefore, an SAO based semantic technological similarity can identify patent infringement. Semantic similarity between SAO structures is automatically measured using SAO based semantic similarity measurement method using WordNet, and the technological relationships among patents were mapped onto a 2-dimensional space using multidimensional scaling (MDS). Furthermore, a clustering algorithm is used to automatically suggest possible patent infringement cases, allowing large sets of patents to be handled with minimal effort by human experts. The proposed method will be verified by detecting real patent infringement in prostate cancer treatment technology, and we expect this method to relieve human experts' work in identifying patent infringement.|Patent mining; Patent litigation; Subject-action-object; SAO; Natural language processing; NLP; Multidimensional scaling; Patent analysis; Patent risk|RESEARCH-AND-DEVELOPMENT; VISUALIZATION; LITIGATION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|35|8|76
Futuristic data-driven scenario building: Incorporating text mining and fuzzy association rule mining into fuzzy cognitive map|2016|Fuzzy cognitive maps (FCMs) are one of the representative techniques in developing scenarios that include future concepts and issues, as well as their causal relationships. The technique, initially dependent on deductive modeling of expert knowledge, suffered from inherent limitations of scope and subjectivity; though this lack has been partially addressed by the recent emergence of inductive modeling, the fact that inductive modeling uses a retrospective, historical data that often misses trend-breaking developments. Addressing this issue, the paper suggests the utilization of futuristic data, a collection of future-oriented opinions extracted from online communities of large participation, in scenario building. Because futuristic data is both large in scope and prospective in nature, we believe a methodology based on this particular data set addresses problems of subjectivity and myopia suffered by the previous modeling techniques. To this end, text mining (TM) and latent semantic analysis (LSA) algorithm are applied to extract scenario concepts from futuristic data in textual documents; and fuzzy association rule mining (FARM) technique is utilized to identify their causal weights based on if-then rules. To illustrate the utility of proposed approach, a case of electric vehicle is conducted. The suggested approach can improve the effectiveness and efficiency of scanning knowledge for scenario development. (C) 2016 Elsevier Ltd. All rights reserved.|Scenarios; Fuzzy cognitive map; Futuristic data; Text mining; Fuzzy association rule mining; Electric vehicle|FORESIGHT; ONLINE; VISUALIZATION; INFORMATION; NETWORKS; IMPACT|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|5|7|75
Inter-cluster connectivity analysis for technology opportunity discovery|2014|In today's competitive business environment, the timely identification of potential technology opportunities is becoming increasingly important for the strategic management of technology and innovation. Existing studies in the field of technology opportunity discovery (TOD) focus exclusively on patent textual information. In this article, we introduce a new method that tackles TOD via technology convergence, using both patent textual data and patent citation networks. We identify technology groups with high convergence potential by measuring connectivity between clusters of patents. From such technology groups we select pairs of core patents based on their technological relatedness, on their past involvement in convergence, and on the impact of their new potential convergence. We finally carry out TOD by extracting representative keywords from the text of the selected patent pairs and organizing them into the basic description of a new invention, which the potential convergence of the patent pair might produce. We illustrate our proposed method using a data set of U.S. patents in the field of digital information and security.|Technology opportunity; Technology convergence; Inter-cluster connectivity; Patent citation network; Keyword; Core patent|PATENT ANALYSIS; DOCUMENTS; NETWORK; TRENDS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|9|4|75
Technology-driven roadmaps for identifying new product/market opportunities: Use of text mining and quality function deployment|2015|A technology roadmap (TRM), an approach that is applied to the development of an emerging technology to meet business goals, is one of the most frequently adopted tools to support the process of technology innovation. Although many studies have dealt with TftMs that are designed primarily for a market-driven technology planning process, a technology-driven TRM is far less researched than a market-driven one. Furthermore, approaches to a technology-driven roadmap using quantitative technological information have rarely been studied. Thus, the aim of this research is to propose a new methodological framework to identify both profitable markets and promising product concepts based on technology information. This study suggests two quality function deployment (QFD) matrices to draw up the TRM in order to find new business opportunities. A case study is presented to illustrate the proposed approach using patents on the solar-lighting devices, which is catching on as a high-tech way to prevent environmental pollution and reduce fuel costs. (C) 2014 Elsevier Ltd. All rights reserved.|Technology roadmap (TRM); Technology-driven approach; Patent analysis; Text mining; Keyword analysis; Quality function deployment (QFD)|INTEGRATES BUSINESS; PATENT ANALYSIS; INNOVATION; EVOLUTION; KNOWLEDGE; INDUSTRY; NETWORK; FIELD; GTM|Computer Science, Artificial Intelligence; Engineering, Multidisciplinary|15|8|73
Detecting the knowledge structure of bioinformatics by mining full-text collections|2013|Bioinformatics is a fast-growing, diverse research field that has recently gained much public attention. Even though there are several attempts to understand the field of bioinformatics by bibliometric analysis, the proposed approach in this paper is the first attempt at applying text mining techniques to a large set of full-text articles to detect the knowledge structure of the field. To this end, we use PubMed Central full-text articles for bibliometric analysis instead of relying on citation data provided in Web of Science. In particular, we develop text mining routines to build a custom-made citation database as a result of mining full-text. We present several interesting findings in this study. First, the majority of the papers published in the field of bioinformatics are not cited by others (63 \% of papers received less than two citations). Second, there is a linear, consistent increase in the number of publications. Particularly year 2003 is the turning point in terms of publication growth. Third, most researches of bioinformatics are driven by USA-based institutes followed by European institutes. Fourth, the results of topic modeling and word co-occurrence analysis reveal that major topics focus more on biological aspects than on computational aspects of bioinformatics. However, the top 10 ranked articles identified by PageRank are more related to computational aspects. Fifth, visualization of author co-citation analysis indicates that researchers in molecular biology or genomics play a key role in connecting sub-disciplines of bioinformatics.|Text mining; PubMed Central; Bioinformatics|COCITATION ANALYSIS; AUTHOR COCITATION; PUBLICATION; NETWORKS; PAGERANK; SCIENCE; TOOL|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|14|5|73
Tracking learners' visual attention during a multimedia presentation in a real classroom|2013|The purpose of the study was to investigate university learners' visual attention during a PowerPoint (PPT) presentation on the topic of ``Dinosaurs{''} in a real classroom. The presentation, which lasted for about 12-15 min, consisted of 12 slides with various text and graphic formats. An instructor gave the presentation to 21 students whose eye movements were recorded by the eye tracking system. Participants came from various science departments in a national university in Taiwan, of which ten were earth-science majors (ES) and the other 11 were assigned to the non-earth-science group (NES). Eye movement indicators, such as total time spent on the interest zone, fixation count, total fixation duration, percent time spent in zone, etc., were abstracted to indicate their visual attention. One-way ANOVA as well as t-test analysis was applied to find the associations between the eye movement data and the students' background as well as different formats of PPT slides. The results showed that the students attended significantly more to the text zones on the PPT slides and the narrations delivered by the instruction. Nevertheless, the average fixation duration, indicating the average information processing time, was longer on the picture zones. In general, the ES students displayed higher visual attention than the NES students to the text zones, but few differences were found for the picture zones. When the students viewed those slides containing scientific hypotheses, the difference in attention distributions between the text and pictures reduced. Further analyses of fixation densities and saccade paths showed that the ES students were better at information decoding and integration. (C) 2012 Elsevier Ltd. All rights reserved.|Applications in subject areas; Improving classroom teaching; Multimedia/hypermedia systems; Pedagogical issues; Teaching/learning strategies|EYE-MOVEMENTS; COGNITIVE LOAD; LEARNING ENVIRONMENTS; SCENE PERCEPTION; MODALITY; COMPREHENSION; INSTRUCTION; KNOWLEDGE; SEARCH; TEXT|Computer Science, Interdisciplinary Applications; Education \& Educational Research|20|2|73
The proximity of co-citation|2012|Traditional co-citation analysis has not taken the proximity of co-cited references into account. As long as two references are cited by the same article, they are retreated equally regardless the distance between where citations appear in the article. Little is known about what additional insights into citation and co-citation behaviours one might gain from studying distributions of co-citation in terms of such proximity. How are citations distributed in an article? What insights does the proximity of co-citation provide? In this article, the proximity of a pair of co-cited reference is defined as the nearest instance of the co-citation relation in text. We investigate the proximity of co-citation in full text of scientific publications at four levels, namely, the sentence level, the paragraph level, the section level, and the article level. We conducted four studies of co-citation patterns in the full text of articles published in 22 open access journals from BioMed Central. First, we compared the distributions of co-citation instances at four proximity levels in journal articles to the traditional article-level co-citation counts. Second, we studied the distributions of co-citations of various proximities across organizational sections in articles. Third, the distribution of co-citation proximity in different co-citation frequency groups is investigated. Fourth, we identified the occurrences of co-citations at different proximity levels with reference to the corresponding traditional co-citation network. The results show that (1) the majority of co-citations are loosely coupled at the article level, (2) a higher proportion of sentence-level co-citations is found in high co-citation frequencies than in low co-citation frequencies, (3) tightly coupled sentence-level co-citations not only preserve the essential structure of the corresponding traditional co-citation network but also form a much smaller subset of the entire co-citation instances typically considered by traditional co-citation analysis. Implications for improving our understanding of underlying factors concerning co-citations and developing more efficient co-citation analysis methods are discussed.|Co-citation proximity; Co-citation analysis; Citation contextual; PubMed Central|SCIENTIFIC LITERATURE; INDEX|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|10|1|73
Invention property-function network analysis of patents: a case of silicon-based thin film solar cells|2011|Technology analysis is a process which uses textual analysis to detect trends in technological innovation. Co-word analysis (CWA), a popular method for technology analysis, encompasses (1) defining a set of keyword or key phrase patterns which are represented in technology-dependent terms, (2) generating a network that codifies the relations between occurrences of keywords or key phrases, and (3) identifying specific trends from the network. However, defining the set of keyword or key phrase patterns heavily relies on effort of experts, who may be expensive or unavailable. Furthermore defining keyword or key phrase patterns of new or emerging technology areas may be a difficult task even for experts. To solve the limitation in CWA, this research adopts a property-function based approach. The property is a specific characteristic of a product, and is usually described using adjectives; the function is a useful action of a product, and is usually described using verbs. Properties and functions represent the innovation concepts of a system, so they show innovation directions in a given technology. The proposed methodology automatically extracts properties and functions from patents using natural language processing. Using properties and functions as nodes, and co-occurrences as links, an invention property-function network (IPFN) can be generated. Using social network analysis, the methodology analyzes technological implications of indicators in the IPFN. Therefore, without predefining keyword or key phrase patterns, the methodology assists experts to more concentrate on their knowledge services that identify trends in technological innovation from patents. The methodology is illustrated using a case study of patents related to silicon-based thin film solar cells.|Property; Function; Patent mining; Patent analysis; Technology analysis; Natural language processing; Social network analysis; Technological trend|CO-WORD ANALYSIS; TECHNOLOGY; CITATIONS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|32|4|73
Clustering scientific documents with topic modeling|2014|Topic modeling is a type of statistical model for discovering the latent ``topics'' that occur in a collection of documents through machine learning. Currently, latent Dirichlet allocation (LDA) is a popular and common modeling approach. In this paper, we investigate methods, including LDA and its extensions, for separating a set of scientific publications into several clusters. To evaluate the results, we generate a collection of documents that contain academic papers from several different fields and see whether papers in the same field will be clustered together. We explore potential scientometric applications of such text analysis capabilities.|Topic modeling; Text analysis; Atent dirichlet allocation|BIBLIOMETRICS; TECHNOLOGIES|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|24|9|72
Twitter, My Space, Digg: Unsupervised Sentiment Analysis in Social Media|2012|Sentiment analysis is a growing area of research with significant applications in both industry and academia. Most of the proposed solutions are centered around supervised, machine learning approaches and review-oriented dalasets. In this article, we focus on the more common informal textual communication on the Web, such as online discussions, tweets and social network comments and propose an intuitive, less domain-specific, unsupervised, lexicon-based approach that estimates the level of emotional intensity contained in text in order to make a prediction. Our approach can be applied to, and is tested in, two different but complementary contexts: subjectivity detection and polarity classification. Extensive experiments were carried on three real-world datasets, extracted from online social Web sites and annotated by human evaluators, against state-of-the-art supervised approaches. The results demonstrate that the proposed algorithm, even though unsupervised, outperforms machine learning solutions in the majority of cases, overall presenting a very robust and reliable solution for sentiment analysis of informal communication on the Web.|Languages; Experimentation; Algorithms; Opinion mining; sentiment analysis; social media|WORDS|Computer Science, Artificial Intelligence; Computer Science, Information Systems|27|3|72
Rehabilitation using virtual reality technology: a bibliometric analysis, 1996-2015|2016|The aim of this study is to conduct a retrospective bibliometric analysis of articles about rehabilitation medicine using virtual reality technology. Bibliometrics is one subfield of scientometric. It is an effective tool for evaluating research trends in different science fields. A systematic bibliometric search was performed using three academic databases (PubMed, Scopus and Web of Science) between January 1, 1996, and December 31, 2015. Research outputs, countries, institutions, authors, major journals, cited articles, subject area and hot research topics were analyzed to base on bibliometrics methodologies. The retrieval of results was analyzed and described in the form of texts, tables, and graphics. Total of 15,191 articles were identified from three academic databases; and from them 48.32 \% published as original articles. The articles were originated from 101 countries and territories. United States was ranked first with 4522 articles, and United Kingdom was on second with 1369 articles. 96.75 \% of the articles are published in English. 527 articles were published by the Lecture Notes In Computer Science Including Subseries Lecture Notes In Artificial Intelligence And Lecture Notes In Bioinformatics. With regard of the research institutions, Eidgenossische Technische Hochschule Zurich published 208 articles ranked first. In the past 20 years, the research outcome of rehabilitation using virtual reality technology research has increased substantially. This study provides a valuable reference for researchers to understand the overview and present situations in this field.|Virtual reality; Rehabilitation; Bibliometric analysis research evaluation|SCIENCE; STROKE; PERFORMANCE; JOURNALS; THERAPY; DESIGN; TRENDS; IMPACT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|22|71
Effects of a computer-assisted concept mapping learning strategy on EFL college students' English reading comprehension|2010|The purpose of this research was to investigate the effects of a computer-assisted concept mapping learning strategy on EFL college learners' English reading comprehension. The research questions were: (1) what was the influence of the computer-assisted concept mapping learning strategy on different learners' English reading comprehension? (2) did the computer-assisted concept mapping learning strategy affect learners' use of other English reading strategies? One hundred ninety-four freshmen who were enrolled in the English course were divided into low-level and high-level groups according to their English proficiency. A computer-assisted concept mapping learning strategy was introduced to the learners in the experimental class to improve their reading ability. Through two-way ANOVA analysis, it was found that the computer-assisted concept mapping learning strategy had greater reading benefit for the low-level group than for the high-level group. In addition, the results of independent sample t-test analysis indicated that the computer-assisted concept mapping learning strategy enhanced learners' use of other English reading strategies-listing, enforcing, and reviewing. (C) 2009 Elsevier Ltd. All rights reserved.|Computer-assisted concept map; English reading instruction; Reading strategies|INSTRUCTION; TEXT; SCIENCE; READERS; CONSTRUCTION; DISABILITIES; THINKING; TOOLS; MODEL; MAPS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|74|6|71
Connection making between multiple graphical representations: A multi-methods approach for domain-specific grounding of an intelligent tutoring system for chemistry|2015|Making connections between graphical representations is integral to learning in science, technology, engineering, and mathematical (STEM) fields. However, students often fail to make these connections spontaneously. Intelligent tutoring systems (ITSs) are suitable educational technologies to support connection making. Yet, when designing an ITS for connection making, we need to investigate what concepts and learning processes play a role within the specific domain. We describe a multi-methods approach for grounding ITS design in the specific requirements of the target domain. Specifically, we applied this approach to an ITS for connection making in chemistry. We used a theoretical framework that describes potential target learning processes and conducted a series of four empirical studies to investigate what role graphical representations play in chemistry knowledge and to investigate which learning processes related to connection making play a role in students' learning about chemistry. These studies combined multiple methods, including knowledge testing, eye tracking, interviews, and log data analysis. We illustrate how our findings inform the design of an ITS for chemistry: Chem Tutor. Results from two pilot studies done in the lab and in the field with altogether 99 undergraduates suggest that Chem Tutor leads to significant and large learning gains on chemistry knowledge. (C) 2014 Elsevier Ltd. All rights reserved.|Connection making; Multiple representations; Perceptual learning; Intelligent tutoring systems; Chemistry|LEARNERS MENTAL MODELS; COHERENCE FORMATION; ACTIVE INTEGRATION; CHEMICAL EDUCATION; EYE-MOVEMENTS; SCIENCE TEXT; MATHEMATICS; MULTIMEDIA; KNOWLEDGE; DIAGRAMS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|9|6|70
Recognizing emotions in text using ensemble of classifiers|2016|Emotions constitute a key factor in human nature and behavior. The most common way for people to express their opinions, thoughts and communicate with each other is via written text. In this paper, we present a sentiment analysis system for automatic recognition of emotions in text, using an ensemble of classifiers. The designed ensemble classifier schema is based on the notion of combining knowledge based and statistical machine learning classification methods aiming to benefit from their merits and minimize their drawbacks. The ensemble schema is based on three classifiers; two are statistical (a Naive Bayes and a Maximum Entropy learner) and the third one is a knowledge-based tool performing deep analysis of the natural language sentences. The knowledge-based tool analyzes the sentence's text structure and dependencies and implements a keyword-based approach, where the emotional state of a sentence is derived from the emotional affinity of the sentence's emotional parts. The ensemble classifier schema has been extensively evaluated on various forms of text such as, news headlines, articles and social media posts. The experimental results indicate quite satisfactory performance regarding the ability to recognize emotion presence in text and also to identify the polarity of the emotions. (C) 2016 Elsevier Ltd. All rights reserved.|Sentiment analysis; Emotion recognition; Text mining; Classifiers ensembles; Affective computing; Machine learning|SENTIMENT ANALYSIS|Automation \& Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical \& Electronic|10|8|55
PREDOSE: A semantic web platform for drug abuse epidemiology using social media|2013|Objectives: The role of social media in biomedical knowledge mining, including clinical, medical and healthcare informatics, prescription drug abuse epidemiology and drug pharmacology, has become increasingly significant in recent years. Social media offers opportunities for people to share opinions and experiences freely in online communities, which may contribute information beyond the knowledge of domain professionals. This paper describes the development of a novel semantic web platform called PREDOSE (PREscription Drug abuse Online Surveillance and Epidemiology), which is designed to facilitate the epidemiologic study of prescription (and related) drug abuse practices using social media. PREDOSE uses web forum posts and domain knowledge, modeled in a manually created Drug Abuse Ontology (DAO - pronounced dow), to facilitate the extraction of semantic information from User Generated Content (UGC), through combination of lexical, pattern-based and semantics-based techniques. In a previous study, PREDOSE was used to obtain the datasets from which new knowledge in drug abuse research was derived. Here, we report on various platform enhancements, including an updated DAO, new components for relationship and triple extraction, and tools for content analysis, trend detection and emerging patterns exploration, which enhance the capabilities of the PREDOSE platform. Given these enhancements, PREDOSE is now more equipped to impact drug abuse research by alleviating traditional labor-intensive content analysis tasks. Methods: Using custom web crawlers that scrape UGC from publicly available web forums, PREDOSE first automates the collection of web-based social media content for subsequent semantic annotation. The annotation scheme is modeled in the DAO, and includes domain specific knowledge such as prescription (and related) drugs, methods of preparation, side effects, and routes of administration. The DAO is also used to help recognize three types of data, namely: (1) entities, (2) relationships and (3) triples. PREDOSE then uses a combination of lexical and semantic-based techniques to extract entities and relationships from the scraped content, and a top-down approach for triple extraction that uses patterns expressed in the DAO. In addition, PREDOSE uses publicly available lexicons to identify initial sentiment expressions in text, and then a probabilistic optimization algorithm (from related research) to extract the final sentiment expressions. Together, these techniques enable the capture of fine-grained semantic information, which facilitate search, trend analysis and overall content analysis using social media on prescription drug abuse. Moreover, extracted data are also made available to domain experts for the creation of training and test sets for use in evaluation and refinements in information extraction techniques. Results: A recent evaluation of the information extraction techniques applied in the PREDOSE platform indicates 85\% precision and 72\% recall in entity identification, on a manually created gold standard dataset. In another study, PREDOSE achieved 36\% precision in relationship identification and 33\% precision in triple extraction, through manual evaluation by domain experts. Given the complexity of the relationship and triple extraction tasks and the abstruse nature of social media texts, we interpret these as favorable initial results. Extracted semantic information is currently in use in an online discovery support system, by prescription drug abuse researchers at the Center for Interventions, Treatment and Addictions Research (CITAR) at Wright State University. Conclusion: A comprehensive platform for entity, relationship, triple and sentiment extraction from such abstruse texts has never been developed for drug abuse research. PREDOSE has already demonstrated the importance of mining social media by providing data from which new findings in drug abuse research were uncovered. Given the recent platform enhancements, including the refined DAO, components for relationship and triple extraction, and tools for content, trend and emerging pattern analysis, it is expected that PREDOSE will play a significant role in advancing drug abuse epidemiology in future. (C) 2013 Elsevier Inc. All rights reserved.|Entity identification; Relationship extraction; Triple extraction; Sentiment extraction; Semantic web; Drug Abuse Ontology; Opiod abuse; Prescription drug abuse; Social media|UNITED-STATES; PRESCRIPTION DRUG; SUBSTANCE USE; OPIOID ABUSE; INTERNET; USERS; INFORMATION; SURVEILLANCE; DEPENDENCE; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|21|5|55
A multidimensional approach for detecting irony in Twitter|2013|Irony is a pervasive aspect of many online texts, one made all the more difficult by the absence of face-to-face contact and vocal intonation. As our media increasingly become more social, the problem of irony detection will become even more pressing. We describe here a set of textual features for recognizing irony at a linguistic level, especially in short texts created via social media such as Twitter postings or ``tweets{''}. Our experiments concern four freely available data sets that were retrieved from Twitter using content words (e.g. ``Toyota{''}) and user-generated tags (e.g. ``\#irony{''}). We construct a new model of irony detection that is assessed along two dimensions: representativeness and relevance. Initial results are largely positive, and provide valuable insights into the figurative issues facing tasks such as sentiment analysis, assessment of online reputations, or decision making.|Irony detection; Figurative language processing; Negation; Web text analysis|HUMOR|Computer Science, Interdisciplinary Applications|67|6|55
Rete-netzwerk-red: analyzing and visualizing scholarly networks using the Network Workbench Tool|2010|The enormous increase in digital scholarly data and computing power combined with recent advances in text mining, linguistics, network science, and scientometrics make it possible to scientifically study the structure and evolution of science on a large scale. This paper discusses the challenges of this `BIG science of science'aEuro{''}also called `computational scientometrics' research-in terms of data access, algorithm scalability, repeatability, as well as result communication and interpretation. It then introduces two infrastructures: (1) the Scholarly Database (SDB) ( http://sdb.slis.indiana.edu ), which provides free online access to 22 million scholarly records-papers, patents, and funding awards which can be cross-searched and downloaded as dumps, and (2) Scientometrics-relevant plug-ins of the open-source Network Workbench (NWB) Tool ( http://nwb.slis.indiana.edu ). The utility of these infrastructures is then exemplarily demonstrated in three studies: a comparison of the funding portfolios and co-investigator networks of different universities, an examination of paper-citation and co-author networks of major network science researchers, and an analysis of topic bursts in streams of text. The article concludes with a discussion of related work that aims to provide practically useful and theoretically grounded cyberinfrastructure in support of computational scientometrics research, education and practice.|Scientometrics; Science of science; Evolution of science; Computational scientometrics; Data access; Algorithm scalability; Cyberinfrastructure; Scholarly Database; Network Workbench; Related tools; Open source; Open access|SCIENCE|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|16|2|55
New multi-stage similarity measure for calculation of pairwise patent similarity in a patent citation network|2015|Being able to effectively measure similarity between patents in a complex patent citation network is a crucial task in understanding patent relatedness. In the past, techniques such as text mining and keyword analysis have been applied for patent similarity calculation. The drawback of these approaches is that they depend on word choice and writing style of authors. Most existing graph-based approaches use common neighbor-based measures, which only consider direct adjacency. In this work we propose new similarity measures for patents in a patent citation network using only the patent citation network structure. The proposed similarity measures leverage direct and indirect co-citation links between patents. A challenge is when some patents receive a large number of citations, thus are considered more similar to many other patents in the patent citation network. To overcome this challenge, we propose a normalization technique to account for the case where some pairs are ranked very similar to each other because they both are cited by many other patents. We validate our proposed similarity measures using US class codes for US patents and the well-known Jaccard similarity index. Experiments show that the proposed methods perform well when compared to the Jaccard similarity index.|Patent citation network; Adjacency matrix; Similarity measure; US class code; Jaccard similarity index; Co-citation; Indirect citation|COCITATION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|5|12|54
A scalable framework for spatiotemporal analysis of location-based social media data|2015|In the past several years, social media (e.g., Twitter and Facebook) has experienced a spectacular rise in popularity and has become a ubiquitous location for discourse, content sharing and social networking. With the widespread adoption of mobile devices and location-based services, social media typically allows users to share the whereabouts of daily activities (e.g., check-ins and taking photos), thus strengthening the role of social media as a proxy for understanding human behaviors and complex social dynamics in geographic spaces. Unlike conventional spatiotemporal data, this new modality of data is dynamic, massive, and typically represented in a stream of unstructured media (e.g., texts and photos), which pose fundamental representation, modeling and computational challenges to conventional spatiotemporal analysis and geographic information science. In this paper, we describe a scalable computational framework to harness massive location-based social media data for efficient and systematic spatiotemporal data analysis. Within this framework, the concept of space-time trajectories (or paths) is applied to represent activity profiles of social media users. A hierarchical spatiotemporal data model, namely a spatiotemporal data cube model, is developed based on collections of space-time trajectories to represent the collective dynamics of social media users across aggregation boundaries at multiple spatiotemporal scales. The framework is implemented based upon a public data stream of Twitter feeds posted on the continent of North America. To demonstrate the advantages and performance of this framework, an interactive flow mapping interface (including both single-source and multiple-source flow mapping) is developed to allow real-time and interactive visual exploration of movement dynamics in massive location-based social media data at multiple scales. (C) 2015 Elsevier Ltd. All rights reserved.|Big data; CyberGIS; Data cube; OLAP; Social media|SPATIAL-ANALYSIS; DATA WAREHOUSES; SPACE-TIME; DATA CUBE; VISUALIZATION; MODEL; OLAP; CYBERINFRASTRUCTURE; PATTERNS|Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research \& Management Science|16|3|54
Counterargumentation and the cultivation of critical thinking in argumentative writing: Investigating washback from a high-stakes test|2014|It is generally acknowledged that counterargumentation is a key factor contributing to the persuasiveness of argumentative essays; however, recent research has revealed that students tend to neglect alternative viewpoints when responding to argumentative writing prompts. This study examines how the washback effect of a high-stakes test is associated with students' neglect of counterargumentation in their essays. A pretest-posttest design was used on experimental and control groups with 125 participants at a Chinese university. The control group received instruction in argumentative writing (which typically ignores counterargumentation in mainland China), while the experimental group received instruction in argumentation which included counterarguing and refuting. The results of the study demonstrated the efficacy of explicit classroom instruction in counterargumentation. Text analysis on posttest scripts showed that the inclusion of counterarguments and rebuttals was significantly positively correlated with the overall score of an argumentative essay using the evaluative rubric of a high-stakes test. These findings may have important implications for writing prompts and rubrics as well as argumentative writing pedagogy in China and beyond. It is proposed that counterargumentation be considered in the writing prompts and rubrics of high-stakes English tests, and included in classroom instruction on argumentative writing. (C) 2014 Elsevier Ltd. All rights reserved.|Argumentative writing; Counterargumentation; Persuasiveness; High-stakes English examination; Writing prompts; Critical thinking|MYSIDE BIAS; WRITTEN ARGUMENTATION; STUDENTS; EDUCATION; AGREEMENT; ABILITY; CHINA; GOAL|Education \& Educational Research; Linguistics|6|4|54
Using statistical text classification to identify health information technology incidents|2013|Objective To examine the feasibility of using statistical text classification to automatically identify health information technology (HIT) incidents in the USA Food and Drug Administration (FDA) Manufacturer and User Facility Device Experience (MAUDE) database. Design We used a subset of 570272 incidents including 1534 HIT incidents reported to MAUDE between 1 January 2008 and 1 July 2010. Text classifiers using regularized logistic regression were evaluated with both balanced' (50\% HIT) and stratified' (0.297\% HIT) datasets for training, validation, and testing. Dataset preparation, feature extraction, feature selection, cross-validation, classification, performance evaluation, and error analysis were performed iteratively to further improve the classifiers. Feature-selection techniques such as removing short words and stop words, stemming, lemmatization, and principal component analysis were examined. Measurements statistic, F1 score, precision and recall. Results Classification performance was similar on both the stratified (0.954 F1 score) and balanced (0.995 F1 score) datasets. Stemming was the most effective technique, reducing the feature set size to 79\% while maintaining comparable performance. Training with balanced datasets improved recall (0.989) but reduced precision (0.165). Conclusions Statistical text classification appears to be a feasible method for identifying HIT reports within large databases of incidents. Automated identification should enable more HIT problems to be detected, analyzed, and addressed in a timely manner. Semi-supervised learning may be necessary when applying machine learning to big data analysis of patient safety incidents and requires further investigation.|health information technology; HIT; incidents; MAUDE; FDA; text classification|UNINTENDED CONSEQUENCES; DECISION-SUPPORT; PATIENT SAFETY; SYSTEMS; EVENTS; ERRORS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|9|0|54
Emotive communication online: A contextual analysis of computer-mediated communication (CMC) cues|2013|More than any other feature, computer-mediated communication (CMC) cues such as emoticons and other typographic markers are associated with digital communication, including text-based chat. Using transcripts from college classroom discussions, this study adopts a pragmatic perspective to analyze how advanced foreign language learners use CMC cues, including emoticons ({''}:-){''}), nonstandard/ multiple punctuation ({''}...{''}, ``!!!{''}), and lexical surrogates ({''}hmmm{''}) in a quasi-synchronous computer-mediated consensus-building discussion. Rather than taking form-meaning pairings for granted (e.g., smiley ``:){''} means ``happy{''}), I adopt a microanalytic approach to show systematic, empirically grounded correlations between CMC cues and their interpretations in different contexts. I argue that the results must be interpreted and viewed alongside the large body of research on emotive communication in offline modes to better understand the pragmatics of online relational work. (C) 2013 Elsevier B.V. All rights reserved.|Synchronous computer-mediated communication (cmc); Cmc cues; Emoticons; Emotive communication; Foreign language|MESSAGE INTERPRETATION; SOCIAL-CONTEXT; HUMOR SUPPORT; EMOTICONS; DISAGREEMENT; IMPOLITENESS; PRAGMATICS; LANGUAGE; POWER; TIME|Linguistics; Language \& Linguistics|28|2|54
An Ontology-Based Text-Mining Method to Cluster Proposals for Research Project Selection|2012|Research project selection is an important task for government and private research funding agencies. When a large number of research proposals are received, it is common to group them according to their similarities in research disciplines. The grouped proposals are then assigned to the appropriate experts for peer review. Current methods for grouping proposals are based on manual matching of similar research discipline areas and/or keywords. However, the exact research discipline areas of the proposals cannot often be accurately designated by the applicants due to their subjective views and possible misinterpretations. Therefore, rich information in the proposals' full text can be used effectively. Text-mining methods have been proposed to solve the problem by automatically classifying text documents, mainly in English. However, these methods have limitations when dealing with non-English language texts, e.g., Chinese research proposals. This paper presents a novel ontology-based text-mining approach to cluster research proposals based on their similarities in research areas. The method is efficient and effective for clustering research proposals with both English and Chinese texts. The method also includes an optimization model that considers applicants' characteristics for balancing proposals by geographical regions. The proposed method is tested and validated based on the selection process at the National Natural Science Foundation of China. The results can also be used to improve the efficiency and effectiveness of research project selection processes in other government and private research funding agencies.|Clustering analysis; decision support systems; ontology; research project selection; text mining|SELF-ORGANIZING MAP; DECISION-SUPPORT; PORTFOLIO SELECTION; HYBRID KNOWLEDGE; SEMANTIC WEB; FUZZY-LOGIC; SYSTEM; MODEL; ENVIRONMENTS; MANAGEMENT|Computer Science, Cybernetics; Computer Science, Theory \& Methods|14|2|54
Identifying new business areas using patent information: A DEA and text mining approach|2011|From a resource-based point of view, firm's technological capabilities can be used as underlying sources for identifying new businesses. However, current methods are insufficient to systematically and clearly support firms in finding new business areas based on their technological strength. This research proposes a systematic approach to identify new business areas grounded on the relative technological strength of firms. Patent information is useful as a measure of firms' technological resources and data envelopment analysis (DEA) is beneficial to obtain the weighted value of patents according to their quality. With this weighted quality of patents, a firm can evaluate their relative technological strength at the industry and product level according to potential business areas. To compute technological strength by products, this research applies text mining method to patent documents, a method which a researcher discovers knowledge with unstructured data with. This paper shows the usefulness of the newly proposed framework with a case study. (C) 2010 Published by Elsevier Ltd.|New business areas; Technological strength; Patent information; Data envelopment analysis; Text mining|DATA ENVELOPMENT ANALYSIS; EFFICIENCY; PERFORMANCE; PRODUCTIVITY; MODELS|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|23|2|54
Associating stock prices with web financial information time series based on support vector regression|2013|Over the past years, the effect of massive information from the web on the financial market has increased. How to process and utilize such information attracts both researchers and portfolio managers. In this paper, financial information obtained daily from the web is treated as a time series and then associated with stock price volatilities. First, six research topics on financial time series are outlined, namely, analyses of stock price time series P, trading volume time series V, web information time series W, and relationship between P and V, P and W, as well as V and W. Second, a model connecting P and W based on the support vector regression (SVR) is examined as an example of the six research topics. Third, given that a typically successful way of computer-based natural language processing is through the conduct of keyword analysis, the novel finance-computer time series W is explicitly defined in terms of financial keywords and is used in the present paper as the topic of investigation. The relationship between P and W is modeled using SVR. Because during the pre-web era people cannot manually and efficiently process image information from the newspapers and sounds from the television and radio over a longer period of time (e.g., a year), they were unable to obtain the time series W. Therefore, it is the web that makes the research on the relationship between P and Win the meaning of quantity of W possible. Finally, experiments on the Shanghai and Shenzhen security markets revealed that the introduction of W helps improve model accuracies. As the web further develops, more and more ordinary people share their views on the web. The ``long-tail{''} of massive financial information formed by these ``grass roots{''} has a noticeable effect on the financial markets. In financial markets, those who quickly capture and interpret financial information have the potential to generate profits. With the use of the newly found model connecting P with W and fast decision making, financial market practitioners can be rewarded. (C) 2013 Elsevier B.V. All rights reserved.|Web financial information time series; Stock price time series; Support vector regression|TRADING VOLUME; MODEL; VOLATILITY; MARKETS; TEXT|Computer Science, Artificial Intelligence|12|1|53
Community detection: Topological vs. topical|2011|The evolution of the Web has promoted a growing interest in social network analysis, such as community detection. Among many different community detection approaches, there are two kinds that we want to address: one considers the graph structure of the network (topology-based community detection approach); the other one takes the textual information of the network nodes into consideration (topic-based community detection approach). This paper conducted systematic analysis of applying a topology-based community detection approach and a topic-based community detection approach to the coauthorship networks of the information retrieval area and found that: (1) communities detected by the topology-based community detection approach tend to contain different topics within each community; and (2) communities detected by the topic-based community detection approach tend to contain topologically-diverse sub-communities within each community. The future community detection approaches should not only emphasize the relationship between communities and topics, but also consider the dynamic changes of communities and topics. Published by Elsevier Ltd.|Community detection; Topics; Communities; Coauthor network|COCITATION ANALYSIS; INFORMATION-RETRIEVAL; BIBLIOMETRIC INFORMATION; AUTHOR COCITATION; NETWORKS; SCIENCE; CITATION; TEXT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|45|5|53
Harnessing the social web to enhance insights into people's opinions in business, government and public administration|2017|Transparency, participation, and collaboration are the core pillars of open government. For the systematic integration of citizens and other stakeholders into the policy and public value creation process, their opinions, wishes, and complaints first need to be received. In the future, including user-generated content from social media will become a main channel for the enrichment of this information base for public administrative bodies and commercial firms. However, the sheer speed of growth of this constantly updated data pool makes manual work infeasible. The automated gathering, combination, analysis, and visualization of user-generated content from various sources and multiple languages is therefore imperative. In this study, we present a design science research approach to develop a general framework ('MarketMiner') to handle large amounts of foreign-language user-generated content. As a first empirical application, we implement the framework in the automotive industry by analyzing Chinese automotive forums for the benefit of English-speaking users. At the same time, the ideas, methods, and insights are transferred to the public sector context, especially in light of the current challenges of a high number of political refugees from Arabic countries entering into the European Union. The results are promising in that MarketMiner can dramatically improve the utilization of multi-language, multi-source social media content. The modular set-up of the artifact allows an easy transfer to additional areas of application.|Open government; Open data; Participation; Public sector; Refugees; User-generated content (UGC); Social media analytics; Text mining; Business intelligence; Design science research|DESIGN SCIENCE RESEARCH; INFORMATION-SYSTEMS RESEARCH; KNOWLEDGE MANAGEMENT; RESEARCH AGENDA; DECISION-SUPPORT; PRODUCT REVIEWS; MATURITY MODEL; BIG DATA; MEDIA; INTELLIGENCE|Computer Science, Information Systems; Computer Science, Theory \& Methods|0|22|52
Formulaic language in L1 and L2 expert academic writing: Convergent and divergent usage|2014|Formulaicity (i.e. knowledge of conventionalised multi-word combinations) in academic writing is not part of the native writer's innate language ability and is thus far from being a linguistic universal skill (Kachru, 2009; Wray, 2008). It can therefore be assumed that L2 academic writers find it particularly difficult to acquire native-like formulaic sequences. Building on this assumption, I use a 5.7 million-word corpus of expert academic writing to compare convergent and divergent usage of lexical bundles in three language variables, L1 English, L2 English and L1 Spanish. I identify core bundles (i.e., bundles shared by the three variables) and contend that writers' usage of these bundles is determined by register. I also compare the structures and functions of bundles specific to one or to two language variables to exemplify how these distinctive bundles build different pragmatic meanings in the texts. In identifying phraseological norms implicitly recognised by L1 writers, I argue that the use of bundles by the L2 writers deviates from L1 norms and conclude that, although they are expert writers, their formulaicity is `hybrid', that is, largely, but not completely, native-like. I also discuss implications regarding L2 expert writers' interlanguage development and propose areas for pedagogical intervention. (C) 2014 Elsevier Ltd. All rights reserved.|Academic writing; English for academic purposes; Research article genre; Lexical bundles; Register analysis; Second language acquisition; Interlanguage development|LEXICAL BUNDLES; ENGLISH; CORPUS; SPEAKERS; STUDENT|Education \& Educational Research; Linguistics; Language \& Linguistics|8|12|52
A social network-empowered research analytics framework for project selection|2013|Traditional approaches for research project selection by government funding agencies mainly focus on the matching of research relevance by keywords or disciplines. Other research relevant information such as social connections (e.g., collaboration and co-authorship) and productivity (e.g., quality, quantity, and citations of published journal articles) of researchers is largely ignored. To overcome these limitations, this paper proposes a social network-empowered research analytics framework (RAF) for research project selections. Scholarmate.com, a professional research social network with easy access to research relevant information, serves as a platform to build researcher profiles from three dimensions, i.e., relevance, productivity and connectivity. Building upon profiles of both proposals and researchers, we develop a unique matching algorithm to assist decision makers (e.g. panel chairs or division managers) in optimizing the assignment of reviewers to research project proposals. The proposed framework is implemented and tested by the largest government funding agency in China to aid the grant proposal evaluation process. The new system generated significant economic benefits including great cost savings and quality improvement in the proposal evaluation process. (C) 2013 Elsevier B.V. All rights reserved.|Research project selection; Research social networks; Research analytics|DECISION-SUPPORT APPROACH; SCIENTIFIC COLLABORATION; KNOWLEDGE; BIBLIOMETRICS; EVOLUTION; MODEL; TEXT; WEB|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|11|1|52
Language Use in Eating Disorder Blogs: Psychological Implications of Social Online Activity|2013|Social media have become a significant means for peer-related communication, self-presentation, and identity management. So-called eating disorder websites that propagate a drastic thin ideal and unhealthy eating behaviors have triggered a debate about the harmful facets of social Internet activity. Little research has addressed the language that is used by the authors of these websites. The present study focuses on personal weblogs, a popular form of mostly text-based, diary-like, online journals. We compared 31 pro-eating disorder blogs, 29 recovery blogs, and 27 control blogs by the means of computerized quantitative text analyses. The language of pro-eating disorder blogs featured lower cognitive processing, a more closed-minded writing style, was less emotionally expressive, contained fewer social references, and focused more on eating-related contents than recovery blogs. A subset of 12 language indicators correctly classified the blogs in 84\% of the cases. The distinct language patterns appear to reflect the psychological conditions of the blog authors and provide insight into their various stages of coping.|computer mediated communication; Internet; language; new technology groups and cultures; pro-eating disorder; health|PRO-ANOREXIA WEBSITES; BULIMIA-NERVOSA; INTERNET; PERSONALITY; CYBERSPACE; VIEWERSHIP; EXPOSURE; WOMEN; MODEL|Communication; Linguistics; Psychology, Social|9|3|52
Assessing researcher interdisciplinarity: a case study of the University of Hawaii NASA Astrobiology Institute|2013|In this study, we combine bibliometric techniques with a machine learning algorithm, the sequential information bottleneck, to assess the interdisciplinarity of research produced by the University of Hawaii NASA Astrobiology Institute (UHNAI). In particular, we cluster abstract data to evaluate Thomson Reuters Web of Knowledge subject categories as descriptive labels for astrobiology documents, assess individual researcher interdisciplinarity, and determine where collaboration opportunities might occur. We find that the majority of the UHNAI team is engaged in interdisciplinary research, and suggest that our method could be applied to additional NASA Astrobiology Institute teams in particular, or other interdisciplinary research teams more broadly, to identify and facilitate collaboration opportunities.|Astrobiology; Bibliometrics; Information bottleneck method; Interdisciplinary science; Machine learning; Text mining|SCIENCE; CITATION; INDICATORS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|6|6|52
An SAO-based text mining approach to building a technology tree for technology planning|2012|A technology tree (TechTree) is a branching diagram that expresses relationships among product components, technologies, or functions of a technology in a specific technology area. A TechTree identifies strategic core technologies and is a useful tool to support decision making in a given market environment for organizations with specified capabilities. However, existing TechTrees generally overemphasize qualitative and expert-dependent knowledge rather than incorporating quantitative and objective information. In addition, the traditional process of developing a TechTree requires vast amounts of information, which costs considerably in terms of time, and cannot provide integrated information from a variety of technological perspectives simultaneously. To remedy these problems, this research presents a text mining approach based on Subject-Action-Object (SAO) structures: this approach develops a TechTree by extracting and analyzing SAO structures from patent documents. The extracted SAO structures are categorized by similarities, and are identified by the type of technological implications. To demonstrate the feasibility of the proposed approach, we developed a TechTree regarding Proton Exchange Fuel Cell technology. (c) 2012 Elsevier Ltd. All rights reserved.|Technology tree; Subject-Action-Object (SAO); Function; Patent mining; Patent analysis; Technology trends analysis|PATENT ANALYSIS; SIMILARITY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|34|5|52
Nominalization and grammatical metaphor: Elaborating the theory|2016|This article presents an elaborated framework for mapping learners' development of nominalizations, one prominent realization of the linguistic resource, grammatical metaphor (Halliday, 1993; Martin, 2008). The framework emerges from a larger, corpus-assisted analysis of the Chinese Longitudinal Learner Corpus (CLLC), 520 Chinese learner texts collected during the students' first four semesters of university (Liardet, 2013b, 2014, 2015). Over the past few decades, SFL research has provided rich descriptions of nominalizations (e.g., Halliday \& Matthiessen, 1999; Taverniers, 2006); however, little has been done to empirically describe deployment quality and map learners' development onto genetically, over time (Baratta, 2010). The proposed framework outlined in this paper seeks to identify how learners develop nominalization proficiency by accounting for intermediate realizations that may otherwise be dismissed as mistakes. These nuanced descriptions are illustrated throughout using excerpts from the CLLC and the paper concludes with pedagogical recommendations for apprenticing learners to advanced nominalization proficiency. (C) 2016 Elsevier Ltd. All rights reserved.|Nominalization; Grammatical metaphor; Academic writing; Systemic functional linguistics; Corpus linguistics|ENGLISH; SUCCESS|Linguistics|1|6|51
A virtual globe-based 3D visualization and interactive framework for public participation in urban planning processes|2010|Public participation is very important for the success of an urban planning project, since any urban planning project will ultimately become part of the everyday life of the public. Most members of the general public are not urban planning professionals; therefore, well-designed visualization and interactive tools can help expand their participation in urban planning processes. The emerging technology of virtual globe-based 3D visualization is a unique opportunity to facilitate public participation in urban planning projects by promoting intuitive 3D interaction, instant interoperability and seamless integration of 3D visualization with other traditional text and multimedia information channels. This paper discusses the technical issues of developing a virtual globe-based 3D visualization framework for publicizing urban planning information, using Web Services and Service Oriented Architecture (SOA) to support visual planning model sharing and interoperability. With 3D photorealistic visualization, end users can conveniently obtain both the macro-vision of a project on the global scale and the micro-details on the street scale, using swift zooming tools like Google Earth. End users can select any available urban planning solution for visual investigation and comparison in a virtual globe-based 3D visualization environment. The service oriented architecture allows urban planning information to be deployed as a service in one server or several geographically distributed servers, or even from the end user's own computer. With the architecture's capability for integrating distributed resources, other traditional interactive functions such as labeling, BBS, forum, and email, can also be conveniently integrated into the system. Auxiliary spatial analysis tools are integrated to help end users perform ``professional{''} tasks such as sunlight analysis and 3D distance measurement. This highly distributed system is designed for the Internet; therefore, any personal computer connected to the Internet can easily access the system and participate in the interaction. (C) 2009 Elsevier Ltd. All rights reserved.|Virtual Globe; Service Oriented Architecture (SOA); Visualization; Interaction; Public participation; Urban planning|GIS; INTEGRATION|Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research \& Management Science|50|7|47
Recent automatic text summarization techniques: a survey|2017|As information is available in abundance for every topic on internet, condensing the important information in the form of summary would benefit a number of users. Hence, there is growing interest among the research community for developing new approaches to automatically summarize the text. Automatic text summarization system generates a summary, i.e. short length text that includes all the important information of the document. Since the advent of text summarization in 1950s, researchers have been trying to improve techniques for generating summaries so that machine generated summary matches with the human made summary. Summary can be generated through extractive as well as abstractive methods. Abstractive methods are highly complex as they need extensive natural language processing. Therefore, research community is focusing more on extractive summaries, trying to achieve more coherent and meaningful summaries. During a decade, several extractive approaches have been developed for automatic summary generation that implements a number of machine learning and optimization techniques. This paper presents a comprehensive survey of recent text summarization extractive approaches developed in the last decade. Their needs are identified and their advantages and disadvantages are listed in a comparative manner. A few abstractive and multilingual text summarization approaches are also covered. Summary evaluation is another challenging issue in this research field. Therefore, intrinsic as well as extrinsic both the methods of summary evaluation are described in detail along with text summarization evaluation conferences and workshops. Furthermore, evaluation results of extractive summarization approaches are presented on some shared DUC datasets. Finally this paper concludes with the discussion of useful future directions that can help researchers to identify areas where further research is needed.|Text summarization; Summarization survey; Text mining; Artificial intelligence; Information retrieval; Natural language processing|NONNEGATIVE MATRIX FACTORIZATION; LATENT SEMANTIC ANALYSIS; MULTIPLE DOCUMENTS; SINGLE-DOCUMENT; INFORMATION; FRAMEWORK; SYSTEM; OPTIMIZATION; EXTRACTION; RETRIEVAL|Computer Science, Artificial Intelligence|16|11|46
Spatiotemporal and semantic information extraction from Web news reports about natural hazards|2015|In the field of geographic information science, modeling geographic dynamics based on spatiotemporal information extracted from the Web, especially unconstructed data such as online news reports, is a growing area of research. Extracting spatiotemporal and semantic information from a set of Web documents enables us to build a rich representation of geographic knowledge described in text, capturing where, when, or what events have occurred. This work investigates the role ontologies play as a key component in the process of semantic information extraction. We show how ontologies can be used in conjunction with natural language gazetteers in order to process semantic information about hazard events and augment spatiotemporal extraction with semantics. We are interested in capturing the spatiotemporal patterns of hazard-related events from online news reports to track the occurrences and evolution of natural hazards, such as severe storms. A hazard ontology has been created to assist the spatiotemporal information extraction process, especially with the automatic detection of different kinds of events at multiple granularities from unstructured texts revealing relationships between the events over space-time. The extraction and retrieval of semantic information about event dynamics provides information about the progression of events using both natural and human perspectives. (C) 2014 Elsevier Ltd. All rights reserved.|Spatiotemporal semantic information retrieval; Natural language processing; Hazard ontology; GIS; Gazetteers|ONTOLOGY; INTEGRATION; RETRIEVAL; TWITTER; SYSTEMS|Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research \& Management Science|6|4|46
How to enable automated trading engines to cope with news-related liquidity shocks? Extracting signals from unstructured data|2014|Financial markets are characterised by high levels of complexity and non-linearity. Information systems have often been applied to support investors by forecasting price changes in securities markets. In addition to the asset price, liquidity represents another financial variable that has a high relevance for investors because it constitutes a main determinant of total transaction costs. Previous research has shown that the level of liquidity is affected by the publication of corporate disclosures. To derive an optimal order execution strategy that minimises the transaction costs, investors as well as automated trading engines must be able to anticipate changes in the available market liquidity. However, there is no research on how to forecast the impact of corporate disclosures on market liquidity. Therefore, we propose an IT artefact that allows automated trading engines to appropriately react to news-related liquidity shocks. The system indicates whether the publication of a regulatory corporate disclosure will be followed by a positive liquidity shock, i.e., lower transaction costs compared to historical levels. Utilising text mining techniques, the content of the corporate disclosures is analysed to generate a trading signal. Furthermore, the trading signal is evaluated within a simulation-based use case that considers English and German corporate disclosures and is shown to be of economic value. (C) 2014 Elsevier B.V. All rights reserved.|Automated trading; Liquidity; Forecasting; Text mining; e-Finance; Simulation|KNOWLEDGE DISCOVERY; TEXTUAL ANALYSIS; ANNOUNCEMENTS; INFORMATION|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|2|9|46
Optimizing SCImago Journal \& Country Rank classification by community detection|2014|Subject classification arises as an important topic for bibliometrics and scientometrics, searching to develop reliable and consistent tools and outputs. Such objectives also call for a well delimited underlying subject classification scheme that adequately reflects scientific fields. Within the broad ensemble of classification techniques, clustering analysis is one of the most successful. Two clustering algorithms based on modularity the VOS and Louvain methods are presented here for the purpose of updating and optimizing the journal classification of the SCImago Journal \& Country Rank (SJR) platform. We used network analysis and Pajek visualization software to run both algorithms on a network of more than 18,000 SJR journals combining three citation-based measures of direct citation, co-citation and bibliographic coupling. The set of clusters obtained was termed through category labels assigned to SJR journals and significant words from journal titles. Despite the fact that both algorithms exhibited slight differences in performance, the results show a similar behaviour in grouping journals. Consequently, they are deemed to be appropriate solutions for classification purposes. The two newly generated algorithm-based classifications were compared to other bibliometric classification systems, including the original SJR and WoS Subject Categories, in order to validate their consistency, adequacy and accuracy. In addition to some noteworthy differences, we found a certain coherence and homogeneity among the four classification systems analysed. (C) 2014 Elsevier Ltd. All rights reserved.|Community detection; Clustering; SCImago Journal \& Country Rank; Journal classification; Citation-based network|SUBJECT CLASSIFICATION; SCIENCE; CITATION; INFORMATION; TEXT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|7|2|46
Mining corporate annual reports for intelligent detection of financial statement fraud - A comparative study of machine learning methods|2017|Financial statement fraud has been serious concern for investors, audit firms, government regulators, and other capital market stakeholders. Intelligent financial statement fraud detection systems have therefore been developed to support decision-making of the stakeholders. Fraudulent misrepresentation of financial statements in managerial comments has been noticed in recent studies. As such, the purpose of this study was to examine whether an improved financial fraud detection system could be developed by combining specific features derived from financial information and managerial comments in corporate annual reports. To develop this system, we employed both intelligent feature selection and classification using a wide range of machine learning methods. We found that ensemble methods outperformed the remaining methods in terms of true positive rate (fraudulent firms correctly classified as fraudulent). In contrast, Bayesian belief networks (BBN) performed best on non-fraudulent firms (true negative rate). This finding is important because interpretable ``green flag{''} values (for which fraud is likely absent) could be derived, providing potential decision support to auditors during client selection or audit planning. We also observe that both financial statements and text in annual reports can be utilised to detect non-fraudulent firms. However, non-annual report data (analysts' forecasts of revenues and earnings) are necessary to detect fraudulent firms. This finding has important implications for selecting variables when developing early warning systems of financial statement fraud. (C) 2017 Elsevier B.V. All rights reserved.|Annual reports; Financial statement fraud; Text mining; Feature selection; Machine learning|MANAGEMENT FRAUD; FEATURE-SELECTION; MODEL; TEXT; MISSTATEMENTS; BANKRUPTCY; PREDICTION; WORDS|Computer Science, Artificial Intelligence|1|29|45
Students' writing from sources for academic purposes: A synthesis of recent research|2016|Educators have long recognized that a major challenge for students learning to write for academic purposes is developing the ability to integrate source material effectively and appropriately into written compositions. To identify and evaluate the current state of empirical evidence, we conducted a systematic synthesis of the published research that has investigated writing from sources systematically from a variety of analytic perspectives, in first and second languages, and in diverse contexts internationally including students in universities, colleges, and secondary schools. Five general claims emerged across our analyses of 69 empirical studies published in refereed journals or books in English from 1993 to 2013. Each claim has firm empirical support but each also warrants further research and refinement: (1) students experience difficulties with, but develop certain strategies to deal with, the complex processes of writing from sources; (2) prior knowledge and experience influence students' performance in writing from sources; (3) differences may appear between Ll and L2 students in their understanding and uses of sources in writing; (4) performance in tasks that involve writing from sources varies by task conditions and types of texts written and read; and (5) instruction can help students improve their uses of sources in their writing. (C) 2016 Elsevier Ltd. All rights reserved.|Writing from sources; Instruction; Student development; English for academic purposes|READING-TO-WRITE; TASK REPRESENTATION; ESL STUDENTS; POSTGRADUATE STUDENTS; UNIVERSITY-STUDENTS; MULTIPLE DOCUMENTS; L2 RESEARCH; TEXT; PLAGIARISM; HISTORY|Education \& Educational Research; Linguistics; Language \& Linguistics|5|12|45
A patent time series processing component for technology intelligence by trend identification functionality|2015|Technology intelligence indicates the concept and applications that transform data hidden in patents or scientific literatures into technical insight for technology strategy-making support. The existing frameworks and applications of technology intelligence mainly focus on obtaining text-based knowledge with text mining components. However, what is the corresponding technological trend of the knowledge over time is seldom taken into consideration. In order to capture the hidden trend turning points and improve the framework of existing technology intelligence, this paper proposes a patent time series processing component with trend identification functionality. We use piecewise linear representation method to generate and quantify the trend of patent publication activities, then utilize the outcome to identify trend turning points and provide trend tags to the existing text mining component, thus making it possible to combine the text-based and time-based knowledge together to support technology strategy making more satisfactorily. A case study using Australia patents (year 1983-2012) in Information and Communications Technology industry is presented to demonstrate the feasibility of the component when dealing with real-world tasks. The result shows that the new component identifies the trend reasonably well, at the same time learns valuable trend turning points in historical patent time series.|Technology intelligence; Patent time series; Piecewise linear representation; Patent analysis|PIECEWISE-LINEAR REPRESENTATION; VISUALIZATION; PREDICTION; MACHINE; SYSTEM; TOOL|Computer Science, Artificial Intelligence|7|9|45
Relevance Theory and translation: Translating puns in Spanish film titles into English|2014|The present paper aims to analyse the translation of puns from a Relevance-Theory perspective. Relevance Theory is a cognitive-pragmatic approach to communication proposed by Sperber and Wilson in the mid-1980s (Sperber and Wilson, 1986). According to such theoretical framework, the relation between a translation and its source text is considered to be based on interpretive resemblance, rather than on equivalence (see Gutt, 1998, 2000). The translator would try to seek optimal relevance, in such a way that s/he would use different strategies to try to recreate the cognitive effects intended by the source communicator with the lowest possible processing effort on the part of the target addressee. The analysis carried out in this study is based on one hundred and ninety titles of Spanish and Latin American film titles containing puns and their translations for the Anglo-Saxon or international market. The strategies used by the translators to render puns in the translated titles have been analysed. The selection of strategy is determined, among other factors, by the principle of relevance. In those cases in which there is a coincidence in the relation between the levels of signifier and signified across source and target language, translators normally opt to translate literally and reproduce a pun based on the same linguistic phenomenon as the source pun and semantically equivalent to it. In the rest of the cases, the translator will have to assess what is more relevant, either content or the effect produced by the pun. (C) 2014 Elsevier B.V. All rights reserved.|Relevance Theory; Translation; Puns; Film titles; Spanish; English|HUMOR|Linguistics; Language \& Linguistics|1|13|45
Rhetorical structure and persuasive language in the subgenre of online advertisements|2014|This paper aims to reveal the rhetorical structure and the linguistic features of persuasive language in online advertisements of electronic products. Nowadays, the bulk of e-commerce is carried out in English, and it is often the case that non-native speakers are required to write different text types for various professional purposes, including promotional texts. This need has prompted the present study and the results have been used to build software to help native speakers of Spanish when writing promotional texts in English. The analysis reveals that these texts typically have two main rhetorical moves: one for identifying the product and another one for describing it. The latter move is further divided into two steps: one including objective features (size, weight, etc.) and the other focusing on persuading the potential customer. This is mainly achieved with the use of a relatively informal style (imperatives, contractions, clipping, subject/auxiliary omissions, etc.) and lexico-grammatical elements conveying positive evaluation (multiple modification, multal quantifying expressions, etc.). The findings show that online advertisements of electronic products may be regarded as a specific subgenre with particular macro- and microlinguistic characteristics, which have been identified in this paper for technical writing assistance. (C) 2013 Elsevier Ltd. All rights reserved.|Online advertisements; Rhetorical move analysis; Persuasive language; Technical writing|ADVERTISING ENGLISH; DISCOURSE; METADISCOURSE; GENRE|Linguistics|12|4|45
Two first-year students' strategies for writing from sources: Patchwriting or plagiarism?|2012|In this paper we report a case study of two first-year students at a university in Hong Kong doing the same writing assignment that required the use of sources. We explore the students' understanding of plagiarism, their strategies for composing, the similarity between their texts and source texts, and the lecturer's assessment of their work. The analyses in the study drew upon textual comparisons between student texts and source texts, interview data, and observation notes. The data indicated that both students appeared to understand the university's plagiarism policy yet their texts were characterized by patchwriting and inappropriate,citation. Only one student's problems were spotted by the lecturer and checked with Turnitin while the other's was hidden to the lecturer. We speculate about the reasons, and then discuss these issues related to students' writing from sources: the place of reading in a source-based assignment, the difficulty level of sources for an assignment in an introductory course, complexities of attribution in source-based writing assignments, and the place of patchwriting in the work of novice writers. We conclude by highlighting the challenges faced by teachers and researchers and echo with others that different labels need to be given to plagiarism as cheating versus misuse of source texts. (C) 2012 Elsevier Inc. All rights reserved.|University plagiarism regulations; Patchwriting; Undergraduate use of sources; Chinese EFL students; Instructor awareness of misuse of sources|COLLEGE; EDUCATION|Linguistics|41|1|45
A comparative study of TF{*}IDF, LSI and multi-words for text classification|2011|One of the main themes in text mining is text representation, which is fundamental and indispensable for text-based intellegent information processing. Generally, text representation inludes two tasks: indexing and weighting. This paper has comparatively studied TF{*}IDF, LSI and multi-word for text representation. We used a Chinese and an English document collection to respectively evaluate the three methods in information retreival and text categorization. Experimental results have demonstrated that in text categorization, LSI has better performance than other methods in both document collections. Also, LSI has produced the best performance in retrieving English documents. This outcome has shown that LSI has both favorable semantic and statistical quality and is different with the claim that LSI can not produce discriminative power for indexing. (C) 2010 Elsevier Ltd. All rights reserved.|Text representation; TF{*}IDF; LSI; Multi-word; Text classification; Information retrieval; Text categorization|INFORMATION-RETRIEVAL; DOCUMENT|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|93|2|45
Development of computer-assisted virtual field trips to support multidisciplinary learning|2009|Multidisciplinary courses are being developed at a number of US colleges and universities to highlight the connections between the rise or fall of world civilizations and the sustainable or unsustainable uses of soil and water resources. The content presented in these courses is complex because it includes concepts from disciplines as varied as geology, soil science, politics, economics, history, and anthropology. The learning goals for the courses include developing skills in the critical analysis of complex ``real-world{''} problems for which there is often no simple or correct solution. Didactic materials for such courses are limited. Field trips to sites around the world that present some of the issues covered in the course would be ideal, but are logistically challenging. We considered that a series of virtual field trips (VFTs) to sites around the world would allow us to present students with complicated real-world situations, with which to practice critical analysis skills. The VFTs envisaged are neither tutorials nor field/lab exercises. Rather, they are meant to be complex, multi-faceted representations of a past or current civilization and how it affects or is affected by its environment. We expect that the students will use the VFTs to explore the relationships between physical geography and culture and how the decisions or actions of a civilization impact natural resources and the environment and thus affect its fate. A goal of the VFTs is that through consideration of their experiences, students arrive at novel associations that lead to dynamic in-class dialogue about the material presented and a deeper understanding of the intricacies of the situation in the field. This article describes the process of assembling a VFT, and analyzes the technological and didactic choices the process requires. Our experience with a pilot VFT suggests that no single medium (i.e., video clips, interactive maps, animation sequences, etc.) is comprehensive enough to meet the course learning goals. Thus, a web-based, open architecture format was selected for the VFTs because of its simplicity, flexibility and extensibility. Each medium was selected for its ability to support the course learning goals. The learning process was mediated by the VFT text, questions for thought, and in-class discussions. Preliminary results with the pilot VFT are encouraging. (C) 2008 Elsevier Ltd. All rights reserved.|Applications in subject area; Media in education; Multimedia/hypermedia systems; Post-secondary education; Virtual reality|GEOLOGY|Computer Science, Interdisciplinary Applications; Education \& Educational Research|23|7|45
Modelling Propagation of Public Opinions on Microblogging Big Data Using Sentiment Analysis and Compartmental Models|2017|Compartmental models have been used to model information diffusion on social media. However, there have been few studies on modelling positive and negative public opinions using compartmental models. This study aimed for using sentiment analysis and compartmental model to model the propagation of positive and negative opinions on microblogging big media. The authors studied the news propagation of seven popular social topics on China's Sina Weibo microblogging platform. Natural language processing and sentiment analysis were used to identify public opinions from microblogging big data. Then two existing (SIZ and SEIZ) models and a newly developed (SE2IZ) model were implemented to model the news propagation and evaluate the trends of public opinions on selected social topics. Simulation study was used to check model fitting performance. The results show that the new SE2IZ model has a better model fitting performance than existing models. This study sheds some new light on using social media for public opinion estimation and prediction.|Big Data; Compartmental Model; Natural Language Processing; News Propagation; Public Opinion; Sentiment Analysis; Sina Weibo Microblogging|TWITTER; DRIVERS|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|6|44
A knowledge based scheme for risk assessment in loan processing by banks|2016|Inadequacy in the compliance auditing (CA) process is one of the major reasons behind corporate frauds and accrual of non-performing assets within the banking sector. This phenomenon threatens the organization, stakeholders and society at large. The traditional CA process is slow and often inadequate in highly regulated and networked sectors such as banking, insurance and healthcare. This paper proposes a knowledge driven automated compliance auditing scheme for the processing of loans by banks. We collect 100 cases that are designated as fraudulent by banks and use them to design an automated risk score card model. The model uses text mining to automatically classify DPCs (Deviation Pattern Components) from unstructured text based cases. DPC patterns in a case give an early indication of the portfolio turning into a NPA. At the same time the cases are reviewed by five expert auditors in order to determine their risk level, risk impact and ease of detection. A logistic regression based model is used to derive risk scores of the case studies and classify the cases. By incorporating experts' opinion along with data mining techniques, the model automates the prediction of risk level, risk impact and ease of detection of fraudulent cases that deal with loan processing. The classifier performs well in terms of various performance metrics. The knowledge based method has the potential to save time and expensive human resources by automating the risk analysis of fraudulent loan processing cases reported by banks. (C) 2016 Elsevier B.V. All rights reserved.|Knowledge-based systems; Compliance auditing; Deviation Pattern Components; Logistic regression; Risk management|NEURAL-NETWORKS; DECISION-AID; QUALITY; SYSTEMS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|6|5|44
Bibliometric analysis for the literature of traditional Chinese medicine in PubMed|2015|The aim of this study is to conduct a retrospective bibliometric analysis of articles about traditional Chinese medicine (TCM) research in PubMed and to learn about the development and perspective of TCM. A systematic bibliometric search was performed based on the PubMed database covering related publications between January 1, 1995, and December 31, 2014. Numbers and type of articles, countries and language of publications, as well as major journals were analyzed in accordance with bibliometrics methodologies. The retrieve results were analyzed and described in the form of texts, tables, and graphs. A total of 42,192 articles were identified from the PubMed database, among which 43.56 \% were published as original articles. The articles were originated from 102 countries and territories. China was ranked first with 20,121 articles, followed by United States with 2207 articles. 57.74 \% of the articles are published in English. 4364 articles were published by Zhongguo Zhong Yao Za Zhi. And complementary medicine was the most focused research are involving 30,544 articles. The publication activity of TCM literature increased rapidly in the past 20 years, indicating enhanced attention attracted to TCM and more research input. In view of its great advances achieved in scientific studies, TCM will continue to play an important role in medical research.|Bibliometric analysis; Traditional Chinese medicine; PubMed; Research trends|OF-THE-ART; SCIENCE; JOURNALS; SYSTEMS; TREND|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|5|44
Sectoral systems of innovation: the case of robotics research activities|2015|Robotics technology holds a significant promise for improving industrial automation and production lines, operating complex surgical procedures, performing space and security missions, and providing services to assist, educate and entertain humans. The emphasis of this paper is primarily on the scientific developments of robotics systems of innovation in a global perspective, identifying actors and institutions involved in developing and diffusing this innovative technology. This quantitative research is grounded on tech mining research method that is the combination of content analysis, bibliometrics and text mining. The analysis measures the scientific performance of individual countries based on robotics-related scientific publications from INSPEC database over the period 1995-2009. It discusses the role of academia, governmental institutions and firms in robotics scientific activities and further identifies the most prolific institutions involved in robotics research. The cross-country analysis sheds light on the evolution of robotics publication activities in time and reveals the relative technological specialization of individual countries in specific domains of robotics technology by the use of revealed technological advantage indices. The findings are particularly useful for science and technology policy makers and R\&D strategists, presenting strengths and weaknesses of robotics innovation systems and existing and future scientific developments of robotics technology.|Robotics; Systems of innovation; Bibliometrics; Tech mining; Science and technology policy|DYNAMICS; INDUSTRY; ISSUES|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|2|2|44
Measuring the impact of translation on the accuracy and fluency of vocabulary acquisition of English|2015|This article assesses the impact of translation on the acquisition of vocabulary for higher-intermediate level students of English for Speakers of Other Languages (ESOL). The use of translation is a relevant issue in the research of Second Language (L2) acquisition and different authors provide arguments on both sides of the issue. Language technologies serve this issue in both the usability of automatic translation and the automatic detection of lexical phenomena. This paper will explore translation as it affects the acquisition of new words in context when students are given real texts retrieved from the Internet in a web-based interface. The students can instantly obtain the dictionary definition of a word and its translation to their native language. This platform can accurately measure how much each student relies on translation and compare this to their accuracy and fluency on a lexical retrieval task using words seen in the texts. Results show that abundant use of translation may increase accuracy in the short term, but in the longer term, it negatively affects accuracy and possibly fluency. However, students who use translation in moderation seem to benefit the most in this lexical task. This paper provides a focused and precise way to measure the relevant variables for each individual student, and new findings that contribute to our understanding of the impact of the use of translation in language learning. (C) 2014 Elsevier Ltd. All rights reserved.|Reading tutor; Vocabulary acquisition; Translation; ESOL|CONTRASTIVE ANALYSIS; FOREIGN-LANGUAGE; 2ND-LANGUAGE; CONTEXT; GLOSSES|Computer Science, Artificial Intelligence|0|0|44
A new sentence similarity measure and sentence based extractive technique for automatic text summarization|2009|The technology of automatic document summarization is maturing and may provide a solution to the information overload problem. Nowadays, document summarization plays an important role in information retrieval. With a large volume of documents, presenting the user with a summary of each document greatly facilitates the task of finding the desired documents. Document summarization is a process of automatically creating a compressed version of a given document that provides useful information to users. and multi-document summarization is to produce a summary delivering the majority of information content from a set of documents about an explicit or implicit main topic. In our study we focus on sentence based extractive document summarization. We propose the generic document summarization method which is based on sentence clustering. The proposed approach is a continue sentence-clustering based extractive summarization methods, proposed in Alguliev {[}Alguliev, R. M., Aliguliyev. R. M., Bagirov, A. M. (2005). Global optimization in the summarization of text documents. Automatic Control and Computer Sciences 39, 42-47], Aliguliyev {[}Aliguliyev, R. M. (2006). A novel partitioning-based clustering method and generic document summarization. In Proceedings of the 2006 IEEE/WIC/ACM international conference on web intelligence and intelligent agent technology (WI-IAT2006 Workshops) (WI-IATW'06),18-22 December (pp. 626-629) Hong Kong, China], Alguliev and Alyguliev {[}Alguliev, R. M., Alyguliev, R. M. (2007). Summarization of text-based documents with a determination of latent topical sections and information-rich sentences. Automatic Control and Computer Sciences 41, 132-140] Aliguliyev, {[}Aliguliyev, R. M. (2007). Automatic document summarization by sentence extraction. Journal of Computational Technologies 12, 5-15.]. The purpose of present paper to show, that summarization result not only depends on optimized function, and also depends on a similarity measure. The experimental results on an open benchmark datasets from DUC01 and DUC02 show that our proposed approach can improve the performance compared to sate-of-the-art summarization approaches. (C) 2008 Elsevier Ltd. All rights reserved.|Similarity measure; Text mining; Sentence clustering; Summarization; Evolution algorithm; Sentence extractive technique|DIFFERENTIAL EVOLUTION; DOCUMENTS; ALGORITHM; DISTANCE; SYSTEM|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|71|2|44
Analyzing concept complexity, knowledge ageing and diffusion pattern of Mooc|2017|Massive open online course (Mooc) is an educational technology that involves both education and technological innovation. The past investigations of Mooc are very limited in research methodologies for this interdisciplinary research field. Using social network analysis, bibliometrics, text mining and idea of epidemic model, this work quantitatively measures, analyzes and compares Mooc research papers' concept complexity, knowledge ageing rate and Mooc diffusion pattern at international and country-specific levels.|Mooc; Concept complexity; Knowledge ageing; Innovation diffusion; Bibliometrics|OPEN ONLINE COURSES; MATHEMATICAL APPROACH; SCIENTIFIC LITERATURE; SOCIAL-SCIENCES; HALF-LIFE; OBSOLESCENCE; EDUCATION; IMPACT; GROWTH; SCHOLARSHIP|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|25|43
More Than Words? The Effect of Line Character Sticker Use on Intimacy in the Mobile Communication Environment|2016|This study investigated how messaging app Line's character sticker use may contribute to the perception of intimate experience and enhance relationship satisfaction in both positive and negative emotion situations. A 2 (situation valence: positive emotion and negative emotion) x 3 (response style: text, sticker, and text and sticker) x 3 (scenario: career, romance, and education) mixed design, with situation valence and response style between-subjects variables and scenario a within-subjects variable, was employed. The results revealed the combination of a text and sticker response to a partner's disclosure can produce the highest level of intimate experience, followed by text- and sticker-only responses. It further suggests that the cartoon-like Line sticker may better convey positive than negative emotions because the detailed illustration is more similar to real-life nonverbal behavior expressing humor and happiness and that may facilitate imagined closeness between communication partners when moving through space. The hyperpersonal affordance of text-based messages to foster relationship may be further distinguished between the cognitive and the affective levels in the messaging app context.|smartphone; application (app); emoticon; intimacy; self-disclosure; hyperpersonal|COMPUTER-MEDIATED COMMUNICATION; CONFIRMATORY FACTOR-ANALYSIS; SELF-DISCLOSURE; CLOSE RELATIONSHIPS; EMOTIONAL SUPPORT; ATTACHMENT-STYLE; SAME-SEX; EMOTICONS; SATISFACTION; FRIENDSHIP|Computer Science, Interdisciplinary Applications; Information Science \& Library Science; Social Sciences, Interdisciplinary|0|6|43
Context sensitive article ranking with citation context analysis|2016|It is hard to detect important articles in a specific context. Information retrieval techniques based on full text search can be inaccurate to identify main topics and they are not able to provide an indication about the importance of the article. Generating a citation network is a good way to find most popular articles but this approach is not context aware. The text around a citation mark is generally a good summary of the referred article. So citation context analysis presents an opportunity to use the wisdom of crowd for detecting important articles in a context sensitive way. In this work, we analyze citation contexts to rank articles properly for a given topic. The model proposed uses citation contexts in order to create a directed and edge-labeled citation network based on the target topic. Then we apply common ranking algorithms in order to find important articles in this newly created network. We showed that this method successfully detects a good subset of most prominent articles in a given topic. The biggest contribution of this approach is that we are able to identify important articles for a given search term even though these articles do not contain this search term. This technique can be used in other linked documents including web pages, legal documents, and patents as well as scientific papers.|Citation context; Citation network; Document retrieval; Ranking; Searching; Information retrieval|COCITATION; NETWORKS; SEARCH|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|6|43
Characterization, description, and considerations for the use of funding acknowledgement data in Web of Science|2016|Funding acknowledgements found in scientific publications have been used to study the impact of funding on research since the 1970s. However, no broad scale indexation of that paratextual element was done until 2008, when Thomson Reuters' Web of Science started to add funding acknowledgement information to its bibliographic records. As this new information provides a new dimension to bibliometric data that can be systematically exploited, it is important to understand the characteristics of these data and the underlying implications for their use. This paper analyses the presence and distribution of funding acknowledgement data covered in Web of Science. Our results show that prior to 2009 funding acknowledgements coverage is extremely low and therefore not reliable. Since 2008, funding information has been collected mainly for publications indexed in the Science Citation Index Expanded; more recently (2015), inclusion of funding texts for publications indexed in the Social Science Citation Index has been implemented. Arts \& Humanities Citation Index content is not indexed for funding acknowledgement data. Moreover, English-language publications are the most reliably covered. Finally, not all types of documents are equally covered for funding information indexation and only articles and reviews show consistent coverage. The characterization of the funding acknowledgement information collected by Thomson Reuters can therefore help understand the possibilities offered by the data but also their limitations.|Funding acknowledgements; Web of Science; Bibliometrics|SCIENTIFIC PUBLICATIONS; INFORMATION-SCIENCE; CANCER-RESEARCH|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|13|11|43
Understanding EFL students' participation in group peer feedback of L2 writing: A case study from an activity theory perspective|2015|While the last three decades have witnessed a growing body of research on peer feedback in first language (L1) and second language (L2) writing, research about students' motives for participating in group peer feedback has remained underexplored. In order to fill this important gap, this case study, guided by the constructs of activity and motive in activity theory, investigates two Chinese university students' motives for participating in group peer feedback activities in the EFL (English as a foreign language) writing classroom. Multiple sources of data were collected, including video recordings of peer feedback sessions, semi-structured interviews, stimulated recalls and student texts. Data analyses indicate that EFL students' group peer feedback activities are driven and defined by their motives, which are shaped and mediated by the sociocultural context. The findings also show that student motives could have direct influence on students' participation in group peer feedback activities and their subsequent revisions. This study contributes new knowledge to the field by relating students' motives to other key elements in peer feedback such as peer stances, group interaction and student revisions of L2 writing, yielding a deepened understanding of students' participation in and engagement with peer feedback in EFL writing.|Activity theory; EFL writing; group work; motives; peer feedback|PAIR WORK; PATTERNS; QUALITY; STANCES; WRITERS|Education \& Educational Research; Linguistics|12|3|43
Understanding the Development and Diffusion of Mobile Commerce Technologies in China: A Biographical Study with an Actor-Network Theory Perspective|2015|Mobile commerce technologies cater to multiple types of users who use them for various purposes in a dynamic fashion over time. Their development and diffusion therefore involves many actors who participate in changing market configurations. In this study we address this complex sociotechnical setting by investigating the biography of mobile text messaging, an instance of mobile commerce technologies, in China. Specifically, we apply an actor-network perspective to understand the development and diffusion of text messaging over time and the changing actor configurations. This analysis was based on 1,403 news items pertaining to the Chinese telecommunications market, which were screened from over 40,000 news items produced over sixteen years. The deduced pattern indicates that the diffusion of text messaging, and possibly other mobile commerce technologies, includes four actor network configurations. Mobile commerce platforms begin to operate within a small network of actors, and via a dynamic process of events and interactions, they end up with a complex network of actors, which can include content and service providers, customers, regulators, and businesses that drive mobile commerce technology diffusion and breadth of uses across markets. The suggested pattern provides a biography of artifacts regarding mobile technologies at the national level.|Actor-network theory; mobile commerce platforms; mobile services development and diffusion processes; short messaging services|INFORMATION TECHNOLOGY; USER ACCEPTANCE; SERVICES; OPPORTUNITIES; ADDICTION; INDUSTRY; MEDIA|Business; Computer Science, Software Engineering|6|2|43
Exploring the bibliometric and semantic nature of negative results|2013|Negative results are not popular to disseminate. However, their publication would help to save resources and foster scientific communication. This study analysed the bibliometric and semantic nature of negative results publications. The Journal of Negative Results in Biomedicine (JNRBM) was used as a role model. Its complete articles from 2002-2009 were extracted from SCOPUS and supplemented by related records. Complementary negative results records were retrieved from Web of Science in ``Biochemistry{''} and ``Telecommunications{''}. Applied bibliometrics comprised of co-author and co-affiliation analysis and a citation impact profile. Bibliometrics showed that authorship is widely spread. A specific community for the publication of negative results in devoted literature is non-existent. Neither co-author nor co-affiliation analysis indicated strong interconnectivities. JNRBM articles are cited by a broad spectrum of journals rather than by specific titles. Devoted negative results journals like JNRBM have a rather low impact measured by the number of received citations. On the other hand, only one-third of the publications remain uncited, corroborating their importance for the scientific community. The semantic analysis relies on negative expressions manually identified in JNRBM article titles and abstracts and extracted to syntactic patterns. By using a Natural Language Processing tool these patterns are then employed to detect their occurrences in the multidisciplinary bibliographical database PASCAL. The translation of manually identified negation patterns to syntactic patterns and their application to multidisciplinary bibliographic databases (PASCAL, Web of Science) proved to be a successful method to retrieve even hidden negative results. There is proof that negative results are not only restricted to the biomedical domain. Interestingly a high percentage of the so far identified negative results papers were funded and therefore needed to be published. Thus policies that explicitly encourage or even mandate the publication of negative results could probably bring about a shift in the current scientific communication behaviour.|Bibliometrics; Scientometrics; Negative result publication; S\&T information; Semantic analysis; Publication bias|PUBLICATION BIAS; METAANALYSIS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|5|1|43
Fleeing, Sneaking, Flooding A Corpus Analysis of Discursive Constructions of Refugees and Asylum Seekers in the UK Press, 1996-2005|2008|This paper examines the discursive construction of refugees and asylum seekers (and to a lesser extent immigrants and migrants) in a 140-million-word corpus of UK press articles published between 1996 and 2005. Taking a corpus-based approach, the data were analyzed not only as a whole, but also with regard to synchronic variation, by carrying out concordance analyses of keywords which occurred within tabloid and broadsheet newspapers, and diachronic change, albeit mainly approached from an unusual angle, by investigating consistent collocates and frequencies of specific terms over time. The analyses point to a number of (mainly negative) categories of representation, the existence and development of nonsensical terms (e.g., illegal refugee), and media confusion and conflation of definitions of the four terms under examination. The paper concludes by critically discussing the extent to which a corpus-based methodological stance can inform critical discourse analysis.(1)|asylum; collocates; corpus; discourse; keywords; newspapers; refugees|DISCOURSE; TEXT|Linguistics; Language \& Linguistics|107|2|43
Using hybrid methods and `core documents' for the representation of clusters and topics: the astronomy dataset|2017|Based on a dataset on Astronomy and Astrophysics, hybrid cluster analyses have been conducted. In order to obtain an optimum solution and to analyse possible issues resulting from the bibliometric methodologies used, we have systematically studied three models and, within these models, two scenarios each. The hybrid clustering was based on a combination of bibliographic coupling and textual similarities using the Louvain method at two resolution levels. The procedure resulted in three clearly hierarchical structures with six and thirteen, seven and thirteen and finally five and eleven clusters, respectively. These structures are analysed with the help of a concordance table. The statistics reflect a high quality of classification. The results of these three models are presented, discussed and compared with each other. For labelling and interpreting clusters, core documents representing the obtained clusters are used. Furthermore, these core documents help depict the internal structure of the complete network and the clusters. This work has been done as part of the international project `Measuring the Diversity of Research' and in the framework a special workshop on the comparative analysis of algorithms for the identification of topics in science organised in Berlin in August 2014.|Astronomy; Astrophysics; Clustering; NLP; Bibliographic coupling; Hybrid clustering; Core documents|COCITATION ANALYSIS; INFORMATION; SCIENCE; NETWORK; TOOL|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|6|27|42
Multi-view clustering with exemplars for scientific mapping|2015|Scientific mapping has now become an important subject in the scientometrics field. Journal clustering can provide insights into both the internal relations among journals and the evolution trend of studies. In this paper, we apply the affinity propagation (AP) algorithm to do scientific journal clustering. The AP algorithm identifies clusters by detecting their representative points through message passing within the data points. Compared with other clustering algorithms, it can provide representatives for each cluster and does not need to pre-specify the number of clusters. Because the input of the AP algorithm is the similarity matrix among data points, it can be applied to various forms of data sets with different similarity metrics. In this paper, we extract the similarity matrices from the journal data sets in both cross citation view and text view and use the AP algorithm to cluster the journals. Through empirical analysis, we conclude that these two clustering results by the two single views are highly complementary. Therefore, we further combine text information with cross citation information by using the simple average scheme and apply the AP algorithm to conduct multi-view clustering. The multi-view clustering strategy aims at obtaining refined clusters by integrating information from multiple views. With text view and citation view integrated, experiments on the Web of Science journal data set verify that the AP algorithm obtains better clustering results as expected.|Scientific mapping; Affinity propagation; Text mining; Link analysis; Multi-view clustering|TEXT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|2|10|42
Analyzing technological convergence trends in a business ecosystem|2015|Purpose - The purpose of this paper is to provide a framework for understanding core technological competencies and identifying the trends on the technological convergence of a business ecosystem using the patent information of leading firms in the system. Design/methodology/approach - The proposed framework is composed of two steps: time-sequential text clustering analysis for comprehending changes in general technological fields and association rule analysis for identifying the trends of convergences in each field. The authors applied the proposed framework to the patents applied to United States Patent Trademark Office by Samsung Electronics, a market leader of the electronics industry, during the period from 2000 to 2011. Findings - In the sequential text clustering analysis, trends of 14 technological fields such as data storage medium and data processing, mobile, lights and heats and memory are identified. Moreover, changes of technological convergence in each field are identified using association rule analysis. For instance, in the case of technologies related to lights and heats, convergences occurred between radio transmission systems and modulated-carrier systems during the period from 2000 to 2001. However, recent convergences appeared between technologies regarding controlling lights and liquid crystal materials since 2008. Originality/value - Utilization of the framework will suggest new business opportunities to SMEs in a business ecosystem by identifying the trends of technological convergences.|Business ecosystem; Technological convergence trend|PATENT CITATION ANALYSIS; AUTOMOTIVE WARRANTY DATA; ALGORITHM; INDUSTRY; INNOVATION; SYSTEM|Computer Science, Interdisciplinary Applications; Engineering, Industrial|4|2|42
Completing keyword patent search with semantic patent search: introducing a semiautomatic iterative method for patent near search based on semantic similarities|2015|Patent search is a substantial basis for many operational questions and scientometric evaluations. We consider it as a sequence of distinct stages. The ``patent wide search{''} involves a definition of system boundaries by means of classifications and a keyword search producing a patent set with a high recall level (see Schmitz in Patentinformetrie: Analyse und Verdichtung von technischen Schutzrechtsinformationen, DGI, Frankfurt (Main), 2010 with an overview of searchable patent meta data). In this set of patents a ``patent near search{''} takes place, producing a patent set with high(er) precision. Hence, the question arises how the researcher has to operate within this patent set to efficiently identify patents that contain paraphrased descriptions of the sought inventive elements in contextual information and whether this produces different results compared to a conventional search. We present a semiautomatic iterative method for the identification of such patents, based on semantic similarity. In order to test our method we generate an initial dataset in the course of a patent wide search. This dataset is then analyzed by means of the semiautomatic iterative method as well as by an alternative method emulating the conventional process of keyword refinement. It thus becomes obvious that both methods have their particular ``raison d'tre{''}, and that the semiautomatic iterative method seems to be able to support a conventional patent search very effectively.|Patent search; Keyword search; Semantic search; Text mining; Similarity measurement; n-grams|CITATION ANALYSIS; TECHNOLOGY; NETWORKS; TRENDS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|7|5|42
Do second-order similarities provide added-value in a hybrid approach?|2013|Recent studies on first- and second-order similarities have shown that the latter one outperforms the first one as input for document clustering or partitioning applications. First-order similarities based on bibliographic coupling or on lexical approaches come with specific methodological issues like sparse matrices, sensitive to spelling variances or context differences. Second-order similarities were proposed to tackle these problems and take the lexical context into account. But also a hybrid combination of both types of similarities proved an important improvement which integrates the strengths of the two approaches and diminishes their weaknesses. In this paper we extend the notion of second-order similarity by applying it in the context of the hybrid approach. We conclude that there is no added value for the clearly defined clusters but that the second-order similarity can provide an additional viewpoint for the more general clusters.|Bibliographic coupling; Text mining; Hybrid clustering; Similarity measures; Public health|COMBINED COCITATION; CORE DOCUMENTS; WORD ANALYSIS; SCIENCE; CITATION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|10|0|42
Investigating the reading-to-write processes and source use of L2 postgraduate students in real-life academic tasks: An exploratory study|2013|Existing studies of source use in academic student writing tend to i), focus more on the writing than the reading end of the reading-to-write continuum and ii), involve the use of insufficiently `naturalistic' writing tasks. Thus, in order to explore the potential of an alternative approach, this paper describes an exploratory case study concerning the ways source material was used by two L2 MA students while involved in a real-life reading-to-write task. Think-aloud sessions were conducted with students at a UK university as they read to write during the dissertation component of their programme. Analysis of the resulting protocols revealed that they engaged with their source material in qualitatively different ways, in both the frequency and range of their reading-to-write behaviours. Specifically, the students differed in the ways they responded to their sources as they read, the ways they elaborated on what they read and drew inferences, and the extent to which they showed intertextual awareness. The findings suggest that, for these writers, the process of ``using{''} source material begins early in the reading-to-write process and involves more complex interactions with sources than may be suggested by the use of `one-shot' reading-to-write tasks of the type used in much reading-to-write research. (C) 2012 Elsevier Ltd. All rights reserved.|Academic writing; Reading-to-write; Academic reading; Source use; Naturalistic task; Think-aloud procedure|ESL STUDENTS; 2ND-LANGUAGE; REACTIVITY; DISCOURSE; TEXTS; SLA|Education \& Educational Research; Linguistics; Language \& Linguistics|15|2|42
An analysis of property-function based patent networks for strategic R\&D planning in fast-moving industries: The case of silicon-based thin film solar cells|2012|Patents are an up-to-date and reliable knowledge source of innovative technologies, and therefore patent analysis has been a vital tool for understanding technological trends and formulating technology strategies. One method of patent analysis is citation-based patent analysis. However, one criticism of the citation-based approach is that it may underestimate new patents because they tend to be less cited. This problem gets worse in fast-moving industries where technology life-cycles shorten and innovative technologies are actively patented. As a remedy, this paper proposes a property-function based patent network using an analysis of patent contents. Properties and functions as the innovation concepts of a system can be extracted using grammatical analysis of patent text. First, this paper represents each patent into a matrix codifying properties, functions and their co-occurrences, and then it constructs a patent network by measuring patent similarities. As a result, the proposed network reveals the internal relationships among patents in a given patent set that many new patents. Furthermore, using several analysis indices, this paper suggests a way to identify technological implications from the network such as the technological importance of new patents, the technological capability of applicants with new patents and the pace of technological progress of new patents. The proposed method is illustrated using silicon-based thin film solar cells. We expect that the proposed method can be incorporated into R\&D planning processes to assist researchers and R\&D policy makers to identify technological implications related to new patents in fast-moving industries. (C) 2012 Elsevier Ltd. All rights reserved.|Property; Function; Patent network; Fast-moving industry; Patent mining|TECHNOLOGICAL-PROGRESS; CITATION NETWORK; INDICATORS|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|18|4|42
Development of a GTM-based patent map for identifying patent vacuums|2012|The patent map has long been considered as a useful tool for mining latent technological information. Among others, the detection of patent vacuums, defined as unexplored areas of new technologies, deserves intensive research. However, previous studies for identifying patent vacuums on the patent map have been subjected to some limitations, stemming from the subjective and manual identification of patent vacuums. To address these limitations, this paper proposes a generative topographic mapping (GTM)-based patent map, which aims to automatically identify a patent vacuum. Since GTM is a probabilistic approach of mapping multidimensional data space onto a low-dimensional latent space and vice versa, it contributes to the automatic detection and interpretation of patent vacuums. The proposed approach consists of three stages. Firstly, text mining is executed in order to transform patent documents into keyword vectors as structured data. Secondly, the GTM is employed to develop the patent map, subsequently leading to the discovery of patent vacuums, which are expressed as blank areas in the map. Lastly, the meaning of each patent vacuum is interpreted by the inverse mapping of patent vacuums onto the original keyword vector. The case study is conducted with lithography technology-related patents. We believe the proposed approach not only saves time and effort for identifying patent vacuums, but also increases objectivity and reliability. (C) 2011 Elsevier Ltd. All rights reserved.|GTM; Patent map; Patent vacuum; Keyword vector|MORPHOLOGY ANALYSIS; TECHNOLOGY; VISUALIZATION; LITHOGRAPHY; INDICATORS; CITATIONS; SCIENCE|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|17|1|42
Gender and genre variation in weblogs|2006|A relationship among language, gender, and discourse genre has previously been observed in informal, spoken interaction and formal, written texts. This study investigates the language/gender/genre relationship in weblogs, a popular new mode of computer-mediated communication (CMC). Taking as the dependent variables stylistic features identified in machine learning research and popularized in a Web interface called the Gender Genie, a multivariate analysis was conducted of entries from random weblogs in a sample balanced for author gender and weblog sub-genre (diary or filter). The results show that the diary entries contained more `female' stylistic features, and the filter entries more `male' stylistic features, independent of author gender. These findings problematize the characterization of the stylistic features as gendered, and suggest a need for more fine-grained genre analysis in CMC research. At the same time, it is observed that conventional associations of gender with certain spoken and written genres are reproduced in weblogs, along with their societal valuations.|CMC; gender; genre; style; text classification; variation; weblog|LANGUAGE|Linguistics|100|2|42
Detecting and predicting the topic change of Knowledge-based Systems: A topic-based bibliometric analysis from 1991 to 2016|2017|The journal Knowledge-based Systems (KnoSys) has been published for over 25 years, during which time its main foci have been extended to a broad range of studies in computer science and artificial intelligence. Answering the questions: ``What is the KnoSys community interested in?{''} and ``How does such interest change over time?{''} are important to both the editorial board and audience of KnoSys. This paper conducts a topic-based bibliometric study to detect and predict the topic changes of KnoSys from 1991 to 2016. A Latent Dirichlet Allocation model is used to profile the hotspots of KnoSys and predict possible future trends from a probabilistic perspective. A model of scientific evolutionary pathways applies a learning-based process to detect the topic changes of KnoSys in sequential time slices. Six main research areas of KnoSys are identified, i.e., expert systems, machine learning, data mining, decision making, optimization, and fuzzy, and the results also indicate that the interest of KnoSys communities in the area of computational intelligence is raised, and the ability to construct practical systems through knowledge use and accurate prediction models is highly emphasized. Such empirical insights can be used as a guide for KnoSys submissions. (C) 2017 Elsevier B.V. All rights reserved.|Topic analysis; Topic detection and tracking; Bibliometrics; Text mining; Knowledge-based Systems|GROUP DECISION-MAKING; ARTIFICIAL NEURAL-NETWORKS; FLY OPTIMIZATION ALGORITHM; SCIENCE-AND-TECHNOLOGY; PREFERENCE RELATIONS; RECOMMENDER SYSTEMS; MODEL; INTELLIGENCE; CLASSIFICATION; COCITATION|Computer Science, Artificial Intelligence|0|41|41
Ranking product aspects through sentiment analysis of online reviews|2017|The electronic word-of-mouth (e-WOM) is one of the most important among all the factors affecting consumers' behaviours. Opinions towards a product through online reviews will influence purchase decisions of other online consumers by changing their perceptions on the product quality. Furthermore, each product aspect may impact consumers' intentions differently. Thus, sentiment analysis and econometric models are incorporated to examine the relationship between purchase intentions and aspect-opinion pairs, which enable the weight estimation for each product aspect. We first identify product aspects and reduce dimensions to extract aspect-opinion pairs. Next the information gain is calculated for each aspect through entropy theory. Based on sentiment polarity and sentiment strength, we formulate an econometric model by integrating the information gain to measure the aspect's weight. In the experiment, we track 386 digital cameras on Amazon for 39 months, and results show that the aspect weight for digital cameras is detected more precisely than TF-ID and HAC algorithms. The results will bridge product aspects and consumption intention to facilitate e-WOM-based marketing.|Aspect ranking; aspect weight; online reviews; aspect-opinion pairs; opinion mining; sentiment analysis|WORD-OF-MOUTH; STRENGTH DETECTION; CLASSIFICATION; SALES; MODEL; TEXT; WEB|Computer Science, Artificial Intelligence|1|8|41
Concept generalization and fusion for abstractive sentence generation|2016|Text summarization is either extractive or abstractive. Extractive summarization is to select the most salient pieces of information (words, phrases, and/or sentences) from a source document without adding any external information. Abstractive summarization allows an internal representation of the source document so as to produce a faithful summary of the source. In this case, external text can be inserted into the generated summary. Because of the complexity of the abstractive approach, the vast majority of work in text summarization has adopted an extractive approach. In this work, we focus on concepts fusion and generalization, i.e. where different concepts appearing in a sentence can be replaced by one concept which covers the meanings of all of them. This is one operation that can be used as part of an abstractive text summarization system. The main goal of this contribution is to enrich the research efforts on abstractive text summarization with a novel approach that allows the generalization of sentences using semantic resources. This work should be useful in intelligent systems more generally since it introduces a means to shorten sentences by producing more general (hence abstractions of the) sentences. It could be used, for instance, to display shorter texts in applications for mobile devices. It should also improve the quality of the generated text summaries by mentioning key (general) concepts. One can think of using the approach in reasoning systems where different concepts appearing in the same context are related to one another with the aim of finding a more general representation of the concepts. This could be in the context of Goal Formulation, expert systems, scenario recognition, and cognitive reasoning more generally. We present our methodology for the generalization and fusion of concepts that appear in sentences. This is achieved through (1) the detection and extraction of what we define as generalizable sentences and (2) the generation and reduction of the space of generalization versions. We introduce two approaches we have designed to select the best sentences from the space of generalization versions. Using four NLTK1 corpora, the first approach estimates the ``acceptability{''} of a given generalization version. The second approach is Machine Learning-based and uses contextual and specific features. The recall, precision and Fl-score measures resulting from the evaluation of the concept generalization and fusion approach are presented. (C) 2016 Elsevier Ltd. All rights reserved.|Artificial intelligence; Natural language processing; Text summarization; Concept fusion; Concept generalization; WordNet|COMPRESSION|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|0|2|41
Website analysis in an EFL context: content comprehension, perceptions on web usability and awareness of reading strategies|2015|Website analysis is an interdisciplinary field of inquiry that focuses on both digital literacy and language competence (Brugger, 2009). Website analysis in an EFL learning context has the potential to facilitate logical thinking and in the process develop functional language proficiency. This study reported on an English language website (http://www.travelbelize.org/) analysis experiment carried out for three weeks as an in-class and homework activity in a third year (junior) level English as a Foreign Language (EFL) course at a Japanese technical university. The purpose was to explore EFL learners' ability to analyze an English language website and produce concrete design responses in English. During the first week of the analysis (involving sixteen students selected due to performing the best during earlier in-class website analysis activities on the course), participants produced their own responses to eight open-ended design questions about the website. The second week of the analysis (involving all 59 students on the course) tested the students' ability to search for information from the website, and recorded their impressions about the website design based on standard usability questionnaires (CSUQ, QUIS, and MPRC). The third week of the analysis had the 59 students self-report on their use of meta-cognitive reading strategies (MARSI 1.0 Questionnaire) during the website analysis. The results of the questionnaires showed that, overall, the EFL students had a basic understanding of major design questions related to information organization, screen interface design, audience, technology used, etc. However, there was statistically significant variability between responses in different groups (comprehensive evaluation, webpage design, terminology and website information and website capabilities) and the respondents were not unanimous in their impressions about the website. The result of the student self-reports on metacognitive reading strategies showed wide acceptability and use of problem-solving strategies.|Website analysis; design; EFL; computer-assisted language learning (CALL)|HEADINGS; KNOWLEDGE; TEXT|Education \& Educational Research; Linguistics; Language \& Linguistics|1|6|41
Exploring L2 writers' collaborative revision interactions and their writing performance|2014|Over the last few decades, researchers and practitioners have acknowledged the social aspects of language learning. This study drew on Vygotsky's sociocultural learning theory to investigate EFL students' interactional dynamics during a collaborative revision activity. It also examined the impact of this jointly performed task on participants' writing performance. Participants included five pairs of EFL learners enrolled in an L2 essay-writing course at an Iranian university. Each pair attended one collaborative revision session during which they jointly revised their argumentative texts utilizing the feedback provided by their instructor. The researchers collected the participants' interactions during collaborative revision and their revised drafts. Data analysis revealed that students employed a variety of functions in their negotiations including scaffolding. It was also observed that scaffolding was mutual and both partners benefited from the joint revision task regardless of their level of L2 writing proficiency. These findings suggest that collaborative revision can be incorporated in EFL writing pedagogy as a method to improve writing and revision skills. (C) 2014 Elsevier Ltd. All rights reserved.|Collaborative revision; Scaffolding; L2 writing; Writing performance|PEER REVISION; ESL STUDENTS; FEEDBACK|Education \& Educational Research; Linguistics|8|4|41
Quantitative cross impact analysis with latent semantic indexing|2014|Cross impact analysis (CIA) consists of a set of related methodologies that predict the occurrence probability of a specific event and that also predict the conditional probability of a first event given a second event. The conditional probability can be interpreted as the impact of the second event on the first. Most of the CIA methodologies are qualitative that means the occurrence and conditional probabilities are calculated based on estimations of human experts. In recent years, an increased number of quantitative methodologies can be seen that use a large number of data from databases and the internet. Nearly 80\% of all data available in the internet are textual information and thus, knowledge structure based approaches on textual information for calculating the conditional probabilities are proposed in literature. In contrast to related methodologies, this work proposes a new quantitative CIA methodology to predict the conditional probability based on the semantic structure of given textual information. Latent semantic indexing is used to identify the hidden semantic patterns standing behind an event and to calculate the impact of the patterns on other semantic textual patterns representing a different event. This enables to calculate the conditional probabilities semantically. A case study shows that this semantic approach can be used to predict the conditional probability of a technology on a different technology. (C) 2013 Elsevier Ltd. All rights reserved.|Cross impact analysis; Latent semantic indexing; Text mining; Conditional probability|NONNEGATIVE MATRIX FACTORIZATION; TECHNOLOGY; TEXT; PROFITABILITY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|5|0|41
Document-document similarity approaches and science mapping: Experimental comparison of five approaches|2009|This paper treats document-document similarity approaches in the context of science mapping. Five approaches, involving nine methods, are compared experimentally. We compare text-based approaches, the citation-based bibliographic coupling approach, and approaches that combine text-based approaches and bibliographic coupling. Forty-three articles, published in the journal Information Retrieval, are used as test documents. We investigate how well the approaches agree with a ground truth subject classification of the test documents, when the complete linkage method is used, and under two types of similarities, first-order and second-order. The results show that it is possible to achieve a very good approximation of the classification by means of automatic grouping of articles. One text-only method and one combination method, under second-order similarities in both cases, give rise to cluster solutions that to a large extent agree with the classification. (C) 2008 Elsevier Ltd. All rights reserved.|Citation data; Textual data; Data source combination; Cluster analysis; Science mapping|INFORMATION; TESTS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|36|2|41
Mining Blogs And Forums To Understand the Use of Social Media in Customer Co-creation|2015|Social media have been used by some companies to support customer co-creation in recent years. However, few academic studies have been done to investigate the use of social media in customer co-creation. To understand the current state-of-the-art and future trends about the use of social media in customer co-creation, we conducted two studies to analyze relevant posts on blogs and social media-based online forums. This study reveals some interesting patterns, themes and future trends in this specific area. Recommendations are given to help managers engage in co-creation activities with customers.|social media; customer co-creation; text mining; blog mining; online forums; user-generated content; case study|BUSINESS INTELLIGENCE; ENTERPRISE SYSTEMS; WEB 2.0; ALGORITHM; COMMUNITIES; PERSPECTIVE; EXPERIENCE; MANAGEMENT; INNOVATION; SEARCH|Computer Science, Hardware \& Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods|3|0|40
Disciplinary and ethnolinguistic influences on citation in research articles|2014|Citation, as an integral part of academic discourse and a signature feature of scholarly publication, has attracted much research attention. Previous research, however, has focused on several aspects of citation practices in a largely discrete fashion and addressed disciplinary and ethnolinguistic influences on citation in isolation from each other. This article reports on a study designed to investigate cross-disciplinary and cross-linguistic variations of multiple citation features from the unifying perspective of Bakhtinian dialogism. The dataset consisted of 84 research articles sampled from 12 leading Chinese- and English-medium journals of applied linguistics and general medicine. All the citations in the corpus were identified and examined in an integrative analytic framework that characterized multiple aspects of citations in terms of dialogic contraction (i.e., closing down the space for alternative views) or dialogic expansion (i.e., opening up the space for alternative voices). Quantitative and textual analyses revealed marked cross-disciplinary and cross-linguistic differences in the level and type of citation-based dialogic engagement. These differences are interpreted in reference to the nature of cited information, epistemologies underlying cultural and disciplinary practices, ethnolinguistic norms of communication, and culturally valued interpersonal relationships. Pedagogical implications derived from these findings are discussed. (C) 2013 Elsevier Ltd. All rights reserved.|Academic writing; Citation; Writer stance; Author/textual integration; Disciplinary influences; Ethnolinguistic influences|DISCOURSE ANALYSIS; REPORTING CLAUSES; SOFT PSYCHOLOGY; CONSTRUCTION; KNOWLEDGE; ENGLISH; THESES; TEXTS|Education \& Educational Research; Linguistics; Language \& Linguistics|10|2|40
Differential importance of language components in determining secondary school students' Chinese reading literacy performance|2013|The present study examined pedagogic components of Chinese reading literacy in a representative sample of 1164 Grades 7, 9 and 11 Chinese students (mean age of 15 years) from 11 secondary schools in Hong Kong with each student tested for about 2.5 hours. Multiple group confirmatory factor analyses showed that across the three grade levels, the eight reading literacy constructs (Essay Writing, Morphological Compounding, Correction of Characters and Words, Segmentation of Text, Text Comprehension, Copying of Characters and Words, Writing to Dictation and Reading Aloud), each subserved by multiple indicators, had differential concurrent prediction of scaled internal school performance in reading and composing. Writing-reading and their interactive effects were foremost in their predictive power, followed by performance in error correction and writing to dictation, morphological compounding, segmenting text and copying with reading aloud playing a negligible role. Our battery of tasks with some refinement could serve as a screening instrument for secondary Chinese students struggling with Chinese reading literacy.|Chinese reading literacy components; multigroup confirmatory factor analyses|MORPHOLOGICAL AWARENESS; DEVELOPMENTAL DYSLEXIA; PHONOLOGICAL AWARENESS; TEXT COMPREHENSION; CHILDREN; ACQUISITION; VOCABULARY; PROSODY; MEMORY; ERRORS|Linguistics; Language \& Linguistics|2|0|40
Individual novices and collective experts: Collective scaffolding in wild-based small group writing|2013|This article reports on a case study that explored the process of wild-based collaborative writing in a small group of English as a Foreign Language (EFL) students at a Chinese university. The study examined the archived logs from the group wild `Discussion' and `History' modules with a focus on the group members' scaffolded interaction when co-constructing texts in the wild space. The analysis revealed that the participants were actively engaged in reciprocal communication in terms of content discussion, social talk, task management, technical communication and language negotiation. They were also found to have scaffolded each other's writing efforts during co-constructing the product via multiple writing change functions, including addition, deletion, rephrasing, reordering and correction. This study explicated a distinct case of `collective scaffolding' (Donato, 1994) in collaborative writing activities, where group members were simultaneously individual novices and collective experts as they pooled their knowledge and mutually guided each other through problem solving as to writing tasks. This study has important implications for instruction and future research on computer-mediated collaborative writing. (C) 2013 Elsevier Ltd. All rights reserved.|Wiki; Second language writing; Collaborative writing; Writing process; Collaboration; Interaction; Collective scaffolding|L2 CLASSROOM; STUDENTS; WIKI; LANGUAGE; PATTERNS; LEARNERS; COLLABORATION; REFLECTIONS; ATTENTION; PROJECTS|Education \& Educational Research; Linguistics|8|4|40
A cost-effective strategy for multi-scale photo-realistic building modeling and web-based 3-D GIS applications in real estate|2013|Web-based 3-D GIS may be the most appropriate tool for decision makers in land management and development. It provides not only the basic GIS functions, but also visually realistic landscape and architectural detail. It also gives the user an immersive 3-D virtual reality environment through the Internet that is rather different from that obtained merely through text, pictures, or videos. However, in terms of high accuracy and level-of-detail (LOD), the generation of a fully photo-realistic city model is labor intensive and time consuming. At the same time, from the aspect of computer graphics, the result is simply a geometric model without thematic information. Thus, the objective of this study is to propose a cost-effective multi-scale building modeling strategy based on the 2-D GIS building footprint that has rich attributes and to realize its application in the real estate market through a web-based 3-D GIS platform. Generally, the data volume needed for a photo-realistic city model is huge, thus for the purpose of increasing Internet data streaming efficiency and reducing the building modeling cost, a multiple-scale building modeling strategy, including block modeling, generic texture modeling, photo-realistic economic modeling, and photo-realistic detailed modeling is proposed. Since 2-D building boundary polygons are popularly used and well attributed, e.g., as to number of stories, address, type, material, etc., we are able to construct the photo-realistic city model based on this. Meanwhile, the conventional 2-D spatial analysis can be maintained and extended to 3-D GIS in the proposed scheme. For real estate applications, a location query system for selecting the optimum living environment is established. Some geospatial query and analysis functionalities are realized, such as address and road-junction positioning and terrain profile analysis. An experimental study area of 11 km(2) in size is used to demonstrate that the proposed multi-scale building modeling strategy and its integration into a web-based 3-D GIS platform is both efficient and cost-effective. (C )2012 Elsevier Ltd. All rights reserved.|Web-based 3-D GIS; Multi-scale building modeling; Land management|TRUE ORTHOPHOTO GENERATION; URBAN GIS; VISUALIZATION; RECONSTRUCTION; IMAGES; CITY|Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research \& Management Science|6|1|40
Selecting Attributes for Sentiment Classification Using Feature Relation Networks|2011|A major concern when incorporating large sets of diverse n-gram features for sentiment classification is the presence of noisy, irrelevant, and redundant attributes. These concerns can often make it difficult to harness the augmented discriminatory potential of extended feature sets. We propose a rule-based multivariate text feature selection method called Feature Relation Network (FRN) that considers semantic information and also leverages the syntactic relationships between n-gram features. FRN is intended to efficiently enable the inclusion of extended sets of heterogeneous n-gram features for enhanced sentiment classification. Experiments were conducted on three online review testbeds in comparison with methods used in prior sentiment classification research. FRN outperformed the comparison univariate, multivariate, and hybrid feature selection methods; it was able to select attributes resulting in significantly better classification accuracy irrespective of the feature subset sizes. Furthermore, by incorporating syntactic information about n-gram relations, FRN is able to select features in a more computationally efficient manner than many multivariate and hybrid techniques.|Natural language processing; machine learning; text mining; subspace selection; affective computing|TEXT ANALYSIS; COMMUNICATION; ALGORITHMS; SYSTEM; WEB|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|48|0|40
On the map: Nature and Science editorials|2011|Bibliometric mapping of scientific articles based on keywords and technical terms in abstracts is now frequently used to chart scientific fields. In contrast, no significant mapping has been applied to the full texts of non-specialist documents. Editorials in Nature and Science are such non-specialist documents, reflecting the views of the two most read scientific journals on science, technology and policy issues. We use the VOSviewer mapping software to chart the topics of these editorials. A term map and a document map are constructed and clusters are distinguished in both of them. The validity of the document clustering is verified by a manual analysis of a sample of the editorials. This analysis confirms the homogeneity of the clusters obtained by mapping and augments the latter with further detail. As a result, the analysis provides reliable information on the distribution of the editorials over topics, and on differences between the journals. The most striking difference is that Nature devotes more attention to internal science policy issues and Science more to the political influence of scientists.|Bibliometrics; Classification; Editorials; Full-text; Mapping; VOSviewer|INFORMATION-SCIENCE; COCITATION ANALYSIS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|15|2|40
Like It or Not: A Survey of Twitter Sentiment Analysis Methods|2016|Sentiment analysis in Twitter is a field that has recently attracted research interest. Twitter is one of the most popular microblog platforms on which users can publish their thoughts and opinions. Sentiment analysis in Twitter tackles the problem of analyzing the tweets in terms of the opinion they express. This survey provides an overview of the topic by investigating and briefly describing the algorithms that have been proposed for sentiment analysis in Twitter. The presented studies are categorized according to the approach they follow. In addition, we discuss fields related to sentiment analysis in Twitter including Twitter opinion retrieval, tracking sentiments over time, irony detection, emotion detection, and tweet sentiment quantification, tasks that have recently attracted increasing attention. Resources that have been used in the Twitter sentiment analysis literature are also briefly presented. The main contributions of this survey include the presentation of the proposed approaches for sentiment analysis in Twitter, their categorization according to the technique they use, and the discussion of recent research trends of the topic and its related fields.|Sentiment analysis; opinion mining; microblogs; twitter|STRENGTH DETECTION; INFORMAL TEXT; WEB|Computer Science, Theory \& Methods|5|10|39
Classifying modeling and simulation as a scientific discipline|2016|The body of knowledge related to modeling and simulation (M\&S) comes from a variety of constituents: (1) practitioners and users, (2) tool developers and (3) theorists and methodologists. Previous work has shown that categorizing M\&S as a concentration in an existing, broader disciple is inadequate because it does not provide a uniform basis for research and education across all institutions. This article presents an approach for the classification of M\&S as a scientific discipline and a framework for ensuing analysis. The novelty of the approach lies in its application of machine learning classification to documents containing unstructured text (e.g. publications, funding solicitations) from a variety of established and emerging disciplines related to modeling and simulation. We demonstrate that machine learning classification models can be trained to accurately separate M\&S from related disciplines using the abstracts of well-index research publication repositories. We evaluate the accuracy of our trained classifiers using cross-fold validation. Then, we demonstrate that our trained classifiers can effectively identify a set of previously unseen M\&S funding solicitations and grant proposals. Finally, we use our approach to uncover new funding trends in M\&S and support a uniform basis for education and research.|Simulation; Research; History of OR; Machine learning|UNIVERSITY DEPARTMENTS; BIBLIOMETRIC RESEARCH; TEXT CLASSIFICATION; PURPOSES; SCIENCE|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|6|39
News-based trading strategies|2016|The marvel of markets lies in the fact that dispersed information is instantaneously processed and used to adjust the price of goods, services and assets. Financial markets are particularly efficient when it comes to processing information; such information is typically embedded in textual news that is then interpreted by investors. Quite recently, researchers have started to automatically determine news sentiment in order to explain stock price movements. Interestingly, this so-called news sentiment works fairly well in explaining stock returns. In this paper, we design trading strategies that utilize textual news in order to obtain profits on the basis of novel information entering the market. We thus propose approaches for automated decision making based on supervised and reinforcement learning. Altogether, we demonstrate how news-based data can be incorporated into an investment system. (C) 2016 Elsevier B.V. All rights reserved.|Decision support; Financial news; Trading strategies; Text mining; Sentiment analysis; Trading simulation|FINANCIAL NEWS; DECISION-SUPPORT; STOCK-MARKET; SENTIMENT; INFORMATION; PREDICTION; SYSTEM|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|3|13|39
Hypertext glosses for foreign language reading comprehension and vocabulary acquisition: effects of assessment methods|2016|This study compared how three different gloss modes affected college students' L2 reading comprehension and vocabulary acquisition. The study also compared how results on comprehension and vocabulary acquisition may differ depending on the four assessment methods used. A between-subjects design was employed with three groups of Mandarin-speaking college freshmen. The participants read an English passage, each with different gloss formats: in-text mode, marginal gloss mode, and pop-up mode. The English proficiency level of the participants was elementary. Summary writing and multiple-choice questions were used to assess reading comprehension; word translation and word matching were used to assess vocabulary acquisition. Results of a multivariate analysis of covariance (with proficiency as the covariate) indicated that different assessment methods using the same gloss mode yielded different outcomes. In general, while the marginal gloss mode resulted in the highest scores on the multiple choice test, in-text glosses brought about the best performance in the rest of the tests, and pop-up glosses led to the lowest scores on all four tests. This study suggests that student performance outcomes concerning gloss mode may be assessment specific. Researchers should consider how investigators obtain their outcomes when interpreting the results of a study.|assessment methods; gloss modes; reading comprehension; vocabulary acquisition|MULTIMEDIA ANNOTATIONS; TEXT COMPREHENSION; COGNITIVE LOAD; L2; ENVIRONMENT; TASKS|Education \& Educational Research; Linguistics; Language \& Linguistics|2|4|39
Where are citations located in the body of scientific articles? A study of the distributions of citation locations|2013|We address issues concerning what one may learn from how citation instances are distributed in scientific articles. We visualize and analyze patterns of citation distributions in the full text of 350 articles published in the Journal of Informetrics. In particular, we visualize and analyze the distributions of citations in articles that are organized in a commonly seen four-section structure, namely, introduction, method, results, and conclusions (IMRC). We examine the locations of citations to the groundbreaking h-index paper by Hirsch in 2005 and how patterns associated with citation locations evolve over time. The results show that citations are highly concentrated in the first section of an article. The density of citations in the first section is about three times higher than that in subsequent sections. The distributions of citations to highly cited papers are even more uneven. (C) 2013 Elsevier Ltd. All rights reserved.|Distribution of citations; Citation location; Structure of scientific articles; Full text analysis|BIOMEDICAL ARTICLES; CITER MOTIVATIONS; INDEX; CLASSIFICATION; CONTEXTS; MODEL|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|14|5|39
A novel text mining approach to financial time series forecasting|2012|Financial time series forecasting has become a challenge because it is noisy, non-stationary and chaotic. Most of the existing forecasting models for this problem do not take market sentiment into consideration. To overcome this limitation, motivated by the fact that market sentiment contains some useful forecasting information, this paper uses textual information to aid the financial time series forecasting and presents a novel text mining approach via combining ARIMA and SVR (Support Vector Regression) to forecasting. The approach contains three steps: representing textual data as feature vectors, using ARIMA to analyze the linear part and developing a SVR model based only on textual feature vector to model the nonlinear part. To verify the effectiveness of the proposed approach, quarterly ROEs (Return of Equity) of six security companies are chosen as the forecasting targets. Comparing with some existing state-of-the-art models, the proposed approach gives superior results. It indicates that the proposed model that uses additional market sentiment provides a promising alternative to financial time series prediction. (C) 2011 Elsevier B.V. All rights reserved.|Financial time series forecasting; ARIMA; Support vector regression; Market sentiment|SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; HYBRID ARIMA; MODEL|Computer Science, Artificial Intelligence|23|3|39
Linking critical discourse analysis with translation studies An example from BBC News|2012|This paper argues for closer interdisciplinarity between critical discourse analysis (CDA) and translation studies (TS). There has been very little CDA investigating discursive representations by news organisations across linguistic, political and cultural boundaries. Similarly researchers in TS have pointed out that the sensitive role news translation plays in discursive phenomena such as globalisation and political discourse remains largely underestimated. To address this gap, three methodological models are proposed for linking the dialectical-relational approach to CDA (Fairclough 1992, 1995, 2003) with text-based approaches in TS. A mini-case study will illustrate such links by analysing talks by Saudi women translated by BBC News into Standard Arabic and English. Findings reveal substantial transformations which cannot be dismissed as inevitable constraints of the news genre or translation, but are more likely to reflect prevailing narratives of Muslim women being `submissive' and `oppressed'.|critical discourse analysis; translation studies; media; BBC News; Saudi women|IDEOLOGY; LANGUAGE|Linguistics; Language \& Linguistics|3|2|39
EVENT-RELATED BRAIN POTENTIALS DURING NATURAL SPEECH PROCESSING - EFFECTS OF SEMANTIC, MORPHOLOGICAL AND SYNTACTIC VIOLATIONS|1993|The present study investigated different aspects of auditory language comprehension. The sentences which were presented as connected speech were either correct or incorrect including a semantic error (selectional restriction), a morphological error (verb inflection), or a syntactic error (phrase structure). After each sentence, a probe word was presented auditorily, and subjects had to decide whether this word was part of the preceding sentence or not. Event-related brain potentials (ERPs) were recorded from 7 scalp electrodes. The ERPs evoked by incorrect sentences differed significantly from the correct ones as a function of error type. Semantic anomalies evoked a `classical' N400 pattern. Morphological errors elicited a pronounced negativity between 300 and 600 ms followed by a late positivity. Syntactic errors, in contrast, evoked an early negativity peaking around 180 ms followed by a negativity around 400 ms. The early negativity was only significant over the left anterior electrode. The present data demonstrate that linguistic errors of different categories evoke different ERP patterns. They indicate that with using connected speech as input, different aspects of language comprehension processes cannot only be described with respect to their temporal structure, but eventually also with respect to possible brain systems subserving these processes.|EVENT-RELATED POTENTIAL; N400; AUDITORY WORD PROCESSING; SEMANTIC PRIMING; SYNTACTIC PRIMING|SENTENCE COMPREHENSION; WORD REPETITION; EYE-MOVEMENTS; CONTEXT; ERRORS; LANGUAGE|Computer Science, Artificial Intelligence; Neurosciences; Neuroimaging|449|3|39
MISNIS: An intelligent platform for twitter topic mining|2017|Twitter has become a major tool for spreading news, for dissemination of positions and ideas, and for the commenting and analysis of current world events. However, with more than 500 million tweets flowing per day, it is necessary to find efficient ways of collecting, storing, managing, mining and visualizing all this information. This is especially relevant if one considers that Twitter has no ways of indexing tweet contents, and that the only available categorization ``mechanism{''} is the \#hashtag, which is totally dependent of a user's will to use it. This paper presents an intelligent platform and framework, named MISNIS - Intelligent Mining of Public Social Networks' Influence in Society - that facilitates these issues and allows a non-technical user to easily mine a given topic from a very large tweet's corpus and obtain relevant contents and indicators such as user influence or sentiment analysis. When compared to other existent similar platforms, MISNIS is an expert system that includes specifically developed intelligent techniques that: (1) Circumvent the Twitter API restrictions that limit access to 1\% of all flowing tweets. The platform has been able to collect more than 80\% of all flowing portuguese language tweets in Portugal when online; (2) Intelligently retrieve most tweets related to a given topic even when the tweets do not contain the topic \#hashtag or user indicated keywords. A 40\% increase in the number of retrieved relevant tweets has been reported in real world case studies. The platform is currently focused on Portuguese language tweets posted in Portugal. However, most developed technologies are language independent (e.g. intelligent retrieval, sentiment analysis, etc.), and technically MISNIS can be easily expanded to cover other languages and locations. (C) 2017 Elsevier Ltd. All rights reserved.|Twitter; Intelligent topic mining; Fuzzy fingerprints; Text analytics; Sentiment analysis|SENTIMENT ANALYSIS; ARCHITECTURE|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|0|38|38
Unveiling the intellectual origins of Social Media-based innovation: insights from a bibliometric approach|2016|This article uses a bundle of bibliometric and text-mining techniques to provide a systematic assessment of the intellectual core of the Social Media-based innovation research field. The goal of this study is to identify main research areas, understand the current state of development and suggest potential future directions by analysing co-citations from 155 papers published between 2003 and 2013 in the most influential academic journals. The main clusters have been identified, mapped, and labelled. Their most active areas on this topic and the most influential and co-cited papers have been identified and described. Also, intra- and inter-cluster knowledge base diversity has been assessed by using indicators stemming from the domains of Information Theory and Biology. A t test has been performed to assess the significance of the inter-cluster diversity. Five co-existing research streams shaping the research field under investigation have been identified and characterized.|Social Media; Innovation; Bibliometric analysis; Content analysis; Diversity analysis|AUTHOR COCITATION ANALYSIS; OPEN-SOURCE SOFTWARE; OPEN-SOURCE PROJECTS; PRODUCT DEVELOPMENT; USER INNOVATION; VIRTUAL COMMUNITIES; RESEARCH ISSUES; SELF-EFFICACY; CO-CREATION; CUSTOMER|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|7|10|38
Towards a new perspective on context based citation index of research articles|2016|Citation index measures the impact or quality of a research publication. Currently, all the standard journal citation indices are used to measure the impact of individual research article published in those journals and are based on the citation count, making them a pure quantitative measure. To address this, as our first contribution, we propose to assign weights to the edges of citation network using three context based quality factors: 1. Sentiment analysis of the text surrounding the citation in the citing article, 2. Self-citations, 3. Semantic similarity between citing and cited article. Prior approaches make use of PageRank algorithm to compute the citation scores. This being an iterative process is not essential for acyclic citation networks. As our second contribution, we propose a non-iterative graph traversal based approach, which uses the edge weights and the initial scores of the non-cited nodes to compute the citation indices by visiting the nodes in topologically sorted order. Experimental results depict that rankings of citation indices obtained by our approach are improved over the traditional citation count based ranks. Also, our rankings are similar to that of PageRank based methods; but, our algorithm is simpler and 70 \% more efficient. Lastly, we propose a new model for future reference, which computes the citation indices based on solution of system of linear inequalities, in which human-expert's judgment is modeled by suitable linear constraints.|Citation index; PageRank; Sentiment analysis; System of linear inequalities; Topological sorting|JOURNALS; PAGERANK; WORDNET|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|2|5|38
Convincing peers of the value of one's research: A genre analysis of rhetorical promotion in academic texts|2014|Intercultural studies have shown the existence of rhetorical variation in the prevalent discourse practices of multilingual scholars and those of English-speaking scholars. In this paper, we examine comparatively the typical rhetorical practices used in the Introduction section of 80 research articles written in English and 80 in Spanish in four disciplines in the fields of Health Sciences and Humanities/Social Sciences. We particularly examine how writers present their research studies in Move 3 (Swales, 2004), with a special focus on those steps that add promotional value to one's research. The results revealed that, within the same field, the English texts present a higher degree of rhetorical promotion than the Spanish texts in each of the disciplines analysed. However, when comparing the two broad fields, the Spanish texts in Health Sciences present a higher degree of promotion than the English (and Spanish) texts in Humanities/Social Sciences. This indicates that, in shaping the promotional features of the (sub)genre in question, when professional and national cultural variables interact simultaneously, cultural factors tend to override the influence of disciplinary context. However, when broad fields of knowledge are compared, it is the disciplinary conventions in specific professional subcultures that seem to prevail over national cultural factors. (C) 2013 Elsevier Ltd. All rights reserved.|Promotional strategy; Research article introduction; Genre analysis; Intercultural rhetoric|RESEARCH ARTICLE INTRODUCTIONS; APPLIED LINGUISTICS; DISCIPLINES; DISCOURSE; HUMANITIES; CHINESE; ENGLISH|Linguistics|9|0|38
Grammatical understanding, literacy and text messaging in school children and undergraduate students: A concurrent analysis|2014|Recent research has demonstrated that use of texting slang when text messaging does not appear to impact negatively on children and young people's literacy and may even benefit children's spelling attainment. However, less attention has been paid to the impact of text messaging on children's and young people's understanding of grammatical forms. This study examined the interrelationships between 243 children and undergraduate students' grammatical violations made when text messaging and their performance on assessments of spoken and written grammatical understanding, orthographic processing and conventional spelling ability. The children were found to make significantly more capitalisation and punctuation errors, and to use unconventional punctuation more frequently that the adults, when the length of their messages was taken into account. For the primary and secondary school children there was no relationship between the tendency to make grammatical violations when texting and their understanding of conventional grammar or orthography. For the young adult sample, there was some evidence of an association between the tendency to make capitalisation and punctuation errors when texting, and poorer performance in selecting the grammatically correct orthographic representation of a pseudoword. This relationship remained after controlling for individual differences in undergraduates' IQ and spelling ability. Overall, there is little evidence that ungrammatical texting behaviour is linked to grammatical understanding or knowledge of orthographic representations of language in children. However, there is some evidence that young adults' violation of grammatical conventions when texting may be linked to limited understanding of grammatically-related orthographic conventions. (C) 2013 Elsevier Ltd. All rights reserved.|Text messaging; SMS; Grammar; Spelling; Language|KNOWLEDGE; SKILLS; ABBREVIATIONS; EMOTICONS; ABILITY; ADULTS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|16|4|38
Business English students learning to write for international business: What do international business practitioners have to say about their texts?|2013|This article reports on a study of how Business English students' writing was received by international business practitioners. The study draws on 40 texts of five Business English students writing in three business genre sets and 1043 comments on the texts by eight international business professionals. Building on Tardy's (2009) framework for genre knowledge and the literature on business discourse, a coding scheme was developed to categorise the comments as formal, process, rhetorical, and subject-matter dimensions of genre knowledge and their respective sub-categories. The data analysis indicates that there was notable diversity amongst the professionals' reception of the students' texts. The professionals were concerned with all four dimensions of genre knowledge. Although the Business English students demonstrated a high level of genre knowledge and this was generally well received, there were considerable differences between the students and the professionals in all the four dimensions. While the professionals highlighted the transactional aspects of Business English as a lingua franca, they were also concerned with linguistic issues. The study results are discussed with reference to Business English as a lingua franca, genre knowledge, and the nature of business discourse. Implications of the study for Business English teaching are also discussed. (C) 2013 Elsevier Ltd. All rights reserved.|Business English; Genre knowledge; Business discourse; Writing for international business; Professional identities; International business professional|LINGUA-FRANCA; COMMUNICATION; CHINESE; GENRE|Linguistics|13|2|38
A novel semantic information retrieval system based on a three-level domain model|2013|This paper presents a methodology and a prototype for extracting and indexing knowledge from natural language documents. The underlying domain model relies on a conceptual level (described by means of a domain ontology), which represents the domain knowledge, and a lexical level (based on WordNet), which represents the domain vocabulary. A stochastic model (the ME-2L-HMM2, which mixes - in a novel way - HMM and maximum entropy models) stores the mapping between such levels, taking into account the linguistic context of words. Not only does such a context contain the surrounding words; it also contains morphologic and syntactic information extracted using natural language processing tools. The stochastic model is then used, during the document indexing phase, to disambiguate word meanings. The semantic information retrieval engine we developed supports simple keyword-based queries, as well as natural language-based queries. The engine is also able to extend the domain knowledge, discovering new and relevant concepts to add to the domain model. The validation tests indicate that the system is able to disambiguate and extract concepts with good accuracy. A comparison between our prototype and a classic search engine shows that the proposed approach is effective in providing better accuracy. (c) 2013 Elsevier Inc. All rights reserved.|HMM; MaxEnt; Ontology; WordNet; Semantic information retrieval; Word sense disambiguation|ONTOLOGY; EXTRACTION; KAPPA; WEB|Computer Science, Software Engineering; Computer Science, Theory \& Methods|6|1|38
Optimal and hierarchical clustering of large-scale hybrid networks for scientific mapping|2012|Previous studies have shown that hybrid clustering methods based on textual and citation information outperforms clustering methods that use only one of these components. However, former methods focus on the vector space model. In this paper we apply a hybrid clustering method which is based on the graph model to map the Web of Science database in the mirror of the journals covered by the database. Compared with former hybrid clustering strategies, our method is very fast and even achieves better clustering accuracy. In addition, it detects the number of clusters automatically and provides a top-down hierarchical analysis, which fits in with the practical application. We quantitatively and qualitatively asses the added value of such an integrated analysis and we investigate whether the clustering outcome provides an appropriate representation of the field structure by comparing with a text-only or citation-only clustering and with another hybrid method based on linear combination of distance matrices. Our dataset consists of about 8,000 journals published in the period 2002-2006. The cognitive analysis, including the ranked journals, term annotation and the visualization of cluster structure demonstrates the efficiency of our strategy.|Optimal and hierarchical clustering; Text mining; Bibliometric analysis; Modularity optimization; Network analysis|INFORMATION-SCIENCE; COMBINED COCITATION; WORD ANALYSIS; WEB|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|6|1|38
Applying text and data mining techniques to forecasting the trend of petitions filed to e-People|2010|As the Internet has been the virtual place where citizens are united and their opinions are promptly shifted into the action, two way communications between the government sector and the citizen have been more important among activities of e-Government. Hence, Anti-corruption and Civil Rights Commission (ACRC) in the Republic of Korea has constructed the online petition portal system named e-People. In addition, the nation's Open Innovation through e-People has gained increasing attention. That is because e-People can be applied for the virtual space where citizens participate in improving the national law and policy by simply filing petitions to e-People as the voice of the nation. However, currently there are problems and challenging issues to be solved until e-People can function as the virtual space for the nation's Open Innovation based on petitions collected from citizens. First, there is no objective and systematic method for analyzing a large number of petitions filed to e-People without a lot of manual works of petition inspectors. Second, e-People is required to forecast the trend of petitions filed to e-People more accurately and quickly than petition inspectors for making a better decision on the national law and policy strategy. Therefore, in this paper, we propose the framework of applying text and data mining techniques not only to analyze a large number of petitions filed to e-People but also to predict the trend of petitions. In detail, we apply text mining techniques to unstructured data of petitions to elicit keywords from petitions and identify groups of petitions with the elicited keywords. Moreover, we apply data mining techniques to structured data of the identified petition groups on purpose to forecast the trend of petitions. Our approach based on applying text and data mining techniques decreases time-consuming manual works on reading and classifying a large number of petitions, and contributes to increasing accuracy in evaluating the trend of petitions. Eventually, it helps petition inspectors to give more attention on detecting and tracking important groups of petitions that possibly grow as nationwide problems. Further, the petitions ordered by their petition groups' trend values can be used as the baseline for making a better decision on the national law and policy strategy. (C) 2010 Elsevier Ltd. All rights reserved.|Text mining; Data mining; Petition; Keyword extracting; Document clustering; Forecasting; e-Government; Open Innovation; e-People|BACKPROPAGATION NEURAL-NETWORK; RADIAL BASIS FUNCTION; K-MEANS ALGORITHM; MARKET-SEGMENTATION; DECISION TREE; MACHINE; INTEGRATION; PREDICTION; ENSEMBLE; MODEL|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|9|2|38
Using content-based and bibliometric features for machine learning models to predict citation counts in the biomedical literature|2010|The most popular method for judging the impact of biomedical articles is citation count which is the number of citations received. The most significant limitation of citation count is that it cannot evaluate articles at the time of publication since citations accumulate over time. This work presents computer models that accurately predict citation counts of biomedical publications within a deep horizon of 10 years using only predictive information available at publication time. Our experiments show that it is indeed feasible to accurately predict future citation counts with a mixture of content-based and bibliometric features using machine learning methods. The models pave the way for practical prediction of the long-term impact of publication, and their statistical analysis provides greater insight into citation behavior.|Bibliometrics; Citation analysis; Machine learning; Information retrieval|TEXT CATEGORIZATION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|18|5|38
Influences of text difficulty and reading ability on learning illustrated science texts for children: An eye movement study|2017|In this study, eye movement recordings and comprehension tests were used to investigate children's cognitive processes and comprehension when reading illustrated science texts. Ten-year-old children (N = 42) who were beginning to read to learn, with high and low reading ability read two illustrated science texts in Chinese (one medium-difficult article, one difficult article), and then answered questions that measured comprehension of textual and pictorial information as well as text-and-picture integration. The high-ability group outperformed the low-ability group on all questions. Eye movement analyses showed that both group of students spent roughly the same amount of time reading both articles, but had different methods of reading them. The low-ability group was inclined to read what seemed easier to them and read the text more. The high-ability group attended more to the difficult article and made an effort to integrate the textual and pictorial information. During a first-pass reading of the difficult article, high-but not low-ability readers returned to the previous paragraph. The low-ability readers spent more time reading the less difficult article and not the difficult one that required teachers' attention. Suggestions for classroom instruction are proposed accordingly. (C) 2017 Elsevier Ltd. All rights reserved.|Applications in subject areas; Elementary education; Evaluation methodologies; Pedagogical issues; Teaching/learning strategies|PICTURES; REPRESENTATIONS; COMPREHENSION; CONSTRUCTION; PATTERNS; DIAGRAMS; TRACKING; READERS; RECALL; PROSE|Computer Science, Interdisciplinary Applications; Education \& Educational Research|0|29|37
Benefits of mobile instant messaging to develop ESL writing|2016|This study investigated the benefits of Mobile Instant Messaging (MIM) through an analysis of grammatical, lexical and mechanical accuracy as well as syntactic complexity in second-language learners' writing. A WhatsApp group was created where 80 Spanish students taking a B1 English course participated in a daily interaction during six months. A quasi-experimental research design with an experimental and control group and a pre post test was followed. Students were divided into two main groups according to treatment type with 40 students in each group. This research focused on the interaction in the application and attempted to measure, through a qualitative and quantitative analysis, the students' degree of writing development. The ratios of lexical, grammatical and mechanical errors as well as error-free clauses per clause and error-free T-unit per T-unit indicated significant differences between the control and experimental group in terms of accuracy. Nevertheless, measures of syntactic complexity together with lexical diversity were not conclusive as the independent parameters for syntactic complexity showed no significant differences between the two groups. WhatsApp constitutes a powerful educational tool to encourage second language interaction among participants and its tremendous potential to activate students' involvement remains one of the least exploited functionalities of mobile phones. (C) 2016 Elsevier Ltd. All rights reserved.|Mobile instant messaging; Chat-based conversation; Second language writing; Mobile assisted language learning; Noticing; Collaborative learning|MEDIATED NEGOTIATED INTERACTION; TEXT CHAT; ACQUISITION; COMPLEXITY; ACCURACY; OUTPUT; MODEL; PAIR|Education \& Educational Research; Linguistics|4|11|37
Does animation enhance learning? A meta-analysis|2016|This meta-analysis investigated whether animation is beneficial overall for learning compared to static graphics, while also identifying moderator factors affecting the global effect. A systematic search was conducted for experimental studies comparing the impact of animated vs. static graphics displays in the context of knowledge acquisition. A total of 50 papers were considered, and consecutively 61 primary studies (N = 7036), yielding 140 pair-wise comparisons of animated vs. static graphic visualizations in multimedia instructional material were analyzed using a random-effects model. An overall positive effect of animation over static graphics was found, with a Hedges's g effect size of 0.226 (95\% confidence interval = 0.12-0.33). Additional moderator analyses indicated substantial effect sizes when the animation was system-paced (g = 0309), when it was coupled with auditory commentary (g = 0.336) or when the instruction did not include any accompanying text (g = 0.883). (C) 2016 Elsevier Ltd. All rights reserved.|Meta-analysis; Animation; Static graphics; Instructional design, teaching/learning strategies; Moderator factors|INSTRUCTIONAL ANIMATIONS; COMPUTER ANIMATION; DYNAMIC VISUALIZATIONS; SPATIAL ABILITY; STATIC PICTURES; COGNITIVE-STYLE; PRIOR KNOWLEDGE; STUDENT AIDS; MULTIMEDIA; INFORMATION|Computer Science, Interdisciplinary Applications; Education \& Educational Research|12|3|37
Tweet categorization by combining content and structural knowledge|2016|Twitter is a worldwide social media platform where millions of people frequently express ideas and opinions about any topic. This widespread success makes the analysis of tweets an interesting and possibly lucrative task, being those tweets rarely objective and becoming the targeting for large-scale analysis. In this paper, we explore the idea of integrating two fundamental aspects of a tweet, the proper textual content and its underlying structural information, when addressing the tweet categorization task. Thus, not only we analyze textual content of tweets but also analyze the structural information provided by the relationship between tweets and users, and we propose different methods for effectively combining both kinds of feature models extracted from the different knowledge sources. In order to test our approach, we address the specific task of determining the political opinion of Twitter users within their political context, observing that our most refined knowledge integration approach performs remarkably better (about 5 points above) than the textual-based classic model. (C) 2016 Elsevier B.V. All rights reserved.|Twitter; Tweet categorization; Ensemble learning; Knowledge combination|TWITTER; POLITICS; NETWORK; TEXT|Computer Science, Artificial Intelligence; Computer Science, Theory \& Methods|4|2|37
The study of subject-classification based on journal coupling and expert subject-classification system|2016|As the framework of scientific research, subject-classification plays an important role in the development of science. In order to combine the development of science with the current expert subject-classification system and further give a more appropriate description of scientific output analysis from subject level, We study the relationship between the natural science related sub-categories of Chinese library classification using objective computerized scientometrics, and give some modification to the first two level subjects of the existing Chinese library classification system. Taking Chinese Science Citation Database as our data source, this article studies the similarity of subjects based on journal coupling strength. Then we try to set up an improved subject-classification system whose top categories are relied on Chinese library classification system and sub-categories are the ensemble clustering result based on journal coupling measure. Further, in order to help identifying and interpreting the rationality of this improved classification system, we make use of some text mining methods, such as key words recognition and topic detection, to explain the cause of similarity between some subjects from the perspective of semantic. Our study shows that the improved subject-classification system constructed in this article not only conforms to previous experience and cognitive but also combines subject development knowledge.|Subject-classification; Journal coupling; Cluster analysis; Text mining; Chinese library classification|SCIENTIFIC JOURNALS; INFORMATION-SCIENCE; COCITATION ANALYSIS; CITATION-REPORTS; CLUSTERS; TERMS; MAPS; SET|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|6|37
One wiki, two groups: Dynamic interactions across ESL collaborative writing tasks|2016|With the growing importance of Web 2.0 tools for communication and collaboration, small group writing using one such tool the wiki has been increasingly implemented in second language classes. A few researchers have examined group interactions during wild-based collaborative writing, but little research has explored changes in interaction patterns that occur when students perform multiple wild writing tasks. This study investigates two ESL groups' interactions during two collaborative writing tasks that used a Wikispaces site in an English for Academic Purposes (EAP) course at an American university. We examined the dynamics of peer interaction across writing tasks for each group by inspecting (1) language functions performed during task negotiation, (2) writing change functions performed during text co-construction, (3) scaffolding strategies, and (4) changes in patterns of interaction across tasks. Data included wiki modules, interviews, and reflection papers. Our analyses show that two ESL groups working on identical tasks in the same wild space enacted strikingly different patterns of interaction and that those patterns changed within each group across two tasks. We discuss these dynamics with reference to the fluidity of scaffolding occurring within small groups. This study fills a gap in computer-mediated collaborative writing research and also sheds new light on networked writing pedagogy. Published by Elsevier Inc.|Collaborative writing; Dynamic interaction; Small group; Wiki|PEER RESPONSE; STUDENTS; PATTERNS; PERSPECTIVE; REFLECTIONS; LEARNERS; STANCES|Linguistics|5|5|37
Pronoun Use Reflects Standings in Social Hierarchies|2014|Five studies explored the ways relative rank is revealed among individuals in small groups through their natural use of pronouns. In Experiment 1, four-person groups worked on a decision-making task with randomly assigned leadership status. In Studies 2 and 3, two-person groups either worked on a task or chatted informally in a get-to-know-you session. Study 4 was a naturalistic study of incoming and outgoing e-mail of 9 participants who provided information on their correspondents' relative status. The last study examined 40 letters written by soldiers in the regime of Saddam Hussein. Computerized text analyses across the five studies found that people with higher status consistently used fewer first-person singular, and more first-person plural and second-person singular pronouns. Natural language use during group interaction suggests that status is associated with attentional biases, such that higher rank is linked with other-focus whereas lower rank is linked with self-focus.|pronouns; language; social hierarchy; power; status; leadership|INTERPERSONAL SENSITIVITY; POWER; DOMINANCE; CONVERSATIONS; PERFORMANCE; DEPRESSION; PRESTIGE; OTHERS; RANK; TOP|Communication; Linguistics; Psychology, Social|27|2|37
An approach to develop intelligent learning environments by means of immersive virtual worlds|2014|Merging Immersive Virtual Environments, Natural Language Processing and Artificial Intelligence techniques provides a number of advantages to develop Intelligent Environments for multiple applications. This paper is focused on the application of these technologies to develop intelligent learning environments. Education is one of the most interesting applications of immersive virtual environments, as their flexibility can be exploited in order to create heterogeneous groups from all over the world who can collaborate synchronously in different virtual spaces. We highlight the potential of virtual worlds as an educative tool and propose a model to create learning environments within Second Life or OpenSimulator combining the Moodle learning management system, embodied conversational metabots, and programmable 3D objects. Our proposal has been applied in several subjects of the Computer Science degree in the Carlos III University of Madrid. The results of the evaluation show that developed learning environment fosters engagement and collaboration and helps students to better understand complex concepts.|Intelligent Environments; immersive virtual worlds; e-learning; conversational agents; Second Life; OpenSimulator; Sloodle; speech interaction|2ND LIFE; DESIGN; PEDAGOGY; STUDENTS; REALITY; TOOLS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications|7|2|37
CROWDSOURCING A WORD-EMOTION ASSOCIATION LEXICON|2013|Even though considerable attention has been given to the polarity of words (positive and negative) and the creation of large polarity lexicons, research in emotion analysis has had to rely on limited and small emotion lexicons. In this paper, we show how the combined strength and wisdom of the crowds can be used to generate a large, high-quality, word-emotion and word-polarity association lexicon quickly and inexpensively. We enumerate the challenges in emotion annotation in a crowdsourcing scenario and propose solutions to address them. Most notably, in addition to questions about emotions associated with terms, we show how the inclusion of a word choice question can discourage malicious data entry, help to identify instances where the annotator may not be familiar with the target term (allowing us to reject such annotations), and help to obtain annotations at sense level (rather than at word level). We conducted experiments on how to formulate the emotion-annotation questions, and show that asking if a term is associated with an emotion leads to markedly higher interannotator agreement than that obtained by asking if a term evokes an emotion.|affect; crowdsourcing; emotion lexicon; emotions; Mechanical; polarity; polarity lexicon; semantic orientation; sentiment analysis; word-emotion associations|CONSUMER COMPLAINT INTENTIONS; BASIC EMOTIONS; SERVICE; TEXT; BEHAVIOR; LOYALTY; RELIABILITY; RECOGNITION; COEFFICIENT; INFORMATION|Computer Science, Artificial Intelligence|116|8|37
A reception study of the articles published in English for Specific Purposes from 1990-1999|2012|EAP practitioners in advanced courses have often focused on assisting junior scholars who are non-native speakers of English with their attempts to publish in English. Today, however, university administrators increasingly rely on post-publication data such as citation records. We therefore suggest that identifying heavily cited and largely uncited papers would be an addition to the advanced writing instructor's toolkit. In fact, many proposals have been made to account for citational success and failure. Disentangling these variables is complex and typically requires in-depth knowledge of the chosen sub-field. Here we examine the reception histories of a decade's worth of main articles in the English for Specific Purposes Journal, using the Google Scholar, Scopus and Web of Science databases. Analysis of the 15 most cited articles indicates that placement in an issue, gender, first language, author status, and provenance are not major determinants. Instead, area of research interest (i.e., discoursal features of academic text) and type of ESP (i.e., EAP) were the main predisposing factors. We then conduct a close analysis of the two top 1990s papers (both, incidentally, written by women whose first language is not English and working in non-Anglophone settings). We conclude with some implications of these findings for EAP practitioners and their ``customers{''}. (C) 2011 Elsevier Ltd. All rights reserved.|Citation analysis; Reception studies; Citation uptake|GOOGLE SCHOLAR; DISCOURSE; SCIENCE; AUTHORS; WEB|Linguistics|12|5|37
Does Urquhart's Law hold for consortial use of electronic journals?|2010|This paper tests the validity of Urquhart's Law ({''}the inter-library loan demand for a periodical is as a rule a measure of its total use{''}). It compares the use of print journals at the Turkish Academic Network and Information Center (ULAKBIM) with the consortial use of the same journals in their electronic form by the individual libraries making up the Consortium of Turkish University Libraries (ANKOS). It also compares the on-site use of electronic journals at ULAKBIM with their consortial use at ANKOS. About 700 thousand document delivery, in-house and on-site use data and close to 28 million consortial use data representing seven years' worth of downloads of full-text journal articles were used. Findings validate Urquhart's Law in that a positive correlation was observed between the use of print journals at ULAKBIM and the consortial use of their electronic copies at ANKOS. The on-site and consortial use of electronic journals was also highly correlated. Both print and electronic journals that were used most often at ULAKBIM tend to get used heavily by the member libraries of ANKOS consortium, too. Findings can be used in developing consortial collection management policies and negotiate better consortial licence agreements.|Urquhart's Law; e-Journals; Consortial use; Interlibrary use; Intralibrary use; Supralibrary use|LOG ANALYSIS; PROBABILITY; COLLECTIONS; MANAGEMENT; FORMULATION; LIBRARY; SCIENCE; SERIALS; IMPACT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|1|37
Developing reading fluency and comprehension using repeated reading: Evidence from longitudinal student reports|2010|In recent years, interest in reading fluency development in first language, and second and foreign language (L2/FL) settings has increased. Reading fluency, in which readers decode and comprehend at the same time, is critical to successful reading. Fluent readers are accurate and fast in their ability to recognize words, and in their use of prosodic and syntactic knowledge to better comprehend text. Reading is a significant and viable means of developing L2/FL ability, particularly in FL settings in which L2 input sources are limited, such as Vietnam or Japan (for English as a foreign language), or the USA (for Japanese or Russian as a foreign language). Yet many L2/FL learners read slowly and laboriously, likely because of poor word recognition skills. Repeated reading (RR) is one method of fluency-building long used in first language (L1) settings and more recently in L2/FL settings, and seems successful in increasing the reading fluency and comprehension of both L1 and L2/FL learners. Nonetheless, it is likely that teachers and learners in L2/FL settings may be unaware of or unconvinced of the role increased reading fluency plays in reading comprehension and, as a result, may not see the utility of devoting class or personal time to repeated reading or, indeed, any reading fluency activity. Because quantitative evidence for positive effects of RR has already been offered (see Taguchi, Sasamoto, \& Gorsuch, 2006; Gorsuch \& Taguchi, 2008), we offer additional evidence in the form of open-ended, post-reading student reports written over the length of an 11-week RR treatment for 30 young adult EFL learners in Vietnam. Iterative analyses of over 200 pages of student reports provided nuanced evidence of the positive effects RR has on FL learners' reading fluency and comprehension development, and general language development. Learners' comments revealed information that suggested a meaningful role for extended experience with RR to increasing use of learner metacognition in reading strategy use, and growing awarenesses on the part of learners of (1) the relationship between fluency and comprehension, (2) the utility of developing fluency as a stand-alone skill, and (3) RR as a causal agent in the development of listening, writing, and speaking skills.|reading fluency; reading comprehension; reading in foreign language programs|WORD RECOGNITION; READERS FLUENCY; LANGUAGE; AUTOMATICITY; CLASSROOM; LEARNERS; CHILDREN|Education \& Educational Research; Linguistics|15|4|37
An R\&D knowledge management method for patent document summarization|2008|Purpose - In an era of rapidly expanding digital content, the number of e-documents and the amount of knowledge frequently overwhelm the R\&D teams and often impede intellectual property management. The purpose of this paper is to develop an automatic patent summarization method for accurate knowledge abstraction and effective R\&D knowledge management. Design/methodology/approach - This paper develops an integrated approach for automatic patent summary generation combining the concepts of key phrase recognition and significant information density. Significant information density is defined based on the domain-specific key concepts/phrases, relevant phrases, title phrases, indicator phrases and topic sentences of a given patent document. Findings - The document compression ratio and the knowledge retention ratio are used to measure both quantitative and qualitative outcomes of the new summarization methodology. Both measurements indicate the significant benefits and superior results of the method. Research limitations/implications - In order to implement the methodology with practical success, the accurate and efficient pre-processing of identifying key concepts and relevant phrases of patent documents is required. The approach relies on a powerful text-mining engine as the pre-process module for key phrase extraction. Practical implications - The methodology helps R\&D companies consistently and automatically process, extract and summarize the core knowledge of related patent documents. This enabling technology is critical to R\&D companies when they are competing to create new technologies and products for short life cycle marketplaces. Originality/value - This research addresses a new perspective in R\&D knowledge management, particularly in solving the knowledge-overloading issue. The methodology helps R\&D collaborative teams consistently to summarize the core knowledge of patent documents with efficiency. Efficient R\&D knowledge management helps the firm to take advantage of IP positioning while avoiding patent conflict and infringement.|document handling; knowledge management; information management; intellectual property|TEXT; CLASSIFICATION; RETRIEVAL|Computer Science, Interdisciplinary Applications; Engineering, Industrial|18|3|37
The nature of negotiations in face-to-face versus computer-mediated communication in pair interactions|2016|The Interaction Approach argues that negotiation for meaning and form is conducive to second language development. To date, most of the research on negotiations has been either in face-to-face (FTF) or text-based synchronous computer-mediated communication (SCMC) modes. Very few studies have compared the nature of negotiations across the modes. Such comparisons are important as they can indicate which mode may be more conducive to language learning. The present study set out to compare the nature of negotiations between FTF and SCMC modes in same-proficiency intermediate dyads. Dyads performed two similar decision-making tasks, one in FTF and one in SCMC mode, and were encouraged to provide corrective feedback, where necessary, to their partner. The analysis revealed that negotiations for form and meaning were scarce in both modes, with more negotiations for meaning in FTF mode. The findings also suggested that mode of interaction influenced the type of negotiations, and their outcomes, in terms of modified output as well as successful uptake.|Computer-mediated negotiations; face-to-face negotiations; negotiations for meaning and form; pair interaction|CORRECTIVE-FEEDBACK; 2ND-LANGUAGE ACQUISITION; PEER INTERACTION; L2 CLASSROOM; RECASTS; LEARNERS; INPUT; CHAT; TEXT; FORM|Education \& Educational Research; Linguistics|3|7|36
Forecasting movements of health-care stock prices based on different categories of news articles using multiple kernel learning|2016|The market state changes when a new piece of information arrives. It affects decisions made by investors and is considered to be an important data source that can be used for financial forecasting. Recently information derived from news articles has become a part of financial predictive systems. The usage of news articles and their forecasting potential have been extensively researched. However, so far no attempts have been made to utilise different categories of news articles simultaneously. This paper studies how the concurrent, and appropriately weighted, usage of news articles, having different degrees of relevance to the target stock, can improve the performance of financial forecasting and support the decision-making process of investors and traders. Stock price movements are predicted using the multiple kernel learning technique which integrates information extracted from multiple news categories while separate kernels are utilised to analyse each category. News articles are partitioned according to their relevance to the target stock, its sub-industry, industry, group industry and sector. The experiments are run on stocks from the Health Care sector and show that increasing the number of relevant news categories used as data sources for financial forecasting improves the performance of the predictive system in comparison with approaches based on a lower number of categories. (C) 2016 Elsevier B.V. All rights reserved.|Stock price prediction; Financial news; Text mining; Multiple kernel learning; Decision support systems|MARKET PREDICTION; TEXTUAL ANALYSIS; FINANCIAL NEWS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|4|9|36
Combining rules and machine learning for extraction of temporal expressions and events from clinical narratives|2013|Objective Identification of clinical events (eg, problems, tests, treatments) and associated temporal expressions (eg, dates and times) are key tasks in extracting and managing data from electronic health records. As part of the i2b2 2012 Natural Language Processing for Clinical Data challenge, we developed and evaluated a system to automatically extract temporal expressions and events from clinical narratives. The extracted temporal expressions were additionally normalized by assigning type, value, and modifier. Materials and methods The system combines rule-based and machine learning approaches that rely on morphological, lexical, syntactic, semantic, and domain-specific features. Rule-based components were designed to handle the recognition and normalization of temporal expressions, while conditional random fields models were trained for event and temporal recognition. Results The system achieved micro F scores of 90\% for the extraction of temporal expressions and 87\% for clinical event extraction. The normalization component for temporal expressions achieved accuracies of 84.73\% (expression's type), 70.44\% (value), and 82.75\% (modifier). Discussion Compared to the initial agreement between human annotators (87-89\%), the system provided comparable performance for both event and temporal expression mining. While (lenient) identification of such mentions is achievable, finding the exact boundaries proved challenging. Conclusions The system provides a state-of-the-art method that can be used to support automated identification of mentions of clinical events and temporal expressions in narratives either to support the manual review process or as a part of a large-scale processing of electronic health databases.|clinical text mining; clinical NLP; event extraction; termporal expression extraction; termporal expression normalization|INFORMATION EXTRACTION; MEDICATION INFORMATION; KNOWLEDGE EXTRACTION; DISCHARGE SUMMARIES; TEXT; SYSTEM; IDENTIFICATION; ASSERTIONS; ONTOLOGY; UMLS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|11|0|36
Sentiment analysis via dependency parsing|2013|Nowadays, Sentiment Analysis (SA) is receiving huge attention because of the wide range of its direct applications like analyses of products, customer profiles, political trends, and so forth. Still, the availability of big amounts of data coming from the World Wide Web makes easier the study of both new techniques and evaluation methods. Current literature mainly focuses on two approaches which rely on sentiment lexicons (i.e., lists of words associated to scores of sentiment polarity) or on Natural Language Processing techniques (NLP). In this paper, on one hand, we introduce and evaluate a novel algorithm for SA that relies on a simple set of propagation rules applied at syntactic level within a dependency parse tree. On the other hand, we propose a context-based model where the users' sentiments (or opinions) are tuned according to some context of analysis. Finally, we present the system called SentiVis which implements these ideas through an orthogonal approach to SA that directly leans on Data Visualization. Extracted sentiments, with respect to some query of analysis, are ordered and represented graphically in a 2-dimensional space, conveying information about their strength and variability. This way, we avoid cumbersome rankings of objects and associated opinions by directly mapping such information on the screen. The user is then able to interact with the visualized data in order to discover interesting facts as well as removing false positive (or negative) opinions deriving by the used algorithm. We then evaluate the efficacy of the proposed system through several case studies. (C) 2012 Elsevier B.V. All rights reserved.|Sentiment analysis; Data visualization; User interfaces|COMPUTER-MEDIATED COMMUNICATION; MESSAGE INTERPRETATION; CLASSIFICATION; EMOTICONS; EMOTION; TEXT|Computer Science, Hardware \& Architecture; Computer Science, Software Engineering|11|0|36
Written Corrective Feedback and Its Challenges for Pre-Service ESL Teachers|2013|This study explored the emerging corrective feedback (CF) practices of a group of 18 pre-service English as a second language (ESL) teachers. Serving as tutors to a group of 61 high school ESL learners during a school semester, the pre-service teachers provided CF on texts written by the learners and exchanged via e-mail. The authors analyzed the types of CF they used and the types of errors they chose to focus on, along with the factors that explained their choices. Quantitative analyses of the frequency distribution of CF types relative to error types and qualitative analyses of data collected through journals and interviews confirmed that, similar to their in-service colleagues, pre-service teachers overused direct corrections at the expense of more indirect CF strategies. Drawing on the challenges faced by the pre-service teachers, the authors highlight the importance of implementing such opportunities for pre-service teachers to engage with and reflect on their emerging CF practices.|L2 teacher training; teacher feedback practices; written corrective feedback|2ND-LANGUAGE WRITING RESEARCH; HONG-KONG; GRAMMAR-CORRECTION; LANGUAGE; BELIEFS; CLASSROOMS; ACCURACY; ERROR|Linguistics|4|1|36
Citation behavior in popular scientific papers: what is behind obscure citations? The case of ethnobotany|2012|Citation studies have become an important tool for understanding scientific communication processes, as they enable the identification of several characteristics of information-retrieval behavior. This study seeks to analyze citation behavior using two popular ethnobotany articles, and our analysis is guided by the following question: when an author references a work, is he pointing out the work's theoretical contribution, or is bias a factor in citing this reference? Citation analysis reveals an interesting phenomenon, as the majority of citing texts do not consider the theoretical contributions made by the articles cited. Two possible conclusions can be drawn from this scenario: (1) citing authors read the original texts that they cite only superficially, and (2) the works cited are not read by the vast majority of people who reference them. Thus, it is clear that even with sufficient access to reference texts; ethnobotanical studies highlight elements less relevant to the research and reproduce discussions in a non-reflective manner.|Citation analysis; Scientometrics; Scientific quality|PLANTS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|11|1|36
What artificial grammar learning reveals about the neurobiology of syntax|2012|In this paper we examine the neurobiological correlates of syntax, the processing of structured sequences, by comparing FMRI results on artificial and natural language syntax. We discuss these and similar findings in the context of formal language and computability theory. We used a simple right-linear unification grammar in an implicit artificial grammar learning paradigm in 32 healthy Dutch university students (natural language FMRI data were already acquired for these participants). We predicted that artificial syntax processing would engage the left inferior frontal region (BA 44/45) and that this activation would overlap with syntax-related variability observed in the natural language experiment. The main findings of this study show that the left inferior frontal region centered on BA 44/45 is active during artificial syntax processing of well-formed (grammatical) sequence independent of local subsequence familiarity. The same region is engaged to a greater extent when a syntactic violation is present and structural unification becomes difficult or impossible. The effects related to artificial syntax in the left inferior frontal region (BA 44/45) were essentially identical when we masked these with activity related to natural syntax in the same subjects. Finally, the medial temporal lobe was deactivated during this operation, consistent with the view that implicit processing does not rely on declarative memory mechanisms that engage the medial temporal lobe. In the context of recent FMRI findings, we raise the question whether Broca's region (or subregions) is specifically related to syntactic movement operations or the processing of hierarchically nested non-adjacent dependencies in the discussion section. We conclude that this is not the case. Instead, we argue that the left inferior frontal region is a generic on-line sequence processor that unifies information from various sources in an incremental and recursive manner, independent of whether there are any processing requirements related to syntactic movement or hierarchically nested structures. In addition, we argue that the Chomsky hierarchy is not directly relevant for neurobiological systems. (C) 2010 Elsevier Inc. All rights reserved.|FMRI; Syntax; Natural language; Artificial language; Broca's area; Artificial grammar learning; Adaptive dynamical systems; Computability; Chomsky hierarchy; Complexity|SIMPLE RECURRENT NETWORKS; TIME ANALOG COMPUTATIONS; INFERIOR FRONTAL-CORTEX; SENTENCE COMPREHENSION; WORKING-MEMORY; BROCAS AREA; FUNCTIONAL LOCALIZATION; DYNAMICAL-SYSTEMS; LANGUAGE FACULTY; BRAIN|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|76|3|36
Effects of a computer-assisted formative assessment intervention based on multiple-tier diagnostic items and different feedback types|2016|Computer-assisted formative assessments with multiple-tier items are a valid instrument for diagnosing students' conceptual understanding in learning domains with well structured declarative knowledge (e.g. science education). However, it is unknown how feedback on multiple-tier items can improve learning success. Therefore, we assessed (1) predictors of students' perception and use of elaborated feedback, and (2) if feedback content (elaborated, verification, control) matters in explaining students' achievement in post- and retention tests. We developed computer-assisted formative tests for a teaching unit on evolutionary adaptations. Three treatment groups were employed with varying feedback content: Treatment 1 (T1) was an elaborated instruction-based feedback, T2 was a dichotomous verification feedback, and T3 (control) consisted of reading appropriate texts (no formative assessment and no feedback). Afterwards, T1 was separated into one subgroup with pupils who used the feedback thoroughly (T1A) and a subgroup that did not use the feedback (T1B). Ten secondary classrooms were used and 261 pupils participated in this study. Each student in each classroom was randomly assigned to one treatment group. Correlation and univariate regression analysis showed that perception and use of elaborated feedback were related to intrinsic motivation and self-reported grades. Multivariate analysis of covariance was applied to check treatment effects on post-tests and retention tests as dependent variables. Results revealed that verification feedback (T2) and elaborated feedback when students did use it (T1A) was superior to no feedback (T3) and elaborated feedback when students did not use it (T1B). Implications for the design of multiple-tier diagnostic assessments are discussed. (C) 2016 Elsevier Ltd. All rights reserved.|Formative assessment; Feedback; Computer-assisted testing; Science education; Secondary education|INSTRUCTION; METAANALYSIS; PERFORMANCE; INSTRUMENT; SCIENCE; DESIGN|Computer Science, Interdisciplinary Applications; Education \& Educational Research|8|1|35
Language technologies applied to document simplification for helping autistic people|2015|People affected by Autism Spectrum Disorders (ASD) have impairments in social interaction because they lack an adequate theory of mind. A significant percentile has inadequate reading comprehension skills. We present a multilingual tool called Open Book (OB) that applies Human Language Technologies (HLT) in order to identify reading comprehension obstacles in text documents and propose more simple alternatives with the aim of assisting the reading comprehension of users. OB involves several text transformations at lexical, syntactic and semantic level. In this paper we focus on three challenging components of the OB tool: the image retrieval component, the idiom detection component and the summarization module. There are very few studies that involve simplification by showing images associated to difficult concepts. In addition, the treatment of figurative language such as idioms or metaphors is one of the most challenging areas in Natural Language Processing (NLP). Finally, although text summarization is a more widely studied field in NLP, its application to text simplification remains as an open research issue. Thus, we focus on the integration of these three modules in our OB tool. We present the motivation for building these components and we describe how they are integrated in the whole system. Moreover, the usability and the usefulness of OB have been evaluated and analysed showing that the tool helps to produce texts easier to understand for autistic people. (C) 2015 Elsevier Ltd. All rights reserved.|Natural Language Processing; Text simplification; ASD; Image retrieval; Text summarization; Topic Models; Idiom detection|SPECTRUM DISORDERS; READING-COMPREHENSION; CHILDREN; STUDENTS; DISABILITIES|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|1|0|35
Searchable talk: the linguistic functions of hashtags|2015|An important dimension of social media discourse is its searchability. A key semiotic resource supporting this function is the hashtag, a form of social tagging that allows microbloggers to embed metadata in social media posts. While popularly thought of as topic-markers, hashtags are able to construe a range of complex meanings in social media texts. This paper uses the concept of linguistic metafunctions, to explore how hashtags enact three simultaneous communicative functions: marking experiential topics, enacting interpersonal relationships, and organizing text. Corpus-based discourse analysis of linguistic patterns in a 100 million word Twitter corpus is used to investigate these functions and how they relate to the notion of social search.|discourse analysis; Twitter; hashtags; systemic functional linguistics; social media; microblogging|AMBIENT AFFILIATION; IMAGINED AUDIENCE; TWITTER|Humanities, Multidisciplinary; Communication; Linguistics|10|5|35
Social Media The Key to Health Information Access for 18-to 30-Year-Old College Students|2015|This work examines where 18- to 30-year-old college students seek health information on the Internet and how they determine site and message credibility. Using a qualitative methodology, five focus groups were conducted with 18- to 30-year-old college students, and transcripts were analyzed with MaxQDA text analysis software. The study revealed that 18- to 30-year-old college students have Internet health information source preferences, reasons for seeking health information on the Internet, and message design factors that improve their perception of site and message credibility. We conclude that the Internet and social media show great promise as effective health communication channels for 18- to 30-year-old college students and confirm that preferred Internet/social media sites can be utilized by health educators to present important risk management/disease prevention information to 18- to 30-year-old college students. In addition, message design factors can lend credibility to both sites and the health information delivered there.|College students; Consumer health informatics; Health education; Social media|COMMUNICATION; LITERACY; ONLINE; PREVENTION; BEHAVIORS; EXPOSURE; CONTEXT; HUMOR|Computer Science, Interdisciplinary Applications; Medical Informatics; Nursing|5|3|35
Tell-Tale Words: Linguistic Cues Used to Infer the Expertise of Online Medical Advice|2015|This article analyzes the linguistic cues used by naive perceivers to assess the expertise of online medical advice. We develop a theoretical framework of linguistic correlates to perceived expertise and test it on a corpus of 120 online medical advice messages, written by either medical doctors or laypersons. Linguistic Inquiry and Word Count (LIWC) analyses show that messages were perceived as more expert if they contained more words (an indicator of uncertainty reduction), fewer I-pronouns and anxiety-related words (indicators of psychological distancing), and more long words and negations (indicators of cognitive complexity). These linguistic cues explained over a third of the variance in expertise ratings. Although unaware of the author of each message, perceivers were able to discern between messages written by doctors versus laypersons. However, only long words were helpful in making this distinction. Results advance the literature on linguistic correlates of psychological processes.|expertise; linguistic cues; online medical advice; LIWC; health communication|HEALTH INFORMATION; LANGUAGE USE; SUBCLINICAL DEPRESSION; INDIVIDUAL-DIFFERENCES; LAY ASSESSMENT; TEXT ANALYSIS; DECEPTION; COMMUNICATION; CREDIBILITY; INTERNET|Communication; Linguistics; Psychology, Social|10|1|35
A system for formative assessment and monitoring of students' progress|2014|Assessment plays a central role in any educational process as a way of evaluating the students' knowledge on the concepts associated with learning objectives. The assessment of free-text answers is a process that, besides being very costly in terms of time spent by teachers, may lead to inequities due to the difficulty in applying the same evaluation criteria to all answers. This paper describes a system composed by several modules whose main goal is to work as a formative assessment tool for students and to help teachers creating and assessing exams as well monitoring students' progress. The system automatically creates training exams for students to practice based on questions from previous exams and assists teachers in the creation of evaluation exams with various kinds of information about students' performance. The system automatically assesses training exams to give automatic feedback to students. The correction of free-text answers is based on the syntactic and semantic similarity between the student answers and various reference answers, thus going beyond the simple lexical matching. For this, several pre-processing tasks are performed in order to reduce each answer to its more manageable canonical form. Besides the syntactic and semantic similarity between answers, the way the teacher evaluates the answers is also acquired. To accomplish that, the assessment is done using sub scores defined by the teacher concerning parts of the answer or its subgoals. The system has been trained and tested on exams manually graded by History teachers. There is a good correlation between the evaluation of the instructors and the evaluation performed by our system. (C) 2014 Elsevier Ltd. All rights reserved.|Computer-assisted assessment; Free-text answers; Natural language processing; Semantic meaning; Automatic feedback|FREE-TEXT ANSWERS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|17|2|35
Coevolution of Political Discussion and Common Ground in Web Discussion Forum|2014|Common ground is vital for developing deliberative democracy. The current study employs text mining techniques to measure common ground in online political discussions and examines how the structure of political discussions coevolves with common ground over time. The present study collected 175,960 messages over a period of 13 months, from a popular discussion forum on 2012 U.S. presidential election. Common ground is measured by a semantic similarity network and an interpretive framework network. The former emphasizes shared political knowledge, while the latter emphasizes shared interpretations. In addition, this study explores the coevolutionary process of political discussion and common ground. Results were obtained by employing longitudinal network analysis. They suggest that political discussions could facilitate the achievement of common ground that might further serve as a facilitator of political discussion among the participants.|common ground; political deliberation; social network analysis; text mining|KNOWLEDGE; INTERNET; PARTICIPATION; NETWORKS; TALK|Computer Science, Interdisciplinary Applications; Information Science \& Library Science; Social Sciences, Interdisciplinary|3|2|35
Mining clinical text for signals of adverse drug-drug interactions|2014|Background and objective Electronic health records (EHRs) are increasingly being used to complement the FDA Adverse Event Reporting System (FAERS) and to enable active pharmacovigilance. Over 30\% of all adverse drug reactions are caused by drug-drug interactions (DDIs) and result in significant morbidity every year, making their early identification vital. We present an approach for identifying DDI signals directly from the textual portion of EHRs. Methods We recognize mentions of drug and event concepts from over 50 million clinical notes from two sites to create a timeline of concept mentions for each patient. We then use adjusted disproportionality ratios to identify significant drug-drug-event associations among 1165 drugs and 14 adverse events. To validate our results, we evaluate our performance on a gold standard of 1698 DDIs curated from existing knowledge bases, as well as with signaling DDI associations directly from FAERS using established methods. Results Our method achieves good performance, as measured by our gold standard (area under the receiver operator characteristic (ROC) curve >80\%), on two independent EHR datasets and the performance is comparable to that of signaling DDIs from FAERS. We demonstrate the utility of our method for early detection of DDIs and for identifying alternatives for risky drug combinations. Finally, we publish a first of its kind database of population event rates among patients on drug combinations based on an EHR corpus. Conclusions It is feasible to identify DDI signals and estimate the rate of adverse events among patients on drug combinations, directly from clinical text; this could have utility in prioritizing drug interaction surveillance as well as in clinical decision support.|Electronic Health Records; Pharmacovigilance; Drug Interaction; Adverse Reactions; Data Mining; Ontology|SPONTANEOUS REPORTS DATABASE; ELECTRONIC HEALTH RECORDS; REPORTING SYSTEM; EVENTS; FDA; SURVEILLANCE; ASSOCIATIONS; ALGORITHMS; SOFTWARE; ACCURACY|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|40|1|35
Text classification for assisting moderators in online health communities|2013|Objectives: Patients increasingly visit online health communities to get help on managing health. The large scale of these online communities makes it impossible for the moderators to engage in all conversations; yet, some conversations need their expertise. Our work explores low-cost text classification methods to this new domain of determining whether a thread in an online health forum needs moderators' help. Methods: We employed a binary classifier on WebMD's online diabetes community data. To train the classifier, we considered three feature types: (1) word unigram, (2) sentiment analysis features, and (3) thread length. We applied feature selection methods based on chi(2) statistics and under sampling to account for unbalanced data. We then performed a qualitative error analysis to investigate the appropriateness of the gold standard. Results: Using sentiment analysis features, feature selection methods, and balanced training data increased the AUC value up to 0.75 and the F1-score up to 0.54 compared to the baseline of using word unigrams with no feature selection methods on unbalanced data (0.65 AUC and 0.40 F1-score). The error analysis uncovered additional reasons for why moderators respond to patients' posts. Discussion: We showed how feature selection methods and balanced training data can improve the overall classification performance. We present implications of weighing precision versus recall for assisting moderators of online health communities. Our error analysis uncovered social, legal, and ethical issues around addressing community members' needs. We also note challenges in producing a gold standard, and discuss potential solutions for addressing these challenges. Conclusion: Social media environments provide popular venues in which patients gain health-related information. Our work contributes to understanding scalable solutions for providing moderators' expertise in these large-scale, social media environments. (C) 2013 Elsevier Inc. All rights reserved.|Online health communities; Consumer health; Human-computer interaction; Text mining; Health information seeking|CATEGORIZATION; QUESTIONS; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|18|3|35
Identifying medical terms in patient-authored text: a crowdsourcing-based approach|2013|Background and objective As people increasingly engage in online health-seeking behavior and contribute to health-oriented websites, the volume of medical text authored by patients and other medical novices grows rapidly. However, we lack an effective method for automatically identifying medical terms in patient-authored text (PAT). We demonstrate that crowdsourcing PAT medical term identification tasks to non-experts is a viable method for creating large, accurately-labeled PAT datasets; moreover, such datasets can be used to train classifiers that outperform existing medical term identification tools. Materials and methods To evaluate the viability of using non-expert crowds to label PAT, we compare expert (registered nurses) and non-expert (Amazon Mechanical Turk workers; Turkers) responses to a PAT medical term identification task. Next, we build a crowd-labeled dataset comprising 10000 sentences from MedHelp. We train two models on this dataset and evaluate their performance, as well as that of MetaMap, Open Biomedical Annotator (OBA), and NaCTeM's TerMINE, against two gold standard datasets: one from MedHelp and the other from CureTogether. Results When aggregated according to a corroborative voting policy, Turker responses predict expert responses with an F1 score of 84\%. A conditional random field (CRF) trained on 10000 crowd-labeled MedHelp sentences achieves an F1 score of 78\% against the CureTogether gold standard, widely outperforming OBA (47\%), TerMINE (43\%), and MetaMap (39\%). A failure analysis of the CRF suggests that misclassified terms are likely to be either generic or rare. Conclusions Our results show that combining statistical models sensitive to sentence-level context with crowd-labeled data is a scalable and effective technique for automatically identifying medical terms in PAT.|text mining; online health forums; medical term extraction; crowdsourcing|CONSUMER HEALTH VOCABULARY; INFORMATION; UMLS; TERMINOLOGY; WEB|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|14|0|35
Using multiple texts in an integrated writing assessment: Source text use as a predictor of score|2013|Interest in integrated tasks is increasing in second language writing, accompanied by a concern for appropriate interpretation of performances and scores from these tasks. Integrated writing adds an element not found in traditional independent writing: the use of source text material. This study investigates how source text use appears in performances on an integrated writing task, and how it differs across score levels and task topics. Educational Testing Service (ETS) supplied 480 performances on the writing section of the Internet-based Test of English as a Foreign Language (TOEFL iBT) to explore these questions. The integrated TOEFL task involves a comparative summary of listening and reading texts that present differing views on a topic. In this study, multiple regression analysis was used to consider three areas of source text use: (1) the importance of source text ideas that writers included in their summary, (2) the use of ideas from a reading source text and from a listening text, and (3) the borrowing of exact wording from the source texts (verbatim source use). These three areas were analyzed across nine score levels and indicated that score and source use are related. Overall, these features of source text use explained over 50\% of the variance in scores on the reading listening writing task. The use of the listening text and the inclusion of important ideas from source texts explained the most variance, while use of the reading text and verbatim source use were less predictive. The latter two held a negative correlation with score, indicating that the lower scoring essays had more of these features. These findings support the claim that integrated writing assessment elicits academic writing processes, which is reflected by score. High-scoring writers selected important ideas from the source texts and used the listening text as the task prompt instructed. Low scoring writers depended heavily on the reading texts for content and direct copying of words and phrases. These findings support the validity of interpreting integrated task scores as a measure of academic writing but provide a nuanced look at the contribution of certain source use features. (C) 2013 Elsevier Inc. All rights reserved.|Integrated writing; Writing assessment; Source use|ESL STUDENTS; TASK REPRESENTATION; PERCEPTIONS; PERFORMANCE; EAP|Linguistics|20|2|35
EFL learner collaborative interaction in Second Life|2012|This paper reports on the task-based interaction of English as a Foreign Language (EFL) learners in the 3D multiuser virtual environment (MUVE) Second Life. The discussion first explores research on the precursors of MUVEs, text-based 2D virtual worlds known as MOOs. This is followed by an examination of studies on the use of MUVEs in Computer Assisted Language Learning (CALL). The discussion then focuses on an investigation of the Second Life-based text chat of learners located at a university in Japan. Data analysis reveals that the environment, and tasks, elicited types of collaborative interaction hypothesized as beneficial in the sociocultural account of language development. Collaborative interaction identified in the data involved peer-scaffolding focusing on lexis, and correction. The data further showed that the participants actively maintained a supportive atmosphere through the provision of utterances designed to signal interest, and the extensive use of positive politeness. These factors facilitated social cohesion, intersubjectivity, and the consistent production of coherent target language output focused on the tasks. Participant feedback was broadly positive, and indicates that specific features of Second Life such as individual avatars, coupled to the computer-based nature of the interaction, appeared to enhance discourse management, engagement, and participation. The findings suggest that Second Life provides an arena for learner centered social interaction that offers valuable opportunities for target language practice, and the development of autonomy. Areas of potential for future research are identified.|Second Life; MUVE; MOO; interaction; computer mediated communication (CMC); CALL|NEGOTIATION|Education \& Educational Research; Linguistics; Language \& Linguistics|19|3|35
A Semantic-based Intellectual Property Management System (SIPMS) for supporting patent analysis|2011|Patent databases provide valuable information for technology management. However, the rapid growth of patent documents, the lengthy text and the rich of content in technical terminology, and the complicated relationships among the patents, make it taking a lot of human effort for conducting analyses. As a result, an automated system for assisting the inventors in patent analysis as well as providing support in technological innovation is in great demand. In this paper, a Semantic-based Intellectual Property Management System (SIPMS) has been developed for supporting the management of intellectual properties (IP). It incorporates semantic analysis and text mining techniques for processing and analyzing the patent documents. The method differentiates itself from the traditional technological management tools in its knowledge base. Instead of eliciting knowledge from domain experts, the proposed method adopts global patent databases as sources of knowledge. The system enables users to search for existing patent documents or relevant IP documents which are related to a potential new invention and to support invention by providing the relationships and patterns among a group of IP documents. The method has been evaluated by benchmarking with the performance against traditional text mining technique and has successfully been implemented at a selected reference site. (C) 2011 Elsevier Ltd. All rights reserved.|Knowledge management; Knowledge-based system; Semantic analysis; Technology management; Concept extraction; Patent analysis|TECHNOLOGY; COCITATION; INDICATORS; CITATIONS; KNOWLEDGE; INDUSTRY|Automation \& Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical \& Electronic|9|7|35
Inferential processing and story recall in children with communication problems: a comparison of specific language impairment, pragmatic language impairment and high-functioning autism|2002|An investigation is reported into the story comprehension abilities of four groups of children: those with typical specific language impairment (SLI-T), those with pragmatic language impairments who were not autistic (PLI), those with high-functioning autism (HFA) and typically developing controls. The story comprehension task required children to answer questions about the literal content of the story, as well as questions involving two types of inferences: text-connecting and gap-filling. The control children outscored the three clinical groups on story comprehension, but the group means of the clinical groups did not differ. However, categorical examination of the data revealed that children with pragmatic difficulties related to HFA were more likely to have specific inferencing deficits. Error analysis suggested that all children could make inferences, but these were not always relevant to the story context. This supports the notion of weak central coherence underlying deficits in inferencing. There were no group differences on story recall. However, there was a strong relationship between story comprehension and recall, in that those who had better comprehension tended to have better recall. It is concluded that comprehension aids recall by enabling the listener to build a more stable mental representation of the story. The pragmatic deficits seen in autism compromise this process.|autism; inferencing; semantic-pragmatic disorder; SLI; PLI; weak central coherence|HIGH-LEVEL AUTISM; CENTRAL COHERENCE; ASPERGER-SYNDROME; COMPREHENSION; DISORDERS; ADULTS; MIND; INDIVIDUALS; SKILLS; SLI|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|137|2|35
Disciplinary interactions: metadiscourse in L2 postgraduate writing|2004|Metadiscourse is self-reflective linguistic expressions referring to the evolving text, to the writer, and to the imagined readers of that text. It is based on a view of writing as a social engagement and, in academic contexts, reveals the ways writers project themselves into their discourse to signal their attitudes and commitments. In this paper, I explore how advanced second language writers deploy these resources in a high stakes research genre. The paper examines the purposes and distributions of metadiscourse in a corpus of 240 doctoral and masters dissertations totalling four million words written by Hong Kong students. The paper proposes a model of metadiscourse as the interpersonal resources required to present propositional material appropriately in different disciplinary and genre contexts. The analysis suggests how academic writers use language to offer a credible representation of themselves and their work in different fields, and thus how metadiscourse can be seen as a means of uncovering something of the rhetorical and social distinctiveness of disciplinary communities. (C) 2004 Elsevier Inc. All rights reserved.|disciplinary interactions; metadiscourse; L2 postgraduate|ARTICLES; READER|Linguistics|101|2|29
Requirement-oriented core technological components' identification based on SAO analysis|2017|Technologies play an important role in the survival and development of enterprises. Understanding and monitoring the core technological components (e.g., technology process, operation method, function) of a technology is an important issue for researchers to develop R\&D policy and manage product competitiveness. However, it is difficult to identify core technological components from a mass of terms, and we may experience some difficulties with describing complete technical details and understanding the terms-based results. This paper proposes a Subject-Action-Object (SAO)-based method, in which (1) a syntax-based approach is constructed to extract the SAO structures describing the function, relationship and operation in specified topics; (2) a systematic method is built to extract and screen technological components from SAOs; and (3) we propose a ``relevance indicator{''} to calculate the relevance of the technological components to requirements, and finally identify core technological components based on this indicator. Based on the considerations for requirements and novelty, the core technological components identified have great market potential and can be useful in monitoring and forecasting new technologies. An empirical study of graphene is performed to demonstrate the proposed method. The resulting knowledge may hold interest for R\&D management and corporate technology strategies in practice.|Subject-Action-Object (SAO); Patent analysis; Text mining; Technological components identification|EMERGING TECHNOLOGIES; MORPHOLOGY ANALYSIS; NETWORK ANALYSIS; PATENT ANALYSIS; SEMANTIC TRIZ; TRENDS; INTELLIGENCE; INFORMATION; DIRECTION; CELLS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|18|28
The scholarly communication of economic knowledge: a citation analysis of Google Scholar|2016|Citation counts can be used as a proxy to study the scholarly communication of knowledge and the impact of research in academia. Previous research has addressed several important factors of citation counts. In this study, we aim to investigate whether there exist quantitative patterns behind citations, and thus provide a detailed analysis of the factors behind successful research. The study involves conducting quantitative analyses on how various features, such as the author's quality, the journal's impact factor, and the publishing year, of a published scientific article affect the number of citations. We carried out full-text searches in Google Scholar to obtain our data set on citation counts. The data set is then set up into panels and used to conduct the proposed analyses by employing a negative binomial regression. Our results show that attributes such as the author's quality and the journal's impact factor do have important contributions to its citations. In addition, an article's citation count does not only depend on its own properties as mentioned above but also depends on the quality, as measured by the number of citations, of its cited articles. That is, the number of citations of a paper seems to be affected by the number of citations of articles that the particular paper cites. This study provides statistical characteristics of how different features of an article affect the number of citations. In addition, it provides statistical evidence that the number of citations of a scientific article depends on the number of citations of the articles it cites.|Bibliometrics; Citation analysis; Economics|IMPACT; DISCIPLINES; REGRESSION; ARTICLES; JOURNALS; MODELS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|9|28
Enhancing feedback provision through multimodal video technology|2016|Peer-to-peer feedback provision is considered crucial to student learning. However, although the studies on peer feedback abound in the literature, most target the face-to-face or written modality; few investigate the pedagogic potential of videos in enhancing students' engagement in the feedback provision process. The current research project thus bridged the research gap by investigating learner engagement through multimodal video feedback as compared to text-based feedback and by exploring the strategies learners employed as well as the challenges they encountered. A total of 60 English as a Foreign Language (EFL) learners participated in a semester-long video feedback project where they produced 3-min speech video clips and 2-min oral feedback video clips that contained multiple semiotic modes such as visual, verbal, and gestural. Data analyses performed on responses to a custom-designed questionnaire, interview transcripts, and learner reflections led to three major findings. First, learners in general valued the role that video technology played in feedback production and provision, delineating that feedback in the video mode cannot only promote more interaction but also foster more personalized learning and attentive engagement. Second, the study uncovered a number of cognitive and social strategies learners used to ensure fluency and accuracy of their oral feedback, to achieve cognitive goals by efficiently producing the feedback, to observe positively reinforced behaviors from peers, and to cooperate with others to generate ideas for future improvement. Nevertheless, the project revealed some potential challenges associated with feedback development and technical problems. Finally, implications are proposed to facilitate feedback provision experience through video technology. (C) 2016 Elsevier Ltd. All rights reserved.|Video feedback; Multimodality; Peer feedback; Technology-enhanced language learning|FACEBOOK; ENVIRONMENT; STUDENTS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|2|10|28
A Commonsense Knowledge-Enabled Textual Analysis Approach for Financial Market Surveillance|2016|Market surveillance systems (MSSs) are increasingly used to monitor trading activities in financial markets to maintain market integrity. Existing MSSs primarily focus on statistical analysis of market activity data and largely ignore textual market information, including, but not limited to, news reports and various social media. As suggested by both theoretical explorations in finance and prevailing market surveillance practice, unstructured market information holds major yet underexplored opportunities for surveillance. In this paper, we propose a news analysis approach with the help of commonsense knowledge to assess the risk of suspicious transactions identified in market activity analysis. Our approach explicitly models semantic relations between transactions and news articles and provides semantic references to words in news articles. We conducted experiments using data collected from a real-world market and found that our proposed approach significantly outperforms the existing methods, which are based on transaction characteristics or traditional textual analysis methods. Experiments also show that the performance advantage of the proposed approach mainly comes from the modeling of news-transaction relationships. The research contributes to the market surveillance literature and has significant practical implications.|market surveillance; text mining; commonsense knowledge; business intelligence; intelligent financial systems|QUERY EXPANSION; INVESTOR SENTIMENT; MODEL; INFORMATION; LANGUAGE; WORDNET; SYSTEM; TALK; WEB|Computer Science, Interdisciplinary Applications; Operations Research \& Management Science|1|2|28
Understanding health information technology adoption: A synthesis of literature from an activity perspective|2015|The vast body of literature on health information technology (HIT) adoption features considerably heterogeneous factors and demands for a synthesis of the knowledge in the field. This study employs text mining and network analysis techniques to identify the important concepts and their relationships in the abstracts of 979 articles of HIT adoption. Through the lens of Activity Theory, the revealed concept map of HIT adoption can be viewed as a complex activity system involving different users, technologies and tasks at both the individual level and the social level. Such a synthesis not only discloses the current knowledge domain of HIT adoption, but also provides guidance for future research on HIT adoption.|Activity theory; Health information technology; System adoption; Text mining; Network analysis; Literature synthesis|PHYSICIAN ORDER ENTRY; TELEMEDICINE TECHNOLOGY; ACCEPTANCE MODEL; NATIONAL-SURVEY; CARE INDUSTRY; CONCEPT MAP; SYSTEMS; RECORDS; IMPLEMENTATION; SATISFACTION|Computer Science, Information Systems; Computer Science, Theory \& Methods|3|2|28
Computer-mediated communication (CMC) in L2 oral proficiency development: A meta-analysis|2015|The ever growing interest in the development of foreign or second (L2) oral proficiency in a computer-mediated communication (CMC) classroom has resulted in a large body of studies looking at both the direct and indirect effects of CMC interventions on the acquisition of oral competences. The present study employed a quantitative meta-analytic approach to investigate such effects by synthesizing (quasi) experimental studies that provide empirical quantitative data for effect size calculation. A literature search located 25 relevant studies for the final analysis. Each study was independently coded for learner, design and publication characteristics. The averaged effect size was estimated from the included studies. The results of the meta-analysis reveal that communication mediated by computer/technologies produced a moderate positive effect on L2 learners' oral proficiency compared to face-to-face (F2F) communication or no interaction. Furthermore, CMC has roughly similar effect on pronunciation, lexical and syntactic level of oral production; however, it might have a negative impact on fluency and accuracy. This meta-analysis also found that the effect of CMC on oral proficiency depends on several methodological factors such as task type, outcome measurement, treatment length, and assessment task. Major findings of the current meta-analysis include: (1) studies relying on elicited data are superior to those utilizing naturalistic data; (2) reading aloud seems to be the task that could elicit the best oral performance from students; (3) surprisingly, CMC appeared to be harmful for accuracy and fluency; (4) studies that employed decision-making generated the largest effect size, followed by studies that used more than one task type; (5) among the four tasks, jigsaw actually generated a negative effect on oral performance; and (6) as the most popular task employed by primary researchers, opinion-exchange studies produced the smallest effect size. These findings need to be interpreted as exploratory rather than confirmatory since each of them became less trustworthy after taking into consideration numerous other factors such as CMC task and the particular CMC tool used, etc. Future research suggestions are provided and the limitations of this meta-analysis are addressed.|computer-mediated communication; meta-analysis; oral proficiency; second language acquisition; research synthesis; effect size|FOREIGN-LANGUAGE CLASSROOM; FACE-TO-FACE; SYNCHRONOUS-CMC; NEGOTIATED INTERACTION; SPEAKING PROFICIENCY; TEXT; 2ND-LANGUAGE; ACQUISITION; PERFORMANCE; COMPLEXITY|Education \& Educational Research; Linguistics; Language \& Linguistics|4|2|28
Meso-level retrieval: IR-bibliometrics interplay and hybrid citation-words methods in scientific fields delineation|2015|In this position paper, we comment on various approaches to the delineation of scientific fields or domains, a typical prerequisite for a wide class of bibliometric studies. There is growing evidence that this meso-level, between micro targets of typical IR and large disciplines handled by macro-level bibliometric studies, takes full advantage of hybrid approaches. Firstly, delineation tasks gain to combine the a priori thinking of traditional IR, which typically involves clearly targeted expectations, and the a posteriori thinking of bibliometric mapping, where the decisions are built on external structuring of the domain in a wider context. The combination of the two ways of thought is far from new, with IR increasingly building on bibliometric networks for query expansion, and bibliometrics building on IR for evaluating and refining its outcomes. Secondly, delineation benefits from the multi-network perspective, which gives different representations of the scientific topics, usually all the more converging than the objects are dense and well separated. Focusing on two basic networks-words and citations-various sequences or combinations of operations are discussed. Bibliometrics and IR, especially when properly combined in multi-network approaches, provide an efficient toolbox for studies of domains delimitation. It should be recalled however that the context of such studies is often loaded with policy stakes that ask for cautious supervision and consultation processes.|Bibliometrics; Information retrieval; Science mapping; Field delineation; Hybrid textual-citation techniques; Query expansion|INFORMATION-RETRIEVAL; COCITATION ANALYSIS; SEARCH ENGINE; SCIENCE; NETWORKS; TOPICS; TEXT; TERM; PERFORMANCE; DYNAMICS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|6|2|28
Semantic Computing of Moods Based on Tags in Social Media of Music|2014|Social tags inherent in online music services such as Last. fm provide a rich source of information on musical moods. The abundance of social tags makes this data highly beneficial for developing techniques to manage and retrieve mood information, and enables study of the relationships between music content and mood representations with data substantially larger than that available for conventional emotion research. However, no systematic assessment has been done on the accuracy of social tags and derived semantic models at capturing mood information in music. We propose a novel technique called Affective Circumplex Transformation (ACT) for representing the moods of music tracks in an interpretable and robust fashion based on semantic computing of social tags and research in emotion modeling. We validate the technique by predicting listener ratings of moods in music tracks, and compare the results to prediction with the Vector Space Model (VSM), Singular Value Decomposition (SVD), Nonnegative Matrix Factorization (NMF), and Probabilistic Latent Semantic Analysis (PLSA). The results show that ACT consistently outperforms the baseline techniques, and its performance is robust against a low number of track-level mood tags. The results give validity and analytical insights for harnessing millions of music tracks and associated mood data available through social tags in application development.|Semantic analysis; social tags; music; music information retrieval; moods; genres; prediction|INFORMATION-RETRIEVAL; EMOTIONS; MODELS; EXPRESSION; SYSTEMS; TEXT|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|18|1|28
An Automated Framework for Incorporating News into Stock Trading Strategies|2014|In this paper we present a framework for automatic exploitation of news in stock trading strategies. Events are extracted from news messages presented in free text without annotations. We test the introduced framework by deriving trading strategies based on technical indicators and impacts of the extracted events. The strategies take the form of rules that combine technical trading indicators with a news variable, and are revealed through the use of genetic programming. We find that the news variable is often included in the optimal trading rules, indicating the added value of news for predictive purposes and validating our proposed framework for automatically incorporating news in stock trading strategies.|Computer applications; evolutionary computing and genetic algorithms; learning; natural language processing; web text analysis|MERGER ANNOUNCEMENTS; INVESTOR SENTIMENT; PRICE REACTION; MARKET; INFORMATION; LANGUAGE; RULES; FIRMS; DRIFT|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|10|1|28
Form and function of citations in discussion sections of master's theses and research articles|2013|The use of source texts in academic writing has been explored in at least two groups of EAP studies, those on the reading-writing connection in student writing and those on citation practices in disciplinary discourse. In recent years, there have been a growing number of studies on the rhetorical functions of intertextual links in different academic genres such as research articles and theses, and studies have also compared citation use by novice and more established writers. Following a brief analysis of citation forms, this article explores the functions of source text use in the discussion sections of master's theses and research articles from biology using two typologies, one created by Thompson (2001, 2005) and, the second, an expanded model described in this paper, which reflects the rhetorical progression of this part-genre. Previous genre studies have only referred to the use of literature in one move in discussions, ``commenting on results.{''} However, the results of this study show that intertextual links are used for a variety of rhetorical functions throughout discussions in master's theses and journal articles. This article concludes with a discussion of implications from this study for the EAP classroom to facilitate the development of advanced second language writers. (C) 2013 Elsevier Ltd. All rights reserved.|Academic writing; Source text; Intertextual; Citations; master's thesis; Genre|DISCOURSE ANALYSIS; CONSTRUCTION; DISCIPLINARY; KNOWLEDGE; TASK|Education \& Educational Research; Linguistics; Language \& Linguistics|15|2|28
Natural language processing: State of the art and prospects for significant progress, a workshop sponsored by the National Library of Medicine|2013|Natural language processing (NLP) is crucial for advancing healthcare because it is needed to transform relevant information locked in text into structured data that can be used by computer processes aimed at improving patient care and advancing medicine. In light of the importance of NLP to health, the National Library of Medicine (NLM) recently sponsored a workshop to review the state of the art in NLP focusing on text in English, both in biomedicine and in the general language domain. Specific goals of the NLM-sponsored workshop were to identify the current state of the art, grand challenges and specific roadblocks, and to identify effective use and best practices. This paper reports on the main outcomes of the workshop, including an overview of the state of the art, strategies for advancing the field, and obstacles that need to be addressed, resulting in recommendations for a research agenda intended to advance the field. (C) 2013 The Authors. Published by Elsevier Inc. All rights reserved.|Natural language processing; Biomedical language processing|CLINICAL TEXT; INFORMATION EXTRACTION; DE-IDENTIFICATION; BIOMEDICAL TEXT; SYSTEM; PNEUMONIA; KNOWLEDGE; DATABASE; BIOLOGY; TOOL|Computer Science, Interdisciplinary Applications; Medical Informatics|35|1|28
The development of source use by international postgraduate students|2013|It is widely accepted that learning to use sources is difficult, especially for international postgraduate students, but to date, few longitudinal studies have been carried out in this area. Therefore, this two-year UK-based study aims to help fill this gap by examining the source use of three Chinese postgraduate students of business, technology and public relations. Data was gathered over four iterations through a Pre-Master's EAP programme and subsequent Master's degree, in order to investigate the development of source use on both EAP and Master's programmes. Four features of source use in the assignments citation, paraphrasing, reporting verbs and attribution - were analysed over the period. Analysis of the results shows that participants started at different points, progressed differently, and did not all reach a competent level. Participants also developed some individual strategies in their source use, such as relying on a small range of features, overcitation and copying sections of attributed text, especially internet sources. The findings offer an insight into student practices and suggest the need for greater and more continuous pedagogical support to enable students to achieve competence in source use. (C) 2013 Elsevier Ltd. All rights reserved.|Postgraduate; Citation; Reporting verbs; Paraphrase; Attribution; Academic writing|ATTRIBUTION; PLAGIARISM; LANGUAGE; CITATION; WRITERS|Education \& Educational Research; Linguistics; Language \& Linguistics|18|1|28
Transforming Wikipedia into a large scale multilingual concept network|2013|A knowledge base for real-world language processing applications should consist of a large base of facts and reasoning mechanisms that combine them to induce novel and More complex information. This paper describes an approach to deriving such a large scale and multilingual resource by exploiting several facets of the on-line encyclopedia Wikipedia. We show how we can build upon Wikipedia's existing network of categories and articles to automatically discover new relations and their instances. Working on top of this network allows for added information to influence the network, and be propagated throughout, it using inference mechanisms that connect different pieces of,existing knowledge. We then exploit this gained information to discover new relations that refine some of those found the previous step: The result is a network containing approximately 3.7 Million concepts with lexicalizations in numerous languages and 49+ Million relation instances. Intrinsic and extrinsic evaluations show that this is a high quality resource and beneficial to various NLP tasks. (C) 2012 Elsevier B.V. All rights reserved.|Knowledge base; Multilinguality; Knowledge acquisition|SEMANTIC RELATEDNESS; WORDNET; DBPEDIA; WEB|Computer Science, Artificial Intelligence|21|0|28
Collaborative Writing Support Tools on the Cloud|2011|Academic writing, individual or collaborative, is an essential skill for today's graduates. Unfortunately, managing writing activities and providing feedback to students is very labor intensive and academics often opt out of including such learning experiences in their teaching. We describe the architecture for a new collaborative writing support environment used to embed such collaborative learning activities in engineering courses. iWrite provides tools for managing collaborative and individual writing assignments in large cohorts. It outsources the writing tools and the storage of student content to third party cloud-computing vendors (i.e., Google). We further describe how using machine learning and NLP techniques, the architecture provides automated feedback, automatic question generation, and process analysis features.|Collaborative learning tools; homework support systems; intelligent tutoring systems; peer reviewing|COORDINATION; EXPERIENCES; SCIENCE|Computer Science, Interdisciplinary Applications; Education \& Educational Research|46|4|28
EFL learners' use of online reading strategies and comprehension of texts: An exploratory study|2009|This study investigated EFL learners' online reading strategies and the effects of strategy use on comprehension. To fulfill the purposes of this study, a Web-based reading program, English Reading Online, was created. Thirty applied English majors, divided into a high group and a low group based on their proficiency levels, were asked to read four authentic online texts; two were appropriate to the students' level of proficiency, and two were more difficult. Results from data analysis showed that the use of support strategies dominated the strategy use and contributed to most of the comprehension gains, but an exclusive dependence on support strategies did not successfully predict the increase in scores on main ideas and details when the students were reading more challenging texts. On the whole, the use of global strategies significantly contributed to better comprehension, especially for low proficiency students. (C) 2008 Elsevier Ltd. All rights reserved.|Teaching/learning strategies; Post-secondary education; Pedagogical issues; Improving classroom teaching|STUDENTS; READERS; KNOWLEDGE; LITERACY; ENGLISH; L1|Computer Science, Interdisciplinary Applications; Education \& Educational Research|42|5|28
Quantifying evidence in forensic authorship analysis|2007|The judicial interest in `scientific' evidence has driven recent work to quantify results for forensic linguistic authorship analysis. Through a methodological discussion and a worked example this paper examines the issues which complicate attempts to quantify results in work. The solution suggested to some of the difficulties is a sampling and testing strategy which helps to identify potentially useful, valid and reliable markers Of authorship. An important feature of the sampling strategy is that these markers identified as being generally valid and reliable are retested for use in specific authorship analysis cases. The suggested approach for drawing quantified conclusions combines discriminant function analysis and Bayesian likelihood measures. The worked example starts with twenty comparison texts for each of three potential authors and then uses a progressively smaller comparison corpus, reducing to fifteen, ten,five and finally three texts per author. This worked example demonstrates how reducing the amount of data affects the way conclusions can be drawn. With greater numbers of reference texts quantified and safe attributions are shown to be possible, but as the number of reference texts reduces the analysis shows how the conclusion which should be reached is that no attribution can be made. The testing process at no point results in instances Of a misattribution.|forensic linguistics; authorship analysis; error; sampling; discriminant analysis; Bayes theorem|IDENTIFICATION|Criminology \& Penology; Linguistics|30|3|28
Combining e-books with mind mapping in a reciprocal teaching strategy for a classical Chinese course|2018|Chinese texts contain the essence of traditional Chinese culture and humanistic spirit, although they are obscure and difficult to understand. The integration of e-books into language learning can play a positive role and improve reading comprehension because of the diversified support tools and features of multimedia interaction in e-books. Therefore, this study investigated the teaching of classical Chinese with a combination of e-books, reciprocal teaching, and mind mapping; the effects of this approach on reading comprehension and knowledge sharing were explored. The sample consisted of two tenth-grade classes of a vocational school. Both groups received the reciprocal teaching strategy with mind mapping. The control group received traditional paper books; the experimental group received e-books. Quantitative and qualitative analyses were used in this study. The results were as follows. (1) Classical Chinese reading comprehension aspect: The experimental group performed more satisfactorily than did the control group, indicating that the integration of the e-book resulted in this measurable improvement by enhancing learners' reading comprehension. (2) Knowledge sharing aspect: The pretest and posttest scores significantly differed between the experimental and control groups, indicating that diversified support tools can promote knowledge sharing. (3) Mind-mapping aspect: the scores of the whole structure (color and image), association skills, and the contents of the articles were more satisfactory in the experimental group than in the control group. (4) Learners had a positive attitude toward the combination of e-books, reciprocal teaching, and mind mapping. (C) 2017 Elsevier Ltd. All rights reserved.|Applications in subject areas; Teaching/learning strategies; Improving classroom teaching|ELEMENTARY-SCHOOL STUDENTS; READING-COMPREHENSION; STORY COMPREHENSION; EMERGENT LITERACY; ELECTRONIC BOOKS; MAPS; KINDERGARTENERS; VOCABULARY; CLASSROOM; AWARENESS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|0|27|27
A cloud-enabled automatic disaster analysis system of multi-sourced data streams: An example synthesizing social media, remote sensing and Wikipedia data|2017|Social media streams and remote sensing data have emerged as new sources for tracking disaster events, and assessing their damages. Previous studies focus on a case-by-case approach, where a specific event was first chosen and filtering criteria (e.g., keywords, spatiotemporal information) are manually designed and used to retrieve relevant data for disaster analysis. This paper presents a framework that synthesizes multi-sourced data (e.g., social media, remote sensing, Wikipedia, and Web), spatial data mining and text mining technologies to build an architecturally resilient and elastic solution to support disaster analysis of historical and future events. Within the proposed framework, Wikipedia is used as a primary source of different historical disaster events, which are extracted to build an event database. Such a database characterizes the salient spatiotemporal patterns and characteristics of each type of disaster. Additionally, it can provide basic semantics, such as event name (e.g., Hurricane Sandy) and type (e.g., flooding) and spatiotemporal scopes, which are then tuned by the proposed procedures to extract additional information (e.g., hashtags for searching tweets), to query and retrieve relevant social media and remote sensing data for a specific disaster. Besides historical event analysis and pattern mining, the cloud-based framework can also support real-time event tracking and monitoring by providing on-demand and elastic computing power and storage capabilities. A prototype is implemented and tested with data relative to the 2011 Hurricane Sandy and the 2013 Colorado flooding. (C) 2017 Elsevier Ltd. All rights reserved.|Disaster coordination and relief; Disaster management|FRAMEWORK; CLUSTERS; HAZARDS; TWITTER|Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research \& Management Science|0|27|27
Predicting the helpfulness of online reviews using a scripts-enriched text regression model|2017|In this paper, we examine the utility of script analysis for predicting the helpfulness of online customer reviews. We employ the lens of cognitive scripts and posit that people share a cognitive script for what constitutes a helpful review in a given domain. Conceptually, a script includes the salient elements that readers look for before determining whether a review is helpful. To operationalize the construct of cognitive script, we seek the help of human annotators and ask them to highlight phrases that they believe are important for determining review helpfulness. The words in the annotated phrases are collected and become part of the script lexicon for a given domain. The lexicon entries represent the shared conception of essential elements, which are key to the evaluation of review helpfulness. We employ the words in the script lexicon as features in a text regression model to predict review helpfulness. Furthermore, we develop and empirically validate a new approach for combining script analysis and dimension reduction. The purpose of the study is to propose a new method to predict review helpfulness and to evaluate the effectiveness and efficiency of the scripts-enriched model. To demonstrate the efficacy of the scripts enriched model, we compare it with benchmark models - a Baseline model and a bag-of-words (BOW) model. The results show that the scripts-enriched text regression model not only produces the highest accuracy, but also the lowest training, testing, and feature selection times. (C) 2016 Elsevier Ltd. All rights reserved.|Business intelligence; Online customer reviews; Review helpfulness; Script theory; Human annotation; Text regression|WORD-OF-MOUTH; PRODUCT REVIEWS; SYSTEMS; FEATURES; QUALITY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|1|13|27
Sentiment analysis in financial texts|2017|The growth of financial. texts in the wake of big data has challenged most organizations and brought escalating demands for analysis tools. In general, text streams are more challenging to handle than numeric data streams. Text streams are unstructured by nature, but they represent collective expressions that are of value in any financial decision. It can be both daunting and necessary to make sense of unstructured textual data. In this study, we address key questions related to the explosion of interest in how to extract insight from unstructured data and howto determine if such insight provides any hints concerning the trends of financial markets. A sentiment analysis engine (SAE) is proposed which takes advantage of linguistic analyses based on grammars. This engine extends sentiment analysis not only at the word token level, but also at the phrase level within each sentence. An assessment heuristic is applied to extract the collective expressions shown in the texts. Also, three evaluations are presented to assess the performance of the engine. First, several standard parsing evaluation metrics are applied on two treebanks. Second, a benchmark evaluation using a dataset of English movie review is conducted. Results show our SAE outperforms the traditional bag of words approach. Third, a financial text stream with twelve million words that aligns with a stock market index is examined. The evaluation results and their statistical significance provide strong evidence of a long persistence in the mood time series generated by the engine. In addition, our approach establishes grounds for belief that the sentiments expressed through text streams are helpful for analyzing the trends in a stock market index, although such sentiments and market indices are normally considered to be completely uncorrelated. (C) 2016 Elsevier B.V. All rights reserved.|Text analysis; Financial time series; Decision support systems|INVESTOR SENTIMENT; TIME-SERIES; VOLATILITY; NEWS; INFORMATION; MANAGEMENT; RETURNS; MARKET; IMPACT|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|2|11|27
To what extent is the Academic Vocabulary List relevant to university student writing?|2016|This paper investigates the use of Academic Vocabulary List (D. Gardner \& Davies, 2014) items in successful university study writing. Overall, levels of use of AVL items are high, and increase as students progress through the years of undergraduate and taught postgraduate study, suggesting that it may be a useful resource. However, significant variation is found across text types and disciplines. While the former is relatively minor, the latter is extensive, suggesting the list is more relevant to some student writers than others. An analysis by items indicates that around half of the words on the list are used very little. Moreover, the items which are frequent differ across disciplines. However, a small core of 427 items was found to be frequent across 90\% of disciplines. This suggests that a generic productive academic vocabulary does exist, but that it is smaller in scope than the full Academic Vocabulary List. (C) 2016 Elsevier Ltd. All rights reserved.|Academic vocabulary; EAP; Vocabulary; Word lists; Corpus linguistics; Academic writing|RESEARCH ARTICLES; FREQUENCY|Linguistics|1|5|27
A critical evaluation of text difficulty development in ELT textbook series: A corpus-based approach using variability neighbor clustering|2016|Although the importance of English Language Teaching (ELT) textbooks is widely acknowledged, previous evaluation of ELT materials has paid little attention to the appropriateness of the text difficulty development in a textbook series. The present study aims to assess the progression of text difficulty in different textbook series in Taiwan, the rationale of which is argued to be generalizable to other ELT contexts. Specifically, there are two methodological emphases. First, text difficulty has been quantitatively measured by the BNC corpus-based frequency lists and a comprehensive set of well-established readability formulas, considering both vocabulary and structure complexity of the texts; second, a clustering-based statistical algorithm variability neighbor clustering is utilized to identify the developmental stages in text difficulty on an empirical basis. This corpus based computational method not only objectively determines the developmental gaps in a textbook series, but also identifies the direction of the difficulty progression in vocabulary and structure complexity. This rigorous textbook evaluation provides a common framework for the assessment of text difficulty progression in the ELT materials. Several pedagogical implications are drawn for EFL learners and teachers as well as ELT textbook developers. (C) 2016 Elsevier Ltd. All rights reserved.|Corpus-based analysis; Readability; Text difficulty; Clustering; Textbooks; Word lists; Vocabulary coverage|READABILITY; VOCABULARY; LINGUISTICS; LANGUAGE; FREQUENCY; YARDSTICK; FORMULA; AUTHORS|Education \& Educational Research; Linguistics|1|6|27
The effect of online summary assessment and feedback system on the summary writing on 6th graders: The LSA-based technique|2016|Studies on teaching of reading strategies have found that summarizing is of tremendous help to reading comprehension. However grading students' summary writings is laborious, but given the importance of summarizing, an effective summarizing learning module is important. This study developed an automatic summary assessment and feedback system based on Latent Semantic Analysis (LSA) to provide score, concept and semantic feedback, and then investigated the effects of concept and semantic feedback on the writing of summaries by students in the sixth grade. The design involved two between-subject factors: semantic feedback (with, without) and concept feedback (with, without). 120 sixth-grade students from an elementary school were recruited for the study, and then were randomly assigned to each group. The overall results demonstrated the effectiveness of the proposed system in improving the summary writing skills of students. The effects of semantic feedback and concept feedback were also discussed. (C) 2016 The Authors. Published by Elsevier Ltd.|Elementary education; Evaluation methodologies; Intelligent tutoring systems; Teaching/learning strategies|LATENT SEMANTIC ANALYSIS; TEXT COMPREHENSION; INSTRUCTION; STUDENTS; LEARNER; SKILL|Computer Science, Interdisciplinary Applications; Education \& Educational Research|3|1|27
The role of idioms in sentiment analysis|2015|In this paper we investigate the role of idioms in automated approaches to sentiment analysis. To estimate the degree to which the inclusion of idioms as features may potentially improve the results of traditional sentiment analysis, we compared our results to two such methods. First, to support idioms as features we collected a set of 580 idioms that are relevant to sentiment analysis, i.e. the ones that can be mapped to an emotion. These mappings were then obtained using a web-based crowdsourcing approach. The quality of the crowdsourced information is demonstrated with high agreement among five Independent annotators calculated using Krippendorffs alpha coefficient (alpha = 0.662). Second, to evaluate the results of sentiment analysis, we assembled a corpus of sentences in which idioms are used in context. Each sentence was annotated with an emotion, which formed the basis for the gold standard used for the comparison against two baseline methods. The performance was evaluated in terms of three measures precision, recall and F-measure. Overall, our approach achieved 64\% and 61\% for these three measures in two experiments improving the baseline results by 20 and 15 percent points respectively. F-measure was significantly improved over all three sentiment polarity classes: Positive, Negative and Other. Most notable improvement was recorded in classification of positive sentiments, where recall was improved by 45 percent points in both experiments without compromising the precision. The statistical significance of these improvements was confirmed by McNemar's test. (C) 2015 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).|Emotion recognition; Sentiment analysis; Natural language processing; User-generated content; Tagging|STRENGTH DETECTION; CONSTRUCTION; EMOTION; TEXT|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|4|1|27
Teacher assessment of grammatical ability in second language academic writing: A case study|2014|In the language assessment literature, grammatical ability is widely accepted as a key component of second language (L2) ability in general and L2 writing ability in particular. Indicators of grammatical ability have been investigated in L2 writing research, but the indicators L2 writing teachers attend to when determining grammatical ability levels of their students have not been studied. Furthermore, there is no research on what students know about their teachers' assessment criteria and how that knowledge might affect their writing and learning process. This mixed methods triangulation study examines these questions in university L2 academic writing classes through a quantitative text-based analysis of academic essay exams, student questionnaires, and teacher and student interviews. The combined results of all data sources indicate that the teachers in this study focus primarily on accuracy when assessing grammatical ability. This leads to risk avoidance behaviour by students and may have a negative impact on their learning as students adapt their writing to meet above all their teachers' expectations for grammatical accuracy. (C) 2014 Elsevier Inc. All rights reserved.|Second language writing; Academic writing; Grammatical ability; Assessment criteria; Rating scales|SYNTACTIC COMPLEXITY; HOLISTIC EVALUATION; ACCURACY; FLUENCY; PROFICIENCY; SCALE|Linguistics|3|1|27
NCBI disease corpus: A resource for disease name recognition and concept normalization|2014|Information encoded in natural language in biomedical literature publications is only useful if efficient and reliable ways of accessing and analyzing that information are available. Natural language processing and text mining tools are therefore essential for extracting valuable information, however, the development of powerful, highly effective tools to automatically detect central biomedical concepts such as diseases is conditional on the availability of annotated corpora. This paper presents the disease name and concept annotations of the NCBI disease corpus, a collection of 793 PubMed abstracts fully annotated at the mention and concept level to serve as a research resource for the biomedical natural language processing community. Each PubMed abstract was manually annotated by two annotators with disease mentions and their corresponding concepts in Medical Subject Headings (MeSH(R)) or Online Mendelian Inheritance in Man (OMIM(R)). Manual curation was performed using PubTator, which allowed the use of pre-annotations as a pre-step to manual annotations. Fourteen annotators were randomly paired and differing annotations were discussed for reaching a consensus in two annotation phases. In this setting, a high inter-annotator agreement was observed. Finally, all results were checked against annotations of the rest of the corpus to assure corpus-wide consistency. The public release of the NCBI disease corpus contains 6892 disease mentions, which are mapped to 790 unique disease concepts. Of these, 88\% link to a MeSH identifier, while the rest contain an OMIM identifier. We were able to link 91\% of the mentions to a single disease concept, while the rest are described as a combination of concepts. In order to help researchers use the corpus to design and test disease identification methods, we have prepared the corpus as training, testing and development sets. To demonstrate its utility, we conducted a benchmarking experiment where we compared three different knowledge-based disease normalization methods with a best performance in F-measure of 63.7\%. These results show that the NCBI disease corpus has the potential to significantly improve the state-of-the-art in disease name recognition and normalization research, by providing a high-quality gold standard thus enabling the development of machine-learning based approaches for such tasks. The NCBI disease corpus, guidelines and other associated resources are available at: http://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/. Published by Elsevier Inc.|Disease name recognition; Named entity recognition; Disease name normalization; Corpus annotation; Disease name corpus|ANNOTATED CORPUS; INFORMATION EXTRACTION; BIOMEDICAL LITERATURE; ENTITY RECOGNITION; GENE NORMALIZATION; TEXT; SYSTEM; ONTOLOGY; UMLS; TASK|Computer Science, Interdisciplinary Applications; Medical Informatics|53|4|27
Narrative and ideologies of violence against women: The Legend of the Black Lagoon|2013|The complete eradication of violence against women remains a challenge for 21st-century societies. In Spain 606 women were killed by their partners or ex-partners in the period 2003-2011 inclusive. Figures like these make this phenomenon a very serious social problem which requires intervention at a plurality of levels. The language used in narratives about these issues is very important. It can be an additional factor that contributes to the transmission of sexism and the perpetuation of indirect sexist ideologies that naturalize violence against women. This article presents a critical stylistics analysis of one such narrative from a feminist point of view. It is a text displayed at a Visitors' Centre in Spain to show local culture to children and the tourists who visit the area. Applying a combined methodology based on feminism, stylistics and critical discourse analysis, the analysis carried out shows how the text conveys an underlying sexist ideology that normalizes violence against women and adopts a victim-blaming stance. The article concludes by stressing the need to raise awareness of the consequences of indirect sexism and naturalized ideologies covert in discourse, particularly in the field of writing for children and in the public domain in general.|Critical discourse analysis; critical stylistics; gender studies; ideology; naming; sexism; transitivity; victim blaming; violence against women; women's studies|RAPE; SEXISM; MYTHS|Linguistics; Language \& Linguistics|0|2|27
Cognitive Abilities Relate to Self-Reported Hearing Disability|2013|Purpose: In this explorative study, the authors investigated the relationship between auditory and cognitive abilities and self-reported hearing disability. Method: Thirty-two adults with mild to moderate hearing loss completed the Amsterdam Inventory for Auditory Disability and Handicap (AIADH; Kramer, Kapteyn, Festen, \& Tobi, 1996) and performed the Text Reception Threshold (TRT; Zekveld, George, Kramer, Goverts, \& Houtgast, 2007) test as well as tests of spatial working memory (SWM) and visual sustained attention. Regression analyses examined the predictive value of age, hearing thresholds (pure-tone averages {[}PTAs]), speech perception in noise (speech reception thresholds in noise {[}SRTNs]), and the cognitive tests for the 5 AIADH factors. Results: Besides the variance explained by age, PTA, and SRTN, cognitive abilities were related to each hearing factor. The reported difficulties with sound detection and speech perception in quiet were less severe for participants with higher age, lower PTAs, and better TRTs. Fewer sound localization and speech perception in noise problems were reported by participants with better SRTNs and smaller SWM. Fewer sound discrimination difficulties were reported by subjects with better SRTNs and TRTs and smaller SWM. Conclusions: The results suggest a general role of the ability to read partly masked text in subjective hearing. Large working memory was associated with more reported hearing difficulties. This study shows that besides auditory variables and age, cognitive abilities are related to self-reported hearing disability.|cognition; hearing loss; speech recognition; speech perception|SPEECH-RECEPTION THRESHOLD; WORKING-MEMORY; INDIVIDUAL-DIFFERENCES; AUDITORY DISABILITY; LISTENING EFFORT; NOISE; AGE; INTELLIGIBILITY; IDENTIFICATION; COMPREHENSION|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|16|3|27
Assessing cultural awareness and linguistic competency of EFL learners in a CMC-based active learning context|2013|Most studies examining Computer Mediated Communication to enhance EFL learning have been limited to evaluating test scores, questionnaires, and interviewing students. This study used a holistic assessment model with qualitative analysis of student reflective essays and descriptive analysis of pre-and post-test oral performance by students in a university English conversation course in Taiwan. The instructional design included Internet videoconferences with a native speaker in the United States and an emphasis on critical thinking about cultural differences and similarities. Although the class was too small for statistical analysis, the students' oral scores improved an average of 44.5\% from the beginning to end of the semester. The analysis of the essays showed that students engaged in reflective thinking about 70\% of the items they observed in their essays, which is evidence of critical thinking. Qualitative analysis revealed four major recurring themes in the students' essays, 1) this was a different kind of class from any they have taken before and the instructional design was helpful, 2) the importance of history and underlying meaning of iconic cultural elements, such as holidays and festivals, 3) their development of a growing multicultural worldview, and 4) their growing confidence as a result of the course. (C) 2013 Elsevier Ltd. All rights reserved.|EFL; CMC; Cultural awareness; Critical text analysis; Holistic assessment; Linguistic competence; Videoconference; Critical thinking; Portfolios|SYNCHRONOUS-CMC; NATIVE SPEAKERS; EDUCATION; PORTFOLIO; TELECOLLABORATION; PROFICIENCY; TECHNOLOGY; CLASSROOMS; QUESTIONS; DISCOURSE|Education \& Educational Research; Linguistics|8|5|27
Computing text semantic relatedness using the contents and links of a hypertext encyclopedia|2013|We propose a method for computing semantic relatedness between words or texts by using knowledge from hypertext encyclopedias such as Wikipedia. A network of concepts is built by filtering the encyclopedia's articles, each concept corresponding to an article. Two types of weighted links between concepts are considered: one based on hyperlinks between the texts of the articles, and another one based on the lexical similarity between them. We propose and implement an efficient random walk algorithm that computes the distance between nodes, and then between sets of nodes, using the visiting probability from one (set of) node(s) to another. Moreover, to make the algorithm tractable, we propose and validate empirically two truncation methods, and then use an embedding space to learn an approximation of visiting probability. To evaluate the proposed distance, we apply our method to four important tasks in natural language processing: word similarity, document similarity, document clustering and classification, and ranking in information retrieval. The performance of the method is state-of-the-art or close to it for each task, thus demonstrating the generality of the knowledge resource. Moreover, using both hyperlinks and lexical similarity links improves the scores with respect to a method using only one of them, because hyperlinks bring additional real-world knowledge not captured by lexical similarity. (C) 2012 Elsevier B.V. All rights reserved.|Text semantic relatedness; Distance metric learning; Learning to rank; Random walk; Text classification; Text similarity; Document clustering; Information retrieval; Word similarity|NATURAL-LANGUAGE; SIMILARITY; WIKIPEDIA; WORDNET; SEARCH; WEB|Computer Science, Artificial Intelligence|23|0|27
From EFL to English as an international and scientific language: analysing Taiwan's high-school English textbooks in the period 1952-2009|2012|Using both quantitative and qualitative content analysis of Taiwan's high-school English textbooks, this study aimed to investigate the projected roles of English in Taiwan's high-school English textbooks over the past 50 years. A total of 1072 lessons from 14 textbook versions dating from 1952 to 2009 were analysed. The results show that the percentages of Anglo-American lessons peaked in the 1970s at 56\% and gradually declined to 30\% in 2009. The percentages of local lessons peaked in the late 1990s at 14\%, but dropped to 6\% in 2009. These changes correspond to the socio-political changes in Taiwan. Intercultural and universal lessons increased steadily through the years and appear likely to be the main types of English lessons in the future. The genres in the textbook lessons changed from those of literature and morality lessons to neutral explanations and scientised text. The subtext of `idealized model of society' hidden in Taiwan's high-school English textbooks gradually shifted from that of American society to that of a world society, manifesting the changing role of English in Taiwan from a foreign language to an international and scientific language.|global English; EFL textbook; EIL; intercultural; Taiwan; English language teaching|KOREA|Education \& Educational Research; Linguistics; Language \& Linguistics|7|5|27
An intercultural analysis of metadiscourse features in research articles written in English and in Spanish|2011|In the last few decades the interpersonal nature of academic communication has been stressed in English for Academic Purposes literature. Taking metadiscourse as the analytical framework, this paper focuses on the cross-cultural analysis of interpersonally driven features in research article writing in a single discipline, Business Management. It aims at analysing to what extent the different contexts (i.e. the US international and the Spanish national) influence the strategic use of metadiscourse features in this discipline. The analysis is based on a corpus of 24 research articles from this discipline: 12 of them written in English by scholars based at North-American institutions and published in international journals, and another 12 written in Spanish by Spanish scholars and published in national journals. Significant differences are reported on the overall frequency of metadiscourse features as well as on the particular incidence of some categories in the two sub-corpora. The particular linguistic/cultural contexts of publication seem to influence scholars' rhetorical choices when writing their research articles. New knowledge appears to be interpersonally negotiated in different terms in research articles in the two cultural contexts within this disciplinary domain. (C) 2011 Elsevier B.V. All rights reserved.|Academic discourse; Genre writing; English for Academic Purposes; Intercultural rhetoric; Interpersonality; Metadiscourse|MANAGEMENT; ABSTRACTS; CRITICISM; TEXTS|Linguistics; Language \& Linguistics|23|1|27
Construction and analysis of educational assessments using knowledge maps with weight appraisal of concepts|2010|The rapid advance of information and communication technologies (ICT) has important impacts on teaching and learning, as well as on the educational assessment. Teachers may create assessments utilizing some developed assessment software or test authoring tools. However, problems could occur, such as neglecting key concepts in the curriculum or having disproportionate course topics distribution, when teachers create assessments or test items. This study proposes a novel approach, which uses knowledge map with appraisal of concept weights and other ICTs, and implements an assessment system KMAAS to help primary school teachers in Taiwan, or elsewhere, create educational assessments properly. When compiling an assessment, KMAAS ensures that teachers can include all important course concepts intended for assessing and maintain correct balance between course concepts among test items. It does so first by analyzing course material of the assessment range and displaying a concept-weight-annotated knowledge map which concretize and visualize the importance of and the relationships among concepts in the range. It then analyzes the test sheet which is being complied and displays another similar real-time updated knowledge map containing balance between course concepts among the test items. Teachers may cross-refer to these maps to help them adjust concept balances and even select appropriate test items from test banks. The system has being evaluated in both the accuracy of learning concepts extraction and the degree of user satisfaction, as measured by questionnaires given to the teachers who tested the system. The promising results confirm the feasibility of this system in helping teachers compile their educational assessments easily and precisely. Other results of the formative evaluations on techniques have being used to improve the system in order to make it more effective and efficient. The methodology and technologies KMAAS employed are all well developed and are domain independent, which makes it highly flexible to transfer to other course subject domain too. (C) 2010 Elsevier Ltd. All rights reserved.|Applications in subject areas; Architectures for educational technology system; Elementary education; Human-computer interface; Improving classroom teaching|TECHNOLOGY ACCEPTANCE MODEL; MULTIPLE ASSESSMENT CRITERIA; TEACHERS; TEXT; MANAGEMENT; DIAGNOSIS; SYSTEM; TESTS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|10|4|27
Computer-supported portfolio analysis and comparison using ontology-based patent classification mapping scheme: the case of mobile communication patent pools|2017|Mobile communication patents must conform to LTE-Advanced (called fourth generation or 4G) specifications to be categorized as LTE-A standard essential patents (SEPs). Global LTE-A patent pools, such as Sisvel and Via Licensing, collect SEPs from patent assignees, facilitate the SEP licensing processes, and provide fast-forward technical solutions to licensees. This research develops a computer-supported ontology-based patent classification (ontology-IPC) mapping scheme. Two major LTE-A patent pools (Sisvel and Via Licensing) and a national research project pool provide the case study. The research methodology defines the patent pool profiles using visualization maps for collaborative SEPs licensing and provides critical data to avoid re-inventing technologies and infringing upon existing intellectual property. The research enables mobile network and device developers to work cooperatively to develop fast, dependable, and interoperable products and services. The ontology-IPC analysis of the data demonstrates the approach's versatile application to support national project research reviews.|LTE-advanced; Patent pool; International Patent Classification (IPC); Text mining; Ontology|DESIGN; TECHNOLOGY; EVOLUTION; NETWORK; LTE|Computer Science, Information Systems; Computer Science, Theory \& Methods|0|17|26
The implementation of task-based teaching in an online Chinese class through web conferencing|2016|From both interactionist and sociocultural perspectives on second language acquisition (SLA), learner-learner interactions provide opportunities for negotiation of meaning, which may facilitate their second language learning. There is yet a paucity of studies on learners' multimodal interaction and collaborative language learning investigating the effect of task design in web conferencing-based environments. This empirical research has a dual aim: 1) to explore how the teacher and learners use multiple modes (video, audio, text chat, voting, raised-hand function, emotions and whiteboard) to make meaning in a web conferencing environment, and 2) to examine whether learners engage in negotiation of meaning in the completion of tasks in the web conferencing environment. In this study, a group of elementary level Chinese students conducted two online sessions one jigsaw task and one information-gap task-delivered by a web conferencing platform (Blackboard Collaborate). A mixed methods approach was adopted in that a) the teacher's and learners' multimodal interactions were recorded and analysed quantitatively in order to illustrate participation patterns, b) Varonis and Gass's (1985) model was used to identify instances of negotiation of meaning in learner-learner interactions through an interpretive analysis of the data. (C) 2016 Elsevier Ltd. All rights reserved.|Web conferencing; Task-based language teaching; Computer-mediated communication; Online Chinese teaching; Multimodality|COMPUTER-ASSISTED CLASSROOM; LANGUAGE CLASSROOM; CONVERSATION; NEGOTIATION; DESIGN; MODEL|Education \& Educational Research; Linguistics|1|7|26
A corpus-aided approach for the teaching and learning of rhetoric in an undergraduate composition course for L2 writers|2016|This paper illustrates a corpus-aided approach for the teaching and learning of rhetoric in an undergraduate writing course for second language writers. The twenty-one international students in the course read and analyzed texts produced by a local environmental group and an international mining company regarding a proposed copper mine in the U.S. southwest. The textual analysis was enhanced and supplemented by a series of activities using corpus data derived from collections of texts from the opposing groups. The contrastive analyses made possible through the study of texts and corpus data from the sharply distinct groups enabled students to notice, analyze, interpret, and discuss the meaningful and purposeful linguistic and rhetorical variation present in the texts, the corpus data, and the debate. This implementation of localized, specialized corpora comprised of texts with immediate relevance to the students' campus and community provides a means to incorporate corpus study in the writing classroom from a rhetorical perspective. This article details the principles guiding the design of the approach, explains the corpus-aided activities, reports students' attitudes to the use of corpus data in their academic writing classroom, and offers suggestions for implementing similar activities in L2 writing classrooms. (C) 2015 Elsevier Ltd. All rights reserved.|Corpus-aided pedagogy; L2 writing; EAP; Rhetorical awareness|GENRE ANALYSIS; LANGUAGE; CONSULTATION; LINGUISTICS; STUDENT; MOVES|Education \& Educational Research; Linguistics; Language \& Linguistics|4|4|26
Phraseology used to comment on results in the Discussion section of applied linguistics quantitative research articles|2015|This paper presents word clusters used to comment on results in the Discussion section of quantitative research articles in the field of applied linguistics. The corpus linguistic approach was adopted to identify clusters in 124 Discussion texts from leading applied linguistics journals. The identified clusters were then comprehensively analysed in context for their discourse functions. Next, the present study mapped the clusters onto an analytical framework termed the `four-Step model', based on Yang and Allison's (2003) genre-based description of the Commenting on results Move. The study provided a detailed corpus linguistic account of how the clusters were used in specific Steps described in the model. A detailed description of the linguistic features, the internal structure (Move/Step cycles and embedding) and communicative functions of specific Steps in the Commenting on results Move were also presented based on the concordance analysis of the clusters. The findings further suggest that the Use of specific clusters strongly manifests, and is conditioned by, the research article genre. The study has pedagogical implications for academic writing courses for students, especially for those from non-English language backgrounds. (C) 2015 Elsevier Ltd. All rights reserved.|Genre-specific corpus; Corpus linguistic analysis; Research article Discussion section; Phraseology; Cluster; Academic writing|GENRE; MOVES|Linguistics|2|3|26
Does writing development equal writing quality? A computational investigation of syntactic complexity in L2 learners|2014|This study examines second language (L2) syntactic development in conjunction with the effects such development has on human judgments of writing quality (i.e., judgments of both overall writing proficiency and more fine-grained judgments of syntactic proficiency). Essays collected from 57 L2 learners in a longitudinal study were analyzed for growth and scoring patterns using syntactic complexity indices calculated by the computational tool Coh-Metrix. The analyses demonstrate that significant growth in syntactic complexity occurred in the L2 writers as a function of time spent studying English. However, only one of the syntactic feattires that demonstrated growth in the L2 learners was also predictive of human judgments of L2 writing quality. Interpretation of the findings suggest that over the course of a semester, L2 writers produced texts that were increasingly aligned with academic writing (i.e., texts that contain more nouns and phrasal complexity), but that human raters assessed text quality based on structures aligned with spoken discourse (i.e., clausal complexity). Thus, this study finds that the syntactic features that develop in L2 learners may not be the same syntactic features that will assist them in receiving higher evaluations of essay quality. (C) 2014 Elsevier Inc. All rights reserved.|Computational linguistics; L2 writing; Writing development; Writing quality; Syntactic complexity|LANGUAGE; PROFICIENCY; LEVEL; COHESION; STUDENTS; FEATURES; INDEXES; SPOKEN; TEXT|Linguistics|17|4|26
Pragmatic uses of person pro-forms in intercultural financial discourse: A contrastive case study of earnings calls|2014|The important role of person pro-forms in establishing interpersonal relations has long been recognized. During interaction, person pro-forms act as indexicals whose referents are determined by the context in which they are used. This study focuses on the pragmatic functions of first and second-person proforms in earnings calls, now the primary channel for oral financial reporting in the corporate world. Earnings calls consist of presentations by company executives followed by question-and-answer sessions with financial analysts who participate via teleconferencing. A contrastive case study based on the earnings call of an Italian company and a US company was undertaken to provide insights into how person pro-forms are used in ICT-mediated financial discourse when English is used as a common language. Text analysis software was used to descriptively analyze person pro-forms. In addition, the two datasets were manually examined to identify pragmatic functions that could shed light on interpersonal relations and participant roles. Overall, person pro-form usage was closely aligned with the distinct objectives of the participants as either ``information seekers{''} or ``information providers.{''} However, some interesting differences suggest that the Italian executives had a more interpersonal approach to the interaction compared to the American executives. This could be influenced by the importance of relationships in the Italian culture, but could also reflect strategic choices to achieve professional goals. The findings can be used to help both corporate professionals and students of management and finance acquire a better understanding of the pragmatics of person pro-forms, and thus become more effective communicators in intercultural contexts.|financial discourse; intercultural communication; pro-forms; interpersonal pragmatics; professional communication; corpus linguistics|HONG-KONG; BUSINESS; PRESENTATIONS; DISCLOSURE; ENGLISH|Linguistics; Language \& Linguistics|0|3|26
The Textual Contents of Media Reports of Information Security Breaches and Profitable Short-Term Investment Opportunities|2013|Information security-related incidents continue to make headlines. Interestingly, researchers have found mixed results when attempting to associate reports of information security breaches with changes in the affected firm's stock price. This research delves further into this puzzle by investigating the association between the textual contents of information security breach media reports and the stock price, as well as the trading volume reactions of the affected firm(s) around the breach announcement day. Our findings suggest that when the textual contents of breach reports provide more detailed information regarding the incidents, a more consistent belief is formed by the market about the negative impact of the reported security incident on the firm's business value. However, when there is a lack of specific information regarding the reported breach, the market does not seem to reach consensus on the impact of reported security incidents. We further demonstrate that different perceptions exist among general and sophisticated investors regarding the impact of reported information security incidents on a firm's future performance as demonstrated by changes in trading volume. By exploiting the different perceptions among investors, we form a trading strategy to demonstrate that, on average, one can make about 300\% annual profit around the breach announcement day.|information security; breach announcements; text mining; decision tree; sophisticated investors|DECISION-TREE INDUCTION; EARNINGS ANNOUNCEMENTS; TRADING VOLUME; MARKET LIQUIDITY; ANALYST; MANAGEMENT; PRICE; FORECASTS; SIZE; EXPECTATIONS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications|1|3|26
Aging and predicting inferences: A diffusion model analysis|2013|In the domain of discourse processing, it has been claimed that older adults (60-90-year-olds) are less likely to encode and remember some kinds of information from texts than young adults. The experiment described here shows that they do make a particular kind of inference to the same extent that college-age adults do. The inferences examined were ``predictive{''} inferences such as the inference that something bad would happen to the actress for the sentence ``The director and cameraman were ready to shoot close-ups when suddenly the actress fell from the 14th story{''} (McKoon \& Ratcliff, 1986). Participants read sentences like the actress one and then later they were asked to decide whether words that expressed an inference (e.g., ``dead{''}) had or had not appeared explicitly in a sentence. To directly compare older adults' performance to college-age adults' performance, we used a sequential sampling diffusion model (Ratcliff, 1978) to map response times and accuracy onto a single dimension of the strength with which an inference was encoded. On this dimension, there were no significant differences between the older and younger adults. (C) 2012 Elsevier Inc. All rights reserved.|Predictive inference; Aging; Diffusion model|ADULT AGE-DIFFERENCES; WORKING-MEMORY CAPACITY; SITUATION MODELS; OLDER-ADULTS; NARRATIVE COMPREHENSION; MENTAL MODELS; TIME-COURSE; BRIGHTNESS-DISCRIMINATION; LANGUAGE COMPREHENSION; ELABORATIVE INFERENCE|Linguistics; Psychology; Psychology, Experimental|9|0|26
Improved multilevel security with latent semantic indexing|2012|Multilevel security (MLS) is specifically created to protect information from unauthorized access. In MLS, documents are assigned to a security label by a trusted subject e.g. an authorized user and based on this assignment; the access to documents is allowed or denied. Using a large number of security labels lead to a complex administration in MLS based operating systems. This is because the manual assignment of documents to a large number of security labels by an authorized user is time-consuming and error-prone. Thus in practice, most MLS based operating systems use a small number of security labels. However, information that is normally processed in an organization consists of different sensitivities and belongs to different compartments. To depict this information in MLS, a large number of security labels is necessary. The aim of this paper is to show that the use of latent semantic indexing is successful in assigning textual information to security labels. This supports the authorized user by his Manual assignment. It reduces complexity by the administration of a MLS based operating system and it enables the use of a large number of security labels. In future, the findings probably will lead to an increased usage of these MLS based operating systems in organizations. (C) 2012 Elsevier Ltd. All rights reserved.|Information security; Text mining; Data protection; Decision support; Multilevel security|OPERATING CHARACTERISTIC CURVES; ACCESS-CONTROL; INFORMATION SECURITY; CUSTOMER CHURN; TEXT; SYSTEMS; CLASSIFICATION; MODELS; PREDICTION; RETRIEVAL|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|12|1|26
The Effect of Pleasure Reading on Japanese University EFL Learners' Reading Rates|2012|Few second-language (L2) reading studies have examined the relationship between reading large amounts of text and fluency, and those studies that have tend to be problematic in terms of their designs and/or analyses. In order to address this lack of empirical L2 reading fluency research, this study investigates the effects of a 1-year pleasure reading program on the reading rate development of first-year Japanese university students (N = 97). The reading rates and reading comprehension of an Intensive Reading Group and three Pleasure Reading Groups were measured at the beginning and end of the academic year. All Pleasure Reading Groups made greater gains than the Intensive Reading Group, and the two Pleasure Reading Groups that read the most made greater reading rate gains than the Pleasure Reading Group that read the least. Reading one book every 2 weeks or more was the most effective means for promoting reading rate gains for the majority of learners. An additional finding was that reading comprehension was consistently high on both the pretest and posttest; thus, the increased reading rates did not come at the expense of passage comprehension. A final finding was that reading simplified rather than unsimplified texts resulted in greater reading rate gains.|extensive reading; pleasure reading; reading fluency; reading rate; reading speed; second-language reading|COMPREHENSION; AUTOMATICITY; ACQUISITION; PERFORMANCE; FLUENCY; WORDS|Education \& Educational Research; Linguistics|27|0|26
Syntactic structure building in the anterior temporal lobe during natural story listening|2012|The neural basis of syntax is a matter of substantial debate. In particular, the inferior frontal gyrus (IFG), or Broca's area, has been prominently linked to syntactic processing, but the anterior temporal lobe has been reported to be activated instead of IFG when manipulating the presence of syntactic structure. These findings are difficult to reconcile because they rely on different laboratory tasks which tap into distinct computations, and may only indirectly relate to natural sentence processing. Here we assessed neural correlates of syntactic structure building in natural language comprehension, free from artificial task demands. Subjects passively listened to Alice in Wonderland during functional magnetic resonance imaging and we correlated brain activity with a word-by-word measure of the amount syntactic structure analyzed. Syntactic structure building correlated with activity in the left anterior temporal lobe, but there was no evidence for a correlation between syntactic structure building and activity in inferior frontal areas. Our results suggest that the anterior temporal lobe computes syntactic structure under natural conditions. (C) 2010 Elsevier Inc. All rights reserved.|Language; Neuroimaging; Syntax; aTL|FALSE DISCOVERY RATE; EVENT-RELATED FMRI; VISUAL WORD RECOGNITION; SENTENCE COMPREHENSION; WORKING-MEMORY; RELATIVE CLAUSES; AUDITORY-CORTEX; BROCAS AREA; BRAIN; FREQUENCY|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|49|1|26
Data Mining to Generate Adverse Drug Events Detection Rules|2011|Adverse drug events (ADEs) are a public health issue. Their detection usually relies on voluntary reporting or medical chart reviews. The objective of this paper is to automatically detect cases of ADEs by data mining. 115 447 complete past hospital stays are extracted from six French, Danish, and Bulgarian hospitals using a common data model including diagnoses, drug administrations, laboratory results, and free-text records. Different kinds of outcomes are traced, and supervised rule induction methods (decision trees and association rules) are used to discover ADE detection rules, with respect to time constraints. The rules are then filtered, validated, and reorganized by a committee of experts. The rules are described in a rule repository, and several statistics are automatically computed in every medical department, such as the confidence, relative risk, and median delay of outcome appearance. 236 validated ADE-detection rules are discovered; they enable to detect 27 different kinds of outcomes. The rules use a various number of conditions related to laboratory results, diseases, drug administration, and demographics. Some rules involve innovative conditions, such as drug discontinuations.|Adverse drug events (ADEs); data mining; decision trees; electronic health records; patient safety|PHARMACOVIGILANCE; SAFETY; MONITOR; SYSTEMS; ALERTS; ERRORS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical \& Computational Biology; Medical Informatics|27|1|26
Fostering metacognitive genre awareness in L2 academic reading and writing: A case study of pre-service English teachers|2011|Although the concept of metacognition has received considerable attention for its impact on learning across disciplinary areas, it has not been sufficiently discussed in the context of L2 academic reading and writing. In this paper, we bring together two theoretical frameworks, genre analysis and metacognition theory, and discuss the concept of metacognitive genre awareness. Drawing on the analysis of the data collected from a group of pre-service English teachers at a major Swedish university, we examine the process of building this awareness within ESP genre-based academic reading and writing instruction and show how it influences L2 students' ability to interpret and compose academic texts. It was found that all study participants developed declarative (what) and procedural (how) metacognitive knowledge of genre-relevant aspects of academic texts, but only a few demonstrated conditional (when and why) knowledge of the genre in their reading analyses and writing assignments. It is concluded that using a metacognition framework to study L2 academic writing provides us with new insights and practical applications for L2 instruction. (C) 2011 Elsevier Inc. All rights reserved.|L2 academic writing; L2 academic reading; Genre analysis; Metacognition; English for academic purposes|LITERACY; INSTRUCTION; TRADITIONS; FRAMEWORK; LEARNERS; ESL|Linguistics|24|4|26
Can differences in learning strategies explain the benefits of learning from static and dynamic visualizations?|2011|The effects of dynamic and static visualizations in understanding physical principles of fish locomotion were investigated. Seventy-five students were assigned to one of three conditions: a text-only, a text with dynamic visualizations, or a text with static visualizations condition. During learning, subjects were asked to think aloud. Learning outcomes were measured by tests assessing verbal factual knowledge, pictorial recall as well as transfer. Learners in the two visualization conditions outperformed those in the text-only condition for transfer and pictorial recall tasks, but not for verbal factual knowledge tasks. Analyses of the think-aloud protocols revealed that learners had generated more inferences in the visualization conditions as opposed to the text-only condition. These results were mirrored by students' self-reported processing demands. No differences were observable between the dynamic and the static condition concerning any of the learning outcome measures. However, think-aloud protocols revealed an illusion of understanding when learning with dynamic as opposed to static visualizations. Furthermore, learners with static visualizations tended to play the visualizations more often. The results stress the importance of not only using outcome-oriented, but also process-oriented approaches to gain deeper insight into learning strategies when dealing with various instructional materials. (C) 2010 Elsevier Ltd. All rights reserved.|Interactive learning environments; Media in education; Multimedia/hypermedia systems; Teaching/learning strategies|INSTRUCTIONAL-DESIGN; COGNITIVE LOAD; MULTIPLE REPRESENTATIONS; ANIMATION|Computer Science, Interdisciplinary Applications; Education \& Educational Research|34|1|26
Age/order of acquisition effects and the cumulative learning of foreign words A word training study|2011|Early acquired words are processed faster than later acquired words in lexical and semantic tasks Demonstrating such age of acquisition (AoA) effects beyond reasonable doubt and then investigating those effects empirically is complicated by the natural correlation between AoA and other word properties such as frequency and imageability In an effort to find a laboratory analog of AoA effects which would allow such issues to be addressed more easily we conducted three experiments in which participants learned foreign words with some (early) words trained from the outset while other (late) words were introduced some time later then interleaved with the early words Order of acquisition effects were observed in picture naming lexical decision and semantic categorization persisting for several weeks after the end of training The results demonstrate an important role for order of acquisition in the formation of lexical representations that is independent of other factors such as cumulative frequency frequency trajectory and imageability Analyses of cumulative learning effects offer the potential to investigate the differential impact of early and later experiences on the formation of lexical and other mental representations The discovery of order of acquisition effects in word learning also has implications for classroom teaching of second language vocabulary (C) 2010 Elsevier Inc All rights reserved|Age of acquisition; Order of acquisition; Word learning; Frequency; Cumulative frequency; Frequency trajectory; Imageability; Second language|AGE-OF-ACQUISITION; SPELLING-SOUND CONSISTENCY; AFFECTS OBJECT RECOGNITION; LEXICAL-DECISION; NAMING TIMES; RETROACTIVE INTERFERENCE; CONNECTIONIST MODELS; MEMORY CONSOLIDATION; FREQUENCY HYPOTHESIS; DISTRIBUTED PRACTICE|Linguistics; Psychology; Psychology, Experimental|27|1|26
Making words work: Using financial text as a predictor of financial events|2010|We develop a methodology for automatically analyzing text to aid in discriminating firms that encounter catastrophic financial events. The dictionaries we create from Management Discussion and Analysis Sections (MD\&A) of 10-Ks discriminate fraudulent from non-fraudulent firms 75\% of the time and bankrupt from nonbankrupt firms 80\% of the time. Our results compare favorably with quantitative prediction methods. We further test for complementarities by merging quantitative data with text data. We achieve our best prediction results for both bankruptcy (83.87\%) and fraud (81.97\%) with the combined data, showing that that the text of the MD\&A complements the quantitative financial information. (C) 2010 Elsevier B.V. All rights reserved.|Automatic text analysis; Financial event prediction; Management fraud; Bankruptcy; SVM; WordNet|DETERMINANTS; SENTIMENT; DOCUMENTS; EARNINGS; YAHOO; TALK; WEB|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|33|1|26
The use of textual, grammatical and sociolinguistic evidence in forensic text comparison|2010|This article suggests the usefulness of the concept of `idiolectal style' in forensic text comparison and presents evidence that was used by the defence in a forensic authorship attribution case to show that the author of four non-disputed faxes could also be the author of four disputed emails, both sets written in Spanish. Apart from qualitative textual analysis, two different quantitative approaches were undertaken: a) the use of the concepts of markedness and saliency in order to establish the rarity in the frequency and use of two grammatical variables - by comparing their behaviour to the one observed in a general corpus - indicated in both data sets the favourite use of two variants - redundant `yo' and compound periphrastic relative pronoun `el cual', and b) the statistical analysis of sequences of linguistic categories classified and grouped the texts in the two sets under analysis (and also the texts in a control text set from another real forensic case) very closely, showing their discriminatory potential, in particular when the sequences were bigrams, something which would lead to the conclusion that these two text sets were produced by the same author.|IDIOLECTAL STYLE; AUTHORSHIP ATTRIBUTION; FORENSIC LINGUISTICS; SOCIOLINGUISTICS; LANGUAGE CONTACT; SPANISH|AUTHORSHIP ATTRIBUTION; ATTENTION; TERMS|Criminology \& Penology; Linguistics|12|0|26
Biomedical innovation at the laboratory, clinical and commercial interface: A new method for mapping research projects, publications and patents in the field of microarrays|2008|Using the example of microarrays, one of the constitutive technologies of post-genomic biomedicine, this paper introduces a method for analyzing publications, patents and research grants as proxies for ``triple-helix interfaces{''} between university, industry and government activities. Our method creates bridges that allow one to move seamlessly between publication, patent and research project databases that use different fields and formats, and contain different information. These links do not require pre-defined categories in order to search for correspondences between sub-topics or research areas in the three databases. Finally, our results are not restricted to quantitative information but, rather, allow one to carry out qualitative investigations of the content of research activities. Our approach draws on a combination of text-mining and network analysis/mapping software packages. (C) 2008 Elsevier Ltd. All rights reserved.|Microarrays; Biomedical innovation; Triple-helix; University-industry-government relations; Publications; Patents; Research projects; Text-mining; Network analysis; Visualization|TECHNOLOGY; SCIENCE|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|10|2|26
Understanding metacognitive confidence: Insights from judgment-of-learning justifications|2017|This study employed the delayed judgment-of-learning (JOL) paradigm to investigate the content of metacognitive judgments; after studying cue-target word-pairs, participants predicted their ability to remember targets on a future memory test (cued recognition in Experiments 1 and 2 and cued recall in Experiment 3). In Experiment 1 and the confidence JOL group of Experiment 3, participants used a commonly employed 6-point numeric confidence JOL scale (0-20-40-60-80-100\%). In Experiment 2 and the binary JOL group of Experiment 3 participants first made a binary yes/no JOL prediction followed by a 3-point verbal confidence judgment (sure-maybe-guess). In all experiments, on a subset of trials, participants gave a written justification of why they gave that specific JOL response. We used natural language processing techniques (latent semantic analysis and word frequency {[}n-gram] analysis) to characterize the content of the written justifications and to capture what types of evidence evaluation uniquely separate one JOL response type from others. We also used a machine learning classification algorithm (support vector machine {[}SVM]) to quantify the extent to which any two JOL responses differed from each other. We found that: (i) participants can justify and explain their JOLs; (ii) these justifications reference cue familiarity and target accessibility and so are particularly consistent with the two-stage metacognitive model; and (iii) JOL confidence judgements do not correspond to yes/no responses in the manner typically assumed within the literature (i.e. 0-40\% interpreted as no predictions). (C) 2017 Elsevier Inc. All rights reserved.|Metacognition; Judgments-of-learning; Episodic memory; Confidence; Linguistics|SUBJECTIVE EXPERIENCE; RETRIEVAL-PROCESSES; DECISION-MAKING; CUE-FAMILIARITY; MEMORY; UNDERCONFIDENCE; ILLUSIONS; COMPETENCE; BIAS; CONSCIOUSNESS|Linguistics; Psychology; Psychology, Experimental|0|25|25
Analysis of the effect of sentiment analysis on extracting adverse drug reactions from tweets and forum posts|2016|Objective: The abundance of text available in social media and health related forums along with the rich expression of public opinion have recently attracted the interest of the public health community to use these sources for pharmacovigilance. Based on the intuition that patients post about Adverse Drug Reactions (ADRs) expressing negative sentiments, we investigate the effect of sentiment analysis features in locating ADR mentions. Methods: We enrich the feature space of a state-of-the-art ADR identification method with sentiment analysis features. Using a corpus of posts from the DailyStrength forum and tweets annotated for ADR and indication mentions, we evaluate the extent to which sentiment analysis features help in locating ADR mentions and distinguishing them from indication mentions. Results: Evaluation results show that sentiment analysis features marginally improve ADR identification in tweets and health related forum posts. Adding sentiment analysis features achieved a statistically significant F-measure increase from 72.14\% to 73.22\% in the Twitter part of an existing corpus using its original train/test split. Using stratified 10 x 10-fold cross-validation, statistically significant F-measure increases were shown in the DailyStrength part of the corpus, from 79.57\% to 80.14\%, and in the Twitter part of the corpus, from 66.91\% to 69.16\%. Moreover, sentiment analysis features are shown to reduce the number of ADRs being recognized as indications. Conclusion: This study shows that adding sentiment analysis features can marginally improve the performance of even a state-of-the-art ADR identification method. This improvement can be of use to pharmacovigilance practice, due to the rapidly increasing popularity of social media and health forums. (C) 2016 The Authors. Published by Elsevier Inc.|Adverse drug reactions; Social media; Sentiment analysis; Text mining|TWITTER; ONLINE|Computer Science, Interdisciplinary Applications; Medical Informatics|9|6|25
Understanding first-year L2 writing: A lexico-grammatical analysis across L1s, genres, and language ratings|2016|Despite a large number of studies on L2 writing at the university level, few have systematically examined the writing produced by these students within the context of their writing classes (Leki, Cumming, \& Silva, 2008; Silva, 1993). This paper investigates the language used in first-year writing across three L1s (English, Arabic, and Chinese) and two genres (Argumentative and Rhetorical Analysis) as well as its relationship to language ratings. We use a lexico-grammatical approach, identifying the vocabulary and grammar that student writers use (e.g., certain verbs that are used frequently with that complement clauses-I think that ... ) and connecting those patterns to particular functions within texts (e.g., stance and argumentation). The corpus is composed of 120 student papers evenly distributed across the three L1s and two genres. The essays were examined for eight lexico-grammatical features, including traditional measures such as type/token ratio and less typical measures (e.g., adjective-noun combinations). Experienced writing teachers rated the essays for language use in order to account for differences in language ability within the student group. Our results reveal important similarities in the use of lexico-grammatical resources across writers from the three L1 backgrounds, due to their status as developing writers. However, differences in patterns of use across the L1 groups point to variation in the expression of stance in relation to argumentation as well as methods of cohesion. Our findings also show the impact of genre on the lexico-grammatical choices of first-year writers. The results have implications for incorporating a lexico-grammatical approach to writing instruction for L2 writers. (C) 2016 Elsevier Inc. All rights reserved.|L1 Arabic; L1 Chinese; Grammatical complexity; Vocabulary; Stance; Cohesion|SYNTACTIC COMPLEXITY; LEXICAL BUNDLES; ENGLISH; LEVEL; CONSTRUCTION; DISCIPLINARY; ACQUISITION; PROFICIENCY; LEARNERS; STUDENTS|Linguistics|3|8|25
Rethinking bibliometric data concerning gender studies: a response to Soderlund and Madison|2015|Comment to the article `Characteristics of gender studies publications: A bibliometric analysis based on a Swedish population database' by Therese Soderlund and Guy Madison (Scientometrics, 2015). From the position of relevant expertise within gender studies and bibliometrics, this text offers a critique of the present study and some suggestions of alternative ways forward. It analyses (1) the object of study of the article (the terms used to denominate the field, keywords and methods to make sample selection), (2) technical issues and the question of language in relation to international citations and impact factor, and (3) the views presented in the article regarding gender studies and political ideology.|Gender studies; Knowledge production; Feminist theory; Intersectionality; Transdisciplinary|NEUROSCIENCE|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|2|4|25
LEXA: Building knowledge bases for automatic legal citation classification|2015|This paper presents a new approach to building legal citation classification systems. Our approach is based on Ripple-down Rules (RDA), an efficient knowledge acquisition methodology. The main contributions of the paper (over existing expert-systems approaches) are extensions to the traditional RDR approach introducing new automatic methods to assist in the creation of rules: using the available dataset to provide performance estimates and relevant examples, automatically suggesting and validating synonyms, re-using exceptions in different portions of the knowledge base. We compare our system LEXA with baseline machine learning techniques. LEXA obtains better results both in clean and noisy subsets of our corpus. Compared to machine learning approaches, LEXA also has other advantages such as supporting continuous extension of the rule base, and the opportunity to proceed without an annotated data set and to validate class labels while building rules. Crown Copyright (C) 2015 Published by Elsevier Ltd. All rights reserved.|Knowledge acquisition; Natural language processing; Citation analysis; Legal documents|SPECIALIZED DOMAINS; DOCUMENT MANAGEMENT; ACQUISITION; INFORMATION; SYSTEMS; LAW|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|2|3|25
Genre, discipline and identity|2015|In Genre Analysis Swales encouraged us to see genres in terms of the communities in which they are used and as a function of the choices and constraints acting on text producers. It is this sensitivity to community practices which make genre a rich source of insights into two key concepts of the social sciences - community and identity. In this paper I take up these themes to explore the relationships between community expectations and the individual writer. To do so I use a corpus approach to recover evidence for repeated patterns of language which encode disciplinary preferences for different points of view, argument styles, attitudes to knowledge, and relationships between individuals and between individuals and ideas. The paper attempts to show how genre can offer insights into the ways actors understand both the here-and now interaction (the context of situation) and the broader constraints of the wider community which influence that interaction (the context of culture), revealing something of actors' orientations to scholarly communities and the ways they stake out individual positions. (C) 2015 Elsevier Ltd. All rights reserved.|Genre; Identity; Academic writing; Corpus analysis; Proximity; Positioning|COMMUNITY|Education \& Educational Research; Linguistics; Language \& Linguistics|8|3|25
Reactivity of concurrent verbal reporting in second language writing|2014|This paper reports an empirical study designed to explore whether concurrent verbal reporting has a reactive effect on the process of second language writing. Ninety-five Chinese EFL learners were randomly assigned to an argumentative writing task under three conditions: metacognitive thinking aloud (MTA), nonmetacognitive thinking aloud (NMTA), and no thinking aloud (NTA), after they completed a similar baseline writing task. Their essays were analyzed in terms of linguistic fluency, complexity, accuracy, and overall quality to examine if there were any significant between-group differences that could be taken as evidence of reactivity. After controlling for baseline differences, analyses revealed no traces of reactivity left on a majority of measures except that: (a) the two think-aloud conditions significantly increased dysfluencies in participants' essays; (b) they also tended to reduce syntactic variety of the essays; and (c) MTA significantly prolonged time on task and retarded the speed of written production. These negative effects are interpreted in light of Kellogg's (1996) cognitive model of writing as suggesting no serious interference with L2 writing processes and are taken as cautions for, rather than counterevidence against, the use of the think-aloud method to obtain L2 writing process data. (C) 2014 Elsevier Inc. All rights reserved.|Reactivity; Think-aloud; Second language acquisition (SLA); L2 writing; Argumentative writing; Chinese EFL writers|SLA RESEARCH METHODOLOGY; WORKING-MEMORY; ALOUD PROTOCOLS; TEXT QUALITY; EFL WRITERS; THINK-ALOUD; L2; FLUENCY; COMPLEXITY; ACCURACY|Linguistics|6|0|25
An Automatic Reference Aid for Improving EFL Learners' Formulaic Expressions in Productive Language Use|2014|Formulaic language is important to language acquisition; however, English language learners are often reported to have problems with formulaic expressions. Several lists of formulaic sequences have been proposed, mainly for developing teaching and testing materials. However, their limited numbers and insufficient usage information seem unable to benefit formulaic language use. To address these issues we have developed GRASP, a reference aid for formulaic expressions, to promote learners' productive competence. Users are allowed multi-word inputs to target their desired phrases or collocations. Utilizing natural language processing techniques, our system categorizes and displays the structures and sequences in a hierarchical way. The corresponding example sentences are also provided. The formulaic structures serve as a quick access index. The formulaic sequences and corpus examples illustrate the real world language use. Importantly, automatic summarization from language data lends support to the idea of data-driven learning. A single-group pre-posttest design was adopted to assess the effectiveness of GRASP on 150 Chinese-speaking college freshmen. The results indicated that our reference aid made a substantial contribution to students' performance on formulaic expression use in a sentence completion task, compared with the existing tools. Notably, the less proficient students showed marked improvement.|Formulaic expression/sequence; productive competence; reference tool; natural language processing; multi-word input; data-driven learning|NONNATIVE SPEAKERS; SEQUENCES; SPEECH; LIST|Computer Science, Interdisciplinary Applications; Education \& Educational Research|1|0|25
Plain English and legal writing: Comparing expert and novice writers|2014|Language-focused materials for teaching professional legal writing to second language writers of English in U.S. law schools have been dominated by a set of ``Plain English{''} recommendations, particularly avoidance of the passive voice and nominalizations. At the same time, little to no research has addressed whether these recommendations actually reflect expert use or whether they are indicative of more or less skilled novice performance. To investigate the use of these features in expert and learner texts, two corpora were examined. The expert corpus was composed of 10 published pedagogical sample memos used in legal writing instruction. The learner corpus was composed of 13 low-rated student memos and 13 high-rated student memos. Although an initial chi-square comparison of learner and expert corpora suggests that the experts use both the passive voice and nominalizations significantly less frequently than learners, further analysis suggests that the usage of these features does not clearly distinguish more skilled novices from those who are less skilled. A closer look at the expert corpus also suggests that the use of these features is highly variable across individual samples. Implications for pedagogy are discussed. (C) 2013 Elsevier Ltd. All rights reserved.|Professional legal writing; English for legal purposes; Plain English; Learner corpus analysis|COMPLEXITY|Linguistics|5|1|25
How do framing strategies influence the user's choice of content on the Web?|2012|A Web user is exposed to a large number of information services available from different sources. Online news is offered combined with relevant service attributes such as pictures, small text, users' recommendations, etc. We previously investigated the Web user's choice of online news, focusing on the trade-offs between reputation and other service attributes, which may explain the user's choice of an unknown source, such as a blog. In the present study, we investigate the Web user's choice of online news in a multi-attribute context. Our findings indicate that the most important service attribute is the accompanying text, followed by the source's reputation, then the percentage of readers recommending or having read the link, and then the picture. We further explore the trade-offs between the attributes through simulations. These findings provide useful insights to practitioners on how to use the service attributes in the framing strategies in order to increase the probability of the choice of online news. Copyright (c) 2011 John Wiley \& Sons, Ltd.|Web user behavior; framing strategy; online news; heuristics; choice-based conjoint; Web design|CONJOINT-ANALYSIS; CLICKSTREAM DATA; CONSUMER CHOICE; ONLINE CATALOG; NEWS; HEURISTICS; JUDGMENT; INTERNET; CLICK|Computer Science, Software Engineering; Computer Science, Theory \& Methods|3|1|25
From once upon a time to happily ever after: Tracking emotions in mail and books|2012|In this paper, we show how sentiment analysis can be used in tandem with effective visualizations to quantify and track emotions in mail and books. We study a number of specific datasets and show, among other things, how collections of texts can be organized for affect-based search and how books portray different entities through co-occurring emotion words. Analysis of the Enron Email Corpus reveals that there are marked differences across genders in how they use emotion words in work-place email. Finally, we show that fairy tales have more extreme emotion densities than novels. Crown Copyright (C) 2012 Published by Elsevier B.V. All rights reserved.|Emotion analysis; Sentiment analysis; Lexicon; Email; Fairy tales; Enron Corpus; Google Books Corpus|GENDER; TEXT; COMMUNICATION; FRIENDSHIP; BEHAVIOR|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|19|0|25
Design of convergent product concepts based on functionality: An association rule mining and decision tree approach|2012|Recent trends in paradigms of digital convergence have accentuated the notions of convergent products that are formed by adding new functions to an existing base product. However, a lacuna still remains in the literature as to systematic design of convergent product concepts (CPCs) based on functionality. This study proposes a systematic approach to design of CPCs based on online community information using data mining techniques. At the heart of the suggested approach is the combined use of association rule mining (ARM) and decision tree (DT) for discovering the significant relationships among items and detecting the meaningful conditions of items. Specifically, the proposed approach is composed of four steps: data collection and transformation, definition of target functions, identification of critical product features, and specification of design details. Three maps - function co-preferences map, feature relations map, and concepts specification map - are developed to aid decision making in design of CPCs, structuring and visualizing design implications. A case of the portable multimedia player (PMP) is presented to illustrate the proposed approach. We believe that our approach can reduce uncertainty and risk involved in the concept design stage. (C) 2012 Elsevier Ltd. All rights reserved.|New product development (NPD); Convergent product; Concept design; Online community information; Text mining; Association rule mining (ARM); Decision tree (DT)|CUSTOMER KNOWLEDGE; SERVICE; SYSTEM; CONCEPTUALIZATION; CLASSIFICATION; IDENTIFICATION; INDUCTION; DATABASES; DIAGNOSIS; COMMUNITY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|18|0|25
Arguing as an academic purpose: The role of asynchronous conferencing in supporting argumentative dialogue in school and university|2012|Learning to argue is a key academic purpose for both first and second language students. It has been claimed that computer mediated asynchronous text-based conferencing is a useful medium for developing argumentation skills (Andriessen, Baker, \& Suthers, 2003). This paper reports on two research studies which explore this claim. One study focused on secondary school history students' use of conferencing to debate interpretations of historical events, the other investigated undergraduate students (in Health and Social Care) exchanging views on controversies surrounding complementary and alternative medicine. In general, research into electronic conferencing and argumentation has tended to be located within cognitive or sociocultural paradigms. In contrast, the studies reported on here used the framework and tools of systemic functional linguistics (supported by concordancing software). Interpretation of the linguistic findings was also aided by questionnaire and interview data. The analyses revealed some significant trends across both student cohorts. Overall, students were more inclined to make or support claims rather than counter or challenge them. Other significant trends included the fact that some sub-topics resulted in sustained argumentative dialogue whilst others quickly petered out. Analysis indicates that the linguistic expression of claims may partly explain this phenomenon. The authors argue that functional linguistic analysis (from text to clause level) provides a useful basis for considering the pedagogic potential of conferencing in facilitating argumentative dialogue and student learning. (C) 2011 Elsevier Ltd. All rights reserved.|Argumentation; Asynchronous electronic conferencing; Corpus analysis; Systemic functional analysis; Genre analysis|ELECTRONIC MAIL; CRITICAL THINKING; KNOWLEDGE; ONLINE; DISCUSSIONS; SKILLS; CONSTRUCTION; SCIENCE; DEBATE|Education \& Educational Research; Linguistics; Language \& Linguistics|10|0|25
Academic Literacies and systemic functional linguistics: How do they relate?|2012|Two approaches to English for Academic Purposes (EAP) research and teaching which have arisen in recent years are systemic functional linguistics (SFL) approaches in Australia and elsewhere (e.g. Hood, 2006; Lee, 2010; Woodward-Kron, 2009) and Academic Literacies approaches in the UK and elsewhere (e.g. Lillis \& Scott, 2008; Thesen \& Pletzen, 2006; Turner, 2004). Although these approaches both draw from ethnographic and sociocultural traditions, they have tended to focus on different aspects of EAP. SFL as a theory of language has employed linguistic analysis to establish the nature of disciplinary discourses and ways of encouraging students to engage in these discourses; research and pedagogy have concentrated on texts, language in use and the language system. Academic Literacies as a research paradigm has maintained a strong commitment to ethnographic investigation and to critiquing dominant academic and institutional practices; methods have concentrated on identifying practices, student identities, and conflicts that individual language users experience in university writing. This article reflects on the two approaches by reviewing their two literatures, uncovering key questions that characterise each, and illuminating similarities and difference in epistemology and methodology. The article concludes by recognising the potential of dialogue and collaboration across the SFL and Academic Literacies research and teaching communities to address current imperatives facing EAP. (C) 2011 Elsevier Ltd. All rights reserved.|Systemic functional linguistics; Academic Literacies; Academic writing; Texts; Practices|ETHNOGRAPHY; SKILLS|Education \& Educational Research; Linguistics; Language \& Linguistics|24|2|25
Multilingual dyslexia in university students: Reading and writing patterns in three languages|2011|We investigated reading and writing in two domestic languages (Swedish and Finnish) and one foreign language (English) among multilingual university students with (n = 20) versus without dyslexia (n = 20). Our analyses encompassed overall speed and accuracy measures and an in-depth analysis of grapheme-phoneme-grapheme errors and inflectional errors. Dyslexic impairments were most conspicuous in word and sentence segmentation, accuracy in oral text reading, single word writing to dictation and free writing across the three languages, most prominently in English. The writing tasks exhibited significantly higher proportions of phoneme-to-grapheme errors in the dyslexia group, especially in English, and marginal differences in inflectional errors, again discernible in English. The results indicate that language proficiency and orthographic depth modulate the appearance of high-performing multilinguals' dyslexic problems in reading and writing. These problems surfaced most clearly in a less proficient foreign, orthographically opaque language.|dyslexia; multilingualism; reading; writing; phonology; error analysis; orthographic depth; language proficiency|SPELLING-ERRORS; DISABILITY; SWEDISH; ENGLISH; READERS; SKILLS|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|6|2|25
To hedge or not to hedge: the use of epistemic modal expressions in popular science in English texts, English-German translations, and German original texts|2011|Hedging plays a significant role in both scientific writing proper and its popularized form. However, most research has concentrated on the former text type, while comparatively little attention has been paid to the phenomenon in popular science. The present study uses a corpus of English popular scientific articles, their German translations, and original German popular scientific articles to investigate the use of epistemic modal markers (such as might, could, perhaps), which represent a common form of hedging, as they serve to mark the speaker's uncertainty about the truth of a proposition. The analysis shows noteworthy differences in usage between English and German. The English texts make use of epistemic modal markers much more frequently than the German original texts. Markers expressing mere possibility (e. g., maybe) are particularly more frequent in English, while German rather uses markers of high probability (e. g., probably). These differences can be related to divergent c-ommunicative preferences, specifically to a preference for indirectness and addressee-orientation in English texts, contrasting with a preference for directness and content-orientedness in German. The German translated texts are situated inbetween English and German originals, i.e., they exhibit some degree of adaptation to German textual conventions as well as some degree of ``shining-through{''} of the English conventions.|epistemic modality; hedging; popular science; translation; cross-cultural pragmatics; intercultural communication|ARTICLES|Communication; Linguistics; Language \& Linguistics|13|0|25
Identity, language, and new media: the Kurdish case|2010|This paper draws on theories that describe interrelationships between identity, language and the media to investigate how the Kurds utilise two forms of electronic media-satellite television and the Internet-to construct their identities. The data for this study is generated from four sources: a Kurdish satellite television channel (Kurdistan TV), a variety of Kurdish Internet sites, literature reflecting on the place of the new media among the Kurds, and informal interviews and personal communications with Kurdish media producers and audiences. Strategies including participant observation and online ethnography have been used to select data. Data analysis is informed by a critical discourse analytic approach that calls for examination of data at three levels: discourse practices, text, and socio-cultural contexts (Fairclough in Media discourse. Arnold, London, 1995). Findings suggest that the Kurdish language is held as one of the most important and salient manifestations of Kurdish identity. Satellite television and the Internet have magnified the symbolic role of the Kurdish language in defining Kurdishness. In addition, these new media have enabled Kurds from different regions and all walks of life to share and discuss cultural, social and political ideas and issues publicly and dialogically, and to construct and reconstruct their identities discursively with relative freedom and ease. The study also underlines significant differences between these two forms of new media in relation to identity construction and language use. Whereas satellite television seems to foster mutual intelligibility among the speakers of different Kurdish varieties the Internet tends to further diversify the language across alphabet and regional lines.|Minority language media; Kurdish; Language policy; Critical discourse analysis; Language and identity; Sociology of language|DISCOURSE; NATIONALISM; DIASPORA; INTERNET; ONLINE|Education \& Educational Research; Linguistics; Language \& Linguistics|12|4|25
On-line syntax: Thoughts on the temporality of spoken language|2009|One fundamental difference between spoken and written language has to do with the `linearity' of speaking in time, in that the temporal structure of speaking is inherently the outcome of an interactive process between speaker and listener. But despite the status of ``linearity{''} as one of Saussure's fundamental principles, in practice little more than lip-service is paid to the temporality of spoken language, which is treated as having few if any consequences for syntactic analysis. It is trivial to point out that a structuralist definition of the sentence is incompatible with an on-line model of syntax processing. A structuralist analysis, even of ostensibly spoken language, is carried out not from a real-time emergence perspective but as if it were-like a written text-a finished product. This article suggests that a significantly untraditional approach to syntax is required when one focuses on its on-line emergence, and outlines such an approach. (C) 2007 Elsevier Ltd. All rights reserved.|Emergent grammar; Language and time; Speech vs. writing; Syntax of spoken language|GRAMMAR|Linguistics; Language \& Linguistics|54|5|25
Concessive constructions in English business letter discourse|2008|This paper presents an analysis of the pragmatic use of concessive constructions in business letter discourse. In linguistics, concession has been analyzed primarily within concessive clauses, which have been widely studied, either alone or compared with other syntactic categories such as adversative, causal, or conditional clauses. The term `concessive' itself belongs to the terminology developed within traditional grammar to classify adverbials and adverbial clauses. Heretofore, less attention has been paid to the pragmatic use of concession, i.e., the way in which concessive constructions strategically function within a specific context. The context under analysis in this paper is that of the `business letter' genre. Analysis of a corpus of English business letters shows that concessive constructions are used in this genre both for propositional (or ideational) and procedural (or interpersonal) reasons. This paper considers only the second to be truly pragmatic. Preference for the first or second strategy depends on the text types belonging to the genre. When procedural reasons prevail, concession is mostly introduced for politeness reasons, politeness being one of the factors constantly at play in business exchanges.|business letter; concessive; genre analysis; move; politeness; rhetoric|POLITENESS; FACE; JAPANESE; UNIVERSALITY; PERSPECTIVE; REQUESTS; LANGUAGE; CHINESE; GENRE|Communication; Linguistics; Language \& Linguistics|1|1|25
A visualization tool of patent topic evolution using a growing cell structure neural network|2017|This research used a cell structure map to visualize technological evolution and showed the developmental trend in a technological field. The basic concept was to organize patents into a map produced by growing cell structures. The map was then disassembled into clusters with similar contexts using the Girvan-Newman algorithm. Next, the continuity between clusters in two snapshots was identified and used as the base for establishing a trajectory in the technology. An analysis of patents in the flaw detection field found that the field was composed of several technological trajectories. Among them, ultrasonic flaw detection, wafer inspection and substrate inspection were relatively larger and more continuing technologies, while infrared thermography defect inspection has been an emerging topic in recent years. It is to be hoped that the map of technology constructed in this research provides insights into the history of technological evolution and helps explain the transition patterns through changes in cluster continuity. This can serve a reference point by experts who attempt to visualize the mapping of technological development or identify the latest focus of attention.|Technology map; Growing cell structures; Neural networks; Girvan-Newman; algorithm; Natural language processing|TECHNOLOGY; FIELD; SCIENCE; CARTOGRAPHY; TRACKING; GROWTH; MAP|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|12|24
Efficient identification of nationally mandated reportable cancer cases using natural language processing and machine learning|2016|Objective To help cancer registrars efficiently and accurately identify reportable cancer cases. Material and Methods The Cancer Registry Control Panel (CRCP) was developed to detect mentions of reportable cancer cases using a pipeline built on the Unstructured Information Management Architecture - Asynchronous Scaleout (UIMA-AS) architecture containing the National Library of Medicine's UIMA MetaMap annotator as well as a variety of rule-based UIMA annotators that primarily act to filter out concepts referring to nonreportable cancers. CRCP inspects pathology reports nightly to identify pathology records containing relevant cancer concepts and combines this with diagnosis codes from the Clinical Electronic Data Warehouse to identify candidate cancer patients using supervised machine learning. Cancer mentions are highlighted in all candidate clinical notes and then sorted in CRCP's web interface for faster validation by cancer registrars. Results CRCP achieved an accuracy of 0.872 and detected reportable cancer cases with a precision of 0.843 and a recall of 0.848. CRCP increases throughput by 22.6\% over a baseline (manual review) pathology report inspection system while achieving a higher precision and recall. Depending on registrar time constraints, CRCP can increase recall to 0.939 at the expense of precision by incorporating a data source information feature. Conclusion CRCP demonstrates accurate results when applying natural language processing features to the problem of detecting patients with cases of reportable cancer from clinical notes. We show that implementing only a portion of cancer reporting rules in the form of regular expressions is sufficient to increase the precision, recall, and speed of the detection of reportable cancer cases when combined with off-the-shelf information extraction software and machine learning.|natural language processing; machine learning; information extraction; neoplasms; electronic health records; user-computer interface|TEXT; UMLS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|4|3|24
Developing a successful SemEval task in sentiment analysis of Twitter and other social media texts|2016|We present the development and evaluation of a semantic analysis task that lies at the intersection of two very trendy lines of research in contemporary computational linguistics: (1) sentiment analysis, and (2) natural language processing of social media text. The task was part of SemEval, the International Workshop on Semantic Evaluation, a semantic evaluation forum previously known as SensEval. The task ran in 2013 and 2014, attracting the highest number of participating teams at SemEval in both years, and there is an ongoing edition in 2015. The task included the creation of a large contextual and message-level polarity corpus consisting of tweets, SMS messages, LiveJournal messages, and a special test set of sarcastic tweets. The evaluation attracted 44 teams in 2013 and 46 in 2014, who used a variety of approaches. The best teams were able to outperform several baselines by sizable margins with improvement across the 2 years the task has been run. We hope that the long-lasting role of this task and the accompanying datasets will be to serve as a test bed for comparing different approaches, thus facilitating research.|Sentiment analysis; Twitter; SemEval|LANGUAGE; AMAZON|Computer Science, Interdisciplinary Applications|6|5|24
SentiMI: Introducing point-wise mutual information with SentiWordNet to improve sentiment polarity detection|2016|Supervised learning has attracted much attention in recent years. As a consequence, many of the state-of-the-art algorithms are domain dependent as they require a labeled training corpus to learn the domain features. This requires the availability of labeled corpora which is a cumbersome task in itself. However, for text sentiment detection SentiWordNet (SWN) may be used. It is a vocabulary where terms are arranged in synonym groups called synsets. This research makes use of SentiWordNet and treats it as the labeled corpus for training. A sentiment dictionary, SentiMI, builds upon the mutual information calculated from these terms. A complete framework is developed by using feature selection and extracting mutual information, from SentiMI, for the selected features. Training, testing and evaluation of the proposed framework are conducted on a large dataset of 50,000 movie reviews. A notable performance improvement of 7\% in accuracy, 14\% in specificity, and 8\% in F-measure is achieved by the proposed framework as compared to the baseline SentiWordNet classifier. Comparison with the state-of-the-art classifiers is also performed on widely used Cornell Movie Review dataset which also proves the effectiveness of the proposed approach. (C) 2015 Elsevier B.V. All rights reserved.|Sentiment analysis; SentiWordNet; Text mining; Data mining; Social media; Mutual information|LEXICON; EXTRACTION; FEATURES|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|9|3|24
A study of active learning methods for named entity recognition in clinical text|2015|Objectives: Named entity recognition (NER), a sequential labeling task, is one of the fundamental tasks for building clinical natural language processing (NLP) systems. Machine learning (ML) based approaches can achieve good performance, but they often require large amounts of annotated samples, which are expensive to build due to the requirement of domain experts in annotation. Active learning (AL), a sample selection approach integrated with supervised ML, aims to minimize the annotation cost while maximizing the performance of ML-based models. In this study, our goal was to develop and evaluate both existing and new AL methods for a clinical NER task to identify concepts of medical problems, treatments, and lab tests from the clinical notes. Methods: Using the annotated NER corpus from the 2010 i2b2/VA NLP challenge that contained 349 clinical documents with 20,423 unique sentences, we simulated AL experiments using a number of existing and novel algorithms in three different categories including uncertainty-based, diversity-based, and baseline sampling strategies. They were compared with the passive learning that uses random sampling. Learning curves that plot performance of the NER model against the estimated annotation cost (based on number of sentences or words in the training set) were generated to evaluate different active learning and the passive learning methods and the area under the learning curve (ALC) score was computed. Results: Based on the learning curves of F-measure vs. number of sentences, uncertainty sampling algorithms outperformed all other methods in ALC. Most diversity-based methods also performed better than random sampling in ALC. To achieve an F-measure of 0.80, the best method based on uncertainty sampling could save 66\% annotations in sentences, as compared to random sampling. For the learning curves of F-measure vs. number of words, uncertainty sampling methods again outperformed all other methods in ALC. To achieve 0.80 in F-measure, in comparison to random sampling, the best uncertainty based method saved 42\% annotations in words. But the best diversity based method reduced only 7\% annotation effort. Conclusion: In the simulated setting, AL methods, particularly uncertainty-sampling based approaches, seemed to significantly save annotation cost for the clinical NER task. The actual benefit of active learning in clinical NER should be further evaluated in a real-time setting. (C) 2015 Elsevier Inc. All rights reserved.|Active learning; Machine learning; Clinical natural language processing; Clinical named entity recognition|ELECTRONIC HEALTH RECORDS; MEDICATION INFORMATION; CORPUS STATISTICS; PRE-ANNOTATION; CLASSIFICATION; EXTRACTION; CHALLENGE; IDENTIFICATION; ASSERTIONS|Computer Science, Interdisciplinary Applications; Medical Informatics|8|2|24
Improving Meta-learning for Algorithm Selection by Using Multi-label Classification: A Case of Study with Educational Data Sets|2015|Recommending classification algorithms is an open research problem the solution to which is of tremendous value for practitioners and non-experts data mining users such as educators. This paper proposes a new meta-learning framework for educational domains based on the use of multi-label learning for selecting the best classification algorithms in order to predict students' performance. In short, the frame-work considers an ofFLine phase where statistical tests are performed to find the subset of algorithms that achieves the best performance over the repository of educational data sets. The subset of algorithms along with the meta-features extracted from the training data are used to generate a multi-label data set. A multi-label classifier is then trained and, in an online phase, this model is used to recommend the most suitable classification algorithms to be applied to new unseen data sets. This new multi-label meta-learning approach has been applied to a repository of educational data sets generated from Moodle usage data. The results obtained show significant improvement compared with a previous nearest neighbor proposal, demonstrating the suitability of the new framework.|Meta-learning; Multi-label classification; Educational data mining; Students' performance|TEXT CATEGORIZATION; STUDENT DATA; SYSTEM; ONLINE; CLASSIFIERS; PERFORMANCE; RANKING; MODELS|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|2|1|24
Validating drug repurposing signals using electronic health records: a case study of metformin associated with reduced cancer mortality|2015|Objectives Drug repurposing, which finds new indications for existing drugs, has received great attention recently. The goal of our work is to assess the feasibility of using electronic health records (EHRs) and automated informatics methods to efficiently validate a recent drug repurposing association of metformin with reduced cancer mortality. Methods By linking two large EHRs from Vanderbilt University Medical Center and Mayo Clinic to their tumor registries, we constructed a cohort including 32 415 adults with a cancer diagnosis at Vanderbilt and 79 258 cancer patients at Mayo from 1995 to 2010. Using automated informatics methods, we further identified type 2 diabetes patients within the cancer cohort and determined their drug exposure information, as well as other covariates such as smoking status. We then estimated HRs for all-cause mortality and their associated 95\% CIs using stratified Cox proportional hazard models. HRs were estimated according to metformin exposure, adjusted for age at diagnosis, sex, race, body mass index, tobacco use, insulin use, cancer type, and non-cancer Charlson comorbidity index. Results Among all Vanderbilt cancer patients, metformin was associated with a 22\% decrease in overall mortality compared to other oral hypoglycemic medications (HR 0.78; 95\% CI 0.69 to 0.88) and with a 39\% decrease compared to type 2 diabetes patients on insulin only (HR 0.61; 95\% CI 0.50 to 0.73). Diabetic patients on metformin also had a 23\% improved survival compared with non-diabetic patients (HR 0.77; 95\% CI 0.71 to 0.85). These associations were replicated using the Mayo Clinic EHR data. Many site-specific cancers including breast, colorectal, lung, and prostate demonstrated reduced mortality with metformin use in at least one EHR. Conclusions EHR data suggested that the use of metformin was associated with decreased mortality after a cancer diagnosis compared with diabetic and non-diabetic cancer patients not on metformin, indicating its potential as a chemotherapeutic regimen. This study serves as a model for robust and inexpensive validation studies for drug repurposing signals using EHR data.|drug repurposing; electronic health records; natural language processing; metformin|GENOME-WIDE ASSOCIATION; DISCHARGE SUMMARIES; PANCREATIC-CANCER; DIABETIC-PATIENTS; INCIDENT CANCER; RISK; THERAPEUTICS; SURVIVAL; GLUCOSE; IDENTIFICATION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|43|5|24
Friend or foe? Google Translate in language for academic purposes|2015|A recent development in digital technology, machine translation (MT), is improving in its ability to translate with grammatical and lexical accuracy, and is also becoming increasingly available for students of language for academic purposes. Given the acceptance of other digital technology for teaching and learning, it seems likely that machine translation will become a tool students will rely on to complete their assignments in a second language. This would have implications for the community of practice of academic language teaching. In this study students were asked to submit an essay in their first language and this was then translated into English through a web-based translation engine. The resulting English text was analysed for grammatical error. The analysis found that the translation engine was far from able to produce error-free text - however, judging in relation to international testing standards, the level of accuracy is approaching the minimum needed for university admission at many institutions. Thus, this paper sets out to argue, based on the assumption that MT will continue to improve, that this technology will have a profound influence on the teaching of Languages for Academic Purposes, and with imaginative use, will allow this influence to be positive for both the students and their instructors. (C) 2014 Elsevier Ltd. All rights reserved.|Language for academic purposes; Machine translation; IT in SLA; Academic literacy|MACHINE TRANSLATION; ENGLISH|Linguistics|7|5|24
A bibliometric analysis of plagiarism and self-plagiarism through Deja vu|2014|Plagiarism is one of the most important current debates among scientific stakeholders. A separate but related issue is the use of authors' own ideas in different papers (i.e., self-plagiarism). Opinions on this issue are mixed, and there is a lack of consensus. Our goal was to gain deeper insight into plagiarism and self-plagiarism through a citation analysis of documents involved in these situations. The Deja vu database, which comprises around 80,000 duplicate records, was used to select 247 pairs of documents that had been examined by curators on a full text basis following a stringent protocol. We then used the Scopus database to perform a citation analysis of the selected documents. For each document pair, we used specific bibliometric indicators, such as the number of authors, full text similarity, journal impact factor, the Eigenfactor, and article influence. Our results confirm that cases of plagiarism are published in journals with lower visibility and thus tend to receive fewer citations. Moreover, full text similarity was significantly higher in cases of plagiarism than in cases of self-plagiarism. Among pairs of documents with shared authors, duplicates not citing the original document showed higher full text similarity than those citing the original document, and also showed greater overlap in the references cited in the two documents.|Plagiarism; Duplicate publications; Deja vu; Citation analysis|SCIENTIFIC LITERATURE; CITATIONS; PUBLICATIONS; MEDLINE; IMPACT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|4|2|24
Text Messaging as Adjunct to Community-Based Weight Management Program|2013|Increasing obesity rates are still a public health priority. The primary aim of this study was to evaluate the effect of tailored text messages on body weight change in overweight and obese adults in a community-based weight management program. A secondary aim was to detect behavioral changes in the same population. The study design was quasi-experimental with pretest and posttest analysis, conducted over 12 weeks. A total of 28 participants were included in the analysis. Body weight, eating behaviors, exercise and nutrition self-efficacy, attitude toward mobile technology, social support, and physical activity were assessed at baseline and at 12 weeks. Text messages were sent biweekly to the intervention but not to the control group. At 12 weeks, the intervention group had lost significant weight as compared with the control group. There was a trend toward an improvement in eating behaviors, exercise, and nutrition self-efficacy in the intervention group, with no significant difference between groups. A total of 79\% of participants stated that text messages helped in adopting healthy behaviors. Tailored text messages appear to enhance weight loss in a weight management program at a community setting. Large-scale and long-term intervention studies are needed to confirm these findings.|Adult; Obesity; Overweight; SMS text messaging; Weight loss|RANDOMIZED CONTROLLED-TRIAL; LIFE-STYLE INTERVENTIONS; PHYSICAL-ACTIVITY; MOBILE PHONE; BEHAVIOR-CHANGE; HEALTH-CARE; OBESITY; SERVICE; ADULTS; WOMEN|Computer Science, Interdisciplinary Applications; Medical Informatics; Nursing|6|2|24
A new computing method for extracting contiguous phraseological sequences from academic text corpora|2013|This study aims to develop a new computing method for extracting contiguous phraseological sequences (PSs) of various lengths from academic text corpora by measuring internal associations of n-grams. We construct a new normalizing algorithm of probability-weighted average for refining the MI measure and enhancing precision in extracting PSs from corpora. This computing method is applied to the data in a medium-sized text corpus of academic English. Results indicate that the resultant new MI measure can provide statistics which better reveal internal associations within an n-gram, regardless of size. Lexico-grammatical sequences extracted with this method are more complete and less arbitrary in terms of grammar and semantics. The method can be applied to treating a variety of linguistic phenomenon, ranging from well-established phrases to likely phrasal entities, thus having potentially practical applications in corpus-based studies of phraseology and natural language processing.|phraseology; n-grams; internal association; pseudo-bigram transformation; probability-weighted average|FORMULAIC LANGUAGE; LEXICAL BUNDLES; LIST|Linguistics; Language \& Linguistics|4|8|24
Duplicate and fake publications in the scientific literature: how many SCIgen papers in computer science?|2013|Two kinds of bibliographic tools are used to retrieve scientific publications and make them available online. For one kind, access is free as they store information made publicly available online. For the other kind, access fees are required as they are compiled on information provided by the major publishers of scientific literature. The former can easily be interfered with, but it is generally assumed that the latter guarantee the integrity of the data they sell. Unfortunately, duplicate and fake publications are appearing in scientific conferences and, as a result, in the bibliographic services. We demonstrate a software method of detecting these duplicate and fake publications. Both the free services (such as Google Scholar and DBLP) and the charged-for services (such as IEEE Xplore) accept and index these publications.|Bibliographic tools; Scientific conferences; Fake publications; Text-mining; Inter-textual distance; Google Scholar; Scopus; WoK|GOOGLE-SCHOLAR|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|19|3|24
Applying content analysis for investigating the reporting of water issues|2012|This article presents a content analysis approach for contextualizing the reporting of water and water-related issues. The intent of our approach is to enable an understanding of how important environmental topics such as water-related issues are presented to the public, and thus potentially influencing public perceptions on the issues. Multiple statistical and analytical methods are integrated in order to analyze online newspapers articles to evaluate the context, regionalism and relevance of the reporting of water issues. Using 10 online newspapers from Nebraska, USA, the content analysis approach revealed that water is most often reported in the state in the context of agriculture, while other topics such as water quality and habitat are less frequently discussed. Second, there is a lack of spatial dependency in the reporting of water across Nebraska as newspapers in close proximity to one another do not demonstrate similar reporting. Finally, the reporting of water in some newspapers is noticeably linked to local daily water quantity observations. These results suggest that, although the topic of waver as an environmental issue may be vitally important across a region, the context of how water issues are reported is driven by local issues and, in some cases, relevant physical processes. Results show that there is a relative lack of coverage on major water and environmental issues except when issues are of immediate public concern. We discuss how these results could be used by resource managers to interpret media content and the public's understanding of important environmental topics. (C) 2012 Elsevier Ltd. All rights reserved.|Water; Newspapers; Content analysis; Text mining; Environmental management; Nebraska|UNITED-STATES; ENVIRONMENT; EVENTS|Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research \& Management Science|7|2|24
Text simplification and comprehensible input: A case for an intuitive approach|2012|Texts are routinely simplified to make them more comprehensible for second language learners. However, the effects of simplification upon the linguistic features of texts remain largely unexplored. Here we examine the effects of one type of text simplification: intuitive text simplification. We use the computational tool, Coh-Metrix, to examine linguistic differences between proficiency levels of a corpus of 300 news texts that had been simplified to three levels of simplification (beginner, intermediate, advanced). The main analysis reveals significant differences between levels for a wide range of linguistic features, particularly between beginner and advanced levels. The results show that lower level texts are generally less lexically and syntactically sophisticated than higher-level texts. The analysis also reveals that lower level texts contain more cohesive features than higher-level texts. The analysis also provides strong evidence that these linguistic features can be used to classify levels of simplified reading texts. Overall, the findings support the notion that intuitively simplified texts at the beginning level contain more linguistic features related to comprehensible input than intuitively simplified texts at the advanced level.|text simplification; intuitive simplification; corpus linguistics; computational linguistics; text comprehensibility|LANGUAGE|Education \& Educational Research; Linguistics|17|0|24
Authorial voice in academic writing: A methodological proposal for its analysis|2011|Academic writing has gradually lost its traditional label of objective and impersonal discourse becoming a persuasive endeavour involving the interaction between writer and reader. Despite its popularity, the notion of voice is far from being a univocal concept and its meaning varies according to the perspective adopted. Problems involve its definition, the relationships with other related concepts, and methodological issues concerning the appropriate dimensions and the relevant aspects that should be addressed when observing, analysing and assessing traces of voice in a specific text. The paper has three main objects. Firstly, we revise research studies that in the last ten years have devoted their efforts to clarify the notion of voice considering their conceptual, theoretical and disciplinary framework. Our revision does not intend to be exhaustive but representative of the studies carried out from each theoretical perspective and its main findings. Our second aim is to build our own perspective of voice integrating the findings of previous research. Finally, a methodological proposal is established detailing three dimensions of analysis which are closely related, each one of them focused on the aspects that, according to the revision, we consider relevant for the study of voice.|Academic voice; authorial identity; academic writing; stance; intertextuality|DISCOURSE; CITATION|Linguistics; Language \& Linguistics|15|4|24
Evaluating student learning in a university-level EAP unit on writing using sources|2010|There has been extensive discussion of the difficulties experienced by tertiary students when writing using sources in both first- and second-language (L1, L2) writing literature; however, few studies have reported on instructional interventions that aim to assist students to master this complex academic literacy. The action research study described in this paper recruited 78 undergraduate students from six strands of credit-bearing L2 writing courses. A pre-unit quiz and guided writing task ascertained participants' current level of skill and knowledge. After 8 hours of instruction and practice on technical and discourse skill components, students completed a post-unit task and wrote reflective comments. Out-of-class assignments were also submitted for analysis. Findings showed a significant improvement in students' declarative knowledge, and in the rule-governed aspects of the skill. Instances of direct copying from the sources decreased in post-tasks and assignments. While there was a modest overall improvement across the cohort, students were clearly not yet proficient, particularly in the more sophisticated and subtle aspects of writing using sources. They had difficulties comprehending complexities in texts, summarising propositional content accurately, and integrating citations with their own voices and positions. This paper discusses implications for teachers, and the desirability of establishing a body of practice-oriented research. (C) 2010 Elsevier Inc. All rights reserved.|Second language writing development; Writing using sources; Plagiarism|ESL STUDENTS; INTERNATIONAL STUDENTS; PLAGIARISM; APPROPRIATION; CONSTRUCTION; ADAPTATION; CITATION; WRITERS|Linguistics|25|3|24
Neural correlates of irony comprehension: The role of schizotypal personality traits|2010|To detect that a conversational turn is intended to be ironic is a difficult challenge in everyday language comprehension. Most authors suggested a theory of mind deficit is crucial for irony comprehension deficits in psychiatric disorders like schizophrenia; however, the underlying pathophysiology and neurobiology are unknown and recent research highlights the possible role of language comprehension abnormalities. Fifteen female right-handed subjects completed personality testing as well as functional magnetic resonance imaging (fMRI) and neuropsychology. Subjects were recruited from the general population. No subject had a lifetime history of relevant psychiatric disorder; however, subjects differed in their score on the German version of the schizotypal personality questionnaire (SPQ). During fMRI scans, the subjects silently read 44 short text vignettes that ended in either an ironic or a literal statement. Imaging was performed using a 3 T Siemens scanner. The influence of schizotypy on brain activation was investigated by using an SPM5 regression analysis with the SPQ total score and the SPQ cognitive-perceptual score as regressors. Reading ironic in contrast to literal sentences activated a bilateral network including left medial prefrontal and left inferior parietal gyri. During reading of ironic sentences, brain activation in the middle temporal gyrus of both hemispheres showed a significant negative association with the SPQ total score and the SPQ cognitive-perceptual score. Significant positive correlation with the SPQ total score was present in the left inferior frontal gyrus. We conclude schizotypal personality traits are associated with a dysfunctional lateral temporal language rather than a theory of mind network. (C) 2009 Elsevier Inc. All rights reserved.|Irony; Sarcasm; Nonliteral; Language; Schizotypy; Schizotypal; Middle temporal gyrus|RIGHT-HEMISPHERE DAMAGE; III-R CRITERIA; INDIVIDUAL-DIFFERENCES; POSITIVE SCHIZOTYPY; VERBAL IRONY; PSYCHIATRIC-DISORDERS; UNDERSTANDING SARCASM; NEUROANATOMICAL BASIS; IDIOM COMPREHENSION; LANGUAGE FUNCTIONS|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|34|1|24
Shifts in repetition vs. shifts in text meaning A study of the textual role of lexical repetition in non-literary translation|2010|This study focuses on the discoursal role of repetition, exploring the way shifts in repetition patterns in text trigger coherence shifts, altering the meaning potential of translations. As repetition in translation has been hypothesized to be affected by certain universals of translation, the paper also offers initial data to support the universals of explicitation and avoiding repetition. Lexical repetitions are investigated using Hoey's (1991) theory in a corpus of Hungarian English news texts. Analyses reveal considerable shifts in repetition in translations; however, these differences are not statistically significant. The corpus also provides evidence for repetition shifts affecting the macropropositional structure of target texts, leading to macropropositional shifts, which alter the global meaning of translations compared to sources.|repetition; cohesion; coherence; text meaning; shift; macroproposition; non-literary translation; translation universal; explicitation; avoidance of repetition|COHESION; DISCOURSE; COHERENCE|Linguistics; Language \& Linguistics|7|0|24
Using Chinese radical parts for sentiment analysis and domain dependent seed set extraction|2018|Although there has been good progress in English sentiment analysis and resources, studies in English cannot be directly used in Chinese owing to the nature of Chinese language. Previous studies suggested adopting linguistic information, such as grammar and morpheme information, to assist in sentiment analysis for Chinese text. However, morpheme-based approaches have a problem in identifying seeds. In addition, these methods do not take advantage of radicals in the characters, which contain a great deal of semantic information. A Chinese word is composed of one or more characters, each of which has its radical part. We can interpret the partial meaning of a character by analyzing that of the radical in the character. Therefore, we not only consider the radical information as the semantic root of a character, but also consider the radical parts between characters in a word as an appropriate linguistic unit for conducting sentiment analysis. In this study, we conducted a series of experiments using radicals as the feature unit in sentiment analysis. Using segmented results from part -of-speech tools as a meaningful linguistic unit (word) in Chinese, we conducted analyses of single-feature word (unigram) and frequently seen two words (pointwise mutual information collocated bigrams) through various sentiment analysis measures. It is concluded that radical features could work better than word features and would consume less computing memory and time. An extended study of the extraction of seeds was also conducted, and the results indicated that 50 seed radical features performed well. A cross-corpus comparison was also conducted; the results demonstrated that the use of 50 extracted radical features as domain-dependent keywords worked better than other sentiment analysis strategies. This study confirmed that radical information could be adopted as a feature unit in sentiment analysis and that domain-dependent radicals could be reused in different corpora. (C) 2017 Elsevier Ltd. All rights reserved.|Sentiment analysis; Chinese radical; Restaurant review analysis; Domain-dependent seed|REVIEWS|Computer Science, Artificial Intelligence|0|23|23
A new web personalization decision-support artifact for utility-sensitive customer review analysis|2017|In recent years there has been increased consumer use of the vast array of online reviews. Given the increasingly high volume of such reviews, automatic analyses of their quality have become imperative. Not surprisingly, this situation has attracted the interest of researchers. However, prior approaches are insufficient to address the consumers' need for non-burdensome sense making of online reviews. This research attempts to close this gap by proposing novel design science artifacts (i.e. construct, architecture, algorithms and prototype) to address the consumers' need. We evaluate these artifacts using a set of experiments and hypothesis tests. The results validate the effectiveness and efficiency of the proposed artifacts. We demonstrate their practical utility and relevance using real world pilot experiments. This paper contributes theoretical knowledge to the review quality literature and, what we believe is the first exemplifier for adequately validating the solutions of review quality research. (C) 2016 Elsevier B.V. All rights reserved.|Decision support; Online review; Review quality; Web personalization; Text mining; Web 2.0|WORD-OF-MOUTH; ONLINE REVIEWS; INFORMATION-SYSTEMS; CURRENT STATE; E-COMMERCE; SEARCH; RECOMMENDATION; ALGORITHM; HELPFULNESS; QUALITY|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|0|9|23
Experiential meaning potential in the Topaz Energy logo: a framework for graphemic and graphetic analysis of graphic logo design|2017|Based on the premise that corporate logos are all pervasive in the semiotic landscapes of the post-industrial, globalized world order, the article contends that there is an increasing need for understanding how logos make meaning thus constraining human behaviour. The article argues that conventional wisdom about the meaning potential of visual texts offers limited insight into logos because they are structurally too simple to convey, for example, ideational meaning as typically understood. Instead, the article argues, we can approach the meaning potential of logos ``from below{''} from phonetic- and phonemic-equivalent strata of graphics. The article suggests graphetics and graphemics as general studies of the expression plane of graphics and tentatively outlines a descriptive and analytical framework for them. The article proceeds to demonstrate the analytical potential of the approach by discussing how the logo for Irish fuel and convenience retail chain Topaz can be interpreted using the concept of experiential meaning potential.|Experiential meaning potential; graphemics; graphetics; graphic design; logo; multimodality; social semiotics|SEMIOTICS|Humanities, Multidisciplinary; Communication; Linguistics|0|5|23
CoTO: A novel approach for fuzzy aggregation of semantic similarity measures|2016|Semantic similarity measurement aims to determine the likeness between two text expressions that use different lexicographies for representing the same real object or idea. There are a lot of semantic similarity measures for addressing this problem. However, the best results have been achieved when aggregating a number of simple similarity measures. This means that after the various similarity values have been calculated, the overall similarity for a pair of text expressions is computed using an aggregation function of these individual semantic similarity values. This aggregation is often computed by means of statistical functions. In this work, we present CoTO (Consensus or Trade-Off) a solution based on fuzzy logic that is able to outperform these traditional approaches. (C) 2016 Elsevier B.V. All rights reserved.|Knowledge-based analysis; Text mining; Semantic similarity measurement; Fuzzy logic|BIOMEDICAL DOMAIN; NATURAL-LANGUAGE|Computer Science, Artificial Intelligence; Neurosciences; Psychology, Experimental|3|0|23
Integrating expert knowledge and multilingual web crawling data in a lead qualification system|2016|Qualifying prospects as leads to contact is a complex exercise. Sales representatives often do not have the time or resources to rationally select the best leads to call. As a result, they rely on gut feeling and arbitrary rules to qualify leads. Model-based decision support systems make this process less subjective. Standard input for such an automated lead qualification system is commercial data. Commercial data, however, tends to be expensive and of ambiguous quality due to missing information. This study proposes web crawling data in combination with expert knowledge as an alternative. Web crawling data is freely available and of higher quality as it is generated by companies themselves. Potential customers use websites as a main information source, so companies benefit from correct and complete websites. Expert knowledge, on the other hand, augments web crawling data by inserting specific information. Web data consists of text that is converted to numbers using text mining techniques that make an abstraction of the text. A field experiment was conducted to test how a decision support system based on web crawling data and expert knowledge compares to a basic decision support system within an international energy retailer. Results verify the added value of the proposed approach. (C) 2015 Elsevier B.V. All rights reserved.|Lead qualification; Multilingual text mining; Web crawling; Expert domain knowledge; Parameter optimization|LATENT SEMANTIC ANALYSIS; DOMAIN KNOWLEDGE; TEXT RETRIEVAL; PREDICTION; FRAMEWORK; MODELS; PROFITABILITY; NETWORKS; INTERNET; SUPPORT|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|5|1|23
Usability of English note-taking applications in a foreign language learning context|2016|The act of note-taking offloads cognitive pressure and note-taking applications could be used as an important tool for foreign language acquisition. Its use, importance, and efficacy in a foreign language learning context could be justifiably debated. However, existing computer-assisted language learning literature is almost silent on the topic. This article reports on a controlled experiment introducing usability of note-taking applications (namely, Evernote, Memonic, SpringPad, Ubernote, and Keeppy) in English as foreign language (EFL) learning context. For pilot testing, 25 students had to complete five scenarios (text editing, entering persuasive content, sharing content, searching, and organizing) using Twitter as a tool similar to note-taking applications. Results suggest that the majority were comfortable with the tasks, although they could not complete all the tasks in the stipulated time, and certain tasks and features in Twitter caused difficulty for some students. The actual testing involved the 10 best candidates (based on their performance, when using Twitter) completing tasks (five scenarios similar to pilot analysis) with any two assigned note-taking applications, from a set of five. Participants were observed, video-recorded, and interviewed concurrently and retrospectively. They also completed perception-based questionnaires on the usability of the software. Data suggested that participants were comfortable opening accounts, typing in text, with general navigation, choosing photos, etc. A few features, such as web clipping and file uploading, caused problems for some participants. Most participants reported having no prior experience with any note-taking applications and that resulted in longer task completion time and errors. This study examines how technically oriented students reflect on using note-taking applications in an EFL learning context.|usability; note-taking; software; design; interface|COMPREHENSION; ENVIRONMENT; NOTETAKING; SOFTWARE; WIKIS|Education \& Educational Research; Linguistics; Language \& Linguistics|1|2|23
Reader identity: a case study of Korean graduate students' meaning construction of an L2 literary text|2015|Grounded in constructivist theories of reading and informed by the contemporary theories of identity, this study explored how three Korean adult speakers of English as a foreign language (EFL) constructed meaning of the novel The Catcher in the Rye, and how their identities mediated this process. Sources of data included think aloud protocols, semi-structured interviews and participant written responses. Qualitative data analysis revealed how the participants' multiple identities at individual and group levels prominently emerged as they constructed a storyline that was internally and externally coherent. Based on the findings, we propose that the concept of the L2 reader identity' is useful for capturing the intricacies of the identity work of readers who construct meanings at the intersection of languages and cultures. The study concludes that the reading processes that L2 readers engage in are not only the site of their multiple identities at work, but also a site where multiple competing concepts of the world meet, clash, transform and coexist resulting in narratives that cross cultures, contexts and individuals. Limitations and implications of the study for L2 research and pedagogy are discussed. ??? ???? ?? ? ???? ?CH?? ?? ? ????, ? ??? ????? ?? (EFL) ? ???? ? ?? ?????? ?? ???? ???? ?? ??? ??? ????, ??? ??? ???? ? ?? ??? ?????? ?????. ??? ??? ? ??? ? ???, ???, ???? ???? ? ???. ??? ?? ??? ?? ??????? ???? ???, ????? ???? ?????? ?? ? ?? ???? ?? ?? ???? ?????. ????, ?2?? ?? ???'? ??? ??? ??? ????? ??? ???? ??? ?? ??? ???? ???? ? ????? ?? ????. ? ???, ?2?? ??? ?? ??? ??? ?? ???? ???? ?? ?? ???, ??, ??, ??? ????? ?????? ???? ???? ???? ???? ?? ???, ????, ????, ???? ???? ??? ?????. ??? ?? ? ???? CH? ??? ??.|L2 reading; reading comprehension; literature; culture; identity; Korean|WRITER IDENTITY; KNOWLEDGE; SELF|Linguistics; Language \& Linguistics|0|2|23
A faster path between meaning and form? Iconicity facilitates sign recognition and production in British Sign Language|2015|A standard view of language processing holds that lexical forms are arbitrary, and that non-arbitrary relationships between meaning and form such as onomatopoeias are unusual cases with little relevance to language processing in general. Here we capitalize on the greater availability of iconic lexical forms in a signed language (British Sign Language, BSL), to test how iconic relationships between meaning and form affect lexical processing. In three experiments, we found that iconicity in BSL facilitated picture-sign matching, phonological decision, and picture naming. In comprehension the effect of iconicity did not interact with other factors, but in production it was observed only for later-learned signs. These findings suggest that iconicity serves to activate conceptual features related to perception and action during lexical processing. We suggest that the same should be true for iconicity in spoken languages (e.g., onomatopoeias), and discuss the implications this has for general theories of lexical processing. (C) 2015 The Authors. Published by Elsevier Inc.|Lexicon; Iconicity; Embodiment; Language comprehension; Language production|SPREADING-ACTIVATION THEORY; FEATURE PRODUCTION NORMS; SOUND-SYMBOLISM; LEXICAL ACCESS; PHONETIC SYMBOLISM; WORD PRODUCTION; SENTENCE PRODUCTION; SPEECH RECOGNITION; NATURAL CATEGORIES; CONCRETE WORDS|Linguistics; Psychology; Psychology, Experimental|7|1|23
Don't Keep It (Too) Simple: How Textual Representations of Scientific Uncertainty Affect Laypersons' Attitudes|2015|This research investigated the question of how laypersons are influenced by textual representations of scientific uncertainty. In an online experiment (N = 78), a blog article about effects of computer games on children was presented in four different versions. Each version contained three arguments on negative effects that were either phrased neutrally, contained assertive statements, or included hedges. The fourth version contained an additional argument on positive effects of computer games (two-sided). In comparison with the basic one-sided version, the two-sided text led to a more moderate attitude toward the topic. According to moderation analyses, this difference was mainly based on readers with more advanced epistemological beliefs and with a higher need for cognition, who were more strongly affected by a two-sided presentation of evidence. The assertive version was less effective than the basic version, suggesting that recipients were skeptical when statements were presented as overly certain.|attitudes; message sidedness; hedging; science communication; elaboration likelihood model; blogs|EPISTEMIC BELIEFS; COGNITION; NEED; INFORMATION; PERSUASION; SCIENCE; ARGUMENTS; KNOWLEDGE; COVERAGE; HEDGES|Communication; Linguistics; Psychology, Social|6|3|23
Coherence analysis of research and education using topic modeling|2015|Research and education are organically connected in that lectures convey the results of research, which is frequently initiated by inspiring lectures. As a result, the contents of lecture materials and research publications and the research capabilities of universities should be considered in the investigations of the relationships between research and teaching. We examine the relationship between research and teaching using automatic text analysis. In particular, we scrutinize the relatedness of the content of research papers with the content of lecture materials to investigate the association between teaching and research. We adopt topic modeling for the correlation analysis of research capabilities and the reflectiveness of research topics in lecture materials. We select the field of machine learning as a case study because the field is contemporary and because data related to teaching and research are easily accessible via the Internet. The results reveal interesting characteristics of lecture materials and research publications in the field of machine learning. The research capability of an institute is independent of the lecture materials. However, for introductory courses, teaching and research measures showed a weak negative relationship, and there is little relationship between the measures for advanced courses.|Relationship between research and teaching; Text mining; Topic modeling; Research measure; Teaching measure; Machine learning|TEACHING EFFECTIVENESS; PRODUCTIVITY; INDEX|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|2|23
Quantifying the development of phraseological competence in L2 English writing: An automated approach|2014|Based on the large body of research that shows phraseology to be pervasive in language, this study aims to assess the role played by phraseological competence in the development of L2 writing proficiency and text quality assessment. We propose to use CollGram, a technique that assigns to each pair of contiguous words (bigrams) in a learner text two association scores (mutual information and t-score) computed on the basis of a large reference corpus, the Corpus of Contemporary American English. Applied to the Michigan State University Corpus of second language writing, CollGram shows a longitudinal decrease in the use of collocations made up of high-frequency words that are less typical of native writers. It also shows that the mean MI scores of the bigrams used by L2 writers are positively correlated with the quality of the essays, while there is a negative correlation between the quality of the texts and the proportion of bigrams that were absent in the reference corpus, most of which were shown to be erroneous. The conclusion discusses the marked differences in the effects revealed by the longitudinal and pseudolongitudinal analyses, the limitations of the study, and some potential implications for the teaching and assessment of second language writing. (C) 2014 Elsevier Inc. All rights reserved.|Phraseology; n-Gram; Collocation; Association measure; L2 learner corpus; Writing assessment|FORMULAIC LANGUAGE; COMPLEXITY; COLLOCATIONS; ACCURACY; LEARNERS; LEXIS; L1|Linguistics|13|2|23
Electronic outlining as a writing strategy: Effects on students' writing products, mental effort and writing process|2014|This study addresses to what extent and how electronic outlining enhances students' writing performance. To this end, the focus of this study is not only on students' final writing products but also on the organisation of the writing process (i.e., planning, translating, and reviewing) and perceived mental effort during writing. In addition, effects of repeated electronic outlining were examined. A combined within and between subjects design was implemented in which 93 10th-grade students wrote two argumentative texts with or without using electronic outlining. Analyses showed that using electronic outlining for planning and writing significantly improved the presentation of the argumentative structure. However, effects were less clear for correctly and completely establishing a text structure and no effects were found on the elaboration of students' argumentation. Process data showed that electronic outlining increased total process time, but no effect was found on students' overall planning and revision activities. Finally, self-reports showed no effect of electronic outlining on students' perceived mental effort. Nevertheless, repeated use of the same writing strategy enhanced writing fluency. (C) 2014 Elsevier Ltd. All rights reserved.|Secondary education; Writing strategies; Writing process; Electronic outlining; Mental effort|INDIVIDUAL-DIFFERENCES; SPEECH RECOGNITION; TEXT COMPOSITION; ERROR-CORRECTION; WORKING-MEMORY; COGNITIVE-LOAD; ORGANIZATION; FLUENCY; DEMANDS; PERFORMANCE|Computer Science, Interdisciplinary Applications; Education \& Educational Research|3|3|23
Orthogonal rotations in latent semantic analysis: An empirical study|2014|The Latent Semantic Analysis (LSA) literature has recently started to address the issue of interpretability of the extracted dimensions. On the software implementation front, recent versions of SAS Text Miner 0 started incorporating Varimax rotations. Considering open source software such as R, when it comes to rotation procedures the user has many more options. However, there is a little work in providing guidance for selecting an appropriate rotation procedure. In this paper we further previous research on LSA rotations by introducing two well known orthogonal rotations, namely Quartimax and Equamax, and comparing them to Varimax. We present a study that empirically tests the influence of the chosen orthogonal rotations on the extraction and interpretation of LSA factors. Our results indicate that, in most cases, Varimax and Equamax produce factors with similar interpretation, while Quartimax tends to produce a single factor. We conclude with recommendations on how these rotation procedures should be used and suggestions for future research. We note that orthogonal rotations can be used to improve the interpretability of other SVD-based models, such as COALS. (C) 2014 Elsevier B.V. All rights reserved.|Latent semantic analysis; Factor rotations; Varimax; Quartimax; Equamax; Big data; COALS|EXPLORATORY FACTOR-ANALYSIS; QUARTIMAX METHOD; INFORMATION|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|7|0|23
How do Planning Time and Task Conditions Affect Metacognitive Processes of L2 Writers?|2014|This study examined the effects of two task environmental factors, planning time (pre-task, extended pre-task, free-writing, and control) and task conditions (topic; topic and ideas; and topic, ideas, and macro-structure) on the frequencies of five metacognitive processes of L2 writers during the planning and writing stages. One hundred and six L2 writers reported their metacognitive processes: genetating new ideas, elaborating new ideas, organizing new ideas, thinking of essay structure, and thinking of language aspects of the task. The results show that the manipulation of the task conditions had a stronger effect than the planning time conditions on the five metacognitive processes of L2 writers. Specifically, the effects of task conditions were significant on the frequencies of generation and organization of new ideas during planning and on the frequencies of elaboration and organization of new ideas during writing. However, the effects of planning time were significant only on the frequency of thinking of language aspects of the task during writing. Our results support Kellogg's (1990) explanation for the Overload Hypothesis in that the L2 writers in the topic condition focused more of their attentional resources on metacognitive processes than the writers in the topic, ideas, and macro-structure condition. Interestingly, the writers in the planning conditions engaged in significantly more on-line planning than the writers in the control group. This study advances second language writing research by verifying contradictory claims about writers' attentional focus during the planning and writing stages. It also points to a trade-off effect between thinking of organization and language aspects of the writing task. (C) 2013 Elsevier Inc. All rights reserved.|Second language writing; Temporal distribution of metacognitive processes; Planning time; Task conditions; Task environment|WRITING PROCESSES; TEXT QUALITY; FORMULATION PROCESSES; TEMPORAL ANALYSIS; PERFORMANCE; COMPLEXITY; BEHAVIOR; STRATEGIES; ALLOCATION; STUDENTS|Linguistics|12|1|23
The processing of different syntactic structures: fMRI investigation of the linguistic distinction between wh-movement and verb movement|2014|Word order variation is a core property of sentence construction in natural languages and has been one of the most extensively studied issues in linguistics and cognitive science. In Hebrew, like in English, the basic word order is Subject-Verb-Object (SVO), but other orders, such as OSV or VSO, are also possible. According to generative syntactic theory, OSV and VSO are derived from the basic SVO order by two different types of syntactic movement: wh-movement, which moves the object to the beginning of the sentence, and verb movement, which moves the verb to a pre-subject position. Using sets of minimally-different sentences, containing the same words in different orders, we investigated the cortical activations related to the processing of these movement types. For wh-movement, we compared OSV and SVO sentences; like earlier studies of wh-movement, we found activations in the left IFG and bilateral posterior temporal regions. Activations related to verb movement were obtained through the comparison of VSO and SVO sentences, which showed activation in the left inferior occipital gyrus. Furthermore, an ROI analysis of regions that were active in the wh-movement contrast showed no difference between VSO and SVO conditions. This is the first fMRI study to compare wh-movement and verb movement, and the first to test verb movement in comprehension. The findings indicate that the different syntactic analyses assumed by linguistic theory for different word orders are reflected in differential brain activations, lending support for the generative theory of syntactic movement and the distinction between wh-movement and verb movement. (C) 2013 Elsevier Ltd. All rights reserved.|Syntactic movement; Broca's area; Neurolinguistics; Sentence processing; Syntax|SENTENCE COMPREHENSION; WORKING-MEMORY; LANGUAGE COMPREHENSION; AGRAMMATIC APHASICS; RELATIVE CLAUSES; CORTICAL REPRESENTATION; GRAMMATICAL STRUCTURE; QUESTION PRODUCTION; CEREBELLAR LESIONS; LEXICAL DECISION|Linguistics; Neurosciences; Psychology, Experimental|8|6|23
EMOTIONS IN TEXT: DIMENSIONAL AND CATEGORICAL MODELS|2013|Text often expresses the writer's emotional state or evokes emotions in the reader. The nature of emotional phenomena like reading and writing can be interpreted in different ways and represented with different computational models. Affective computing (AC) researchers often use a categorical model in which text data are associated with emotional labels. We introduce a new way of using normative databases as a way of processing text with a dimensional model and compare it with different categorical approaches. The approach is evaluated using four data sets of texts reflecting different emotional phenomena. An emotional thesaurus and a bag-of-words model are used to generate vectors for each pseudo-document, then for the categorical models three dimensionality reduction techniques are evaluated: Latent Semantic Analysis (LSA), Probabilistic Latent Semantic Analysis (PLSA), and Non-negative Matrix Factorization (NMF). For the dimensional model a normative database is used to produce three-dimensional vectors (valence, arousal, dominance) for each pseudo-document. This three-dimensional model can be used to generate psychologically driven visualizations. Both models can be used for affect detection based on distances amongst categories and pseudo-documents. Experiments show that the categorical model using NMF and the dimensional model tend to perform best.|affective computing; text mining; emotion models|VALENCE; WORDS|Computer Science, Artificial Intelligence|29|5|23
Literary intertextuality in genre-based pedagogies: Building lexical cohesion in fifth-grade L2 writing|2013|Literary narrative is a highly privileged genre in subject English classrooms in school and university contexts. This article investigates how an explicit instructional focus on the language in this literary genre supported language minority students in developing advanced academic literacy. Through a systemic functional linguistics and ethnographic analytic framework, the study explores how an urban school teacher's genre-based pedagogy in literature, implemented with the support of a professional development initiative, afforded her 5th grade students with a meta linguistic awareness of how to use an expanded repertoire of linguistic choices in their genre writing. An SFL analysis of students' texts over the course of five months reveals how the teacher's explicit focus on intertextuality encouraged her language minority students to borrow and play with lexical patterns, such as repetition, taxonomic categorization, and synonymy from children's literature, to build the genre sequences in their narratives and other academic writing. The concluding section of the paper discusses possible implications, including the importance of an explicit instructional focus on literature as an intertextual resource in teaching writing. (C) 2013 Elsevier Inc. All rights reserved.|Critical genre-based pedagogy; Second language writing; Systemic functional linguistics; Intertextuality; Urban teacher education; Literature instruction|LANGUAGE; LEARNERS|Linguistics|12|3|23
APPLICATIONS OF TEXT ANALYSIS TOOLS FOR SPOKEN RESPONSE GRADING|2013|This study explores the potential for automated indices related to speech delivery, language use, and topic development to model human judgments of TOEFL speaking proficiency in second language (L2) speech samples. For this study, 244 transcribed TOEFL speech samples taken from 244 L2 learners were analyzed using automated indices taken from Coh-Metrix, CPIDR, and LIWC. A stepwise linear regression was used to explain the variance in human judgments of independent speaking ability and overall speaking proficiency. Automated indices related to word type counts, causal cohesion, and lexical diversity predicted 52\% of the variance in human ratings for the independent speech samples. Automated indices related to word type counts and word frequency predicted 61\% of the variance of the human scores of overall speaking proficiency. These analyses demonstrate that, even in the absence of indices related to pronunciation and prosody (e.g., phonological accuracy, intonation, and stress), automated indices related to vocabulary size, causality, and word frequency can predict a significant amount of the variance in human ratings of speaking proficiency. These findings have important implications for understanding the construct of speaking proficiency and for the development of automatic scoring techniques.|Language Testing; Speaking Proficiency; Computational Linguistics; Corpus Linguistics; Machine Learning|PROFICIENCY; COHERENCE; SPEECH; KNOWLEDGE; COHESION; IMAGERY; MODELS; RATER|Education \& Educational Research; Linguistics|14|10|23
Semantics-based information extraction for detecting economic events|2013|As today's financial markets are sensitive to breaking news on economic events, accurate and timely automatic identification of events in news items is crucial. Unstructured news items originating from many heterogeneous sources have to be mined in order to extract knowledge useful for guiding decision making processes. Hence, we propose the Semantics-Based Pipeline for Economic Event Detection (SPEED), focusing on extracting financial events from news articles and annotating these with meta-data at a speed that enables real-time use. In our implementation, we use some components of an existing framework as well as new components, e.g., a high-performance Ontology Gazetteer, a Word Group Look-Up component, a Word Sense Disambiguator, and components for detecting economic events. Through their interaction with a domain-specific ontology, our novel, semantically enabled components constitute a feedback loop which fosters future reuse of acquired knowledge in the event detection process.|Event detection; Semantics; Natural language processing; Information extraction|TECHNICAL TRADING RULES|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|10|1|23
WNavi(s): Navigating Wikipedia semantically with an SNA-based summarization technique|2012|Link-based applications like Wikipedia are becoming increasingly popular because they provide users with an efficient way to find needed knowledge, such as searching for definitions and information about a particular topic, and exploring articles on related topics. This work introduces a semantics-based navigation application called WNavi(s), to facilitate information-seeking activities in internal link-based websites in Wikipedia. WNavi(s) is based on the theories and techniques of link mining, semantic relatedness analysis and text summarization. Our goal is to develop an application that helps users find related articles for a seed query (topic) easily and then quickly check the content of articles to explore a new concept or topic in Wikipedia. Technically, we construct a preliminary topic network by analyzing the internal links of Wikipedia and applying the normalized Google distance algorithm to quantify the strength of the semantic relationships between articles via key terms. Because not all the content of articles in Wikipedia is relevant to users' information needs, it is desirable to locate specific information for users and enable them to quickly explore and read topic-related articles. Accordingly, we propose an SNA-based single and multiple-document summarization technique that can extract meaningful sentences from articles. We applied a number of intrinsic and extrinsic evaluation methods to demonstrate the efficacy of the summarization techniques in terms of precision, and recall. The results suggest that the proposed summarization technique is effective. Our findings have implications for the design of a navigation tool that can help users explore related articles in Wikipedia quickly. (C) 2012 Elsevier B.V. All rights reserved.|Navigation; Normalized Google distance; Semantics-based; SNA-based summary; Wikipedia|SEARCH; WEB; CONTEXT; CENTRALITY; LINK|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|2|1|23
Learning the ``Whys{''}: Discovering design rationale using text mining - An algorithm perspective|2012|Collecting design rationale (DR) and making it available in a well-organized manner will better support product design, innovation and decision-making. Many DR systems have been developed to capture DR since the 1970s. However, the DR capture process is heavily human involved. In addition, with the increasing amount of DR available in archived design documents, it has become an acute problem to research a new computational approach that is able to capture DR from free textual contents effectively. In our previous study, we have proposed an ISAL (issue, solution and artifact layer) model for DR representation. In this paper, we focus on algorithm design to discover DR from design documents according to the ISAL modeling. For the issue layer of the ISAL model, we define a semantic sentence graph to model sentence relationships through language patterns. Based on this graph, we improve the manifold-ranking algorithm to extract issue-bearing sentences. To discover solution-reason bearing sentences for the solution layer, we propose building up two sentence graphs based on candidate solution-bearing sentences and reason-bearing sentences respectively, and propagating information between them. For artifact information extraction, we propose two term relations, i.e. positional term relation and mutual term relation. Using these relations, we extend our document profile model to score the candidate terms. The performance and scalability of the algorithms proposed are tested using patents as research data joined with an example of prior art search to illustrate its application prospects. (C) 2011 Elsevier Ltd. All rights reserved.|Design rationale; Rationale representation; Rationale discovery; Text Mining; Patent mining|PATENT ANALYSIS; RETRIEVAL; INFORMATION; REPRESENTATION; SEARCH; CLASSIFICATION; EXTRACTION; MANAGEMENT; KNOWLEDGE; SYSTEMS|Computer Science, Software Engineering|16|1|23
Construction and Preliminary Validation of a Dictionary for Cognitive Rigidity: Linguistic Markers of Overconfidence and Overgeneralization and their Concomitant Psychological Distress|2012|Fanaticism and extremism are increasingly recognized as seminal to psychopathology and distress, especially considering the increase in political unrest and violence over the last decade. In the psychopathological literature, however, the cognitive style associated with extremism and overgeneralization has long been recognized as a risk factor for emotional distress, leading to both externalizing behavior (e.g. aggression) and internalizing pathology (e.g. depression). Despite its recognized importance, however, virtually no standardized measures of this cognitive style exist. Since direct inquiry about a respondent's Cognitive Rigidity, is likely to be biased, a text-analytical measure of extremism in spontaneous autobiographical narratives is proposed. In contrast to self-reports, naturally occurring speech often suggests cognitive proclivities towards overgeneralization, overconfidence or extremization. In this study, spoken autobiographical narratives were elicited from 483 participants, and contrasted with extensive mental health information using a hierarchical concordanced-keyword technique. The resulting corpus-based dictionary is context-sensitive, and exhibits significant correlations with measures of negative emotionality, with minimal association with response bias measures.|Cognitive rigidity; Overgeneralization; Text-analysis; Corpus-linguistics; Autobiographical narratives; Psychological distress|ATTRIBUTIONAL STYLE QUESTIONNAIRE; BORDERLINE PERSONALITY-DISORDER; BECK DEPRESSION INVENTORY; ARTICULATED THOUGHTS; SOCIAL-PSYCHOLOGY; DEFENSE STYLES; SELF-REPORT; DYSFUNCTIONAL ATTITUDES; EMOTIONAL INFORMATION; DISCRIMINANT VALIDITY|Linguistics; Psychology, Experimental|8|2|23
Sentic PROMs: Application of sentic computing to the development of a novel unified framework for measuring health-care quality|2012|Barriers to use health related quality of life measuring systems include the time needed to complete the forms and the need for staff to be trained to understand the results. An ideal system of health assessment needs to be clinically useful, timely, sensitive to change, culturally sensitive, low burden, low cost, involving for the patient and built into standard procedures. A new generation of short and easy-to-use tools to monitor patient outcomes on a regular basis has been recently proposed. These tools are quick, effective and easy to understand, as they are very structured and rigid. Such structuredness, however, leaves no space to those patients who would like to say something more. Patients, in fact, are usually willing to express their opinions and feelings in free text, rather than simply filling in a questionnaire, for either speaking out their satisfaction or for cathartic complaining. Sentic PROMs allow patients to evaluate their health status and experience in a semi-structured way and accordingly aggregate input data by means of sentic computing, while tracking patients' physio-emotional sensitivity. (C) 2012 Elsevier Ltd. All rights reserved.|Al; E-Health; Natural language processing; Opinion mining; Sentiment analysis|DIGITAL INTUITION; EMOTIONS; SCALES|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|28|4|23
Writing to learn via text chat: Task implementation and focus on form|2012|Research has shown that task-based computer-mediated communication (CMC) can foster attention to linguistic form in ways that may promote language learning (c.f., Blake, 2000; Smith, 2003, 2005). However, relatively little research has investigated how differences in the way that tasks are used in CMC settings influence learning opportunities during the task. In an attempt to shed light on the manner in which second language (L2) writing may contribute to L2 development, this chapter present's an empirical study of how two implementation features (degree of task structure and provision of language support) of a writing group task in simultaneous text-CMC influenced learner attention to linguistic form. The analysis draws on data from text chat performance and post-task group interviews to illustrate how aspects of task implementation in a technology-enhanced learning environment may promote attention to language expression and encourage collaborative work on language errors during writing task performance. (C) 2012 Elsevier Inc. All rights reserved.|Task complexity; Computer-mediated communication; Focus-on-form; Cognition Hypothesis; Writing-to-learn the language|COMPUTER-MEDIATED COMMUNICATION; NEGOTIATED INTERACTION; COMPLEXITY; PERFORMANCE; LANGUAGE; FLUENCY; OUTPUT; ACCURACY; FEEDBACK; ENGLISH|Linguistics|11|0|23
Does the Modality Effect Exist? and if So, Which Modality Effect?|2012|The modality effect is a central issue in multimedia learning {[}see Mayer (Cambridge University Press, 2005a), for a review]. Sweller's Cognitive Load Theory (CLT), for example, presumes that an illustrated text is better understood when presented visually rather than orally. The predictive power of CLT lies in how it links in to Baddeley's (1986) model of working memory and Penney's (Mem Cognit 17: 398-442, 1989) Separate-Streams Hypothesis. Ginns's (Learn Instr 4: 313-331, 2005) recent meta-analysis also supports the modality effect (d = 0.72, based on 43 independent effects). This article replicates the meta-analysis of the modality effect based on 86 independent effects (with within-study subgroups as the unit of analysis and with mean of the outcomes as the dependent measure), with results showing a reduction of the overall effect size by almost half (d = 0.38), and even more when Duval and Tweedie's Trim and Fill method is used to correct publication bias (d = 0.20). This article also widens the scope of the analysis of moderator variables (e. g. Pace of presentation, Type of visualization, Research group) as well as their potentially confounded effects. Finally, it is argued that, for theoretical reasons, the so-called modality effect cannot be based on Penney's or Baddeley's theories and must be explained in a different way.|Modality effect; Meta-analysis; Illustrated text; Working memory; Cognitive load theory|COGNITIVE LOAD THEORY; ANIMATED PEDAGOGICAL AGENTS; DUAL-TASK METHODOLOGY; WORKING-MEMORY; EYE-MOVEMENTS; MULTIMEDIA INSTRUCTION; SPLIT-ATTENTION; WORLD KNOWLEDGE; TEXT; SCIENCE|Linguistics; Psychology, Experimental|8|1|23
New Measures of Masked Text Recognition in Relation to Speech-in-Noise Perception and Their Associations With Age and Cognitive Abilities|2012|Purpose: In this research, the authors aimed to increase the analogy between Text Reception Threshold (TRT; Zekveld, George, Kramer, Goverts, \& Houtgast, 2007) and Speech Reception Threshold (SRT; Plomp \& Mimpen, 1979) and to examine the TRT's value in estimating cognitive abilities that are important for speech comprehension in noise. Method: The authors administered 5 TRT versions, SRT tests in stationary (SRTSTAT) and modulated (SRTMOD) noise, and 2 cognitive tests: a reading span (RSpan) test for working memory capacity and a letter-digit substitution test for information-processing speed. Fifty-five adults with normal hearing (18-78 years, M = 44 years) participated. The authors examined mutual associations of the tests and their predictive value for the SRTs with correlation and linear regression analyses. Results: SRTs and TRTs were well associated, also when controlling for age. Correlations for the SRTSTAT were generally lower than for the SRTMOD. The cognitive tests were correlated to the SRTs only when age was not controlled for. Age and the TRTs were the only significant predictors of SRTMOD. SRTSTAT was predicted by level of education and some of the TRT versions. Conclusions: TRTs and SRTs are robustly associated, nearly independent of age. The association between SRTs and RSpan is largely age dependent. The TRT test and the RSpan test measure different nonauditory components of linguistic processing relevant for speech perception in noise.|masked text recognition; speech perception; cognitive abilities; age; working memory|RECEPTION THRESHOLD TEST; WORKING-MEMORY; INDIVIDUAL-DIFFERENCES; NORMAL-HEARING; ADULTS; LISTENERS; COMPREHENSION; COMPRESSION; SENTENCES; CONTEXT|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|32|2|23
Mining Travel Patterns from Geotagged Photos|2012|Recently, the phenomenal advent of photo-sharing services, such as Flickr and Panoramio, have led to volumous community-contributed photos with text tags, timestamps, and geographic references on the Internet. The photos, together with their time- and geo-references, become the digital footprints of photo takers and implicitly document their spatiotemporal movements. This study aims to leverage the wealth of these enriched online photos to analyze people's travel patterns at the local level of a tour destination. Specifically, we focus our analysis on two aspects: (1) tourist movement patterns in relation to the regions of attractions (RoA), and (2) topological characteristics of travel routes by different tourists. To do so, we first build a statistically reliable database of travel paths from a noisy pool of community-contributed geotagged photos on the Internet. We then investigate the tourist traffic flow among different RoAs by exploiting the Markov chain model. Finally, the topological characteristics of travel routes are analyzed by performing a sequence clustering on tour routes. Testings on four major cities demonstrate promising results of the proposed system.|Design; Measurement; Documentation; Travel pattern mining; geotagged photos|MOVEMENT; TOURISTS; SYSTEM|Computer Science, Artificial Intelligence; Computer Science, Information Systems|24|2|23
Similar neural correlates for language and sequential learning: Evidence from event-related brain potentials|2012|We used event-related potentials (ERPs) to investigate the time course and distribution of brain activity while adults performed (1) a sequential learning task involving complex structured sequences and (2) a language processing task. The same positive ERP deflection, the P600 effect, typically linked to difficult or ungrammatical syntactic processing, was found for structural incongruencies in both sequential learning as well as natural language and with similar topographical distributions. Additionally, a left anterior negativity (LAN) was observed for language but not for sequential learning. These results are interpreted as an indication that the P600 provides an index of violations and the cost of integration of expectations for upcoming material when processing complex sequential structure. We conclude that the same neural mechanisms may be recruited for both syntactic processing of linguistic stimuli and sequential learning of structured sequence patterns more generally.|Event-related potentials (ERPs); Sequential learning; Implicit learning; Language processing; Prediction; P600|VERB AGREEMENT VIOLATIONS; ARTIFICIAL LANGUAGE; HEMISPHERIC ASYMMETRIES; METAPHOR COMPREHENSION; PHONOLOGICAL MARKERS; 8-MONTH-OLD INFANTS; BEHAVIORAL EVIDENCE; JOKE COMPREHENSION; TEMPORAL STRUCTURE; BROCAS APHASIA|Linguistics; Psychology, Experimental|32|3|23
A Web Search Engine-Based Approach to Measure Semantic Similarity between Words|2011|Measuring the semantic similarity between words is an important component in various tasks on the web such as relation extraction, community mining, document clustering, and automatic metadata extraction. Despite the usefulness of semantic similarity measures in these applications, accurately measuring semantic similarity between two words (or entities) remains a challenging task. We propose an empirical method to estimate semantic similarity using page counts and text snippets retrieved from a web search engine for two words. Specifically, we define various word co-occurrence measures using page counts and integrate those with lexical patterns extracted from text snippets. To identify the numerous semantic relations that exist between two given words, we propose a novel pattern extraction algorithm and a pattern clustering algorithm. The optimal combination of page counts-based co-occurrence measures and lexical pattern clusters is learned using support vector machines. The proposed method outperforms various baselines and previously proposed web-based semantic similarity measures on three benchmark data sets showing a high correlation with human ratings. Moreover, the proposed method significantly improves the accuracy in a community mining task.|Web mining; information extraction; web text analysis|LANGUAGE|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|43|1|23
An ontology-based measure to compute semantic similarity in biomedicine|2011|Proper understanding of textual data requires the exploitation and integration of unstructured and heterogeneous clinical sources, healthcare records or scientific literature, which are fundamental aspects in clinical and translational research. The determination of semantic similarity between word pairs is an important component of text understanding that enables the processing, classification and structuring of textual resources. In the past, several approaches for assessing word similarity by exploiting different knowledge sources (ontologies, thesauri, domain corpora, etc.) have been proposed. Some of these measures have been adapted to the biomedical field by incorporating domain information extracted from clinical data or from medical ontologies (such as MeSH or SNOMED CT). In this paper, these approaches are introduced and analyzed in order to determine their advantages and limitations with respect to the considered knowledge bases. After that, a new measure based on the exploitation of the taxonomical structure of a biomedical ontology is proposed. Using SNOMED CT as the input ontology, the accuracy of our proposal is evaluated and compared against other approaches according to a standard benchmark of manually ranked medical terms. The correlation between the results of the evaluated measures and the human experts' ratings shows that our proposal outperforms most of the previous measures avoiding, at the same time, some of their limitations. (C) 2010 Elsevier Inc. All rights reserved.|Semantic similarity; Ontologies; SNOMED CT; Biomedicine; Data mining|INFORMATION-RETRIEVAL; CONCEPTUAL DISTANCE; CONTEXT; RELATEDNESS|Computer Science, Interdisciplinary Applications; Medical Informatics|93|1|23
A contrastive study of the rhetorical organisation of English and Spanish PhD thesis introductions|2011|This paper presents an analysis of the introductory sections of a corpus of 20 doctoral theses on computing written in Spanish and in English Our aim was to ascertain whether the theses produced within the same scientific-technological area but by authors from different cultural and linguistic backgrounds, employed the same rhetorical strategies to Introduce the work presented The analysis follows the Swalesian approach and is based on a move/step/sub step model proposed for PhD introductions in Spanish (Carbonell-Olivares, Gil-Salom, \& Soler-Monreal, 2009) The Spanish academic conventions appear to be that move 1 (M 1-Establishing the Territory) and move 3 (M3-Occupying the Niche) are obligatory moves in PhD thesis introductions in Spanish, while move 2 (M2-Establishing the Niche) is optional The structure of English thesis introductions reveals that they conform more closely to the M1-M2-M3 arrangement Moreover, combinations of moves and patterns, cyclicity and embedding make their organisation more complex The step analysis suggests that introductions in both languages rely mainly on the presentation of background information and the work carried out However, the English introductions tend to stress the writer's own work its originality and its contribution to the field of study They also present more embedding and overlapping of steps and sub-steps than the Spanish texts (C) 2010 Elsevier Ltd All rights reserved|Contrastive rhetoric; Intercultural rhetoric; Genre analysis; Doctoral thesis; Introduction; Academic writing; Computing|GENRE ANALYSIS; ABSTRACTS|Linguistics|26|1|23
Developing and integrating courseware for oral presentations into ESP learning contexts|2010|This study reports on the development of ESP (English for Specific Purposes) multimedia courseware on oral presentations, and its integration into self-study learning and elective courses for students with different English proficiencies, as one solution to problems in ESP courses in Taiwan. The courseware design is based on Mayer's multimedia learning cognitive theory, and the language learning focus draws on Chapelle's suggested criteria for development of multimedia CALL Evaluation of student performance with two different formats for courseware integration is based upon data from pre- and post-tests for preparing speech texts, and a questionnaire survey. The courseware provides authentic materials with a logical situational layout and a friendly interface design for learning ESP for oral presentations in international business and technical settings and offers rich and flexible learning activities with corresponding on-line self-evaluation so that students actively engage in cognitive processing. Students with different English proficiencies have different concerns about giving a presentation. Meanwhile, after students' self-study for six weeks, regardless of level of proficiency, students' learning effectiveness and satisfaction with the courseware integration were significantly improved, by qualitative and quantitative analysis. Such students' improvement suggests success of the courseware design and learning effectiveness with its integration. (C) 2010 Elsevier Ltd. All rights reserved.|Interactive learning environments; Multimedia/hypermedia systems; Improving classroom teaching; Post-secondary education|LANGUAGE; COMPREHENSION; INSTRUCTION; CLASSROOM; STUDENTS; NEEDS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|15|1|23
Lexical and Affective Prosody in Children With High-Functioning Autism|2010|Purpose: To investigate the perception and production of lexical stress and processing of affective prosody in adolescents with high-functioning autism (HFA). We hypothesized preserved processing of lexical and affective prosody but atypical lexical prosody production. Method: Sixteen children with HFA and 15 typically developing (TD) peers participated in 3 experiments that examined the following: (a) perception of affective prosody (Experiment 1), (b) lexical stress perception (Experiment 2), and (c) lexical stress production (Experiment 3). In Experiment 1, participants labeled sad, happy, and neutral spoken sentences that were low-pass filtered, to eliminate verbal content. In Experiment 2, participants disambiguated word meanings based on lexical stress (HOTdog vs. hot DOG). In Experiment 3, participants produced these words in a sentence completion task. Productions were analyzed with acoustic measures. Results: Accuracy levels showed no group differences. Participants with HFA could determine affect from filtered sentences and disambiguate words on the basis of lexical stress. They produced appropriately differentiated lexical stress patterns but demonstrated atypically long productions, indicating reduced ability in natural prosody production. Conclusions: Children with HFA were as capable as their TD peers in receptive tasks of lexical stress and affective prosody. Prosody productions were atypically long, despite accurate differentiation of lexical stress patterns. Future research should use larger samples and spontaneous versus elicited productions.|autism; prosody; lexical stress; affective prosody; perception; production|PERVASIVE DEVELOPMENTAL DISORDERS; SPECTRUM DISORDERS; REVISED VERSION; VOCAL EMOTION; SPEECH; STRESS; LANGUAGE; ADOLESCENTS; EXPRESSION; ADULTS|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|59|2|23
Computer Vision and Natural Language Processing: Recent Approaches in Multimedia and Robotics|2017|Integrating computer vision and natural language processing is a novel interdisciplinary field that has received a lot of attention recently. In this survey, we provide a comprehensive introduction of the integration of computer vision and natural language processing in multimedia and robotics applications with more than 200 key references. The tasks that we survey include visual attributes, image captioning, video captioning, visual question answering, visual retrieval, human-robot interaction, robotic actions, and robot navigation. We also emphasize strategies to integrate computer vision and natural language processing models as a unified theme of distributional semantics. We make an analog of distributional semantics in computer vision and natural language processing as image embedding and word embedding, respectively. We also present a unified view for the field and propose possible future directions.|Computer Vision; Natural Language Processing; Robotics; Language and vision; survey; multimedia; robotics; symbol grounding; distributional semantics; computer vision; natural language processing; visual attribute; image captioning; imitation learning; word2vec; word embedding; image embedding; semantic parsing; lexical semantics|WEB DATA; DISTRIBUTIONAL SEMANTICS; RECOGNITION; MODELS; IMAGES; COMMUNICATION; ANNOTATION; PERCEPTION; GRAMMAR; NORMS|Computer Science, Theory \& Methods|0|13|22
WEB-BASED COLLABORATIVE WRITING IN L2 CONTEXTS: METHODOLOGICAL INSIGHTS FROM TEXT MINING|2017|The increasingly widespread use of social software (e.g., Wikis, Google Docs) in second language (L2) settings has brought a renewed attention to collaborative writing. Although the current methodological approaches to examining collaborative writing are valuable to understand L2 students' interactional patterns or perceived experiences, they can be insufficient to capture the quantity and quality of writing in networked online environments. Recently, the evolution of techniques for analyzing big data has transformed many areas of life, from information search to marketing. However, the use of data and text mining for understanding writing processes in language learning contexts is largely underexplored. In this article, we synthesize the current methodological approaches to researching collaborative writing and discuss how new text mining tools can enhance research capacity. These advanced methods can help researchers to elucidate collaboration processes by analyzing user behaviors (e. g., amount of editing, participation equality) and their link to writing outcomes across large numbers of exemplars. We introduce key research examples to illustrate this potential and discuss the implications of integrating the tools for L2 collaborative writing research and pedagogy.|Collaborative Learning; Writing; Digital Literacies; Research Methods|LANGUAGE; WIKIS; LEARNERS; STUDENTS; TECHNOLOGY; FACILITATE|Education \& Educational Research; Linguistics|4|13|22
A multimodal discourse analysis of international postgraduate business students' finance texts: an investigation of theme and information value|2016|Thematic progression patterning and the composition of information value facilitate the development of well-structured messages. The text-based research of systemic functional linguistics (SFL) into textual features has been confined to language learning and workplace contexts. Empirical research studies involving finance have investigated students' performance in finance courses and the effects of class attendance on their performance. However, no published studies have yet explored or analysed the textual features of tertiary finance texts. This study investigated the Theme and information value in 6 group assignments in finance, written by 19 Master's students in accounting. Underpinned by Halliday's SFL and Kress and van Leeuwen's system of the composition of information value, this study employed a systemic functional multimodal discourse analysis (SF-MDA) of the texts. The SF-MDA revealed a high frequency of Theme reiteration patterns, the rare occurrence of a linear Theme pattern, and the minimal use of a multiple-Theme pattern. These findings have both theoretical and pedagogical implications for the teaching and learning of writing, particularly in the context of teaching English for business purposes.|Business discourse; finance discourse; composition of information value; thematic progression; systemic functional linguistic (SFL); multimodal discourse analysis (MDA)|COHESION|Humanities, Multidisciplinary; Communication; Linguistics|0|5|22
Plagiarism in English academic writing: A comparison of Chinese university teachers' and students' understandings and stances|2016|Research on plagiarism has largely left English-as-a-Foreign-Language (EFL) teachers out of the picture. This study set out to bridge the gap by comparing how 142 Chinese university EFL teachers and 270 undergraduate students viewed exemplars of unacknowledged copying and unattributed paraphrasing, two forms of intertextuality generally regarded as plagiarism in Anglo-American academia. More than half of the teacher participants had overseas academic experience. Quantitative and qualitative analyses found that the participants, though understanding plagiarism in English academic writing differently from Anglo-American academia, clearly disapproved of recognized cases of plagiarism. The analyses also revealed that greater knowledge of and harsher stances on both types of transgressive intertextuality were associated with wider exposure to and more experience in English academic writing. Furthermore, the participants had more similar understandings of unacknowledged copying than of unattributed paraphrasing and took harsher stances on the former. These findings highlight complex and nuanced understandings of plagiarism and point to the crucial role of academic socialization in shaping knowledge of and attitudes toward plagiarism. (C) 2015 Elsevier Ltd. All rights reserved.|Academic socialization; Chinese teachers and students; English academic writing; Plagiarism; Transgressive intertextuality|PERCEPTIONS; KNOWLEDGE; VALUES; TEXT|Education \& Educational Research; Linguistics|6|1|22
Configuring image and context: Writing `about' pictures|2016|Humanities texts have been little studied in ESP, and the few analyses attempted have not always been as successful as those directed at the social sciences, life sciences and natural sciences. However, in largely post-industrial communities, the growth of museums and galleries (as well as the corresponding increase in museum studies programs) suggests that humanities texts in this sector might now warrant attention. Since, outside English-speaking countries, these texts about artworks or cultural artifacts are typically produced both in English and the local language, there is clearly potential here for ESP development. In this case study of a small corpus of one-page accounts of pictures, analysis shows that the interpretations are rarely organized in a general-specific or specific-general manner, but rather oscillate between reference to the micro image and the broader context, as in this 26-sentence example (Con = Context; Image = Im): {[}GRAPHICS] This kind of patterning is teachable, as are more specific features, such as the exegetic role of comparisons, the subdued versus prominent employment of intertextual references, and the judicious use of parenthetical information and qualifying hedges. The article closes with an illustrative learner task designed to raise awareness of the oscillating pattern. (C) 2015 Elsevier Ltd. All rights reserved.|Art historical discourse; Single image accounts; Image and context; Pedagogical applications|RESEARCH ARTICLES; DISCOURSE; THESIS|Linguistics|0|2|22
SemPathFinder: Semantic path analysis for discovering publicly unknown knowledge|2015|The enormous amount of biomedicine's natural-language texts creates a daunting challenge to discover novel and interesting patterns embedded in the text corpora that help biomedical professionals find new drugs and treatments. These patterns constitute entities such as genes, compounds, treatments, and side effects and their associations that spread across publications in different biomedical specialties. This paper proposes SemPathFinder to discover previously unknown relations in biomedical text. SemPathFinder overcomes the problems of Swanson's ABC model by using semantic path analysis to tell a story about plausible connections between biological terms. Storytelling-based semantic path analysis can be viewed as relation navigation for bio-entities that are semantically close to each other, and reveals insight into how a series of entity pairs is organized, and how it can be harnessed to explain seemingly unrelated connections. We apply SemPathFinder for two well-known use cases of Swanson's ABC model, and the experimental results show that SemPathFinder detects all intermediate terms except for one and also infers several interesting new hypotheses. (C) 2015 Elsevier Ltd. All rights reserved.|Literature based discovery; Named entity recognition; Relation extraction; Semantic path analysis; Semantic relatedness score|FISH-OIL; MAGNESIUM; MIGRAINE; TEXT; CONNECTIONS; ASSOCIATIONS; MODULATION; SIMILARITY; PROTEINS; DISEASES|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|2|2|22
Exploring relation types for literature-based discovery|2015|Objective Literature-based discovery (LBD) aims to identify ``hidden knowledge{''} in the medical literature by: (1) analyzing documents to identify pairs of explicitly related concepts (terms), then (2) hypothesizing novel relations between pairs of unrelated concepts that are implicitly related via a shared concept to which both are explicitly related. Many LBD approaches use simple techniques to identify semantically weak relations between concepts, for example, document co-occurrence. These generate huge numbers of hypotheses, difficult for humans to assess. More complex techniques rely on linguistic analysis, for example, shallow parsing, to identify semantically stronger relations. Such approaches generate fewer hypotheses, but may miss hidden knowledge. The authors investigate this trade-off in detail, comparing techniques for identifying related concepts to discover which are most suitable for LBD. Materials and methods A generic LBD system that can utilize a range of relation types was developed. Experiments were carried out comparing a number of techniques for identifying relations. Two approaches were used for evaluation: replication of existing discoveries and the ``time slicing{''} approach.(1) Results Previous LBD discoveries could be replicated using relations based either on document co-occurrence or linguistic analysis. Using relations based on linguistic analysis generated many fewer hypotheses, but a significantly greater proportion of them were candidates for hidden knowledge. Discussion and Conclusion The use of linguistic analysis-based relations improves accuracy of LBD without overly damaging coverage. LBD systems often generate huge numbers of hypotheses, which are infeasible to manually review. Improving their accuracy has the potential to make these systems significantly more usable.|literature based discovery; text mining; knowledge discovery; natural language processing|BIOMEDICAL CONCEPTS; FISH-OIL; MEDICAL LITERATURES; ALZHEIMERS-DISEASE; CONNECTIONS; MAGNESIUM; KNOWLEDGE; MIGRAINE; IMPLICIT; RAYNAUDS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|5|9|22
Anticipation - the underlying science of sport. Report on research in progress|2015|Professional sport practitioners intuitively acknowledge anticipation. Sports researchers sometimes discuss it. Still, there is little data-based evidence to characterize the role anticipation plays in human performance. Even less documented is the distinction between reaction and anticipation. This text presents the real-time quantification environment developed as an AnticipationScope (TM). Based on a very large data harvest from this experimental set-up, hypotheses regarding the role of anticipation in sport are advanced. The conclusion is that while preparation and reaction play an important role in sports performance, in the final analysis anticipation distinguishes the professional from other sport practitioners. Work in progress is presented with the aim of engaging the community of researchers in the design of alternative methods for quantifying anticipation and for processing the data. Generalization from sport to human performance is one of the intended outcomes of this research.|variability; reaction; anticipation; space of possibilities; perception; holistic perspective|INFEROTEMPORAL CORTEX; VISUAL-SEARCH; EVOLUTION; PLAYERS; TENNIS; PERFORMANCE; SHOULDER; OBJECT; MONKEY; TIME|Computer Science, Theory \& Methods; Ergonomics|1|0|22
A hierarchical classification approach to automated essay scoring|2015|This study evaluates the use of a hierarchical classification approach to automated assessment of essays. Automated essay scoring (AES) generally relies on machine learning techniques that compute essay scores using a set of text variables. Unlike previous studies that rely on regression models, this study computes essay scores using a hierarchical approach, analogous to an incremental algorithm for hierarchical classification. The corpus in this study consists of 1243 argumentative (persuasive) essays written on 14 different prompts, across 3 different grade levels (9th grade, 11th grade, college freshman), and four different time limits for writing or temporal conditions (untimed essays and essays written in 10, 15, and 25 minute increments). The features included in the analysis are computed using the automated tools, Coh-Metrix, the Writing Assessment Tool (WAT), and Linguistic Inquiry and Word Count (LIWC). Overall, the models developed to score all the essays in the data set report 55\% exact accuracy and 92\% adjacent accuracy between the predicted essay scores and the human scores. The results indicate that this is a promising approach to AES that could provide more specific feedback to writers and may be relevant to other natural language computations, such as the scoring of short answers in comprehension or knowledge assessments. (C) 2014 Elsevier Ltd. All rights reserved.|Automated essay scoring; AES; Writing assessment; Hierarchical classification|MRC PSYCHOLINGUISTIC DATABASE; LATENT SEMANTIC ANALYSIS; COH-METRIX; LINGUISTIC FEATURES; WRITING ASSESSMENT; TEXT; COMPREHENSION; COHESION; LANGUAGE; STUDENTS|Education \& Educational Research; Linguistics|20|2|22
Generic structure and rhetorical moves in English-language empirical law research articles: Sites of interdisciplinary and interdiscursive cross-over|2015|In the globalized, competitive contemporary world of science, legal research articles (RAs) provide a favourable medium for disciplinary knowledge exchange to the wider scholarly community. However, there is little understanding of how structure reflects this knowledge in the writing of such articles. In this paper, I interrogate the overall generic structure of empirical law research articles written in English together with the set of communicative/functional move categories represented across sections of the article's structure. Using Genre Analysis as a framework and the prototypical IMRD model for the identification of discourse structure across a representative sample of texts from the genre, the study reveals structural-level features of IMRD standardization and variability within the overall rhetorical purpose of the genre, where distinct rhetorical move types contribute to determining the internal organization of discourse by providing the generic research writing with its own identity. The discourse structure and content of the public genre provides an opportunity to distinguish between theoretical and empirical tasks of writing in the legal RA genre, and to bring out the nature and function of interdisciplinarity and interdiscursivity in empirical legal research reporting. The paper concludes with some pedagogic implications for ESP teaching and research. (C) 2014 Elsevier Ltd. All rights reserved.|IMRD; Communicative purpose; Scientific writing; Legal discourse and genre; Interdisciplinarity; Interdiscursivity|APPLIED LINGUISTICS; INTRODUCTIONS; ORGANIZATION; BIOCHEMISTRY|Linguistics|10|1|22
Publishing research in English-language journals: Attitudes, strategies and difficulties of multilingual scholars of medicine|2014|Over the last few decades a growing number of multilingual scholars have shown an increasing interest in having the results of their research published in English-language journals. Many of these researchers, however, experience difficulties in producing effective research articles (RAs) to meet the expectations of their international disciplinary communities. In this paper we report some of the results obtained from the analysis of the responses to a large-scale online survey {[}http://eneida.unileon.es/eneidaquestionnaire.php] which was administered to Ph. D.-holding researchers from various disciplines, affiliated to five Spanish teaching and research institutions. The results we present here are related to Spanish scholars of Medicine, a field of research in which researchers are in need of specialized assistance in English for Research Publication Purposes (ERPP). We focus on their motivations for reporting their research in English, their writing strategies, past publishing experiences and future needs for training in ERPP. The findings revealed an overall positive attitude towards writing in English, although difficulties with specific discourse features and with the most challenging sections and aspects of the RA were also identified. The information derived from this survey should allow us to design training materials that can be of assistance to multilingual scholars of medicine. (C) 2014 Elsevier Ltd. All rights reserved.|Multilingual scholars of medicine; Needs analysis; English for research publication purposes|WRITING RESEARCH ARTICLES; SPANISH; PUBLICATION; IMPACT; TEXTS|Education \& Educational Research; Linguistics; Language \& Linguistics|9|2|22
UNIVERSITY LEVEL SECOND LANGUAGE READERS' ONLINE READING AND COMPREHENSION STRATEGIES|2014|With the growing prevalence of Web 2.0 technologies and use of online resources in their classrooms, language learners have increasing exposure to online texts. In this study we attempted to understand how university level second language (L2) readers construct meaning when reading online. We investigated L2 readers' information-seeking strategies and decision-making processes as they read online. Seven participants were asked to read two online texts and answer comprehension questions. Observation, think-aloud protocols, and interviews were our main sources of data. Through careful thematic coding analysis, we were able to characterize L2 readers' processes of constructing meaning while reading online using Internet resources. The findings indicate that L2 readers employ considerable prior knowledge of the structure of both offline and online resources to aid their online reading. Also, they follow a recursive pattern of self-regulated reading strategies when they construct meanings. Some themes highlighted by the study include L2 readers' online knowledge construction, their demonstration of cognitive flexibility, and the emergence of new literacy skills.|Reading; Literacy; Language Learning Strategies|ACADEMIC-ACHIEVEMENT; LITERACY; LEARNERS; INTERNET; KNOWLEDGE; AWARENESS; STUDENTS; ENGLISH; TASKS|Education \& Educational Research; Linguistics|2|1|22
Exploring the relationships among student preferences, prewriting tasks, and text quality in an EAP context|2014|Despite their prevalence in second language (L2) writing classrooms, prewriting discussions have not been widely investigated in terms of their relationship to students written texts. Furthermore, students' preferences for individual or collaborative work have not been considered in terms of their potential impact on the quality of either prewriting tasks or written texts. The current study investigates the relationships among students' preferences for collaboration, the format of prewriting tasks (collaborative or individual) and student text quality in an English for Academic Purposes (EAP) course (N = 21). The students carried out three collaborative and three individual prewriting tasks, submitted six written texts, and completed a questionnaire about their learning preferences. Analysis of two focal participants with divergent preferences for collaboration revealed that the collaboratively-oriented student reflected more on content during the collaborative discussions than the individually-oriented student. However, the individually-oriented students did not engage in more reflection during individual prewriting tasks. In addition, the texts both students produced after collaborative prewriting discussions received higher ratings than the texts they wrote after individual prewriting tasks. The findings suggest that collaborative prewriting may be beneficial for text quality, even for students who prefer to work individually. (C) 2014 Elsevier Ltd. All rights reserved.|Second language writing; Second language interaction; Collaboration; Group work; Prewriting tasks; Student preferences|PAIR WORK; COLLABORATION; COMPLEXITY; ACCURACY; LANGUAGE; PATTERNS; FLUENCY|Education \& Educational Research; Linguistics; Language \& Linguistics|2|1|22
Why fifth- and seventh-graders submit off-task responses to a web-based reading comprehension tutor rather than expected learning responses|2014|Research shows the students improve their reading comprehension with Intelligent Tutoring of the Structure Strategy (ITSS). One problem for ITSS is that some students are producing responses in the online instruction that are unrelated to learning and practicing the reading strategy. These types of disengaged responses can be referred to as system active off-task responses ({''}off-task{''}). In this study we characterize who produces off-task responses and why. Classification and Regression Trees (C\&RT) and logistic regression analyses were used to answer the why question. Variables predicted to relate to gaming included reading strategy and skill variables, motivation, attitude, self-efficacy, and goal orientation variables, demographic variables, and type of computer feedback (simple versus elaborated). C\&RT analysis could explain 66\% of the variance in off-task responses. Students without off-task responses were higher in motivation to read and worked in ITSS to produce good main ideas. Students with higher off-task responses had low scores on work mastery goals. The highest producers of off-task responses in Grades 5 and 7 (averaging 24 off-task responses over 7 lessons) had low motivation to read and scored over 2 SD below average on recall tasks in ITSS. The logistic regression could explain 42\% of the variance in off-task responses. Use of motivational scales prior to starting instruction as well as on-line performance measures could be used to flag students for early intervention to prevent system active off-task responses and increase on-line learning. The C\&RT approach may be particularly helpful to designers in making software more appropriate for different types of students. (C) 2014 Elsevier Ltd. All rights reserved.|Human-computer interface; Intelligent tutoring systems; Pedagogical issues; Teaching/learning strategies|ACHIEVEMENT GOAL THEORY; STRUCTURE STRATEGY; MOTIVATIONAL PROCESSES; GAMING BEHAVIORS; SELF-EFFICACY; SYSTEM; STUDENTS; TEXT; CLASSROOM; RECALL|Computer Science, Interdisciplinary Applications; Education \& Educational Research|0|3|22
Do men and women differ in their use of tables and graphs in academic publications?|2014|In psychological research there is huge literature on differences between the sexes. Typically it used to be thought that women were more verbally and men more spatially oriented. These differences now seem to be waning. In this article we present three studies on sex differences in the use of tables and graphs in academic articles. These studies are based on data mining from approximately 2,000 articles published in over 200 peer-reviewed journals in the sciences and social sciences. In Study 1 we found that, in the sciences, men used 26 \% more graphs and figures than women, but that there were no significant differences between them in their use of tables. In Study 2 we found no significant differences between men and women in their use of graphs and figures or tables in social science articles. In Study 3 we found no significant differences between men and women in their use of what we termed `data' and `text' tables in social science articles. It is possible that these findings indicate that academic writing is now becoming a genre that is equally undertaken by men and women.|Academic writing; Textual design; Tables; Graphs; Gender studies|GENDER-DIFFERENCES; SEX-DIFFERENCES; PERFORMANCE; MATHEMATICS; PSYCHOLOGY|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|2|0|22
On Ideology, Language, and Identity: Language Politics in the Soviet and Post-Soviet Lithuania|2014|The paper illuminates links between state politics and language politics in Lithuania during different historical periods: (a) the thaw period, (b) the stagnation period, (c) the liberalization periods of Soviet socialism, and (d) the two post-Soviet decades characterized by both nationalism and liberalization. Based on analysis of the texts by leading Lithuanian linguists published in the main language and culture journals during the period of 1960-2010, the paper argues that the concept of a good, proper language is a purely political idea, produced for the sake of governance by both the Soviet authorities as well as the pro-nationalist governments. The nationalist version of a ``good language{''} is sanitized from foreign effects; the socialist version is sanitized from bourgeois remnants and capitalist influence. In both cases, the proper language is assigned a moral value, but the ideological construct masks inequalities of power. During the post-Soviet years, due to democratization, liberalization, and growing diversity, the idea of one ``good, proper language{''} forfeited its social significance; it remained purely a linguistic ideal. With the development of multiple language cultures and subcultures, it stands increasingly as a metaphor for the totalitarian Soviet period for its omnipresent uniformity and homogeneity.|Language policy; Language ideology; Socialism; Nationalism|WRITERS; RUSSIA|Education \& Educational Research; Linguistics; Language \& Linguistics|2|0|22
Text trajectories and media discourse: tracking gendered representations in presidential politics|2014|During the US Democratic presidential primary campaign in 2007-8, Hillary Rodham Clinton's laughter became the subject of intense scrutiny by mass media and was dubbed the Clinton cackle. This article investigates how the `cackle' characterisation was first established, and thus, formed the basis of an intertextual series, wherein this dominant re-presentation of Clinton's laughter circulated across multiple discursive contexts. By examining the intertextual (and ideological) processes at work in decontextualising and recontextualising her laughter as it `travelled' across contexts, the analysis illustrates how this characterisation gained its status as an authoritative re-presentation - one that not only relied upon the reproduction of a common, (negative) gendered stereotype, but that also worked to reinforce perceptions of a stereotypically sexist, ` inappropriate' gendered identity, incompatible with the masculinist ideals of the presidency. It also discusses the significance of tracking the trajectory of this `text' in terms of the `double-bind' situation women politicians continue to face in the realm of presidential politics.|GENDER; INTERTEXTUALITY; MEDIA DISCOURSE; POLITICS; SEXISM|HILLARY CLINTON; COVERAGE; CAMPAIGNS; WOMEN|Linguistics; Language \& Linguistics; Women's Studies|4|5|22
UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization|2013|Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Inter active Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.|Latent Dirichlet allocation; nonnegative matrix factorization; topic modeling; visual analytics; interactive clustering; text analytics|VISUAL ANALYTICS; TEXT; VISUALIZATION; EXPLORATION|Computer Science, Software Engineering|48|0|22
Longitudinal analysis of pain in patients with metastatic prostate cancer using natural language processing of medical record text|2013|Objectives To test the feasibility of using text mining to depict meaningfully the experience of pain in patients with metastatic prostate cancer, to identify novel pain phenotypes, and to propose methods for longitudinal visualization of pain status. Materials and methods Text from 4409 clinical encounters for 33 men enrolled in a 15-year longitudinal clinical/molecular autopsy study of metastatic prostate cancer (Project to ELIminate lethal CANcer) was subjected to natural language processing (NLP) using Unified Medical Language System-based terms. A four-tiered pain scale was developed, and logistic regression analysis identified factors that correlated with experience of severe pain during each month. Results NLP identified 6387 pain and 13827 drug mentions in the text. Graphical displays revealed the pain landscape' described in the textual records and confirmed dramatically increasing levels of pain in the last years of life in all but two patients, all of whom died from metastatic cancer. Severe pain was associated with receipt of opioids (OR=6.6, p<0.0001) and palliative radiation (OR=3.4, p=0.0002). Surprisingly, no severe or controlled pain was detected in two of 33 subjects' clinical records. Additionally, the NLP algorithm proved generalizable in an evaluation using a separate data source (889 Informatics for Integrating Biology and the Bedside (i2b2) discharge summaries). Discussion Patterns in the pain experience, undetectable without the use of NLP to mine the longitudinal clinical record, were consistent with clinical expectations, suggesting that meaningful NLP-based pain status monitoring is feasible. Findings in this initial cohort suggest that outlier' pain phenotypes useful for probing the molecular basis of cancer pain may exist. Limitations The results are limited by a small cohort size and use of proprietary NLP software. Conclusions We have established the feasibility of tracking longitudinal patterns of pain by text mining of free text clinical records. These methods may be useful for monitoring pain management and identifying novel cancer phenotypes.|Natural Language Processing; Pain Management; Metastatic Prostate Cancer; Personalized Medicine; Individualized Medicine; Cancer Pain|QUALITY-OF-LIFE; RHEUMATOID-ARTHRITIS; PALLIATIVE CARE; SMOKING STATUS; IDENTIFICATION; SYSTEM; MEN; ASSOCIATION; POPULATION; NARRATIVES|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|7|1|22
Dictionary construction and identification of possible adverse drug events in Danish clinical narrative text|2013|Objective Drugs have tremendous potential to cure and relieve disease, but the risk of unintended effects is always present. Healthcare providers increasingly record data in electronic patient records (EPRs), in which we aim to identify possible adverse events (AEs) and, specifically, possible adverse drug events (ADEs). Materials and methods Based on the undesirable effects section from the summary of product characteristics (SPC) of 7446 drugs, we have built a Danish ADE dictionary. Starting from this dictionary we have developed a pipeline for identifying possible ADEs in unstructured clinical narrative text. We use a named entity recognition (NER) tagger to identify dictionary matches in the text and post-coordination rules to construct ADE compound terms. Finally, we apply post-processing rules and filters to handle, for example, negations and sentences about subjects other than the patient. Moreover, this method allows synonyms to be identified and anatomical location descriptions can be merged to allow appropriate grouping of effects in the same location. Results The method identified 1970731 (35477 unique) possible ADEs in a large corpus of 6011 psychiatric hospital patient records. Validation was performed through manual inspection of possible ADEs, resulting in precision of 89\% and recall of 75\%. Discussion The presented dictionary-building method could be used to construct other ADE dictionaries. The complication of compound words in Germanic languages was addressed. Additionally, the synonym and anatomical location collapse improve the method. Conclusions The developed dictionary and method can be used to identify possible ADEs in Danish clinical narratives.|Adverse Drug Event; Adverse Drug Reaction Reporting Systems; Electronic Health Records; Dictionary; Data Mining|EXTRACTION SYSTEM; INFORMATION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|24|1|22
Predicting Emotional Responses to Long Informal Text|2013|Most sentiment analysis approaches deal with binary or ordinal prediction of affective states (e.g., positive versus negative) on review-related content from the perspective of the author. The present work focuses on predicting the emotional responses of online communication in nonreview social media on a real-valued scale on the two affective dimensions of valence and arousal. For this, a new dataset is introduced, together with a detailed description of the process that was followed to create it. Important phenomena such as correlations between different affective dimensions and intercoder agreement are thoroughly discussed and analyzed. Various methodologies for automatically predicting those states are also presented and evaluated. The results show that the prediction of intricate emotional states is possible, obtaining at best a correlation of 0.89 for valence and 0.42 for arousal with the human assigned assessments.|Sentiment analysis; valence; arousal; ANEW; human annotation|PSYCHOLOGICAL CONSTRUCTION; CORE AFFECT; WORDS|Computer Science, Artificial Intelligence; Computer Science, Cybernetics|14|3|22
Continuity and change in anti-immigrant discourse in Italy An analysis of the visual propaganda of the Lega Nord|2013|Anti-immigrant political arguments have long been at the centre of the campaigning of the Lega Nord (the Northern League), the Italian extreme-right secessionist party. The paper analyses posters from political campaigns between 2001 and 2008 in order to detect similarities and differences emerging over time, and to show how continuity and change intertwine in the Lega Nord's anti-immigrant discourse. The analysis is presented across two axes: first, the visual dimensions of the texts are examined, concentrating predominantly on the use of images; and second, we analyse the linguistic content of the leaflets, paying particular attention to referential strategies and argumentative structure. The sampled posters show that although the Lega Nord's immigration policies have long been driven by an enduring basic antipathy towards foreigners, in the 2008 campaign the strategy shifted to one stressing arguments reminiscent of the Nouvelle Droite's ethnopluralism. Accordingly, in the interest of respecting cultural diversity, the Lega Nord argues that different national communities need to be kept separate, thereby inverting liberal values for the purpose of countering multiculturalism.|Lega Nord; extreme-right politics; political posters; anti-immigrant discourse; Critical Discourse Analysis; Multimodal discourse; visual rhetoric|ALLEANZA-NAZIONALE; TALK|Linguistics; Language \& Linguistics|9|2|22
Automatic generation of natural language nursing shift summaries in neonatal intensive care: BT-Nurse|2012|Introduction: Our objective was to determine whether and how a computer system could automatically generate helpful natural language nursing shift summaries solely from an electronic patient record system, in a neonatal intensive care unit (NICU). Methods: A system was developed which automatically generates partial NICU shift summaries (for the respiratory and cardiovascular systems), using data-to-text technology. It was evaluated for 2 months in the NICU at the Royal Infirmary of Edinburgh, under supervision. Results: In an on-ward evaluation, a substantial majority of the summaries was found by outgoing and incoming nurses to be understandable (90\%), and a majority was found to be accurate (70\%), and helpful (59\%). The evaluation also served to identify some outstanding issues, especially with regard to extra content the nurses wanted to see in the computer-generated summaries. Conclusions: It is technically possible automatically to generate limited natural language NICU shift summaries from an electronic patient record. However, it proved difficult to handle electronic data that was intended primarily for display to the medical staff, and considerable engineering effort would be required to create a deployable system from our proof-of-concept software. (c) 2012 Elsevier B.V. All rights reserved.|Natural language generation; Natural language processing; Data to text; Neonatal intensive care; Health informatics|WEATHER FORECASTS; CLINICAL-DATA; INFORMATION; TECHNOLOGY; TEXT; SUPPORT; DESIGN; SYSTEM; UNIT|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|18|1|22
Investigating the relationship between the use of English for academic purposes and academic attainment|2012|The purpose of this study is to determine whether differences in academic attainment between university students could be correlated with their use of English for academic purposes. Using the diagnostic language assessment procedure known as Measuring the Academic Skills of University Students (MASUS(2)), as well as informal analysis of assignment feedback and interviews with students, students' performance in assignments in three subject areas was investigated. Results confirmed that there was a strong correlation between the overall scores students obtained in the MASUS language assessment and their attainment as represented by their assignment grade. However, analysis of the five separate categories of the MASUS scores showed that only the scores for the category, use of source material, correlated strongly with student attainment and that the scores on the more explicit language categories, structure and development of the text, academic writing style, and grammar, did not. The paper considers the implications of these findings for future studies of the role of English for academic purposes in students' attainment and for EAP pedagogy. (C) 2012 Elsevier Ltd. All rights reserved.|Academic attainment; Academic writing; Diagnostic writing assessment; Measuring the academic skills of university students; Systemic functional linguistics|STUDENTS; SKILLS|Education \& Educational Research; Linguistics; Language \& Linguistics|5|2|22
Genres and registers of student report writing: An SFL perspective on texts and practices|2012|Academic literacies research has tended to focus on writers in context, while systemic functional linguistic research has tended to focus on texts in context. While literacy practices and written texts may be usefully analysed independently, this paper describes how an investigation of genres of academic writing in the BAWE (British Academic Written English) corpus draws on an exploration of the social context of assessed student writing in order to support the analysis of texts with an IMRD (Introduction, Methods, Results, Discussion) type structure as members of either the Research Report or Methodology Recount genre family. It also illustrates how register analysis in SFL allows the analyst to gain insights into disciplinary contexts and ideologies through a comparison of extracts from the methods sections of corpus linguistics, psychology and chemistry assignment texts. The paper not only shows how research into writing practices and participant perspectives is combined with text analysis in one project, but also argues that an understanding of both is essential for the application of research findings in teaching EAP. (C) 2011 Elsevier Ltd. All rights reserved.|Genre analysis; Systemic functional linguistics; Academic literacies; Research reports; Student writing|ETHNOGRAPHY|Education \& Educational Research; Linguistics; Language \& Linguistics|11|2|22
Ontology-driven web-based semantic similarity|2010|Estimation of the degree of semantic similarity/distance between concepts is a very common problem in research areas such as natural language processing, knowledge acquisition, information retrieval or data mining. In the past, many similarity measures have been proposed, exploiting explicit knowledge-such as the structure of a taxonomy-or implicit knowledge-such as information distribution. In the former case, taxonomies and/or ontologies are used to introduce additional semantics; in the latter case, frequencies of term appearances in a corpus are considered. Classical measures based on those premises suffer from some problems: in the first case, their excessive dependency of the taxonomical/ontological structure; in the second case, the lack of semantics of a pure statistical analysis of occurrences and/or the ambiguity of estimating concept statistical distribution from term appearances. Measures based on Information Content (IC) of taxonomical concepts combine both approaches. However, they heavily depend on a properly pre-tagged and disambiguated corpus according to the ontological entities in order to compute accurate concept appearance probabilities. This limits the applicability of those measures to other ontologies like specific domain ontologies- and massive corpus -like the Web-. In this paper, several of the presented issues are analyzed. Modifications of classical similarity measures are also proposed. They are based on a contextualized and scalable version of IC computation in the Web by exploiting taxonomical knowledge. The goal is to avoid the measures' dependency on the corpus pre-processing to achieve reliable results and minimize language ambiguity. Our proposals are able to outperform classical approaches when using the Web for estimating concept probabilities.|Semantic similarity; Ontologies; Information content; Web; Knowledge discovery|RELATEDNESS|Computer Science, Artificial Intelligence; Computer Science, Information Systems|38|1|22
Exploring creative thinking in graphically mediated synchronous dialogues|2010|This paper reports on an aspect of the EC funded Argunaut project which researched and developed awareness tools for moderators of online dialogues. In this study we report on an investigation into the nature of creative thinking in online dialogues and whether or not this creative thinking can be coded for and recognized automatically such that moderators can be alerted when creative thinking is occurring or when it has not occurred after a period of time. We outline a dialogic theory of creativity, as the emergence of new perspectives from the interplay of voices, and the testing of this theory using a range of methods including a coding scheme which combined coding for creative thinking with more established codes for critical thinking, artificial intelligence pattern-matching techniques to see if our codes could be read automatically from maps and `key event recall' interviews to explore the experience of participants. Our findings are that: (1) the emergence of new perspectives in a graphical dialogue map can be recognized by our coding scheme supported by a machine pattern-matching algorithm in a way that can be used to provide awareness indicators for moderators; (2) that the trigger events leading to the emergence of new perspectives in the online dialogues studied were most commonly disagreements and (3) the spatial representation of messages in a graphically mediated synchronous dialogue environment such as Digalo may offer more afforclance for creativity than the much more common scrolling text chat environments. All these findings support the usefulness of our new account of creativity in online dialogues based on dialogic theory and demonstrate that this account can be operationalised through machine coding in a way that can be turned into alerts for moderators. (C) 2009 Elsevier Ltd. All rights reserved.|CSCL; Discourse analysis; Dialogic; Creativity; Artificial intelligence; Graphical interfaces|DISCUSSIONS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|19|0|22
Using corpus methodology for semantic and pragmatic analyses: What can corpora tell us about the linguistic expression of emotions?|2010|The aim of this paper is to explore some of the possibilities, advantages and difficulties of corpus-based analyses of semantic and pragmatic aspects of language in one particular field, namely the linguistic expression of emotion concepts. For this purpose, a methodological procedure is proposed and an exemplary analysis of the emotion concept ``fear{''} in English is performed. The procedure combines Kovecses' lexical approach and Stefanowitsch's metaphorical pattern analysis with additional concepts from corpus linguistics such as semantic preference and semantic prosody The results of the study show that such a corpus-based analysis of emotion words offers several advantages. Firstly, by exploring the surroundings of the search word in a vast amount of text, we are not only able to find evidence of conceptual metaphor and metonymy that structure the emotion concept and of related emotion concepts, but also we can enrich the description of the emotion concept with information from a series of dimensions and add a pragmatic viewpoint by revealing an explicit or implicit evaluation of the emotion. The second advantage offered by a corpus-based approach lies in the possibility of quantifying results, i.e., comparing the frequency, productivity and creative use of individual metaphors and metonymies, which is especially interesting in view of contrastive studies.|Emotion concepts; corpus methodology; conceptual metaphor; conceptual metonymy; semantic preference; semantic prosody|PROSODY|Linguistics; Language \& Linguistics|14|4|22
Politeness in computer-mediated discourse of a virtual team|2010|Drawing on the newest findings of politeness research, this paper proposes an interactionally grounded approach to computer-mediated discourse (CMD). Through the analysis of naturally occurring text-based synchronous interactions of a virtual team the paper illustrates that the interactional politeness approach can account for linguistic phenomena not yet fully explored in computer-mediated discourse analysis. Strategies used for compensating for the lack of audio-visual information in computer-mediated communication, strategies to compensate for the technological constraints of the medium, and strategies to aid interaction management are examined from an interactional politeness viewpoint and compared to the previous findings of CMD analysis. The conclusion of this preliminary research suggests that the endeavour to communicate along the lines of politeness norms in a work-based virtual environment contradicts some of the previous findings of CMD research (unconventional orthography, capitalization, economizing), and that other areas (such as emoticons, backchannel signals and turn-taking strategies) need to be revisited and re-examined from an interactional perspective to fully understand how language functions in this merely text-based environment.|CMC; computer-mediated discourse analysis; politeness|SOCIAL-CONTEXT; COMMUNICATION; EMOTICONS; INTERNET|Linguistics; Language \& Linguistics|20|0|22
Specific language impairment as systemic developmental disorders|2009|Specific Language Impairment (SLI) is a disorder characterised by slow, abnormal language development. Most children with this disorder do not present any other cognitive or neurological deficits. There are many different pathological developmental profiles and switches from one profile to another often occur. An alternative would be to consider SLI as a generic name covering three developmental language disorders: developmental verbal dyspraxia, linguistic dysphasia, and pragmatic language impairment. The underlying cause of SLI is unknown and the numerous studies on the subject suggest that there is no single cause. We suggest that SLI is the result of all abnormal development of the language system, occurring when more than one part of the system fails, thus blocking the system's natural compensation mechanisms. Since compensation also hinders linguistic evaluation, one possibility for diagnosis and remediation control is to assess basic cognitive abilities by non-linguistic means whenever possible, Neurological plausible bases for language and language development should also be taken into account to offer new hypotheses and research issues for future work oil SILL (C) 2008 Elsevier Ltd. All fights reserved.|Specific language impairment; Language system; Developmental disorder|SHORT-TERM-MEMORY; VERBAL WORKING-MEMORY; CATEGORICAL PERCEPTION; PROCESSING DEFICITS; DEVELOPING-CHILDREN; SPEECH-PERCEPTION; GRAMMATICAL SLI; DYSLEXIA; BRAIN; CLASSIFICATION|Linguistics; Neurosciences; Psychology, Experimental|14|3|22
The self-telling body|2006|This essay will examine some of the narrative practices emerging in the health care professions-medicine, nursing, social work, and psychotherapy. We have always, of course, understood that the most fertile and clinically salient information we derive about patients comes from listening to them talking about their illnesses. Nonetheless, medicine's recent past is marked by not so much a suspicion of as a dismissal of word in diagnosing and treating disease. Of late, medicine (and because I am a doctor, I will limit myself to thinking about medicine in the essay) has found sustenance from such fields as trauma studies, oral history, and testimony work. Finally, we are coming around to understanding that our tasks include the duty to bear witness as others tell of trauma and loss. The narrative practice of medicine-or, as I have come to say, the practice of narrative medicine-unites a host of neighboring concerns and approaches. Historically, medicine came into the narrative realms through qualitative social science, especially sociolinguistics, as a means to represent and comprehend the conversations that take place between doctors and patients. Such scholars as Elliot Mishler, Richard Frankel, Catherine Riessman, and Candice West really altered medical practice by making medical discourse amenable to inspection and then analysis. Around the same time, we also turned to literary texts and ways of thinking that help us to enter the worlds of patients, see others' experience from their perspectives, greet the metaphorical as well as the factual power of words, and be moved by what we hear. Oddly, then, medical practice became a bridge between the qualitative social sciences and literary theory, letting us, from the inside, see how very similar are the efforts of the sociologist examining discourse and the novelist creating it. We doctors feel great good fortune in having the ultimate objective correlative-what might be captivating but ethereal theorizing becomes as practical and concrete and earthy as can be by virtue of being about somebody's body-particularly somebody's ailing body. What extreme pleasure that my thinking complicated thoughts and being attuned to the complex ways of language can translate into control of my patients' blood sugar or relief of their migraines or diagnosis of their coronary artery disease. Narrative medicine becomes, in the end, a heady, brainy, compassionate, corporeal practice that can heal the patient and nourish the doctor at the same time-by virtue of the talk.|narrative medicine; life-writing; medical interviewing; doctor-patient relationships|MEDICINE|Communication; Linguistics; Language \& Linguistics|32|0|22
Persuasion and advertising English: Metadiscourse in slogans and headlines|2001|Metadiscourse plays a vital role both in organising the discourse and in engaging the audience, thus becoming an important aspect of persuasive writing. Assuming that metadiscourse is context-dependent and that it is linked to the norms and expectations of a particular setting and genre, this article studies the metadiscourse devices typically used by copywriters to construct their slogans and/or headlines. Our analysis starts from the assumption that advertising English should be represented as a continuum of text functions fluctuating between `informing' and `manipulating' in accordance with the idea that advertising is an example of covert communication. Examples selected from a typical women's magazine show that both textual and interpersonal metadiscourse help copywriters to convey a persuasive message under an informative mask.|advertising; English; metadiscourse; intertextuality; genre; pragmatics|PRAGMATICS; DISCOURSE; ARTICLES|Linguistics; Language \& Linguistics|48|1|22
Extraction of emotions from multilingual text using intelligent text processing and computational linguistics|2017|Extraction of Emotions from Multilingual Text posted on social media by different categories of users is one of the crucial tasks in the field of opining mining and sentiment analysis. Every major event in the world has an online presence and social media. Users use social media platforms to express their sentiments and opinions towards it. In this paper, an advanced framework for detection of emotions of users in Multilanguage text data using emotion theories has been presented, which deals with linguistics and psychology. The emotion extraction system is developed based on multiple features groups for the better understanding of emotion lexicons. Empirical studies of three real-time events in domains like a Political election, healthcare, and sports are performed using proposed framework. The technique used for dynamic keywords collection is based on RSS (Rich Site Summary) feeds of headlines of news articles and trending hashtags from Twitter. An intelligent data collection model has been developed using dynamic keywords. Every word of emotion contained in a tweet is important in decision making and hence to retain the importance of multilingual emotional words, effective pre-processing technique has been used. Naive Bayes algorithm and Support Vector Machine (SVM) are used for fine-grained emotions classification of tweets. Experiments conducted on collected data sets, show that the proposed method performs better in comparison to corpus-driven approach which assign affective orientation or scores to words. The proposed emotion extraction framework performs better on the collected dataset by combining feature sets consisting of words from publicly available lexical resources. Furthermore, the presented work for extraction of emotion from tweets performs better in comparisons of other popular sentiment analysis techniques which are dependent of specific existing affect lexicons. (C) 2017 Elsevier B.V. All rights reserved.|Emotion extraction; Machine learning; Text mining; Twitter; Classification; Natural language processing|TWITTER; SPORTS; NEWS|Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods|0|20|21
Current State of Text Sentiment Analysis from Opinion to Emotion Mining|2017|Sentiment analysis from text consists of extracting information about opinions, sentiments, and even emotions conveyed by writers towards topics of interest. It is often equated to opinion mining, but it should also encompass emotion mining. Opinion mining involves the use of natural language processing and machine learning to determine the attitude of a writer towards a subject. Emotion mining is also using similar technologies but is concerned with detecting and classifying writers emotions toward events or topics. Textual emotion-mining methods have various applications, including gaining information about customer satisfaction, helping in selecting teaching materials in e-learning, recommending products based on users emotions, and even predicting mental-health disorders. In surveys on sentiment analysis, which are often old or incomplete, the strong link between opinion mining and emotion mining is understated. This motivates the need for a different and new perspective on the literature on sentiment analysis, with a focus on emotion mining. We present the state-of-the-art methods and propose the following contributions: (1) a taxonomy of sentiment analysis; (2) a survey on polarity classification methods and resources, especially those related to emotion mining; (3) a complete survey on emotion theories and emotion-mining research; and (4) some useful resources, including lexicons and datasets.|Emotion detection; text mining; polarity classification; opinion mining; sentiment analysis; data mining; machine learning|CLASSIFICATION|Computer Science, Theory \& Methods|0|11|21
Writing with attitude: Stance expression in learner and professional dentistry research reports|2017|Medical students often lack key skills in academic writing, yet good academic writing is often a pre-requisite for employment, promotion and enculturation into the profession. This article focuses on the rhetorical strategies used for the presentation of academic stance by student writers of dentistry research reports. Adopting a contrastive, corpus based approach, we compare student writing with that of comparable professionally written research reports for evidence of hedging, boosting, self-mention and attitude markers. Our findings indicate that professional reports exhibit a narrower set of linguistic devices than used by student writers, who tend to use a much wider range of the four stance feature types analysed for discussion of both others' and their own personal stance, both across whole texts and by section. We discuss pedagogical implications for ESP professionals working to more closely align student writing with that of professional norms. (C) 2017 Elsevier Ltd. All rights reserved.|Stance; Contrastive Interlanguage Analysis; English for specific purposes; Learner corpus; Dentistry|DISCIPLINARY; CURRICULUM; CORPUS|Linguistics|0|10|21
The multimodal nature of spoken word processing in the visual world: Testing the predictions of alternative models of multimodal integration|2017|Ambiguity in natural language is ubiquitous, yet spoken communication is effective due to integration of information carried in the speech signal with information available in the surrounding multimodal landscape. Language mediated visual attention requires visual and linguistic information integration and has thus been used to examine properties of the architecture supporting multimodal processing during spoken language comprehension. In this paper we test predictions generated by alternative models of this multimodal system. A model (TRACE) in which multimodal information is combined at the point of the lexical representations of words generated predictions of a stronger effect of phonological rhyme relative to semantic and visual information on gaze behaviour, whereas a model in which sub-lexical information can interact across modalities (MIM) predicted a greater influence of visual and semantic information, compared to phonological rhyme. Two visual world experiments designed to test these predictions offer support for sub-lexical multi modal interaction during online language processing. (C) 2016 Elsevier Inc. All rights reserved.|Visual world paradigm; Visual attention; Spoken word recognition; Connectionist modelling; Multimodal processing|CONTINUOUS SPEECH RECOGNITION; EYE-MOVEMENTS; TIME-COURSE; LANGUAGE COMPREHENSION; INTERACTIVE PROCESSES; AMBIGUITY RESOLUTION; LEXICAL ACCESS; TRACE MODEL; PERCEPTION; ACTIVATION|Linguistics; Psychology; Psychology, Experimental|3|4|21
Linguistic Markers of Inference Generation While Reading|2016|Words can be informative linguistic markers of psychological constructs. The purpose of this study is to examine associations between word use and the process of making meaningful connections to a text while reading (i.e., inference generation). To achieve this purpose, think-aloud data from third-fifth grade students (N = 218) reading narrative texts were hand-coded for inferences. These data were also processed with a computer text analysis tool, Linguistic Inquiry and Word Count, for percentages of word use in the following categories: cognitive mechanism words, nonfluencies, and nine types of function words. Findings indicate that cognitive mechanisms were an independent, positive predictor of connections to background knowledge (i.e., elaborative inference generation) and nonfluencies were an independent, negative predictor of connections within the text (i.e., bridging inference generation). Function words did not provide unique variance towards predicting inference generation. These findings are discussed in the context of a cognitive reflection model and the differences between bridging and elaborative inference generation. In addition, potential practical implications for intelligent tutoring systems and computer-based methods of inference identification are presented.|Inference; Linguistic markers; Cognitive processes; Coherence|WORKING-MEMORY CAPACITY; LANGUAGE USE; COMPREHENSION STRATEGIES; PSYCHOLOGICAL DISTRESS; TEXT COMPREHENSION; SPONTANEOUS SPEECH; STRESSFUL EVENTS; MENTAL MODEL; WORD USE; READERS|Linguistics; Psychology, Experimental|0|1|21
Conceptual blending in legal writing: Linking definitions to facts|2016|Although the body of research on legal language is significant, analysis of the kinds of texts that lawyers learn to write in the vocational stage of their training remains limited. While some legal writing textbooks explicitly address the lexicogrammatical resources necessary to write common genres such as the legal memorandum, the use of features such as tense and articles is largely tied to explanations based on generality or specificity. Drawing on conceptual blending theory, this study examines the use of such features in the ``Question Presented{''} section of eleven legal memoranda. Textual analysis is further supplemented with questionnaire data from legal writing professionals. Analysis suggests that rather than representing a clear distinction between general and specific reference, these linguistic features indexically reference and blend various ``mental spaces{''} that are necessary for common law argumentation. The study highlights the need to connect discipline specific concepts to linguistic meaning in English for Legal Purposes, particularly for L2 students trained in other jurisdictions. (C) 2015 Elsevier. Ltd. All rights reserved.|Legal writing; English for legal purposes; Conceptual blending; Mental spaces; Legal memoranda|GENRE ANALYSIS; CONSTRUCTION; LANGUAGE; IDENTITY; METAPHOR|Linguistics|0|2|21
Metadiscourse in the introductions of PhD theses and research articles|2015|Previous studies have indicated that the introductions of PhD theses and research articles are similar in their rhetorical features. In contrast, it has been suggested that metadiscourse as a rhetorical device is constructed in a different manner in these texts. However, very few studies have sought to empirically validate this assumption. This paper investigates how research writers construct metadiscourse in the introductions of their PhD theses and subsequently published research articles. The analysis shows that the majority of the writers make greater use of metadiscourse in their article introductions. The most significant changes include greater use of phrases referring to previous research, less reference to other parts of the text, and still less use of phrases signalling authorial presence. Close examination reveals that these variations derive from genre-specific features, including that writers of PhD thesis introductions present previews of the subsequent chapters. This paper closes by arguing that the variations can also be ascribed to the nature of the PhD thesis as an educational genre and that of research articles as a professional genre in which writers need to survive severe competition to get their manuscripts published. (C) 2015 The Author. Published by Elsevier Ltd.|Genre analysis; Rhetoric; Metadiscourse; Doctoral thesis or dissertation; Research article; Introduction|DISCOURSE|Education \& Educational Research; Linguistics; Language \& Linguistics|5|2|21
Diving deep into digital literacy: emerging methods for research|2015|Literacy studies approaches have tended to adopt a position which enables ethnographic explorations of a wide range of literacies'. An important issue arising is the new challenge required for researchers to capture, manage, and analyse data that highlight the unique character of practices around texts in digital environments. Such inquiries, we argue, require multiple elements of data to be captured and analysed as part of effective literacy ethnographies. These include such things as the unfolding of digital texts, the activities around them, and features of the surrounding social and material environment. This paper addresses these methodological issues drawing from three educationally focused studies, and reporting their experiences and insights within uniquely different contexts. We deal with the issue of adopting new digital methods for literacy research through the notion of a deep dive' to explore educational tasks in classrooms. Through a discussion of how we approached the capture and analysis of our data, we present methods to better understand digital literacies in education. We then outline challenges posed by our methods, how they can be used more broadly for researching interaction in digital environments, and how they augment transdisciplinary debates and trends in research methods.|digital literacy; CAQDAS; Literacy Studies; digital methods; ethnography|ETHNOGRAPHY|Education \& Educational Research; Linguistics; Language \& Linguistics|2|1|21
Building intimacy through linguistic choices, text structure and voices in political discourse|2015|This paper analyzes linguistic variables employed strategically in various instances of political communication to present different levels of intimacy in relation to a continuum between contextuality and formality (Heylighen and Dewaele, 2002) in political talk. Within a given situation, political actors express these-choices also in relation to a broader context around their personas: the Message (Lempert and Silverstein, 2012, 2003). The linguistic variables under consideration range from concrete units such as lexical choices (i.e., ``marked register usages{''} {[}Moven, 2007; Myers-Scotton, 2001], to narratives of belonging (Duranti, 2006), to textual organization and instances of intertextuality (Blackledge, 2005; Fairclough, 1992, 2003; Wodak, 2008), in particular, by means of different voices (Balchtin, 1981) politicians bring into the here-and-now moment of discourse. The data for the analysis is obtained from different instances of political talk (speeches and debates) and different politicians (Palin, Biden, George W. Bush and Obama). The linguistic variables display different levels of formality indexing two Aristotelian modes of persuasion: Pathos and Ethos. (C) 2015 Elsevier Ltd. All rights reserved.|Political discourse; Contextuality; Informality; Linguistic choices; Voices; Narratives of belonging|SELF; SPEAKERS; LANGUAGE; IDENTITY; EVENTS|Communication; Linguistics|2|1|21
Exploring the potential of second/foreign language writing for language learning: The effects of task factors and learner variables|2015|This investigation aimed at examining the potential of second/foreign language (L2/FL) writing for language learning through the manipulation of task complexity and learner-related variables, including L2 proficiency levels and performance levels on task. It focused on task complexity in essay writing and measures of syntactic complexity, linguistic accuracy, and fluency (CAF). Analysis was based on the data from two separate studies the author conducted on this topic with undergraduate FL learners of Spanish in an American university at two distinct levels of language proficiency: advanced and intermediate. Findings indicated that task complexity in L2/FL writing as determined by familiarity of topic, genre, and/or task type, and reasoning demands seemed to have an impact on writing as a possible context for language learning, namely on CAF measures, in two ways: First, within given levels of language proficiency, results showed a tendency towards a trade-off effect among measures of linguistic production in writing affected by task complexity. Second, findings also suggest that the relationship between task complexity in L2/FL writing and the effect on attentional resources and CAF measures may be associated with the language proficiency level (Norris \& Ortega, 2009) in conjunction with the level of expertise in writing of the learner. These findings shed further light on the connection between L2/FL writing and task-based language teaching (TBLT) (Byrnes \& Manch On, 2014). Limitations of the study as well as suggestions for future research are stated. (C) 2015 Elsevier Inc. All rights reserved.|Language-learning potential of writing; Task complexity; Language proficiency; Performance on task; Working memory capacity; CAF measures|COGNITIVE-PROCESSES; FOREIGN-LANGUAGE; WORKING-MEMORY; COMPLEXITY; FLUENCY; WRITERS; OUTPUT; TEXT; SLA|Linguistics|6|1|21
A classification of eLearning tools based on the applied multimedia|2015|This paper proposes a classification that should help understanding key aspects of multimedia application in eLearning tools. The classification tries to cover important aspects of multimedia application in eLearning tools: communication channels and exchange of different types of contents throughout the channels, understanding in communication, and the ways of object manipulation in the user-tool interaction. Types of contents are classified according to the senses they affect on both sides of communication channels. The paper presents characteristics of 30 representative tools through a uniformly structured text. The presented tools are analyzed according to the proposed classification. A view of the future challenges, based on an analysis of the global trends in the area, is given.|Multimedia tools; eLearning tools; Multimedia in education; Applied multimedia|COMPUTER ARCHITECTURE; AUGMENTED REALITY; MEDICAL-EDUCATION; SYSTEM; ORGANIZATION; DESIGN; GAME|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|4|0|21
Writing strategy instruction: Its impact on writing in a second language for academic purposes|2015|Writing for academic purposes in a second/foreign language is a major challenge faced by many students at both secondary and tertiary levels. This suggests that displaying content knowledge and understanding of a subject through a second language is a very complex process. This article discusses the findings of a longitudinal intervention study that attempted to investigate the impact of writing strategy instruction on writing strategy use and writing performance of a group of undergraduate students following a course in English for Academic Purposes in Sri Lanka. The study used a pre-test post-test experimental research design and the data were collected using multiple methods. The results revealed that the students could be trained to use writing strategies effectively and their writing strategy use and writing performance increased significantly after strategy instruction.|Second language writing; strategy instruction; English for Academic Purposes|FORMULATION PROCESSES; TEMPORAL ANALYSIS; LANGUAGE; STUDENTS; LEARNER; GENRE; TEXT; L1|Education \& Educational Research; Linguistics|4|0|21
Teachers' practices in EAP writing instruction: Use of models and modeling|2014|This paper presents findings from an exploratory study into the practices of teachers of EAP writing. Its aim was to learn about how writing instruction is organised, the kinds of instructional strategies teachers employ, and how they account for their choices. Data were collected from seven experienced practitioners in five tertiary institutions over 10-12 class hours through observations supported by post-lesson interviews and analysis of teaching materials and course documents. Findings revealed repeated use of a number of instructional strategies that can be termed ``modeling{''}. Teachers presented flawed or exemplary text products for analysis and discussion, focused on the processes involved in creating a particular text by demonstrating and discussing cognitive processes with the class, led whole-class collaborations that produced jointly constructed texts, and facilitated cooperative pair or group composing and editing activities. Their practices blended textual, cognitive, and interactional components in order to advance students' skill across a range of academic text types. The study highlights the importance and value of explicit instructional conversations and social interactions that blend planned and responsive teaching to generate learning opportunities in the L2 writing classroom. Possibilities for further investigations in this under-researched area are suggested. (C) 2013 Elsevier Ltd. All rights reserved.|Academic writing; Writing instruction; Models and modeling; Social learning|STUDENTS; ESL; LANGUAGE; PEDAGOGY; GOALS|Education \& Educational Research; Linguistics|5|2|21
Research synthesis in collaborative planning forecast and replenishment|2014|Purpose - The purpose of this research synthesis is to gather and integrate findings on Collaborative Planning Forecast and Replenishment (CPFR) as a business process and as a management practice; and to assemble quantitative evidence of its impact on supply chain (SC) performance. Design/methodology/approach - The researchers independently conducted a systematic review of 629 abstracts and 47 full-text papers. Original keywords were applied to four key electronic databases for operations management and information systems. Rigorous and verifiable selection criteria governed inter-coders reliability, review of steps and exclusion of papers. Resource and dependency-based view of the firm, contingency research and maturity models informed the analysis. Findings - There is not a single ``blueprint{''} for CPFR. Competing models emphasize the need for ``trust and confidence{''} and reliable data systems. The type of products, scope, spatial diversity and number of partners in the network are important contextual variables. Firm resources that are unique and advantages from multiple and reciprocal dependencies are powerful levers. There is no consensus on maturity model and on required investment in data and communication systems. Practical implications - Practical implications are implementation related: cost-benefit analysis and simulations should precede full-scale collaboration. There is a consensus on starting CPFR small and expanding gradually. Originality/value - This synthesis applies a rigorous review method and attempts to assemble the dispersed literature in one study, utilizing explanatory operations management and information systems theories.|Collaboration; Operations management; Supply chain; Trust; Information communication technology|SUPPLY-CHAIN COLLABORATION; RETAIL INDUSTRY; CPFR; INFORMATION; MANAGEMENT; PERFORMANCE; SIMULATION; STRATEGIES; SUCCESS; SYSTEMS|Computer Science, Interdisciplinary Applications; Engineering, Industrial|14|1|21
The representation of professionalism in native English-speaking teachers recruitment policies: A comparative study of Hong Kong, Japan, Korea and Taiwan|2013|The status of English as a global language has played a significant role in contemporary language education policies across the world. In East Asia, the hegemony of English has been reflected in a number of central governments' policies of recruiting native English-speaking teachers (NESTs) to participate in English language education. This paper focuses on the NESTs recruitment policies in Japan, Korea, Hong Kong and Taiwan with the aim of examining how teacher professionalism is represented in these policy discourses and how this conceived teacher professionalism impacts on English teaching and learning in these countries. Through the analysis of policy texts and documents, we argue that teacher professionalism has been assigned a different agenda by the governments who subscribe to ``native speaker norms{''} and legitimise unqualified and inexperienced NESTs in the profession of English language teaching (ELT). These anti-professionalism policies have not achieved the intended consequence of improving students' English proficiency, but have instead resulted in the unintended consequences of damaging the quality of English instruction and jeopardising the professional identity of local non-native English-speaking teachers (NNESTs) in these countries. The results reveal an urgent need to evaluate the effectiveness of these NEST recruitment programmes.|NESTs; NNESTs; teacher professionalism; language policy; policy analysis|EDUCATION; IDENTITY; OWNERSHIP; LANGUAGE|Education \& Educational Research; Linguistics; Language \& Linguistics|2|2|21
A hybrid system for temporal information extraction from clinical text|2013|Objective To develop a comprehensive temporal information extraction system that can identify events, temporal expressions, and their temporal relations in clinical text. This project was part of the 2012 i2b2 clinical natural language processing (NLP) challenge on temporal information extraction. Materials and methods The 2012 i2b2 NLP challenge organizers manually annotated 310 clinic notes according to a defined annotation guideline: a training set of 190 notes and a test set of 120 notes. All participating systems were developed on the training set and evaluated on the test set. Our system consists of three modules: event extraction, temporal expression extraction, and temporal relation (also called Temporal Link, or TLink') extraction. The TLink extraction module contains three individual classifiers for TLinks: (1) between events and section times, (2) within a sentence, and (3) across different sentences. The performance of our system was evaluated using scripts provided by the i2b2 organizers. Primary measures were micro-averaged Precision, Recall, and F-measure. Results Our system was among the top ranked. It achieved F-measures of 0.8659 for temporal expression extraction (ranked fourth), 0.6278 for end-to-end TLink track (ranked first), and 0.6932 for TLink-only track (ranked first) in the challenge. We subsequently investigated different strategies for TLink extraction, and were able to marginally improve performance with an F-measure of 0.6943 for TLink-only track.|Temporal information extraction; Clinic event extraction; Temporal expression extraction; Temporal relation extraction; Natural language processing; Machine learning|KNOWLEDGE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|20|1|21
Differential contributions of the inferior parietal and inferior frontal regions to the processing of grammatical and semantic relationships in wh-questions|2013|The processing of grammatical and semantic relationships is important in sentence comprehension. Although previous studies have demonstrated brain activities during grammatical and semantic processing in declarative sentences, functional MRI (fMRI) evidence related to these processes in wh-questions is largely unavailable. In Japanese wh-questions, a wh-phrase is grammatically associated with the closest particle, and a sentential subject is semantically associated with the verb. These features in Japanese wh-questions enable us to make grammatical or semantic anomalies without adding other words or morphemes in the violation paradigm. According to this advantage of Japanese wh-questions, this fMRI study investigated the brain activities in Japanese native speakers during grammatical and semantic processing of wh-questions to judge whether or not presented sentences were natural Japanese sentences (naturalness decision task). Three types of wh-questions were presented: correct, grammatically anomalous, and semantically anomalous conditions. This study yielded three main findings. First, activity in the left inferior parietal lobule was greater during processing of grammatically anomalous than correct or semantically anomalous wh-questions. Second, activity in the left inferior frontal gyrus was greater during processing of semantically anomalous than correct or grammatically anomalous wh-questions. Finally, significant correlations were identified between activities in the left inferior parietal lobule and the left inferior frontal gyms during grammatically anomalous and semantically anomalous wh-questions. These findings suggest that the left inferior parietal and inferior frontal regions have differential contributions to the processing of grammatical and semantic relationships in wh-question sentences, and that the interaction between these regions could be essential in the comprehension of wh-questions by combining the grammatical process with the semantic process. (C) 2012 Elsevier Ltd. All rights reserved.|Grammar; Semantics; Violation paradigm; Sentence comprehension; Wh-questions; Functional magnetic resonance imaging|EVENT-RELATED FMRI; LEFT PREFRONTAL CORTEX; SENTENCE COMPREHENSION; LANGUAGE COMPREHENSION; SYNTACTIC VIOLATIONS; TEMPORAL CORTEX; HUMAN BRAIN; FORM; INTEGRATION; MODULATION|Linguistics; Language \& Linguistics|2|0|21
A non-native student's experience on collaborating with native peers in academic literacy development: A sociopolitical perspective|2013|This sociopolitically-oriented case study aims to further explore the complex social network non-native students are engaged in during their literacy activities. In previous research, institutional policies, supervisors and instructors, and gatekeepers of target journals are normally regarded as key players to influence students fulfilling their sociopolitical purposes. Native speaking peers are rarely viewed as key players in non-native students' writing endeavors. Taking the perspectives of a non-native graduate student and drawing upon the concepts of ``Community of Practice{''} and ``individual agency{''}, the current case study qualitatively reports the social and political interaction and collaboration between the non-native participant and her native peers in completing group writing projects across two semesters. The analysis shows that power inequality did exist between these two parties with native peers initially assuming more powerful and central roles and the non-native participant being placed in the periphery. However, the non-native student gained disciplinary knowledge and developed coping strategies in the power-infused sociopolitical contexts, which eventually resulted in a much better group writing experience. The author proposes the importance of raising students and instructors' awareness of existence of power relations between non-native and native novice writers in group projects and puts forward some questions for future research. (C) 2012 Elsevier Ltd. All rights reserved.|Academic literacy; Non-native speakers of English; Peer group work; Power; Sociopolitical perspective|RESPONSE GROUPS; PARTICIPATION; LANGUAGE; SCIENCE; WRITERS; GENRE; TEXTS|Education \& Educational Research; Linguistics; Language \& Linguistics|5|1|21
Why do we say what we say the way we say it?|2013|This paper seeks answer to the question why exactly we say what we say the way we say it. Although Giora (1997, 2003) argued that cognitively prominent salient meanings, rather than literal meanings, play the most important role both in production and comprehension of language, most attention in pragmatics research has been focused on comprehension rather than production. This paper claims that salience plays as important a role in language production as in comprehension, and discusses how salience of an entity can be interpreted as a measure of how well an entity stands out from other entities and biases the preference of the individual in selecting words, expressions, and complex constructs in the process of communication. It is argued that there is a unique interplay between linguistic salience and perceptual salience both in production and comprehension. The role of perceptual and linguistic salience involves a relation between prominence of entities in a ranking, and preference of a choice among alternatives. From the perspective of interlocutors, three theoretically significant categories are distinguished: inherent salience, collective salience, and emergent situational salience. Inherent salience is largely equivalent to cognitive status. It is characterized as a natural built-in preference in the general conceptual and linguistic knowledge of the speaker, which has developed as a result of prior experience with the use of lexical items and situations, and changes both diachronically and synchronically. Inherent salience is affected by collective salience and emergent situational salience. Collective salience is shared with the members of a speech community, and changes diachronically. Emergent situational salience that changes synchronically refers to the salience of specific objects or linguistic elements in the context of language production and comprehension, and may accrue through such determinants as vividness, speaker motivation and recency of mention. In an actual situational context inherent, individual salience is affected and shaped both by collective and situational salience. When the speaker is faced with the choice of a word or an expression, a ranking of the available choices is obtained on the basis of the degree of salience of entities in the generation context. The word or phrase then is selected for utterance on the basis of maximum salience. This paper argues that inherent salience is dominated by linguistic salience, while emergent situational salience is usually governed by perceptual salience. As stated above salience is equally important both in production and comprehension. However, the focus of this paper will mainly be on speaker production because this issue has received less attention so far. (C) 2012 Elsevier B.V. All rights reserved.|Socio-cognitive approach; Linguistic salience; Perceptual salience; Cooperation; Egocentrism; Accessibility|DISCOURSE; LANGUAGE; COHERENCE; ATTENTION|Linguistics; Language \& Linguistics|12|0|21
The influence of code-mixing and speaker information on perception and assessment of foreign language proficiency: An experimental study|2012|The study draws on different lines of research on the influence of social and other information on the evaluation of language production in school contexts. On the one hand, names or other background information is well known to influence teachers and other gatekeepers' evaluations, and on the other hand, code-switching and other non-standard features in pupils' language production are also known to affect assessment outcomes not only of linguistic skills but also of general academic potential. Taking into account these two research traditions, this study investigates the influence of different ethnically marked names and code-switches on teachers' evaluations of pupils' oral proficiency in French as a foreign language. Three authentic oral texts were rerecorded once by inserting German words and once without such inserts. Additionally, these samples were presented either as stemming from a bilingual Swiss German native or from a multilingual Swiss-German Serbian boy. A total of 157 future teachers rated the speech samples with respect to different dimensions (fluency, correctness, but also the pupil's academic potential in general). The analyses provide evidence for positive and negative stereotyping of the Serbian first name, and there is also an unexpected interaction with code-mixing into German: without insertional mixing, the texts with a Balkan name are perceived as being superior, but with such mixing this superiority is lost and turns into significantly lower assessment scores.|code-mixing; code-switching; education; foreign language learning; migration; social inequalities; stereotyping|JUDGMENTS|Linguistics; Language \& Linguistics|4|1|21
Translation Techniques in Cross-Language Information Retrieval|2012|Cross-language information retrieval (CLIR) is an active sub-domain of information retrieval (IR). Like IR, CLIR is centered on the search for documents and for information contained within those documents. Unlike IR, CLIR must reconcile queries and documents that are written in different languages. The usual solution to this mismatch involves translating the query and/or the documents before performing the search. Translation is therefore a pivotal activity for CLIR engines. Over the last 15 years, the CLIR community has developed a wide range of techniques and models supporting free text translation. This article presents an overview of those techniques, with a special emphasis on recent developments.|Algorithms; Languages; Cross-language information retrieval; query translation; document translation; bilingual dictionary; parallel corpora; machine translation; semantic model|TRANSITIVE DICTIONARY TRANSLATION; LATENT SEMANTIC ANALYSIS; TEXT RETRIEVAL; WEB; MODELS; WORDS; QUERY; CLIR; TRANSLITERATION; PERFORMANCE|Computer Science, Theory \& Methods|12|2|21
Computer-Based and Paper-Based Reading Comprehension in Adolescents With Typical Language Development and Language-Learning Disabilities|2012|Purpose: With the global expansion of technology, our reading platform has shifted from traditional text to hypertext, yet little consideration has been given to how this shift might help or hinder students' reading comprehension. The purpose of this study was to compare reading comprehension of computer-based and paper-based texts in adolescents with and without language-learning disabilities (LLD). Method: Fourteen adolescents with LLD and 25 adolescents with typical language development (TLD) read literary texts in computer-based and paper-based formats and then answered reading comprehension questions. Results: The LLD group scored significantly lower than the TLD group on the reading comprehension measure, but there were no significant between-group differences for reading or answering time. In addition, there were no significant within-group differences for the computer-based or paper-based conditions. Predictors for reading comprehension varied by group and condition. Conclusion: Neither group appeared to be affected by the additional cognitive load imposed by hypertext in the computer-based condition; however, the load between conditions may not have been sufficient to differentially impact reading comprehension. Based on the regression analyses, it appears that working memory, oral language, and decoding differed in their contribution to reading comprehension for each group and condition.|reading comprehension; computer-based; hypertext; language-learning disabilities; adolescents|WORKING-MEMORY CAPACITY; LATE-TALKING TODDLERS; PRIOR KNOWLEDGE; TEXT STRUCTURE; INTERACTIVE OVERVIEWS; POOR COMPREHENDERS; WORD RECOGNITION; MEDIATED TEXT; SIMPLE VIEW; BOTTOM-UP|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|4|2|21
Preparing history teachers to work with English learners through a focus on the academic language of historical analysis|2012|This article reports empirical evidence about the influence of embedding language-based strategies into a history methods course to prepare novice history teachers to teach English learners (ELs). Mixed methods were used in an action research cycle to analyze participants' attitudes and preparedness to teach ELs history before and after being exposed to strategies for teaching the academic language of historical analysis. Data sources included surveys, interviews, observations, and student work. Findings suggest participants recognized a specialized language of history and their role as teachers of the language of history. Modifications to the infusion that increased language-based and literacy-focused activities seemed to contribute to an increased sense of preparedness for the second cohort. Participants found using language analysis to `do history' helpful, but few could articulate how to utilize specific strategies. One implication is the language of history needs to be made visible to history teachers before they can teach language demands of history. A second implication is infusing language-based strategies in content methods classes is one component of a comprehensive approach to preparing teachers to teach ELs. Further research is recommended to follow participants into early teaching experiences, provide site-based coaching, observe transfer of teaching skills, and assess pupil learning. (C) 2012 Elsevier Ltd. All rights reserved.|History; English for academic purposes; Teacher education; English learners; Secondary school|STUDENTS; CLASSROOM; RETHINKING; LITERACY; TEXTS|Education \& Educational Research; Linguistics; Language \& Linguistics|4|0|21
Investigating the validity of an integrated listening-speaking task: A discourse-based analysis of test takers' oral performances|2012|Performance on integrated tasks requires candidates to engage skills and strategies beyond language proficiency alone, in ways that can be difficult to define and measure for testing purposes. While it has been widely recognized that stimulus materials impact test performance, our understanding of the way in which test takers make use of these materials in their responses, particularly in the context of listening-speaking tasks, remains predominantly intuitive. Recent studies have highlighted the problems associated with content-related aspects of task fulfilment on integrated tasks, but little attempt has been made to operationalize the way in which content from the input material is integrated into speaking performances. Using discourse data from a trial administration of a pilot for an Oxford English language test, this paper investigates how test takers integrate stimulus materials into their speaking performances on an integrated listening-then-speaking summary task, whether these behaviours are reflected in the relevant rating scale and, by implication, whether the test scores assigned according to this scale reflect real differences in the quality of oral performances. An innovative discourse analytic approach was developed to analyse content-related aspects of performance in order to determine if such aspects represent an appropriate measure of the speaking ability construct. Results showed that the measures devised, such as the number of key points included from the input text, and the accuracy with which information was reproduced or reformulated, effectively distinguished participants according to their level of speaking proficiency. The study's findings support the use of this particular task-type and the appropriateness of the associated rating scale as a measure of speaking proficiency, as well as the utility of the devised discourse-based measures for the validation of integrated tasks in other assessment contexts.|integrated tasks; rating criteria; speaking assessment; assessing content; discourse analysis|PROTOCOLS; STUDENTS; LANGUAGE|Linguistics; Language \& Linguistics|4|1|21
Effects of Stress and Working Memory Capacity on Foreign Language Readers' Inferential Processing During Comprehension|2011|Although stress is frequently claimed to impede foreign language (FL) reading comprehension, it is usually not explained how. We investigated the effects of stress, working memory (WM) capacity, and inferential complexity on Spanish FL readers' inferential processing during comprehension. Inferences, although necessary for reading comprehension, vary in inferential complexity and WM demands. We measured 55 intermediate-level Spanish FL learners' reading comprehension, using questions with three levels of inferential complexity: non-inference (factual), bridging inference (pronoun referent), and pragmatic inference. We measured participants' WM capacity and varied their stress level between blocks using a video camera. Results showed that higher WM learners were more accurate overall. Inference construction during comprehension was negatively related to inferential complexity. Stress increased processing time overall, with a trend toward greater effect on response times (RTs) for questions requiring greater inferential complexity. Higher WM learners showed a greater effect of inferential complexity on RTs than lower WM learners. More generally, and consistent with the <link rid={''}b28{''}>Eysenck, Santos, Derekschan, and Calvo's (2007) Attentional Control Theory, analyses showed that higher WM learners strategically traded reading speed (processing efficiency) for greater comprehension accuracy (processing effectiveness), whereas lower WM learners only did so under stress and did so less successfully. Thus, stress impedes FL reading comprehension through interactions between WM capacity and inferential complexity, and such effects are moderated by strategy use.|foreign language; reading comprehension; working memory; inferences; inferential complexity; stress; anxiety; Attentional Control Theory|SOCIAL-EVALUATIVE STRESS; READING SPAN TESTS; INDIVIDUAL-DIFFERENCES; TEXT COMPREHENSION; CONSTRUCTING INFERENCES; TASK-PERFORMANCE; EXPOSITORY TEXT; ANXIETY; PROFICIENCY; REPRESENTATION|Education \& Educational Research; Linguistics|19|0|21
Analyzing the semantic content and persuasive composition of extremist media: A case study of texts produced during the Gaza conflict|2011|While terrorism informatics research has examined the technical composition of extremist media, there is less work examining the content and intent behind such media. We propose that the arguments and issues presented in extremist media provide insights into authors' intent, which in turn may provide an evidence-base for detecting and assessing risk. We explore this possibility by applying two quantitative text-analysis methods to 50 online texts that incite violence as a result of the 2008/2009 Israeli military action in Gaza and the West Bank territories. The first method-a content coding system that identifies the occurrence of persuasive devices-revealed a predominance of moral proof arguments within the texts, and evidence for distinguishable `profiles' of persuasion use across different authors and different group affiliations. The second method-a corpus-linguistic technique that identifies the core concepts and narratives that authors use-confirmed the use of moral proof to create an in-group/out-group divide, while also demonstrating a movement from general expressions of discontent to more direct audience-orientated expressions of violence as conflict heightened. We conclude that multi-method analyses are a valuable approach to building both an evidence-based understanding of terrorist media use and a valid set of applications within terrorist informatics.|Extremist language; Content analysis; Influence tactics; Semantic tagging; Key concept analysis|COMMUNICATION BEHAVIOR; CRISIS NEGOTIATIONS; PATTERNS; TERRORISM; INTERNET; WEB|Computer Science, Information Systems; Computer Science, Theory \& Methods|16|1|21
How doctors view their health and professional practice: An appraisal analysis of medical discourse|2010|Doctors' health is a major problem for healthcare systems, and several surveys have been carried out in different countries to assess the situation. Yet information about doctors' health is limited, especially in Latin America. The problem is that many doctors find it difficult to admit that they are in trouble, that their work is stressful, or that they need help. Thus the aim of this paper is to explore how doctors view their health and the professional practice in relation with their health, through the analysis of the resources of appraisal in informal communication among them. We present a qualitative analysis of a corpus of texts from a discussion forum in which doctors from Spanish-speaking Latin America wrote about their health and profession. We aimed to answer the following questions: (1) How do doctors view and evaluate their professional practice? (2) Do doctors see their working conditions as a risk factor for their own health? (3) To what extent do doctors express positive or negative values in discussions about their work? (4) What do they evaluate in the discussion? (5) Who do they find are responsible for this situation: health systems, their patients or their colleagues? The analysis was conducted using the framework of Appraisal Theory within a Systemic Functional Linguistics (SFL) approach and focused on three main areas: ``appraiser{''}, ``appraised{''} and ``goals considered valuable{''}. These were examined within the semantic domain of attitude, which includes assessments of human behaviour by reference to social norms (judgment), personal feelings (affect) and assessments of the value of objects, artefacts, happenings and states of affairs (appreciation). In all three areas, attitude was found to be largely negative. Most doctors were acutely aware of risks to their own health as well as of other professional problems, and only a few expressed happiness and satisfaction with their profession. The most interesting findings were the negative judgment of social esteem with regard to neglect of their own health and the judgment of social sanction with regard to the healthcare system, as a whole, and to senior colleagues, in particular. From the point of view of engagement, when doctors valued their work as hard and distressful, they showed a tendency to present the propositions as unproblematic, so they seemed to assume that their audience shared their position. But when they referred to the causes of doctors' illnesses, which implied judgments of social esteem of themselves and their colleagues, they tended to acknowledge alternative positions and they apparently aimed at persuading their audience to promote a change of situation. (C) 2010 Elsevier B.V. All rights reserved.|Appraisal; Systemic Functional Linguistics; Medical discourse; Doctors health|HOSPITAL CONSULTANTS|Linguistics; Language \& Linguistics|6|3|21
A blog emotion corpus for emotional expression analysis in Chinese|2010|Weblogs are increasingly popular modes of communication and they are frequently used as mediums for emotional expression in the ever changing online world. This work uses blogs as object and data source for Chinese emotional expression analysis. First, a textual emotional expression space model is described, and based on this model, a relatively fine-grained annotation scheme is proposed for manual annotation of an emotion corpus. In document and paragraph levels, emotion category, emotion intensity, topic word and topic sentence are annotated. In sentence level, emotion category, emotion intensity, emotional keyword and phrase, degree word, negative word, conjunction, rhetoric, punctuation, objective or subjective, and emotion polarity are annotated. Then, using this corpus, we explore these linguistic expressions that indicate emotion in Chinese, and present a detailed data analysis on them, involving mixed emotions, independent emotion, emotion transfer, and analysis on words and rhetorics for emotional expression. (C) 2010 Elsevier Ltd. All rights reserved.|Emotion analysis; Weblogs; Corpus annotation; Natural language processing|TEXT|Computer Science, Artificial Intelligence|55|1|21
Why we mix metaphors (and mix them well): Discourse coherence, conceptual metaphor, and beyond|2010|The paper explores the phenomenon of metaphors that occur in close textual adjacency, i.e. as metaphor clusters, but do not share a similar cognitive basis. Clusters frequently mix ontologies and are thus devoid of coherence that can be explained as emerging from a single conceptual metaphor. Evidence to that effect comes from a British corpus (Sun and Guardian) of 675 newspaper commentaries covering the 2004/05 EU referenda (in all, 2574 metaphors). First, it turns out that journalists combine metaphors into complex, yet well-formed arguments on a regular basis, with 39\% and 62\% of all metaphors respectively occurring in clusters. Even more strikingly, the data reveals that ontologically mixed metaphors account for 76\% of all clusters and that almost all of these are straightforwardly comprehensible. This challenges the view of mixed metaphor as awkward language usage. I argue that mixing works because metaphors are typically embedded in separate clauses situated at different temporal, causal, speaker, or belief-related conceptual planes. By consequence, no strong joint processing pressure arises that could result in a perceived clash of metaphorical imagery. Thus, felicitous mixing is a natural by-product of the shifting logic of clauses in complex argumentation. In addition, I present a qualitative typology of how clustering metaphors interact in argumentation. It calls into question the view that conceptual metaphors are the coherence-maintaining device par excellence. While conceptual metaphors may create ``internal binding{''} in ontologically coherent clusters, complementary ``external binding{''} models are needed to explain the mixed clusters (and ultimately for a full explanation of all kinds of metaphor-based argumentation). (C) 2009 Elsevier B.V. All rights reserved.|Mixed metaphor; Metaphor clusters; Political argumentation; Discourse coherence; Conceptual metaphor theory; Software-assisted metaphor analysis|FIGURATIVE LANGUAGE|Linguistics; Language \& Linguistics|25|1|21
Electronic delivery of lectures in the university environment: An empirical comparison of three delivery styles|2008|The purpose of this study was to consider the efficacy and popularity of ``Virtual Lectures{''} (text-based, structured electronic courseware with information presented in manageable ``chunks{''}, interaction and multimedia) and ``e-Lectures{''} (on-screen synchrony of PowerPoint slides and recorded voice) as alternatives to traditional lectures. We considered how three modes of delivery compare when increasingly deeper forms of learning are assessed and also student reaction to electronic delivery. Fifty-eight students in three groups took three topics of a human genetics module, one in each delivery style. Results indicated no overall greater efficacy of either delivery style when all question types were taken into account but significantly different delivery-specific results depending on which level of Bloom's taxonomy was assessed. That is, overall, questions assessing knowledge consistently achieved the highest marks followed by analysis, comprehension, evaluation and application. Students receiving traditional lectures scored significantly lower marks for comprehension questions. Students receiving Virtual Lectures scored high for knowledge, comprehension and application but significantly lower for analysis and evaluation questions. The e-Lectures scored high for knowledge questions and were the median for all question types except application. Questionnaire analysis revealed a preference for traditional lectures over computer-based but nevertheless an appreciation of the advantages offered by them. (C) 2006 Elsevier Ltd. All rights reserved.|architectures for educational technology system; computer-mediated communication; evaluation of CAL systems; human-computer interface; teaching/learning strategies|WEB; POWERPOINT; CLASSROOM; EDUCATION; REPLACE; COURSES; TRIAL; MEDIA|Computer Science, Interdisciplinary Applications; Education \& Educational Research|30|0|21
Counterfeit product detection: Bridging the gap between design science and behavioral science in information systems research|2017|In IS research, there is a dichotomy where design science and behavioral science are distinct research paradigms. IS researchers should view these paradigms as complementary with research drawing upon the strengths of both, yet few have done so. This work demonstrates how design science and behavioral science can be united in IS research via counterfeit product detection based on product reviews in an online marketplace. Product authenticity in the online marketplace is a common issue plaguing consumers. The decision process.involved in determining product authenticity is lengthy and complex. Despite the pressing need for an automatic authenticity rating system for online shopping, little research has been done to develop such a system and assess its effects on consumer purchase behavior. To respond to this need, our study develops a design artifact, called OnCDS, to automatically calculate the likelihood that a product is counterfeit based on online customer reviews. Drawing upon lexicon-based sentiment analysis approaches and TF-IDF as kernel theories for our design, we employ web scraping, natural language processing, and topic analysis methods to process customer reviews and calculate the counterfeit score of a product. In assessing the effects of OnCDS on consumer behavior, we develop a research model that encompasses trust and perceived risk based on the valence framework. Results show that our design artifact's efficacy is validated and that the,counterfeit score affects perceived risk and trust, which in turn influences attitude toward purchase. (C) 2017 Elsevier B.V. All rights reserved.|Counterfeit; Design science; Behavioral science; Trust; Risk; Attitude|TECHNOLOGY ACCEPTANCE MODEL; CONSUMER DECISION-MAKING; ELECTRONIC COMMERCE; PLANNED BEHAVIOR; SERVICES ADOPTION; PERCEIVED RISK; WEB SITE; TRUST; INTENTION; PURCHASE|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|0|20|20
Document type assignment accuracy in the journal citation index data of Web of Science|2017|This article reports the results of a study of the correctness of document type assignments in the commercial citation index database Web of Science (SCIE, SSCI, AHCI collections). The document type assignments for publication records are compared to those given on the official journal websites or in the publication full-texts for a random sample of 791 Web of Science records across the four document type categories articles, letters, reviews and others, according to the definitions of WoS. The proportion of incorrect assignments across document types and its influence on document specific normalized citations scores are analysed. It is found that document type data is correct in 94\% of records. Further analyses show that within records of one document type as assigned in the data source, the records assigned to the type correctly and incorrectly have different average page counts and reference counts.|Citation normalization; Document type; Data accuracy; Bibliometric data; Citation impact; Web of Science; Scopus; Data quality|IMPACT; ARTICLES; REVIEWS; SCOPUS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|20|20
A survey of multimodal sentiment analysis|2017|Sentiment analysis aims to automatically uncover the underlying attitude that we hold towards an entity. The aggregation of these sentiments over a population represents opinion polling and has numerous applications. Current text-based sentiment analysis relies on the construction of dictionaries and machine learning models that learn sentiment from large text corpora. Sentiment analysis from text is currently widely used for customer satisfaction assessment and brand perception analysis, among others. With the proliferation of social media, multimodal sentiment analysis is set to bring new opportunities with the arrival of complementary data streams for improving and going beyond text-based sentiment analysis. Since sentiment can be detected through affective traces it leaves, such as facial and vocal displays, multimodal sentiment analysis offers promising avenues for analyzing facial and vocal expressions in addition to the transcript or textual content. These approaches leverage emotion recognition and context inference to determine the underlying polarity and scope of an individual's sentiment. In this survey, we define sentiment and the problem of multimodal sentiment analysis and review recent developments in multimodal sentiment analysis in different domains, including spoken reviews, images, video blogs, human machine and human human interactions. Challenges and opportunities of this emerging field are also discussed, leading to our thesis that multimodal sentiment analysis holds a significant untapped potential. (C) 2017 Elsevier B.V. All rights reserved.|Sentiment; Affect; Sentiment analysis; Human behavior analysis; Computer vision; Affective computing|SPOKEN REVIEWS; EMOTIONS; ENGLISH; TEXT; EXPRESSIONS; LANGUAGE; NORMS; AUDIO|Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic; Optics|0|20|20
Conceptual foundations of a landmark personality scale based on a destination personality scale: Text mining of online reviews|2017|Landmarks play an important role in representing tourist destinations because they symbolize a destination's image and personality. Despite the significance of landmarks to the perception of a destination's image and personality, a personality scale based on landmarks has not been developed. To this end, the purpose of this study is to propose a conceptual foundation of a landscape personality scale based on a destination personality scale using online travel reviews, which are regarded as more valid sources for understanding actual tourist perceptions than simple answers to survey questionnaires. The results of this study imply that the words that describe specific landmarks may differ from those that portray the entire destination and suggest that the words tourists actually use in real situations to characterize tourism resources can be distinguished from hypothetical words of a destination personality scale. Finally, the theoretical and practical implications of the research and directions for future studies are discussed.|Landmark perspective; Landmark personality scale; Destination personality scale; Brand personality; Online travel review; Tourism destination|BRAND PERSONALITY; 5-FACTOR MODEL; BIG 5; DIMENSIONS; IMPACT; IMAGE; PERSPECTIVE; VALIDATION; COUNTRIES; CULTURE|Computer Science, Information Systems; Computer Science, Theory \& Methods|2|18|20
Semi-automatic terminology ontology learning based on topic modeling|2017|Ontologies provide features like a common vocabulary, reusability, machine-readable content, and also allows for semantic search, facilitate agent interaction and ordering \& structuring of knowledge for the Semantic Web (Web 3.0) application. However, the challenge in ontology engineering is automatic learning, i.e., the there is still a lack of fully automatic approach from a text corpus or dataset of various topics to form ontology using machine learning techniques. In this paper, two topic modeling algorithms are explored, namely LSI \& SVD and Mr.LDA for learning topic ontology. The objective is to determine the statistical relationship between document and terms to build a topic ontology and ontology graph with minimum human intervention. Experimental analysis on building a topic ontology and semantic retrieving corresponding topic ontology for the user's query demonstrating the effectiveness of the proposed approach. (C) 2017 Elsevier Ltd. All rights reserved.|Ontology Learning (OL); Latent Semantic Indexing (LSI); Singular Value Decomposition (SVD); Probabilistic Latent Semantic Indexing (pLSI); MapReduce Latent Dirichlet Allocation(Mr.LDA); Correlation Topic Modeling (CTM)|LATENT DIRICHLET ALLOCATION; RETRIEVAL; OWL|Automation \& Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical \& Electronic|2|7|20
Modeling of fuzzy-based voice of customer for business decision analytics|2017|Identification, interpretation and response to customer requirements are the key success factors for companies, regardless of their industry. Failing to satisfy customer requirements can damage a company's reputation and cause heavy losses. In this study, we have developed a new approach for properly interpreting and analyzing the fuzzy voice of the customer using association rule learning and text mining. This unique methodology converts textual and qualitative data into a common quantitative format which is then used to develop a mapped Integrated Customer Satisfaction Index (ICSI). ICSI is a framework for measuring customer satisfaction. Previous measures of customer satisfaction ratio failed to incorporate the cost implications of resolving customer complaints/issues and the fuzzy impact of those complaints/issues on the system. In addition to including these important and unique factors in the present study, we have also introduced a dynamic Critical to Quality (CTQ) concept, a novel method that provides a real-time system to monitor the CTQ list through an updated CTQ library. Finally, a procedure for customer feedback mining and sentiment analysis is proposed that handles typographical errors, which are unavoidable in every real database. The results of this study suggest that incorporating the fuzzy level of negativity and positivity of comments into the model instead of treating negative and positive comments as binary variables, leads to more reasonable outcomes. In addition, this study provides a more structured framework for understanding customer requirements. (C) 2017 Elsevier B.V. All rights reserved.|Voice of customer; Text mining; Sentiment analysis; Product development; Fuzzy logic; Association rule and machine learning; Data mining; Decision support system; Integrated customer satisfaction index (ICSI); Critical to quality (CTQ)|QUALITY FUNCTION DEPLOYMENT; PRODUCT DEVELOPMENT; SENTIMENT ANALYSIS; REQUIREMENTS ANALYSIS; SERVICE INDUSTRY; SATISFACTION; SYSTEM; EXTRACTION; MANAGEMENT; REVIEWS|Computer Science, Artificial Intelligence|2|9|20
Development and Examination of the Linguistic Category Model in a Computerized Text Analysis Method|2017|The linguistic category model (LCM) seeks to understand social psychological processes through the lens of language use. Its original development required human judges to analyze natural language to understand how people assess actions, states, and traits. The current project sought to computerize the LCM assessment based on an idea of language abstraction with a previously published data set. In the study, a computerized LCM analysis method was built using an LCM verb dictionary and a part-of-speech tagging program that identified relevant adjectives and nouns. This computerized method compared open-ended texts written in first-person and third-person perspectives from 130 college students. Consistent with construal-level theory, third-person writing resulted in higher levels of abstraction than first-person writing. Implications of relying on an automated LCM method are discussed.|LIWC; linguistic category model; LCM; imagery perspective|DISTANCE; PERSPECTIVE; EVENTS; LEVEL|Communication; Linguistics; Psychology, Social|0|9|20
Using text mining techniques for identifying research gaps and priorities: a case study of the environmental science in Iran|2017|This study aims to observe the researchers' behavior in Iranian scientific databases to determine the research gaps and priorities in their field of research. Text mining and natural language processing techniques were used to identify what researchers are looking for and to analyze existing research works. In this paper, the information about the behavior of researchers who work in the field of environmental science and existing research works in the Iranian scientific database are processed. The search trends in all areas are evaluated by analyzing the users' search data. The trend analysis indicates that in the period of February 2013 to July 2015, the growth of the researchers' requests in some domains of the environment such as Industry, Training, Assessment, Material, Water and Pollution was 1.5 up to 2 times more than the overall requests. A Combination of the trend analysis and clustering of queries led to shaping four priority zones. Then, the research priorities for each environmental research area were determined. The results show that Training, Pollution, Rangeland, Management and Law are those domains in the environmental research which have the most research gaps in Iran, but there are enough research in Forest, Soil and Industry domains. At the end, we describe the steps for the implementation of a decision support system in environmental research management. Researchers, managers and policy makers can use this proposed ``research demand and supply monitoring'' system or RDSM to make appropriate decisions and allocate their resources more efficiently.|Research priority; Research gap; Text mining; Environment studies; Researchers' behavior analysis|LOG FILES; TRENDS; PREDICTION; MANAGEMENT; RETRIEVAL; FEEDBACK|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|7|20
The politics of response to terror: the reshaping of community and immunity in the aftermath of 7 July 2005 London bombings|2017|This article explores the politics of response to the 7 July 2005 London bombings, by analysing UK counter-terrorism institutional campaigns in the three years following the attack. By drawing on the interpretive category of community/immunity, the semiotic analysis of counter-terrorism campaigns aims to describe their representation of the political community and citizen in the immediate aftermath of the terrorist attacks. The article argues that the counter-terrorism discourse relies on two contrasting tendencies: on the one hand, the unifying force that brings people together in the name of common values; and on the other, the necessity to weaken communitarian bonds in order to allow the citizen to control and check-up on others, reporting ``anything suspicious{''} to authorities. In these texts, the figure of the citizen surveillant clearly emerges. Surveillance activities are shaped around the representation of the terrorist event, from the image of the terrorist in normal everyday life to the actual attacks. Paradoxically this brings about a mimicry effect. The surveillance action carried out by the citizen and the imagined actions of the preparation of a terrorist attack partially overlap in the way they are described and visually represented.|Terrorism; security; semiotics; 7 July 2005 London bombings; community; immunity; counter-terrorism discourse|COUNTER-TERRORISM; PREEMPTION|Humanities, Multidisciplinary; Communication; Linguistics|0|2|20
Figurative messages and affect in Twitter: Differences between \#irony, \#sarcasm and \#not|2016|The use of irony and sarcasm has been proven to be a pervasive phenomenon in social media posing a challenge to sentiment analysis systems. Such devices, in fact, can influence and twist the polarity of an utterance in different ways. A new dataset of over 10,000 tweets including a high variety of figurative language types, manually annotated with sentiment scores, has been released in the context of the task 11 of SemEval-2015. In this paper, we propose an analysis of the tweets in the dataset to investigate the open research issue of how separated figurative linguistic phenomena irony and sarcasm are, with a special focus on the role of features related to the multi-faceted affective information expressed in such texts. We considered for our analysis tweets tagged with {*}irony and {*}sarcasm, and also the tag \#not, which has not been studied in depth before. A distribution and correlation analysis over a set of features, including a wide variety of psycholinguistic and emotional features, suggests arguments for the separation between irony and sarcasm. The outcome is a novel set of sentiment, structural and psycholinguistic features evaluated in binary classification experiments. We report about classification experiments carried out on a previously used corpus for {*}irony vs {*}sarcasm. We outperform in terms of F-measure the state-of-the-art results on this dataset. Overall, our results confirm the difficulty of the task, but introduce new data-driven arguments for the separation between {*}irony and {*}sarcasm. Interestingly, \#not emerges as a distinct phenomenon. (C) 2016 Elsevier B.V. All rights reserved.|Figurative language; Affective knowledge; Irony; Sarcasm; Twitter|NEGATION; EMOTIONS|Computer Science, Artificial Intelligence|8|4|20
Text mining for precision medicine: automating disease-mutation relationship extraction from biomedical literature|2016|Objective Identifying disease-mutation relationships is a significant challenge in the advancement of precision medicine. The aim of this work is to design a tool that automates the extraction of disease-related mutations from biomedical text to advance database curation for the support of precision medicine. Materials and Methods We developed a machine-learning (ML) based method to automatically identify the mutations mentioned in the biomedical literature related to a particular disease. In order to predict a relationship between the mutation and the target disease, several features, such as statistical features, distance features, and sentiment features, were constructed. Our ML model was trained with a pre-labeled dataset consisting of manually curated information about mutation-disease associations. The model was subsequently used to extract disease-related mutations from larger biomedical literature corpora. Results The performance of the proposed approach was assessed using a benchmarking dataset. Results show that our proposed approach gains significant improvement over the previous state of the art and obtains F-measures of 0.880 and 0.845 for prostate and breast cancer mutations, respectively. Discussion To demonstrate its utility, we applied our approach to all abstracts in PubMed for 3 diseases (including a non-cancer disease). The mutations extracted were then manually validated against human-curated databases. The validation results show that the proposed approach is useful in a real-world setting to extract uncurated disease mutations from the biomedical literature. Conclusions The proposed approach improves the state of the art for mutation-disease extraction from text. It is scalable and generalizable to identify mutations for any disease at a PubMed scale.|precision medicine; disease-mutation relationship; automated extraction; machine learning; text mining; breast cancer; prostate cancer|SEQUENCE VARIANTS; SYSTEM; TOOL|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|6|5|20
`Singing your tune': Genre structure and writer identity in personal statements for doctoral applications|2016|Personal Statements are considered as an academic promotional genre that students will usually have to compose as part of their application for graduate study. Yet, relatively little research has explored this type of text across institutional contexts. The present study looks into the personal statement and also explores the perspectives of writers who composed these texts in the context of PhD admissions. The text data were drawn from 21 PhD students at one UK- and one US-based university with the aim to explore rhetorical patterns of structure of the student personal statements following genre analysis. Student interviews were used to complement the results of text analysis to better understand how they present and position themselves in their texts. The findings reveal that the rhetorical moves and the discoursal construction of writer identity are associated with their sense of writer positioning, sensitivity to target audience, and the context for this act of writing. The findings have implications not only for writing pedagogy but also for future research to investigate the different and often implicit features of the personal statement across different disciplines, programmes, and institutional contexts. (C) 2015 Elsevier Ltd. All rights reserved.|Personal statement; Genre analysis; PhD admission; Institutional context; Writer self-representation; Writer identity|MOVES; SELF|Education \& Educational Research; Linguistics; Language \& Linguistics|1|6|20
Evaluation of semantic similarity metrics applied to the automatic retrieval of medical documents: An UMLS approach|2016|One promise of current information retrieval systems is the capability to identify risk groups for certain diseases and pathologies based on the automatic analysis of vast amounts of Electronic Medical Records repositories. However, the complexity and the degree of specialization of the language used by the experts in this context, make this task both challenging and complex. In this work, we introduce a novel experimental study to evaluate the performance of the two semantic similarity metrics (Path and Intrinsic IC-Path, both widely accepted in the literature) in a real-life information retrieval situation. In order to achieve this goal and due to the lack of methodologies for this context in the literature, we propose a straightforward information retrieval system for the biomedical field based on the UMLS Metathesaurus and on semantic similarity metrics. In contrast with previous studies which focus on testbeds with limited and controlled sets of concepts, we use a large amount of information (101,712 medical documents extracted from TREC Medical Records Track 2011). Our results show that in real-life cases, both metrics display similar performance, Path (F-Measure = 0.430) e Intrinsic IC-Path (F-Measure = 0.427). Thereby we suggest that the use of Intrinsic IC-Path is not justified in real scenarios. (C) 2015 Elsevier Ltd. All rights reserved.|Semantic similarity; Information retrieval; Electronic Health Record; UMLS|ELECTRONIC HEALTH RECORDS; QUERY EXPANSION; BIOMEDICAL DOMAIN; LANGUAGE SYSTEM; INFORMATION-CONTENT; KNOWLEDGE; TEXT; IDENTIFICATION; RELATEDNESS; PERSPECTIVE|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|3|0|20
Discursive mechanisms and human agency in language policy formation: negotiating bilingualism and parallel language use at a Swedish university|2016|In the wake of the enactment of Sweden's Language Act in 2009 and in the face of the growing presence of English, Swedish universities have been called upon by the Swedish Higher Education Authority to craft their own language policy documents. This study focuses on the discursive negotiation of institutional bilingualism by a language policy committee at one Swedish university during the process of developing a draft language policy. Following an ethnographic/discourse analytic orientation to language policy and planning research, data were collected during language policy committee meetings at the university. Using nexus analysis, circulating discourses are mapped and analyzed, with a specific focus on how these discourses were negotiated through mediated actions during committee meeting interaction and then entextualized in a draft policy. Analysis reveals how bilingualism' became reinterpreted as parallel language use,' a concept developed and used in Nordic language planning over the past 15 years. Analysis further shows how committee members negotiated the meaning of parallel language use and the processes of resemiotization that took place as discourses from other sociolinguistic scales entered into the committee's discussion and writing. In all, the study highlights discursive mechanisms of language planning and the interplay of social actors and texts.|bilingualism; discourse; language planning; language policy; parallel language use; higher education; Sweden|ENGLISH|Education \& Educational Research; Linguistics; Language \& Linguistics|9|0|20
The multimodal approach in audiovisual translation|2016|This paper will explore the multimodal approach to audiovisual translation (AVT). It must first be stressed, however, that most research on multimodality has not as yet focused on questions of translation. The Routledge Handbook of Multimodal Analysis (Jewitt 2009), which contains articles by most of the leading figures in the field, while representing a major step forward in multimodal studies, does not tackle translation head on. The word `translation' does not even appear in the index. Over a relatively short time span, most of the major contributions to the field have been more purely linguistically based and intent on providing keys to the understanding of the interplay of semiotic resources such as words, images, gesture, music, light, etc. (see O'Toole 1994; Kress and van Leeuwen 1996; Martinec 2000; Unsworth 2001; Baldry and Thibault 2006, etc.). The work of these scholars, however, has provided an impetus to developing ideas on how to exploit multimodal analyses in the area of AVT. Thibault's work, for example, on the `multimodal transcription' provided this author with the basis for investigating how the integration of semiotic modalities in a film text could assist the subtitler in making those all-important decisions on what to retain and what to discard when faced with time constraints. Other scholars have studied the co-articulation of words and image in their discussion of how different modalities realize social functions and make meaning (O'Halloran 2008; Bednarek 2010), emphasising the importance of supplementing purely linguistic analyses with studies of all the other semiotic resources that make up a multimodal text. Findings will inevitably be reported verbally but the analyses need to explore the concept of integration and how other resources can interact with language and, crucially, how translators can be made sensitive to the entire semiotic impact of a multimodal text.|multimodal texts; audiovisual translation; multimodal transcription; modes; access|TEXTS|Linguistics; Language \& Linguistics|0|6|20
Semantic Text Classification for Supporting Automated Compliance Checking in Construction|2016|Automated regulatory and contractual compliance checking requires automated rule extraction from regulatory and contractual textual documents (e.g., contract specifications). Automated rule extraction is a challenging task that requires complex processing of text. In the proposed automated compliance checking (ACC) approach, the first step in automating the rule extraction process is automatically classifying the different documents and parts of documents (e.g., contract clauses) into predefined categories (environmental, safety, health, etc.) for preparing it for further text analysis and rule extraction. These categories are defined in a semantic model for normative reasoning. This paper presents a semantic, machine learning-based text classification algorithm for classifying clauses and subclauses of general conditions for supporting ACC in construction. The multilabel classification problem was transformed into a set of binary classification problems. Different machine learning algorithms, text preprocessing techniques, methods of text feature scoring, methods of feature weighting, and feature sizes were implemented and evaluated at different thresholds. The developed classifier achieved 100 and 96\% recall and precision, respectively, on the testing data. (C) 2014 American Society of Civil Engineers.|Automated compliance checking; Semantic systems; Automated construction management systems; Natural language processing; Text classification; Machine learning|CATEGORIZATION; RECALL|Computer Science, Interdisciplinary Applications; Engineering, Civil|6|11|20
Claiming centrality as promotion in applied linguistics research article introductions|2015|This study explores how promotion is realized in applied linguistics (AL) research article introductions (RAIs). We focus on one promotional strategy, claiming centrality, and examine what appeals and linguistic devices applied linguists (ALs) employ and how they deploy them in RAIs to achieve positive evaluation of the significance of the topic or the research area. Fifty-one RAIs from three top-tier journals in AL were selected for a corpus-based study. Qualitative analyses of the texts revealed four major types of appeals, that is, appeals to salience, magnitude, topicality, and problematicity Of the topic in either the research world or the real world, which ALs made in varied ways. Linguistic devices realizing these appeals were also analyzed with the tool of appraisal. Quantitative analyses further unveiled ALs' frequent use of appeals, their reliance on indirect over direct approaches to promotion, and their preferred patterns in appeal deployment. The pervasion of promotional elements is interpreted as indicative of academic marketization and as discipline-specific, and the indirect way of promotion is viewed as indicating a compromise between the need for promotion and the need to maintain objectivity. (C) 2015 Elsevier Ltd. All rights reserved.|Claiming centrality; Promotion; Research article introductions; Appeals; Linguistic devices|ACADEMIC DISCOURSE; KNOWLEDGE CLAIMS; DISCIPLINES; ABSTRACTS; SCIENCE; WRITERS; CORPUS; STANCE|Education \& Educational Research; Linguistics; Language \& Linguistics|1|8|20
The Language of Press Advertising in the UK: A Multi-dimensional Study|2015|This exploratory study provides the first multi-dimensional (MD) analysis of textual variation in modern British press advertising, using Biber's (1988) methodology. The 364 texts used in the study are systematically sampled to include both commercial advertisements sub-categorized by various types of goods and services, and non-commercial advertisements sponsored by charities and the government. Six dimensions of variation in advertising discourse are identified through a factor analysis, on the basis of linguistic co-occurrence patterns. In particular, several different mechanisms of persuasion are identified and compared. The proposed MD model is then applied to analyze gender-specific advertising strategies. Focusing on one product type, I show that advertisements targeting females tend to use elaborate product descriptions with a semi-scientific focus, while adverts aimed at males are characterized by a terse description dominated by disjunctive grammatical structure. Possible causes of the observed variation are critically discussed, and further research issues amenable to the proposed model are briefly outlined.|Multi-dimensional analysis; advertising; language variation; gender|PROCESSING STRATEGIES; DISCOURSE; ENGLISH|Linguistics; Language \& Linguistics|1|5|20
Expert guided natural language processing using one-class classification|2015|Introduction Automatically identifying specific phenotypes in free-text clinical notes is critically important for the reuse of clinical data. In this study, the authors combine expert-guided feature (text) selection with one-class classification for text processing. Objectives To compare the performance of one-class classification to traditional binary classification; to evaluate the utility of feature selection based on expert-selected salient text (snippets); and to determine the robustness of these models with respects to irrelevant surrounding text. Methods The authors trained one-class support vector machines (1C-SVMs) and two-class SVMs (2C-SVMs) to identify notes discussing breast cancer. Manually annotated visit summary notes (88 positive and 88 negative for breast cancer) were used to compare the performance of models trained on whole notes labeled as positive or negative to models trained on expert-selected text sections (snippets) relevant to breast cancer status. Model performance was evaluated using a 70:30 split for 20 iterations and on a realistic dataset of 10 000 records with a breast cancer prevalence of 1.4\%. Results When tested on a balanced experimental dataset, 1C-SVMs trained on snippets had comparable results to 2C-SVMs trained on whole notes (F = 0.92 for both approaches). When evaluated on a realistic imbalanced dataset, 1C-SVMs had a considerably superior performance (F = 0.61 vs. F = 0.17 for the best performing model) attributable mainly to improved precision (p = .88 vs. p = .09 for the best performing model). Conclusions 1C-SVMs trained on expert-selected relevant text sections perform better than 2C-SVMs classifiers trained on either snippets or whole notes when applied to realistically imbalanced data with low prevalence of the positive class.|one class classification; novelty detection; natural language processing; feature selection|ANNOTATION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|2|0|20
Multi-lingual support for lexicon-based sentiment analysis guided by semantics|2014|Many sentiment analysis methods rely on sentiment lexicons, containing words and their associated sentiment, and are tailored to one specific language. Yet, the ever-growing amount of data in different languages on the Web renders multi-lingual support increasingly important. In this paper, we assess various methods for supporting an additional target language in lexicon-based sentiment analysis. As a baseline, we automatically translate text into a reference language for which a sentiment lexicon is available, and subsequently analyze the translated text. Second, we consider mapping sentiment scores from a semantically enabled sentiment lexicon in the reference language to a new target sentiment lexicon, by traversing relations between language-specific semantic lexicons. Last, we consider creating a target sentiment lexicon by propagating sentiment of seed words in a semantic lexicon for the target language. When extending sentiment analysis from English to Dutch, mapping sentiment across languages by exploiting relations between semantic lexicons yields a significant performance improvement over the baseline of about 29\% in terms of accuracy and macro-level F-1 on our data. Propagating sentiment in language-specific semantic lexicons can outperform the baseline by up to about 47\%, depending on the seed set of sentiment-carrying words. This indicates that sentiment is not only linked to word meanings, but tends to have a language-specific dimension as well. (C) 2014 Elsevier B.V. All rights reserved.|Multi-lingual sentiment analysis; Semantics; Lexicon; Machine translation; Map; Propagation|INFORMATION EXTRACTION; MEDIA; TEXT|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|17|0|20
Moves and steps to sell a paper: a cross-cultural genre analysis of applied linguistics conference abstracts|2014|Conference abstracts are under-represented promotional texts in spite of their key role in the academic life of and communication among scholars. This generic study attempts to capture the structures and strategies of 160 applied linguistics conference abstracts from four world areas in terms of semantic units of Introduction, Method, and Findings and their Moves and Steps. Results revealed similarities and differences arising mainly from the idiosyncratic nature of genre, place of presentation, and western versus non-western, center versus periphery, and theory-versus application-oriented cultures. Implications for novice and non-native researchers to communicate and submit conference abstracts effectively follow a detailed report.|applied linguistics; conference abstracts; genre analysis; Move and Step models; macro-structure; micro-structure|RESEARCH ARTICLES; INTRODUCTIONS; ORGANIZATION; ENGLISH|Communication; Linguistics; Language \& Linguistics|2|0|20
Mining term networks from text collections for crime investigation|2012|An efficient term mining method to build a general term network is presented. The resulting term network can be used for entity relation visualization and exploration, which is useful in many text-mining applications such as crime exploration and investigation from vast piles of crime news or official criminal records. In the proposed method, terms from each document in a text collection are first identified. They are subjected to an analysis for pairwise association weights. The weights are then accumulated over all the documents to obtain final similarity for each term pair. Based on the resulting term similarity, a general term network for the collection is built with terms as nodes and non-zero similarities as links. In application, a list of predefined terms having similar attributes was selected to extract the desired sub-network from the general term network for entity relation visualization. This text analysis scenario based on the collective terms of the similar type or from the same topic enables evidence-based relation exploration. Some practical instances of crime exploration and investigation are demonstrated. Our application examples show that term relations, be it causality, subordination, coupling, or others, can be effectively revealed by our method and easily verified by the underlying text collection. This work contributes by presenting an integrated term-relationship mining and exploration approach and demonstrating the feasibility of the term network to the increasingly important application of crime exploration and investigation. (c) 2012 Elsevier Ltd. All rights reserved.|Co-occurrence analysis; Term relations; Visualization; Network analysis; Knowledge discovery|CO-WORD ANALYSIS; LAW-ENFORCEMENT; KNOWLEDGE; INFORMATION; MANAGEMENT; CLUSTERS; COPLINK; SYSTEM|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|11|3|20
A Comparative Analysis of the Impact of Cooperative versus Textbook-based Individual Prereading Activities on the Reading Comprehension of Students of Spanish|2012|Reading texts with historical and sociopolitical content in a foreign language is often a challenge for second language students. The obstacles encountered by students should be of concern to language instructors. Lack of background knowledge frequently causes the reader to abandon the reading activity with a sense of disappointment and frustration. This quantitative semester-long study examined and compared the effects of two different types of prereading activities on the reading comprehension of college students of fourth-semester Spanish when reading texts about sociopolitical and historical issues. The prereading activities were guided cooperative versus textbook-based individual. Multiple-choice test findings indicated that guided cooperative prereading activities significantly increased participants' comprehension. However, holistic results from a written recall protocol showed no difference between the two prereading treatments. Yet, the results confirmed that guided cooperative prereading activities prompted participants to remember a significantly high percentage of main ideas, but did not impact the recall of supporting ideas and/or minor details.|cooperative learning/aprendizaje cooperativo; individual learning/aprendizaje individual; multiple choice/opcion multiple; prereading/prelectura; reading comprehension/comprension lectora; reading comprehension measurement tools/herramientas de evaluacion de comprension lectora; written recall protocol/protocolo de recuerdo inmediato|NONHANDICAPPED STUDENTS; LANGUAGE CLASSROOM; KNOWLEDGE; RECALL; PROSE|Linguistics; Language \& Linguistics; Literature, Romance|0|1|20
Thinking ahead or not? Natural aging and anticipation during reading|2012|Despite growing evidence of young adults neurally pre-activating word features during sentence comprehension, less clear is the degree to which this generalizes to older adults. Using ERPs, we tested for linguistic prediction in younger and older readers by means of indefinite articles (a's and an's) preceding more and less probable noun continuations. Although both groups exhibited doze probability-graded noun N400s, only the young showed significant article effects, indicating probabilistic sensitivity to the phonology of anticipated upcoming nouns. Additionally, both age groups exhibited prolonged increased frontal positivities to less probable nouns, although in older adults this effect was prominent only in a subset with high verbal fluency (VF). This ERP positivity to contextual constraint violations offers additional support for prediction in the young. For high VF older adults, the positivity may indicate they, too, engage in some form of linguistic pre-processing when implicitly cued, as may have occurred via the articles. (C) 2012 Elsevier Inc. All rights reserved.|Aging; Language; Comprehension; Prediction; Event-related brain potentials; N400; Frontal positivity; Verbal fluency; Implicit cueing; Executive processes|AGE-RELATED DIFFERENCES; LANGUAGE COMPREHENSION; OLDER-ADULTS; BRAIN POTENTIALS; SENTENCE CONTEXT; WORD RECOGNITION; WORKING-MEMORY; LEXICAL ACCESS; INFORMATION; CATEGORIZATION|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|34|5|20
Predicting the proficiency level of language learners using lexical indices|2012|This study explores how second language (L2) texts written by learners at various proficiency levels can be classified using computational indices that characterize lexical competence. For this study, 100 writing samples taken from 100 L2 learners were analyzed using lexical indices reported by the computational tool Coh-Metrix. The L2 writing samples were categorized into beginning, intermediate, and advanced groupings based on the TOEFL and ACT ESL Compass scores of the writer. A discriminant function analysis was used to predict the level categorization of the texts using lexical indices related to breadth of lexical knowledge (word frequency, lexical diversity), depth of lexical knowledge (hypernymy, polysemy, semantic co-referentiality, and word meaningfulness), and access to core lexical items (word concreteness, familiarity, and imagability). The strongest predictors of an individual's proficiency level were word imagability, word frequency, lexical diversity, and word familiarity. In total, the indices correctly classified 70\% of the texts based on proficiency level in both a training and a test set. The authors argue for the applicability of a statistical model as a method to investigate lexical competence across language levels, as a method to assess L2 lexical development, and as a method to classify L2 proficiency.|frequency; language proficiency; lexical competence; lexical diversity; second language acquisition; word familiarity; word imagability|2ND-LANGUAGE SPEAKERS; VOCABULARY KNOWLEDGE; FREQUENCY PROFILES; WORD FAMILIARITY; 2ND LANGUAGE; MONTE-CARLO; ACQUISITION; CONCRETENESS; POLYSEMY; AGE|Linguistics; Language \& Linguistics|7|2|20
Collaborative writing tasks in the L2 classroom: Comparing group, pair, and individual work|2012|This study investigates the benefits of collaborative writing tasks. Previous research from the perspective of the sociocultural theory of mind suggests that writing tasks completed in pairs offer learners an opportunity to collaborate in the solution of their language-related problems, co-construct new language knowledge, and produce linguistically more accurate written texts. Building on this research, the present study compares the performance of the same writing task by groups of four learners (n = 15), pairs (n = 15), and individual learners (n = 21). It examines the effect of the number of participants on the fluency, complexity, and accuracy of the written texts produced, as well as the nature of the oral interaction between the pairs and the groups as they collaborate throughout the writing process. The analysis of interaction focused on language-related episodes (LREs) reveals that although both groups and pairs focused their attention on language relatively often, groups produced more LREs and a higher percentage of correctly resolved LREs than pairs. As a result, the texts written by the groups were more accurate not only than those written individually, but also than those written in pairs. The implications of these results for the understanding of both collaborative writing tasks and collaborative problem solving activity are discussed. (C) 2011 Elsevier Inc. All rights reserved.|Collaborative writing; Second language interaction; Group and pair work|PROFICIENCY; COMPLEXITY; LANGUAGE; PATTERNS; LEARNERS; ACCURACY; DIALOGUE; FLUENCY; CONTEXT; VERBS|Linguistics|56|5|20
Unknown agents in translated political discourse|2012|This article investigates the role of translation and interpreting in political discourse. It illustrates discursive events in the domain of politics and the resulting discourse types, such as jointly produced texts, press conferences and speeches. It shows that methods of Critical Discourse Analysis can be used effectively to reveal translation and interpreting strategies as well as transformations that occur in recontextualisation processes across languages, cultures, and discourse domains, in particular recontextualisation in mass media. It argues that the complexity of translational activities in the field of politics has not yet seen sufficient attention within Translation Studies. The article concludes by outlining a research programme for investigating political discourse in translation.|political discourse; political institution; recontextualisation; Critical Discourse Analysis; agency|NEWSPAPERS; NEWS|Linguistics; Language \& Linguistics|6|0|20
DETECTING CONTRAST PATTERNS IN NEWSPAPER ARTICLES BY COMBINING DISCOURSE ANALYSIS AND TEXT MINING|2011|Text mining aims at constructing classification models and finding interesting patterns in large text collections. This paper investigates the utility of applying these techniques to media analysis, more specifically to support discourse analysis of news reports about the 2007 Kenyan elections and post-election crisis in local (Kenyan) and Western (British and US) newspapers. It illustrates how text mining methods can assist discourse analysis by finding contrast patterns which provide evidence for ideological differences between local and international press coverage. Our experiments indicate that most significant differences pertain to the interpretive frame of the news events: whereas the newspapers from the UK and the US focus on ethnicity in their coverage, the Kenyan press concentrates on sociopolitical aspects.|Text mining; Discourse analysis; Pragmatics; Ideology; Kenyan elections|CATEGORIZATION; IDEOLOGY; CORPORA; GENRE|Linguistics; Language \& Linguistics|6|1|20
How to design and utilize online customer center to support new product concept generation|2011|Websites can be effective vehicles for firms to communicate with their customers but the use of websites has been limited to pacifying complaint customers. To better use a website's information, this research presents a framework for extracting customer opinions from websites and transforming them into product specification data. For the purpose, firstly, customer opinions were collected from an online customer center and then transformed into customer needs using text-mining. Then, after customers were segmented into several groups based on their needs, relations among their needs were visualized by co-word analysis and product specifications to meet those needs t analyzed by decision tree. Lastly, a final target product specification for new products were determined and a target market was identified based on customer profile data. The suggested framework enables to incorporate customer opinions efficiently with new product development processes and to design online customer centers to better collect and analyze useful information. (C) 2011 Elsevier Ltd. All rights reserved.|Online customer center; Customer opinions; New product development; Concept generation; Text-mining; Decision tree|MANAGEMENT; KNOWLEDGE; CARTOGRAPHY; TECHNOLOGY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|22|0|20
Structure and infrastructure of infectious agent research literature: SARS|2011|Text mining was used to extract technical intelligence from the open source global SARS research literature. A SARS-focused query was applied to the Science Citation Index (SCI) (SCI 2008) database for the period 1998-early 2008. The SARS research literature infrastructure (prolific authors, key journals/institutions/countries, most cited authors/journals/documents) was obtained using bibliometrics, and the SARS research literature technical structure (hierarchical taxonomy) was obtained using computational linguistics/document clustering.|Severe acute respiratory syndrome (SARS); Coronavirus; Infectious diseases; Text mining; Bibliometrics; Citation analysis|DATABASE TOMOGRAPHY; DISCOVERY LRD; BIBLIOMETRICS; COV; CHINA|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|4|0|20
What do students do in a F2F CSCL classroom? The optimization of multiple communications modes|2010|This exploratory study analyzes how students use different communication modes to share information, negotiate meaning and construct knowledge in the process of doing a group learning activity in a Primary Grade 5 blended learning environment in Singapore. Small groups of students interacted face-to-face over a computer-mediated communication (CMC) technology called Group Scribbles (GS) to jointly complete a learning task. The lesson designers attempted to optimize the use of CMC technology and face-to-face (F2F) discussion in students' collaborative learning, with the aim of harnessing the specific features of each medium. Building on notions from communication studies and from interaction analysis, we observed the construction and evolution of the interactions through analyzing the artifacts that were produced by a group of students - in verbal talk, gestures, and sketches drawn and text inscribed in GS. F2F and GS interactions intertwined to support collaborative learning. The findings from this study could inform design aspects concerning integrating and reinforcing the strengths of both communication modes when introducing computer-assisted collaborative learning (CSCL) in a F2F classroom. (C) 2010 Elsevier Ltd. All rights reserved.|Cooperative/collaborative learning; Elementary education; Media in education; Computer-mediated communication; Communication modes; Face-to-face discussion|COMPUTER-MEDIATED COMMUNICATION; TURN-TAKING; PARTICIPATION; CONVERSATION; TECHNOLOGY; TEACHERS; ONLINE|Computer Science, Interdisciplinary Applications; Education \& Educational Research|16|0|20
Functional connectivity between brain regions involved in learning words of a new language|2010|Previous studies have identified several brain regions that appear to be involved in the acquisition of novel word forms. Standard word-by-word presentation is often used although exposure to a new language normally occurs in a natural, real world situation. In the current experiment we investigated naturalistic language exposure and applied a model-free analysis for hemodynamic-response data. Functional connectivity, temporal correlations between hemodynamic activity of different areas, was assessed during rest before and after presentation of a movie of a weather report in Mandarin Chinese to Dutch participants. We hypothesized that learning of novel words might be associated with stronger functional connectivity of regions that are involved in phonological processing. Participants were divided into two groups, learners and non-learners, based on the scores on a post hoc word recognition task. The learners were able to recognize Chinese target words from the weather report, while the non-learners were not. In the first resting state period, before presentation of the movie, stronger functional connectivity was observed for the learners compared to the non-learners between the left supplementary motor area and the left precentral gyrus as well as the left insula and the left rolandic operculum, regions that are important for phonological rehearsal. After exposure to the weather report, functional connectivity between the left and right supramarginal gyrus was stronger for learners than for non-learners. This is consistent with a role of the left supramarginal gyrus in the storage of phonological forms. These results suggest both pre-existing and learning-induced differences between the two groups. (C) 2010 Elsevier Inc. All rights reserved.|Language; Word learning; Second language; Phonology; Functional connectivity; Resting state|RESTING-STATE NETWORKS; WORKING-MEMORY; DEFAULT MODE; SPEECH; FLUCTUATIONS; INSULA; CORTEX; PET; ACTIVATION; HYPOTHESIS|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|34|1|20
GENERIC PATTERNS AND SOCIO-CULTURAL RESOURCES IN ACKNOWLEDGEMENTS ACCOMPANYING ARABIC Ph.D. DISSERTATIONS|2010|Even though the acknowledgement genre is a common practice in Arabic scholarly texts, this area is largely neglected in academic research. The present study examines the generic structure and the linguistic patterns of gratitude expressions used in acknowledegments accompanying the Arabic Ph.D. dissertation genre. To this end, I have analyzed the various rhetorical component options that writers use to convey gratitude and the role played by the socio-cultural factors in shaping this genre in a corpus of 100 Arabic acknowledgements accompanying Ph.D. dissertations in soft sciences written by doctoral Arabic native speakers. A discursive genre analysis reveals that Arab writers tend to use certain sociocultural specific components that can be seen as contextualization cues bringing about the religious beliefs, and the academic and social conventions of the Arab writers. Further, they tend to utilize certain preferred address forms, and social honorifics together with various gratitude expression options having different degree of intensification to respond to different types of audience and reflect their complex relationships with the academic and social community members.|Genre; Arabic dissertations; Acknowledgements; Socio-cultural motivations|GENRE|Linguistics; Language \& Linguistics|8|1|20
Developing conversational competence through language awareness and multimodality: the use of DVDs|2009|The argument for a pedagogy of input oriented learning for the development of speaking competence (Sharwood-Smith, 1986; Bardovi-Harlig and Salsbury, 2004; Eslami-Rasekh, 2005) has been of increasing interest in Applied Linguistics circles. It has also been argued that Multimedia applications, in particular DVDs, provide language learners with multimodal representations that may help them `to gain broad access to oral communication both Visually and auditory' (Tschirner, 2001: 305). Thus this paper focuses on an exploratory Study of teaching oral interaction through input processing by means of multimodal texts. The paper is divided into a number of interconnected sections. First, we outline briefly what teaching conversation implies and examine the important role of oral comprehension in the development of conversational interaction. In fact, it has been suggested that effective speaking depends very Much on successful understanding (Oprandy, 1994). In this paper we pay special attention to the crucial role of context in understanding oral interactions. Therefore, we outline the theory of context in English Language Teaching (ELT). The discussion draws on approaches to teaching conversation and it also offers a brief reflection about the need for materials which might convey the sociocultural and semiotic elements of oral communication through which meaning is created. We then discuss the decisions taken to propose a new multimodal approach to teaching conversation from a three-fold perspective: (a) the selection of texts taken from films, and the benefits Of using DVDs (digital versatile disc); (b) the development of a multimodal analysis of film clips for the design of activities; and (c) the promotion of a conversation awareness methodology through a bank of DVD clips to achieve an understanding of how native speakers actually go about the process of constructing oral interactions. In sum, the main thrust of this paper is to pinpoint the advantages Of using multimodal materials taken from DVDs, as they provide learners with broad access to oral communication, both visual and auditory, making classroom conditions similar to the target cultural environment (Tschirner, 2001).|Conversational competence; language awareness; multimodal analysis; DVD technology|COMPREHENSION; CONTEXT|Education \& Educational Research; Linguistics; Language \& Linguistics|8|1|20
A COGNITIVE APPROACH TO THE TRANSLATION OF METONYMY-BASED HUMOR|2009|This paper proposes an approach to the translation of humorous texts based on Cognitive Linguistics, one of the few linguistic theories which have attempted to unveil and understand the cognitive mechanisms that underlie the use of language for humorous purposes. More specifically, we argue that a model focused on the frames or knowledge structures activated in the text and on the metonymical mappings that guide humorous inferences may help its gain useful insights into the cognitive mechanisms used during humor production and understanding. This model is applied to the analysis of :a number of examples from three different novels and their translations into Spanish: Small World by David Lodge, Money, by Martin Amis, and The Buddha of Suburbia by Hanif Kureishi. The approach suggested here has centered on the metonymical patterns which have been most relevant to explain the humorous examples found in our corpus. In this sense, we have specifically focused on the analysis oh four of the most productive types of metonymical mappings: PART FOR WHOLE, MATERIAL FOR OBJECT, CAUSE FOR EFFECT and PRODUCER FOR PRODUCT. Following Peirsman and Geeraerts' (2006) prototypical organization of conceptual contiguity, these mappings have been classified into two different domains: a) contiguity in the spatial and material domain and b) contiguity in the domain of actions, events and processes. We will argue that such a model Call guide translators, helping them to develop a systematic method to solve the problems implied in the translation of humor. In this way, it will be easier to adjust the comprehension mechanisms of the ST audience and those of the TT audience and elaborate a translation that achieves an equivalent effect to that of the ST.|metonymical mapping; cultural frame; Cognitive Linguistics; Cognitive Theory of Metonymy; Frame Semantics; humor|VIEW|Linguistics; Language \& Linguistics|0|0|20
Humble servants of the discipline? Self-mention in research articles|2001|In this paper, I examine the view that research writing is a modest, self-effacing task which involves authors eradicating themselves from their texts to gain acceptance for their work. Conflicting advice in textbooks and style guides, and the apparently diverse conventions of different disciplines, mean that the extent to which writers can explicitly intrude into their discourse is highly problematic for students, teachers, and experienced writers alike. However, the choices which express writer presence are also closely associated with authorial identity and authority and these not only affect the ideational meaning that writers convey, but also influence the impression they make on their readers. Self-mention is therefore a powerful rhetorical strategy for emphasising a writer's contribution. Here I focus on the use of self-citation and exclusive first person pronouns in a corpus of 240 research articles in eight disciplines. Through an analysis of these texts and interviews with expert informants I seek to reveal something of how self-mention is used and perceived as a way of understanding more about writing in the disciplines and about the kinds of options available to students. (C) 2001 The American University. Published by Elsevier Science Ltd. All rights reserved.|research writing; self-citation; identity; disciplinary authority|DISCOURSE|Linguistics|172|2|20
Recent advances in document summarization|2017|The task of automatic document summarization aims at generating short summaries for originally long documents. A good summary should cover the most important information of the original document or a cluster of documents, while being coherent, non-redundant and grammatically readable. Numerous approaches for automatic summarization have been developed to date. In this paper we give a self-contained, broad overview of recent progress made for document summarization within the last 5 years. Specifically, we emphasize on significant contributions made in recent years that represent the state-of-the-art of document summarization, including progress on modern sentence extraction approaches that improve concept coverage, information diversity and content coherence, as well as attempts from summarization frameworks that integrate sentence compression, and more abstractive systems that are able to produce completely new sentences. In addition, we review progress made for document summarization in domains, genres and applications that are different from traditional settings. We also point out some of the latest trends and highlight a few possible future directions.|Document summarization; Natural language generation; Natural language processing; Text mining|SENTENCE|Computer Science, Artificial Intelligence; Computer Science, Information Systems|1|19|19
Subject-method topic network analysis in communication studies|2016|Communication studies depend on information and communication technology (ICT) and the behavior of people using the technology. ICT enables individuals to transfer information quickly via various media. Social changes are occurring rapidly and their studies are growing in number. Thus, a tool to extract knowledge to comprehend the quickly changing dynamics of communication studies is required. We propose a subject-method topic network analysis method that integrates topic modeling analysis and network analysis to understand the state of communication studies. Our analysis focuses on the relationships between topics classified as subjects and methods. From the relationships, we examine the societal and perspective changes relative to emerging media technologies. We apply our method to all papers listed in the Journal Citation Reports Social Science Citation Index as communication studies between 1990 and 2014. The study results allow us to identify popular subjects, methods, and subject-method pairs in proportion and relation.|Communication studies; ICT; Subject-method topic network analysis; Text mining|SOCIAL-SCIENCE; JOURNALS; MEDIA; INTERNET; FACEBOOK; CITATION; INFORMATION; DEPRESSION; HISTORY; TRENDS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|3|19
From Spin to Swindle: Identifying Falsification in Financial Text|2016|Despite legislative attempts to curtail financial statement fraud, it continues unabated. This study makes a renewed attempt to aid in detecting this misconduct using linguistic analysis with data mining on narrative sections of annual reports/10-K form. Different from the features used in similar research, this paper extracts three distinct sets of features from a newly constructed corpus of narratives (408 annual reports/10-K, 6.5 million words) from fraud and non-fraud firms. Separately each of these three sets of features is put through a suite of classification algorithms, to determine classifier performance in this binary fraud/non-fraud discrimination task. From the results produced, there is a clear indication that the language deployed by management engaged in wilful falsification of firm performance is discernibly different from truth-tellers. For the first time, this new interdisciplinary research extracts features for readability at a much deeper level, attempts to draw out collocations using n-grams and measures tone using appropriate financial dictionaries. This linguistic analysis with machine learning-driven data mining approach to fraud detection could be used by auditors in assessing financial reporting of firms and early detection of possible misdemeanours.|Classification; Coh-Metrix; Deception; Financial statement fraud|COMPUTER-MEDIATED COMMUNICATION; FEATURE-SELECTION; STATEMENT FRAUD; DECEPTION; DISCLOSURES; PREDICTION; PACKAGE; WORDS; COST|Computer Science, Artificial Intelligence; Neurosciences|5|4|19
Use of a support vector machine for categorizing free-text notes: assessment of accuracy across two institutions|2013|Background Electronic health record (EHR) users must regularly review large amounts of data in order to make informed clinical decisions, and such review is time-consuming and often overwhelming. Technologies like automated summarization tools, EHR search engines and natural language processing have been shown to help clinicians manage this information. Objective To develop a support vector machine (SVM)-based system for identifying EHR progress notes pertaining to diabetes, and to validate it at two institutions. Materials and methods We retrieved 2000 EHR progress notes from patients with diabetes at the Brigham and Women's Hospital (1000 for training and 1000 for testing) and another 1000 notes from the University of Texas Physicians (for validation). We manually annotated all notes and trained a SVM using a bag of words approach. We then used the SVM on the testing and validation sets and evaluated its performance with the area under the curve (AUC) and F statistics. Results The model accurately identified diabetes-related notes in both the Brigham and Women's Hospital testing set (AUC=0.956, F=0.934) and the external University of Texas Faculty Physicians validation set (AUC=0.947, F=0.935). Discussion Overall, the model we developed was quite accurate. Furthermore, it generalized, without loss of accuracy, to another institution with a different EHR and a distinct patient and provider population. Conclusions It is possible to use a SVM-based classifier to identify EHR progress notes pertaining to diabetes, and the model generalizes well.|electronic health record; support vector machine; natural language processing; search|ELECTRONIC HEALTH RECORDS; PATIENT SMOKING STATUS; INFORMATION; IDENTIFICATION; NLP|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|8|0|19
Finding falls in ambulatory care clinical documents using statistical text mining|2013|Objective To determine how well statistical text mining (STM) models can identify falls within clinical text associated with an ambulatory encounter. Materials and Methods 2241 patients were selected with a fall-related ICD-9-CM E-code or matched injury diagnosis code while being treated as an outpatient at one of four sites within the Veterans Health Administration. All clinical documents within a 48-h window of the recorded E-code or injury diagnosis code for each patient were obtained (n=26010; 611 distinct document titles) and annotated for falls. Logistic regression, support vector machine, and cost-sensitive support vector machine (SVM-cost) models were trained on a stratified sample of 70\% of documents from one location (dataset A(train)) and then applied to the remaining unseen documents (datasets A(test)-D). Results All three STM models obtained area under the receiver operating characteristic curve (AUC) scores above 0.950 on the four test datasets (A(test)-D). The SVM-cost model obtained the highest AUC scores, ranging from 0.953 to 0.978. The SVM-cost model also achieved F-measure values ranging from 0.745 to 0.853, sensitivity from 0.890 to 0.931, and specificity from 0.877 to 0.944. Discussion The STM models performed well across a large heterogeneous collection of document titles. In addition, the models also generalized across other sites, including a traditionally bilingual site that had distinctly different grammatical patterns. Conclusions The results of this study suggest STM-based models have the potential to improve surveillance of falls. Furthermore, the encouraging evidence shown here that STM is a robust technique for mining clinical documents bodes well for other surveillance-related topics.|Text Mining; Accidental Falls; Electronic Health Records; Ambulatory Care|UNITED-STATES; OLDER-ADULTS; CLASSIFICATION; MACHINE; SYSTEM; RISK|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|8|3|19
Phonetic and Syntactic Transfer Effects in the English Interlanguage of Basque/Spanish Bilinguals|2013|The present study examines transfer errors at the levels of phonetics and syntax in the interlanguage of 10 fourteen-year-old Basque/Spanish bilinguals who have been learning English for 7 years in a formal school context in the Basque Country. Analyses showed that learners display L1 effects in the acquisition of both English phonetics and syntax, even though phonetic transfer errors (replacement of novel phonemes by L1 sounds, spirantisation and lack of aspiration in stop sounds, closure of fricative sounds) were far more frequent than syntactic ones (use of null subjects, null objects and null determiners). It is suggested that negative transfer would be minimised if certain educational measures were adopted, such as the enhancement of teachers'/learners' linguistic awareness towards interlanguage processes, the inclusion of contrastive linguistics and language acquisition topics in teacher training programmes, and learners' participation in courses where the target language is used in a more natural, communicative way.|transfer; interlanguage; syntax; phonetics; contrastive analysis|2ND LANGUAGE-ACQUISITION; 2ND-LANGUAGE ACQUISITION; LEARNERS; SPEAKERS; SPANISH; SPEECH; KNOWLEDGE; ARTICLES; EFL|Linguistics; Language \& Linguistics|4|3|19
Critical reflections on genre analysis|2012|Genre Analysis of academic and professional texts has traditionally been the focus of much of ESP (English for Specific Purposes) inspired language descriptions. The emphasis in this form of analysis was, and still continues to be, on the use of text-internal linguistic resources, in particular, on the use of formal and functional properties of language, especially analysis of rhetorical ``moves{''} with relatively limited focus on context or text-external resources, which play an important role in the socio-pragmatics of academic and professional genres. This paper is an attempt to critically reflect on a general overview of this approach to the analysis of professional genres, while at the same, extending the scope of the construction, interpretation and use of professional genres by focusing on the academic and professional ``practices{''} that most academics and professional experts are engaged in as part of their daily routine within what Bhatia (2010) calls ``socio-pragmatic space{''} in which such professional genres invariably function.|(critical) genre analysis; interdiscursivity; professional discourse; socio-pragmatic space; text-internal and text-external resources|DISCOURSE|Linguistics; Language \& Linguistics|15|1|19
Legitimate textual borrowing: Direct quotation in L2 student writing|2012|Using textual analysis and interviews with student writers, this study aims to provide an insight into second language students' use of direct quotations in their MA theses by comparing direct quotations in high-rated and low-rated Master's theses, and by exploring student writers' own motivations to quote directly from sources. The corpus consists of eight high-rated and eight low-rated Master's theses written in English in the field of gender studies by students from Central and Eastern Europe studying at an English-medium university in Central Europe. The findings show that high-rated theses display almost three times as many direct quotations per 1000 words as low-rated theses, which was found to be statistically significant. Differences are also evident in the type of quotations preferred: while high-rated theses primarily use quotation fragments (i.e., quotations shorter than a T-unit), low-rated theses rely on clause-based quotations, which do not require modification when quoted in a text. Interviews with student writers reveal the following motivations to quote directly from sources: (a) source-related motivations (e.g., vivid expression of an idea), (b) writers' own goals (e.g., stylistic variety), (c) external factors (e.g., lack of time), and (d) students' beliefs and fears (e.g., fear of plagiarism). The findings are discussed with reference to the development of student academic writing in the area of source use and citation. Pedagogical recommendations aimed at making students' use of direct quotations more effective are also offered. (C) 2012 Elsevier Inc. All rights reserved.|Direct quotation; Citation; Source use; L2 writers; Master's thesis|PLAGIARISM; CONTEXT; VOICES|Linguistics|22|3|19
Extract conceptual graphs from plain texts in patent claims|2012|This paper develops techniques to extract conceptual graphs from a patent claim using syntactic information (POS, and dependency tree) and semantic information (background ontology). Due to plenteous technical domain terms and lengthy sentences prevailing in patent claims, it is difficult to apply a NLP Parser directly to parse the plain texts in the patent claim. This paper combines techniques such as finite state machines, Part-Of-Speech tags, conceptual graphs, domain ontology and dependency tree to convert a patent claim into a formally defined conceptual graph. The method of a finite state machine splits a lengthy patent claim sentence into a set of shortened sub-sentences so that the NLP Parser can parse them one by one effectively. The Part-Of-Speech and dependency tree of a patent claim are used to build the conceptual graph based on the pre-established domain ontology. The result shows that 99\% sub-sentences split from 1700 patent claims can be efficiently parsed by the NLP Parser. There are two types of nodes in a conceptual graph, the concept and the relation nodes. Each concept or relation can be extracted directly from a patent claim and each relation can link with a fixed number of concepts in a conceptual graph. From 100 patent claims, the average precision and recall of a concept class mapping from the patent claim to domain ontology are 96\% and 89\%, respectively, and the average precision and recall for Real relation class mapping are 97\% and 98\%, respectively. For the concept linking of a relation, the average precision is 79\%. Based on the extracted conceptual graphs from patents, it would facilitate automated comparison and summarization among patents for judgment of patent infringement. (C) 2012 Elsevier Ltd. All rights reserved.|Conceptual graph; Natural language processing; Patent document analysis; Patent claims information extraction; Ontology; Dependency tree|REPRESENTATION; CATEGORIZATION; RETRIEVAL; LANGUAGE; SYSTEM|Automation \& Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical \& Electronic|14|1|19
Content and Form in the Narratives of Children With Specific Language Impairment|2011|Purpose: This project investigated the relationship of content and form in the narratives of school-age children. Method: Two samples of children with specific language impairment (SLI) and their age-matched peers (British Columbia sample, M age = 9; 0 {[}years; months], N = 26; Texas/Kansas sample, M age = 7; 6, N = 40) completed the Test of Narrative Language (TNL; Gillam \& Pearson, 2004). The relative strength of content elaboration and grammatical accuracy were measured for each child using variables derived from the TNL scoring system (Study 1) and from analysis of the story texts (Study 2). Results: Both studies indicated that, compared with age peers, the children with SLI were more likely to produce stories of uneven strength-either stories with poor content that were grammatically quite accurate or stories with elaborated content that were less grammatical. Conclusions: These findings suggest that school-age children with SLI may struggle with the cumulative load of creating a story that is both elaborate and grammatical. They also show that the absence of errors is not necessarily a sign of strength. Finally, they underscore the value of comparing individual differences in multiple linguistic domains, including the elaboration of content, grammatical accuracy, and syntactic complexity.|narratives; assessment; specific language impairment; school-age children|SCHOOL-AGE-CHILDREN; COGNITIVE-DEVELOPMENT; DISORDERED CHILDREN; WORKING-MEMORY; FOLLOW-UP; SKILLS; COMPREHENSION; DISCOURSE; GRAMMAR; CONVERSATION|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|22|1|19
Teachers' decision-making processes when designing EAP reading materials in a Lithuanian university setting|2011|A shift from teaching English for general to teaching English for specific purposes has called for changes in English teachers' practices in a Lithuanian university; in line with research in the area of EAP, teachers are thus expected to design their own reading materials that could cater to the special needs of their students. However, while designing new materials can be extremely satisfying, both professionally and creatively, it can also be a complex undertaking posing a number of challenges to the teachers. This study aimed to explore eight Lithuanian EAP teachers' decision-making processes and the factors influencing their decisions when (1) conducting needs analysis, (2) formulating goals and objectives, (3) finding input materials, (4) creating activities, and (5) using materials in class. Results obtained from lesson observation, video-stimulated recall and document data analysis revealed that the selection of materials was intuition-led rather than research based. In addition, contextual factors, such as the principal's requirements and the availability of resources, appeared to greatly mediate the teachers' decision making. Implications of these findings for implementing appropriate reading materials in a Lithuanian context are discussed. (C) 2011 Elsevier Ltd. All rights reserved.|EAP; Teacher decision-making processes; Design of reading materials; Lithuanian context|TEXT STRUCTURE; LEARNERS|Education \& Educational Research; Linguistics; Language \& Linguistics|3|2|19
Perceived benefits and drawbacks of synchronous voice-based computer-mediated communication in the foreign language classroom|2011|This study explored the benefits and drawbacks of synchronous voice-based computer-mediated communication (CMC) in a blended course of English for specific purposes. Quantitative and qualitative data from two groups following the same syllabus, except for the oral component, were compared. Oral tasks were carried out face-to-face with same L1 partners in the control group and through synchronous voice-based CMC with different L1 partners in the experimental group. The analysis included data from general proficiency pre- and post-test scores, oral Power Point presentation grades, students' questionnaires and students' and teachers' diaries. The results showed that achievements were significantly better in the experimental group and that there was also an increase of other positive factors which may effectively contribute both to second language acquisition (SLA) and to solving many of the problems which make speaking skills the weakest skill in foreign language contexts.|computer-mediated communication; voice-based exchanges; non-native/non-native CMC; students' perceptions; oral skills|NEGOTIATED INTERACTION; TEXT; CMC; PROFICIENCY; CHAT|Education \& Educational Research; Linguistics; Language \& Linguistics|27|1|19
A human mirror neuron system for language: Perspectives from signed languages of the deaf|2010|Language is proposed to have developed atop the human analog of the macaque mirror neuron system for action perception and production {[}Arbib M.A. 2005. From monkey-like action recognition to human language: An evolutionary framework for neurolinguistics (with commentaries and author's response). Behavioral and Brain Sciences, 28, 105-167; Arbib M.A. (2008). From grasp to language: Embodied concepts and the challenge of abstraction. Journal de Physiologie Paris 102,4-20]. Signed languages of the deaf are fully-expressive, natural human languages that are perceived visually and produced manually. We suggest that if a unitary mirror neuron system mediates the observation and production of both language and non-linguistic action, three prediction can be made: (1) damage to the human mirror neuron system should non-selectively disrupt both sign language and non-linguistic action processing; (2) within the domain of sign language, a given mirror neuron locus should mediate both perception and production; and (3) the action-based tuning curves of individual mirror neurons should support the highly circumscribed set of motions that form the ``vocabulary of action{''} for signed languages. In this review we evaluate data from the sign language and mirror neuron literatures and find that these predictions are only partially upheld. (C) 2009 Elsevier Inc. All rights reserved.|Mirror neurons; Sign language; Deafness; fMRI; Broca's area; Action schemas; Object perception|PREMOTOR CORTEX; ACTION REPRESENTATION; ACTION RECOGNITION; BRAIN; COMPREHENSION; DISSOCIATION; ORGANIZATION; HEARING; FMRI; FRAMEWORK|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|9|1|19
Young children's engagement with digital texts and literacies in the home: Pressing matters for the teaching of English in the early years of schooling|2009|Research has established young children's increasing use of computers and other new technologies in the home. Yet, teaching about digital texts and digital practices most often appears as an addition to early literacy instruction in classrooms where ``business-as-usual{''} maintains an emphasis on print and print-based texts. This article examines two young children's literacy practices in the home during their searches for information about lizards using Google, Wikipedia and a reference book about reptiles. Conversation analysis of the young children's social interaction establishes how interaction resources produced socially recognisable actions, how social activity mutually accomplished knowledge about lizards, searches, images and print, and how children shifted seamlessly between various technologies and texts. It is concluded that the children's activities constitute the kinds of digital literacy practices that might inform, reform, or transform, the teaching of English in the early years of schooling.|Digital literacy practices; new technologies; young children; conversation analysis|ONLINE|Education \& Educational Research; Linguistics; Language \& Linguistics|23|0|19
An interview-based study of the functions of citations in academic writing across two disciplines|2009|This paper is an emic. interview-based study of computer scientists' and sociologists' accounts of the functions of citations in their writing. Twelve informants took part in the research, commenting upon their citations in one of their own articles, Informants were not provided with functional checklists, and were free to ascribe as many functions to each citation as they wished. Eleven citation functions are identified and described, and evidence of inter- and intra-disciplinary similarities and differences is provided. While the computer scientists used citations to direct their audience to further reading more often, the sociologists' texts featured more case., of critical citations. The type of paper informants were writing (e.g. theoretical/empirical), the anticipated audience, and the publication outlet resulted in intra-disciplinary differences. Over half of the citations in both fields were said to have more than one function. The insights and implications of the study are discussed. (c) 2008 Elsevier B.V. All rights reserved.|Citation analysis; Academic writing; Scholarly communication; Disciplinary differences|SELF-CITATION; CITER MOTIVATIONS; RESEARCH-PROJECT; CITING BEHAVIOR; COGNITIVE MODEL; DOCUMENT USE; CLASSIFICATION; SCIENCE; COMMUNICATION; SCIENTISTS|Linguistics; Language \& Linguistics|69|6|19
The impact of computer use at home on students' Internet skills|2007|This article reports on a study into the impact of students' use of the Internet and the computer at home on digital skills they need for school. The study was conducted in the lower grades of Dutch secondary education (students aged 13-15). More than 2500 students, distributed over 116 classes in 68 schools, participated in the study. Internet and computer skills were measured by means of an objective test. Multilevel analysis was used to examine the impact of home access and use on Internet and computer skills taking into account the effect of students' backgrounds. Students in pre-university education, third-graders and non-minority students appeared to have better Internet skills and a more advantageous home computer use than students in pre-vocational education, first-graders and minority students, respectively. The Internet skills of girls were hardly less developed than those of boys. Home access to e-mail and the extent to which students use the home computer for surfing, e-malling, chatting and text processing were found to be substantially related to Internet and computer skills (taking into account the effect of several background characteristics of the students). (C) 2005 Elsevier Ltd. All rights reserved.|teaching/learning strategies; Internet skills; distributed learning environments; secondary education; gender studies|SCHOOL; TECHNOLOGIES; GENDER; ACCESS; PUPILS; TESTS; ICT|Computer Science, Interdisciplinary Applications; Education \& Educational Research|69|0|19
`We do not seem to have a theory... The theory I present here attempts to fill this gap': Inclusive and exclusive pronouns in academic writing|2005|This paper is a qualitative and quantitative corpus-based study of how academic writers use the personal pronouns I and inclusive and exclusive we. Using a multidisciplinary corpus comprising of journal research articles ( RAs) from the fields of Business and Management, Computing Science, Economics, and Physics, I present data extracts which reveal how I and we can help writers create a sense of newsworthiness and novelty about their work, showing how they are plugging disciplinary knowledge gaps. Inclusive pronouns can act as positive politeness devices by describing and/or critiquing common disciplinary practices, and elaborating arguments on behalf of the community. They can also organize the text for the reader, and highlight the current problems and subject areas which preoccupy the field. The quantitative analysis reveals that while all instances of we in the Business and Management articles and all but one of the instances of we in the Economics articles are inclusive, only a third of the instances in the Computing articles and under 10 per cent of the instances in the Physics articles are inclusive. The study ends with a brief discussion of what a few English for Academic Purposes ( EAP) textbooks tell students about inclusive and exclusive pronouns, and offers some suggestions for EAP classroom activities.|azoles; prophylaxis; empirical; Aspergillus; Candida|ARTICLES; STUDENT; READER|Linguistics|83|3|19
Traditions of dispute: from negotiations of talmudic texts to the arena of political discourse in the media|2002|Israeli political talk-show debates are notoriously fierce and overtly confrontational. To understand the structures and origins of this discursive style, we apply a historical pragmatics perspective, comparing debates of current political events on a popular talk-show to a classic and historically cherished form of traditional Jewish argumentation-the oral study of the premodern Talmud-as performed through paired-study debate (xavruta) in contemporary Talmudic academies. The institutional environments and deeper social significance of the two speech events we compared are highly divergent: Political talk shows represent the uneasy coexistence of real-life conflict and antagonistic game, while xavruta interactions make use of a superficially adversarial format to maximize mutual comprehension between interlocutors and ultimately enhance sociability. Yet on the level of performance-in rhetorical strategy and confrontational style-they have marked similarities. Transcribed recordings of debates in these two arenas of argument were analyzed and compared, and the analysis yields a series of marked similarities in discursive attributes between the two. These similarities include: i. a marked preference for disagreement, ii. high dialogicity of the exchanges in the sense of nuanced listening and responding, iii. acceptability of occasional disruptions in the dialogicity of the conversation-flow without its breakdown. and iv. high complexity of logic and structure in argument and argumentation. Given the direction of the historical timeline, these findings suggest the possibility of a carry-over of discursive styles from the religious/scholarly milieu to the public sphere of ideological and political debate. The survival of this unique discursive style from antiquity to the present, both within and across the scholarly, educational, and public spheres, and across media of communication, would demonstrate tire resilience of traditional cultural patterns in the face of radical technological, political, and ideological change. (C) 2002 Elsevier Science B.V. All rights reserved.|argumentative discourse; media discourse; historical pragmatics; Jewish studies; Talmudic texts|DISAGREEMENT|Linguistics; Language \& Linguistics|30|2|19
Priming in sentence processing: Intralexical spreading activation, schemes, and situation models|2000|A series of eye-tracking experiments investigated priming in natural language understanding. Intralexical spreading activation accounts of priming: predict that the response to a target word will be speeded (i.e., primed) when strong associates appear prior to the target. Schema-based priming accounts predict that priming will occur when the target word is a component of an activated schema or script. Situation model accounts predict that priming will occur when a target word can be integrated easily into an evolving discourse representation. In separate experiments, we measured the effect of associated words, synonyms, and identity primes on processing times for subsequently encountered target,words. Our designs crossed prime type (e.g.. synonyms vs. unassociated words) with semantic plausibility (i.e.. the target word was a plausible vs. an implausible continuation of the sentence). The results showed that identity primes, bur nor associates or synonyms, primed target words in early measures of processing like first fixation and gaze duration. Plausibility effects tended to emerge in later measures of processing (e.g., on total reading time), although some evidence was obtained for early effects of semantic plausibility. We propose that priming in naturalistic conditions is nor caused bq intralexical spreading activation or access to precompiled schemas.|spreading activation; priming; sentence processing; text comprehension; lexical access|LATENT SEMANTIC ANALYSIS; LEXICAL AMBIGUITY; EYE-TRACKING; LANGUAGE COMPREHENSION; GARDEN-PATHS; CONTEXT; RESOLUTION; ACCESS; PLAUSIBILITY; CONSTRAINTS|Linguistics; Psychology, Experimental|51|1|19
Emotion classification of YouTube videos|2017|Watching online videos is a major leisure activity among Internet users. The largest video website, YouTube, stores billions of videos on its servers. Thus, previous studies have applied automatic video categorization methods to enable users to find videos corresponding to their needs; however, emotion has not been a factor considered in these classification methods. Therefore, this study classified YouTube videos into six emotion categories (i.e., happiness, anger, disgust, fear, sadness, and surprise). Through unsupervised and supervised learning methods, this study first categorized videos according to emotion. An ensemble model was subsequently applied to integrate the classification results of both methods. The experimental results confirm that the proposed method effectively facilitates the classification of YouTube videos into suitable emotion categories. (C) 2017 Elsevier B.V. All rights reserved.|Data mining; Sentiments analysis; Machine leaming; YouTube|SENTIMENT ANALYSIS; MODEL; TEXT; WORDS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|0|18|18
Effects of innovation management system standardization on firms: evidence from text mining annual reports|2017|Using a management formula to standardize innovation management can be thought of as deeply contradictory, however, several successful firms in Spain have been certified under the pioneer innovation management standard UNE 166002. This paper analyzes the effects that standardization has in the attitudes and values as regard to innovation for a sample of firms by text-mining their corporate disclosures. Changes in the relevance of the concepts, co-word networks and emotion analysis have been employed to conclude that the effects of certification on the corporate behavior about innovation are coincident with the open innovation and transversalization concepts that UNE 166002 promotes.|UNE 166002; Innovation management; Text mining; Sentiment analysis; Management standards|PERFORMANCE; CERTIFICATION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|8|18
Trend monitoring for linking science and strategy|2017|Rapid changes in Science \& Technology (S\&T) along with breakthroughs in products and services concern a great deal of policy and strategy makers and lead to an ever increasing number of Foresight and other types of forward-looking work. At the outset, the purpose of these efforts is to investigate emerging S\&T areas, set priorities and inform policies and strategies. However, there is still no clear evidence on the mutual linkage between science and strategy, which may be attributed to Foresight and S\&T policy making activities. The present paper attempts to test the hypothesis that both science and strategy affect each other and this linkage can be investigated quantitatively. The evidence for the mutual attribution of science and strategy is built on a quantitative trend monitoring process drawing on semantic analysis of large amount of textual data and text mining tools. Based on the proposed methodology the similarities between science and strategy documents along with the overlaps between them across a certain period of time are calculated using the case of the Agriculture and Food sector, and thus the linkages between science and strategy are investigated.|Science and strategy; Science push; Strategy pull; Text mining; Tech; mining; Trend analysis; Semantic similarity; Foresight; Agriculture and food sector|TRIZ EVOLUTION TRENDS; TECHNOLOGY TRENDS; PATENTS; IDENTIFICATION; METHODOLOGY; FORESIGHT; SUCCESS; TOOL|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|15|18
Detecting sarcasm in customer tweets: an NLP based approach|2017|Purpose - The purpose of this paper is to study sarcasm in online text - specifically on twitter - to better understand customer opinions about social issues, products, services, etc. This can be immensely helpful in reducing incorrect classification of consumer sentiment toward issues, products and services. Design/methodology/approach - In this study, 5,000 tweets were downloaded and analyzed. Relevant features were extracted and supervised learning algorithms were applied to identify the best differentiating features between a sarcastic and non-sarcastic sentence. Findings - The results using two different classification algorithms, namely, Naive Bayes and maximum entropy show that function words and content words together are most effective in identifying sarcasm in tweets. The most differentiating features between a sarcastic and a non-sarcastic tweet were identified. Practical implications - Understanding the use of sarcasm in tweets let companies do better sentiment analysis and product recommendations for users. This could help businesses attract new customers and retain the old ones resulting in better customer management. Originality/value - This paper uses novel features to identify sarcasm in online text which is one of the most challenging problems in natural language processing. To the authors' knowledge, this is the first study on sarcasm detection from a customer management perspective.|Text mining; Natural language processing; Artificial intelligence; Data mining; Business intelligence; Sarcasm detection|SENTIMENT ANALYSIS; IRONY|Computer Science, Interdisciplinary Applications; Engineering, Industrial|0|13|18
Metacognitive perspectives on the development of reading comprehension: a classroom study of literary text-talks|2017|The current study is a contribution to reading research dealing with tuition in reading comprehension and specifically with the issue of arranging tuition to support the development of metacognition. The empirical findings referred to in this study are from textual discussions of works of fiction in grades 6 and 7. The specific focus of the study is the correlation between the linguistic strategies used by the teacher and the pupils' opportunities to develop metacognitive perspectives as a consequence of these strategies. The study shows how the teachers, by use of a series of linguistic strategies, can offer pupils support in order to (1) identify and visualise the premises of their personal queries; (2) observe and verbalise their processes of interpretation together with their emotional reactions when reading; (3) survey, adjust and communicate their use of reading comprehension strategies and (4) recognise the text as an aesthetic construction and the interaction/transaction between texts and the reader.|metacognition; teacher skills; reading comprehension; practice analysis|INSTRUCTION; STRATEGIES|Education \& Educational Research; Linguistics; Language \& Linguistics|0|6|18
The impact of topic interest, L2 proficiency, and gender on EFL incidental vocabulary acquisition through reading|2017|This study investigated the impact of topic interest, alongside L2 proficiency and gender, on L2 vocabulary acquisition through reading. A repeated-measures design was used with 135 Korean EFL students. Control variables included topic familiarity, prior target-word knowledge, and target-word difficulty (word length, class, and concreteness). Participants read both high- and low-interest topic passages and took vocabulary posttests (word-form recognition, translation recognition, and translation production) immediately and four weeks after reading. Analyses revealed significant effects of topic interest and L2 proficiency, and a significant interaction between topic interest and gender. These results were maintained over time. The article concludes by discussing the facilitative role of topic interest, expanding on the motivational factor considered in the involvement load hypothesis.|Gender; involvement load hypothesis; L2 incidental vocabulary acquisition; L2 proficiency; topic interest|KNOWLEDGE; TEXT; COMPREHENSION; FAMILIARITY; LITERACY; STUDENTS; TASK|Education \& Educational Research; Linguistics|0|4|18
Effects of a Text-Processing Comprehension Intervention on Struggling Middle School Readers|2016|Purpose: We examined the effects of a text-processing reading comprehension intervention emphasizing listening comprehension and expressive language practices with middle school students with reading difficulties. Method: A total of 134 struggling readers in grades 6-8 were randomly assigned to treatment (n = 83) and control conditions (n = 51) using a 2: 1 ratio (two students randomized to treatment for every one student randomized to control). Students in the treatment condition received 40 min of daily instruction in small groups of four to six students for approximately 17 hr. Results: One-way analysis of covariance models on outcome measures with the respective pretest scores as a covariate revealed significant gains on proximal measures of vocabulary and key word and main idea formulation. No significant differences were found on standardized measures of listening and reading comprehension. Discussion: Results provide preliminary support for integrating listening comprehension and expressive language practices within a text-processing reading comprehension intervention framework for middle-grade struggling readers.|listening comprehension; reading comprehension; struggling middle-grade readers|RANDOMIZED CONTROLLED-TRIAL; READING-COMPREHENSION; LANGUAGE INTERVENTION; INDIVIDUAL-DIFFERENCES; DISCIPLINARY LITERACY; LEARNING-DISABILITIES; VOCABULARY KNOWLEDGE; SCIENCE LITERACY; EXPOSITORY TEXT; SIMPLE VIEW|Linguistics; Rehabilitation|2|3|18
An SNN-Based Semantic Role Labeling Model with Its Network Parameters Optimized Using an Improved PSO Algorithm|2016|Semantic role labeling (SRL) is a fundamental task in natural language processing to find a sentence-level semantic representation. The semantic role labeling procedure can be viewed as a process of competition between many order parameters, in which the strongest order parameter will win by competition and the desired pattern will be recognized. To realize the above-mentioned integrative SRL, we use synergetic neural network (SNN). Since the network parameters of SNN directly influence the synergetic recognition performance, it is important to optimize the parameters. In this paper, we propose an improved particle swarm optimization (PSO) algorithm based on log-linear model and use it to effectively determine the network parameters. Our contributions are two-folds: firstly, a log-linear model is introduced to PSO algorithm which can effectively make use of the advantages of a variety of different knowledge sources, and enhance the decision making ability of the model. Secondly, we propose an improved SNN model based on the improved PSO and show its effectiveness in the SRL task. The experimental results show that the proposed model has a higher performance for semantic role labeling with more powerful global exploration ability and faster convergence speed, and indicate that the proposed model has a promising future for other natural language processing tasks.|Semantic role labeling (SRL); Synergetic neural network (SNN); Particle swarm optimization (PSO); Log-linear model|PARTICLE SWARM OPTIMIZATION; NEURAL P SYSTEMS; POWER|Computer Science, Artificial Intelligence|0|8|18
The Role of Semiotic Metaphor in the Verbal-Visual Interplay of Three Children's Picture Books. A Multisemiotic Systemic-Functional Approach|2016|This paper aims to explore how the use of semiotic metaphors in picture books contributes to children's understanding of the stories. The three picture books selected for analysis were written during the twentieth century and respond to a standard of literary quality: Guess How Much I Love You (1994), Where the Wild Things Are (1963) and Gorilla (1983). The concept of semiotic metaphor as a tool to create ideational meaning is analysed within the framework of Systemic Functional Linguistics and Systemic-Functional Multimodal Discourse Analysis. Kay O'Halloran extends the Hallidayan concept of grammatical metaphor to the semiotic metaphor in order to determine how verbal and visual modes interact with each other in multimodal texts. Like grammatical metaphor, semiotic metaphor also involves a shift in the grammatical class or function of an element. As this process does not take place intra-semiotically, but rather inter-semiotically, the reconstrual produces a semantic change in the function of that element, creating a new way of making meaning and representing reality. The results of the analysis show that semiotic metaphors are essentially used in children's tales to facilitate young children's understanding of the story by making some abstract phenomena related to states of being more concrete and specific.|Systemic Functional Linguistics; grammatical metaphor; semiotic metaphor; verbal-visual intersemiosis; picture books|LANGUAGE|Linguistics; Language \& Linguistics; Literature|0|4|18
Author's editor revisions to manuscripts published in international journals|2016|English as Additional Language (EAL) scholarly writers have to overcome numerous obstacles to meet the expectations of editors and peer reviewers before they can publish their research articles in international journals published in English. A number of shapers (Burrough-Boenisch, 2003) are often involved in revising such articles before their eventual publication. This study focuses on the revision changes made by an author's editor to a corpus of such articles leading up to their eventual publication. Based on textual analysis of the early drafts and published manuscripts of 15 SCI-indexed journal articles by Chinese doctoral students, a double-entry coding scheme was developed to describe 5160 revision changes made to the manuscripts, in terms of five types of revision, i.e., substitution, correction, addition, deletion, and rearrangement, and four different lexico-grammatical levels, i.e., morpheme, word, group and clause/clause complex. With the exception of correction, a category which applies to surface-level errors (which do not affect meaning), and is the second most frequent category of changes, all of the other categories represent changes which often substantially alter the meanings of the texts and which involve negotiation between the editor and the writer. The theoretical and pedagogical implications of the findings are discussed with reference to previous studies focusing on revision changes and to debates concerning English as a Lingua Franca franca and World Englishes. (C) 2016 Elsevier Inc. All rights reserved.|Writing for publication; Proofreading; Revision; Scientific editing|CORRECTIVE FEEDBACK; ENGLISH; SCIENTISTS; PUBLICATION; SCHOLARS; WORLD; TEXTS|Linguistics|4|2|18
Multi-document summarization using closed patterns|2016|There are two main categories of multi-document summarization: term-based and ontology-based methods. A term-based method cannot deal with the problems of polysemy and synonymy. An ontology-based approach addresses such problems by taking into account of the semantic information of document content, but the construction of ontology requires lots of manpower. To overcome these open problems, this paper presents a pattern-based model for generic multi-document summarization, which exploits closed patterns to extract the most salient sentences from a document collection and reduce redundancy in the summary. Our method calculates the weight of each sentence of a document collection by accumulating the weights of its covering closed patterns with respect to this sentence, and iteratively selects one sentence that owns the highest weight and less similarity to the previously selected sentences, until reaching the length limitation. The sentence weight calculation by patterns reduces the dimension and captures more relevant information. Our method combines the advantages of the term-based and ontology-based models while avoiding their weaknesses. Empirical studies on the benchmark DUC2004 datasets demonstrate that our pattern-based method significantly outperforms the state-of-the-art methods. Multi-document summarization can be used to extract a particular individual's opinions in the form of closed patterns, from this individual's documents shared in social networks, hence provides a useful tool for further analyzing the individual's behavior and influence in group activities. (C) 2016 Elsevier B.V. All rights reserved.|Multi-document summarization; Closed patterns; Text mining; Diversity; Content coverage|SEQUENCES; ALGORITHMS|Computer Science, Artificial Intelligence|4|3|18
Bibliometric indicators in the context of regional repositories: proposing the D-index|2016|In collaboration with the managers of a university, we have conducted an action research to gauge the adequacy of texts written by researchers in the doctoral programs of the institution as the input (content) for the university's distance learning program. For the analyses, bibliometric data were collected regarding the articles in question from the regional SciELO repository. This repository was chosen because the articles are mostly published in Portuguese, which is in the domain of the target readership of the distance learning project. It was observed that there was a need for an indicator that related the number of downloads of an article to the total number of downloads of the journal in which it was published. Thus, we propose the D-index, defined as the number of papers with download number a parts per thousand yend, as a useful index for characterizing the academic popularity (hits) of a journal. The first applications of the D-index in terms of professional practice were positive, given its usefulness and practicality. The D-index aids the analysis of the download of an article, which is a fundamental event for subsequent reading, internalization and learning. An analysis of this set of actions is essential to the context of regional repositories, as their mission also includes the dissemination of information to aid the learning and education of their readers.|Article download; Regional repository; H-index; D-index; Academic article; Scientific article; Action research|JOURNAL IMPACT FACTOR|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|3|1|18
Information extraction from multi-institutional radiology reports|2016|Objectives: The radiology report is the most important source of clinical imaging information. It documents critical information about the patient's health and the radiologist's interpretation of medical findings. It also communicates information to the referring physicians and records that information for future clinical and research use. Although efforts to structure some radiology report information through predefined templates are beginning to bear fruit, a large portion of radiology report information is entered in free text. The free text format is a major obstacle for rapid extraction and subsequent use of information by clinicians, researchers, and healthcare information systems. This difficulty is due to the ambiguity and subtlety of natural language, complexity of described images, and variations among different radiologists and healthcare organizations. As a result, radiology reports are used only once by the clinician who ordered the study and rarely are used again for research and data mining. In this work, machine learning techniques and a large multi-institutional radiology report repository are used to extract the semantics of the radiology report and overcome the barriers to the re-use of radiology report information in clinical research and other healthcare applications. Material and methods: We describe a machine learning system to annotate radiology reports and extract report contents according to an information model. This information model covers the majority of clinically significant contents in radiology reports and is applicable to a wide variety of radiology study types. Our automated approach uses discriminative sequence classifiers for named-entity recognition to extract and organize clinically significant terms and phrases consistent with the information model. We evaluated our information extraction system on 150 radiology reports from three major healthcare organizations and compared its results to a commonly used non-machine learning information extraction method. We also evaluated the generalizability of our approach across different organizations by training and testing our system on data from different organizations. Results: Our results show the efficacy of our machine learning approach in extracting the information model's elements (10-fold cross-validation average performance: precision: 87\%, recall: 84\%, F1 score: 85\%) and its superiority and generalizability compared to the common non-machine learning approach (p-value < 0.05). Conclusions: Our machine learning information extraction approach provides an effective automatic method to annotate and extract clinically significant information from a large collection of free text radiology reports. This information extraction system can help clinicians better understand the radiology reports and prioritize their review process. In addition, the extracted information can be used by researchers to link radiology reports to information from other data sources such as electronic health records and the patient's genome. Extracted information also can facilitate disease surveillance, real-time clinical decision support for the radiologist, and content-based image retrieval. (C) 2015 Elsevier B.V. All rights reserved.|Natural language processing; Information extraction; Discriminative sequence classifier; Radiology report narrative|TEXT; CLASSIFICATION; ALGORITHM; MODEL|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|12|5|18
Graduate students' genre knowledge and perceived disciplinary practices: Creating a research space across disciplines|2016|Disciplinary differences in academic writing have been addressed in applied linguistics from multiple perspectives. This article focuses on the rhetorical strategies used by multilingual graduate students from the sciences, the social sciences, and the humanities to create a research space in academic introductions. Adopting an in-depth qualitative approach, we draw on three data sources: graduate learners' analyses of model texts, their reflections on their own writing strategies, and a textual analysis of their introductions, to better understand how genre knowledge is connected to perceived disciplinary practices. Our findings indicate that the students' formal and rhetorical knowledge of genre is linked to their perception of knowledge-making practices in their respective disciplines. We discuss pedagogical implications for EAP professionals working with students from different disciplines in multilingual contexts. (C) 2015 Elsevier Ltd. All rights reserved.|Genre knowledge; Disciplinary discourse; Knowledge-making practices; Multilingual graduate students; Academic introductions|APPLIED LINGUISTICS; RESEARCH ARTICLES; DISCOURSE; AWARENESS; LITERACY; INTRODUCTIONS; PERFORMANCE; LANGUAGE; ENGLISH; TASKS|Linguistics|3|2|18
VisOHC: Designing Visual Analytics for Online Health Communities|2016|Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHO administrators{''} tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs which can be encoded for thread visualizations at the users requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.|Online health communities visual analytics; conversation analysis; thread visualization; healthcare; design study|VISUALIZATION; INFORMATION; SUPPORT; TEXT; EXPERIENCES; NETWORKS; WORDLE; CARE|Computer Science, Software Engineering|6|0|18
Graphical causal inference and copula regression model for apple keywords by text mining|2015|Apple is a leading company of technological evolution and innovation. This company founded and produced the Apple I computer in 1976. Since then, based on its innovative technologies, Apple has launched creative and innovative products and services such as the iPod, iTunes, the iPhone, the Apple app store, and the iPad. In many fields of academia and business, diverse studies of Apple's technological innovation strategy have been performed. In this paper, we analyze Apple's patents to better understand its technological innovation. We collected all applied patents by Apple until now, and applied statistics and text mining for patent analysis. By using graphical causal inference method, we created the causal relations among Apple keywords preprocessed by text mining, and then we carried out the semiparametric Gaussian copula regression model to see how the target response keyword and the predictor keywords are relating to each other. Furthermore, Gaussian copula partial correlation was applied to Apple keywords to find out the detailed dependence structure. By performing these methods, this paper shows the technological trends and relations between Apple's technologies. This research could make contributions in finding vacant technology areas and central technologies for Apple's R\&D planning. (C) 2015 Elsevier Ltd. All rights reserved.|Apple keywords; Text mining; Patent analysis; Graphical causal inference; Copula regression|DIRECTED ACYCLIC GRAPHS; TECHNOLOGICAL-INNOVATION; PATENT ANALYSIS; PC-ALGORITHM; NETWORK; DEPENDENCE; DOCUMENTS; KNOWLEDGE; CHINA; FIRMS|Computer Science, Artificial Intelligence; Engineering, Multidisciplinary|12|1|18
LEXICOMETRIC ANALYSIS OF THE SPECIFICITY OF TEENAGERS' DIGITAL WRITING IN WHATSAPP|2015|The article presents a lexicometric and factorial research in which we analyze the most relevant linguistic and paralinguistic characteristics of Spanish teenagers' digital writing in one of the most popular and used instant messaging programs (WhatsApp (c)). Writing in digital mobile devices (smartphones and tablets) is one of the most commonly activities in our society and is an essential component of communicative competence in the Information and Communication Society. Digital communication is part of our lives and the analysis of the use of digital and ubiquitous communication devices and programs has a broad social, language, and teaching impact. The research has been contextualized in four Spanish provinces with a sample of 417 WhatsApp digital chats among high school students aged from 13 to 16. A quantitative methodology has been implemented from a lexicometric approach in order to analyze the digital linguistic corpus with reference to the most relevant linguistic and paralinguistic elements. Therefore, we have established correlations between independent variables that could explain digital writing linguistic patterns and usage. The results show that digital writing in this instant messaging app has special orthotypographic and audiovisual characteristics conditioned by usage variables such as size of the device display, hours of conversation, and relationship between speakers.|Digital writing; lexicometry; lexical specificity; WhatsApp; ciberlinguistics|TEXT MESSAGE ABBREVIATIONS; COLLEGE-STUDENTS; COMMUNICATION|Linguistics; Language \& Linguistics|8|2|18
Exploring multiple profiles of L2 writing using multi-dimensional analysis|2014|In this paper, we explore the application of corpus-based multi-dimensional analysis (MDA) pioneered by Biber (1988, 1995, 2006) in understanding microscopic linguistic variation in an L2 writing corpus. The primary goals of our study are: (1) to identify the functional dimensions of L2 academic essays from the corpus collected for this special issue of the Journal of Second Language Writing, and (2) to analyze linguistic variation in the corpus across parameters of time and average assessment scores (in language, vocabulary, and total average score). The corpus was tagged for part-of-speech and additional semantic categories (e.g., semantic categories. of verbs and nouns) using the Biber tagger (Biber, 2006). Rates of occurrence were computed for over 80 linguistic features across 209 essays based on tag counts for each text. The values of these variables were then subjected to an exploratory factor analysis. A total of four functional dimensions were identified and interpreted. These are: (1) Involved vs. Informational Focus, (2) Addressee-Focused Description vs. Personal Narrative, (3) Simplified vs. Elaborated Description, and (4) Personal Opinion vs. Impersonal Evaluation/Assessment. Overall, our study shows a successful application of MDA on a micro-level producing a range of functional profiles along different parameters in L2 writing. Published by Elsevier Inc.|Multi-dimensional analysis; L2 academic essays; Writing profiles|COMPLEXITY; FEATURES; QUALITY|Linguistics|8|3|18
Commenting on You Tube rants: Perceptions of inappropriateness or civic engagement?|2014|Ranting is often conflated with flaming and hating, which are frequently interpreted as inappropriate forms of online interaction. Scholars have categorized rants, which contain emotional criticisms of something or someone, as ``anti-social{''} (Vrooman, 2002). However, scholars are moving away from universal interpretations of inappropriateness, and now engage in contextual analyses of online behavior. The present study examines a random sample of 330 text comments (drawn from a pool of 13,609 comments) that were posted across 35 rant videos on YouTube. Ranters describe numerous technical and social problems with the video-sharing site. But how are rant videos received on YouTube? Do commenters characterize them as inappropriate? Do rants stimulate productive discussion or do most commenters prefer to express emotional support for the ranter? Rather than displaying personal offense, numerous commenters discussed how problems with YouTube were being publicly revealed in video rants. Such issues are particularly relevant, as expectations about communicative norms are being proposed and contested in new media sites (Markham, 2011). This study argues that under the right circumstances, ranting helps construct an emotional public sphere (Lunt and Stenner, 2005) that generates discussion among similarly concerned YouTube participants about their online communicative rights and privileges. (C) 2014 Elsevier B.V. All rights reserved.|Rants; Computer-mediated communication; YouTube; Civic engagement; Social media; Impoliteness|IMPOLITENESS; YOUTUBE; (IM)POLITENESS; DISAGREEMENT; DISCOURSE; INTERNET; TALKING; GENRE; SHOW; AGE|Linguistics; Language \& Linguistics|5|2|18
Metadiscourse in results and discussion chapters: A cross-linguistic analysis of English and Spanish thesis writers in engineering|2014|This study investigates cross-linguistic variation of metadiscourse in the results and discussion chapters of engineering master's theses written in English and Spanish. The analysis is based on a corpus of 200 master's thesis results and discussion chapters: 100 written by L1 English students and 100 written by L1 Spanish students. Using Hyland's (2005a) interpersonal model of metadiscourse, the results and discussion chapters were compared to examine the influence of lingua-cultural contexts of writing on student writer's employment of metadiscoursal resources. Findings of the comparative analysis reveal significant cross-linguistic differences for overall frequency of metadiscourse as well as for most (sub-)categories. The analysis suggests that interpersonal features of writing are inexorably linked to the specific lingua-cultural contexts in which texts are produced and consumed, even within the same discipline and (part-)genre. The paper concludes with some pedagogical implications for L2 writing instruction. (C) 2014 Elsevier Ltd. All rights reserved.|Academic writing; Cross-linguistic analysis; Engineering writing; Masters thesis; Metadiscourse|RESEARCH ARTICLES; ACADEMIC DISCOURSE|Education \& Educational Research; Linguistics|4|0|18
A Latent Semantic Indexing-based approach to multilingual document clustering|2008|The creation and deployment of knowledge repositories for managing, sharing, and reusing tacit knowledge within an organization has emerged as a prevalent approach in current knowledge management practices. A knowledge repository typically contains vast amounts of formal knowledge elements, which generally are available as documents. To facilitate users' navigation of documents within a knowledge repository, knowledge maps, often created by document clustering techniques, represent an appealing and promising approach. Various document clustering techniques have been proposed in the literature, but most deal with monolingual documents (i.e., written in the same language). However, as a result of increased globalization and advances in Internet technology, an organization often maintains documents in different languages in its knowledge repositories, which necessitates multilingual document clustering (MLDC) to create organizational knowledge maps. Motivated by the significance of this demand, this study designs a Latent Semantic Indexing (LSI)-based MLDC technique capable of generating knowledge maps (i.e., document clusters) from multilingual documents. The empirical evaluation results show that the proposed LSI-based MLDC technique achieves satisfactory clustering effectiveness, measured by both cluster recall and cluster precision, and is capable of maintaining a good balance between monolingual and cross-lingual clustering effectiveness when clustering a multilingual document corpus. (c) 2007 Elsevier B.V. All rights reserved.|document management; text mining; document clustering; multilingual document clustering; multilingual knowledge management; Latent Semantic Indexing|KNOWLEDGE MANAGEMENT; RETRIEVAL; WEB|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|34|3|18
Meaning-Making, Multimodal Representation, and Transformative Pedagogy: An Exploration of Meaning Construction Instructional Practices in an ESL High School Classroom|2008|This study was an exploration of how high school language learners and their teacher jointly constructed word meanings through multimodal representation and the sociopolitical reality of learners' lives as mediating factors in the context of simultaneous multiple learning activities. Thirty-three high school Advanced ESL 3 students were taught using a political text, photographs, and a campaign video clip. Using a variety of learning activities-meaning guessing, campaign advertisement, and cartoon strips; group and whole-class activities-learners negotiated meanings of selected vocabulary items and phrases in the text. A close analysis of the students' scripts revealed that they used multimodal resources as a tool to convey their identity/subjectivity in meaning-making engagements. I recommend a meaning-making theoretical framework and classroom practices that link English language learners with the sociocontextual frame of learning, critique and challenge social power relations between migrant English learners and the broader society, and emphasize transformation as the goal of pedagogical processes in the classroom.|ESL teacher; meaning-making theory; word meaning; participatory pedagogy; transformative pedagogy; visual literacy|LANGUAGE; PERSPECTIVE|Education \& Educational Research; Linguistics; Language \& Linguistics|13|2|18
Gendered representations through speech: The case of the Harry Potter series|2017|This study considers the text of the Harry Potter novels to understand the way in which gender is represented. The analysis centers on the two sidekick characters, Hermione Granger and Ron Weasley, cataloging the way in which their direct speech is reported throughout the series. From a wide-lens perspective, verbs used for each of these characters are largely the same. However, a more fine-grained analysis reveals patterns of asymmetry that also reflect broader cultural ideologies about gender, reproducing stereotypical views about essential' differences between females and males for the millions of readers that comprise the audience of these fictional works.|Corpus studies; reported speech; gender asymmetry in language|COMMUNITY; LANGUAGE|Linguistics; Language \& Linguistics|0|17|17
An approach for modelling and forecasting research activity related to an emerging technology|2017|The understanding of emerging technologies and the analysis of their development pose a great challenge for decision makers, as being able to assess and forecast technological change enables them to make the most of it. There is a whole field of research focused on this area, called technology forecasting, in which bibliometrics plays an important role. Within that framework, this paper presents a forecasting approach focused on a specific field of technology forecasting: research activity related to an emerging technology. This approach is based on four research fields-bibliometrics, text mining, time series modelling and time series forecasting-and is structured in five interlinked steps that generate a continuous flow of information. The main milestone is the generation of time series that measure the level of research activity and can be used for forecasting. The usefulness of this approach is shown by applying it to an emerging technology: cloud computing. The results enable the technology to be structured into five main sub-technologies which are characterised through five time series. Time series analysis of the trends related to each sub-technology shows that Privacy and Security has been the most active sub-technology to date in this area and is expected to maintain its level of interest in the near future.|Technology forecasting; Research-activity forecasting; Bibliometrics; Text mining; Trend analysis; Structural time series models|TIME-SERIES; DEMAND; ENERGY|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|10|17
Detecting Influencers in Multiple Online Genres|2017|Social media has become very popular and mainstream, leading to an abundance of content. This wealth of content contains many interactions and conversations that can be analyzed for a variety of information. One such type of information is analyzing the roles people take in a conversation. Detecting influencers, one such role, can be useful for political campaigning, successful advertisement strategies, and detecting terrorist leaders. We explore influence in discussion forums, weblogs, and micro-blogs through the development of learned language analysis components to recognize known indicators of influence. Our components are author traits, agreement, claims, argumentation, persuasion, credibility, and certain dialog patterns. Each of these components is motivated by social science through Robert Cialdini's ``Weapons of Influence{''} {[}Cialdini 2007]. We classify influencers across five online genres and analyze which features are most indicative of influencers in each genre. First, we describe a rich suite of features that were generated using each of the system components. Then, we describe our experiments and results, including using domain adaptation to exploit the data from multiple online genres.|Influence; natural language processing; social media; psychology; computational social science|NETWORKS|Computer Science, Information Systems; Computer Science, Software Engineering|0|13|17
Automatic extraction and visualization of semantic relations between medical entities from medicine instructions|2017|Recent years have witnessed the rapid development and tremendous research interests in healthcare domain. The health and medical knowledge can be acquired from many sources, such as professional health providers, health community generated data and textual descriptions of medicines. This paper explores the classification and extraction of semantic relation between medical entities from the unstructured medicine Chinese instructions. In this paper, three kinds of textual features are extracted from medicine instruction according to the nature of natural language texts. And then, a support vector machine based classification model is proposed to categorize the semantic relations between medical entities into the corresponding semantic relation types. Finally, the extraction algorithm is utilized to obtain the semantic relation triples. This paper also visualizes the semantic relations between medical entities with relationship graph for their future processing. The experimental results show that the approach proposed in this paper is effective and efficient in the classification and extraction of semantic relations between medical entities.|Semantic relation; Medical entity; Classification model; Extraction algorithm; Semantic relation triple; Semantic relationship graph|RECOGNITION; KNOWLEDGE|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|1|10|17
Striking similarities between publications from China describing single gene knockdown experiments in human cancer cell lines|2017|Comparing 5 publications from China that described knockdowns of the human TPD52L2 gene in human cancer cell lines identified unexpected similarities between these publications, flaws in experimental design, and mis-matches between some described experiments and the reported results. Following communications with journal editors, two of these TPD52L2 publications have been retracted. One retraction notice stated that while the authors claimed that the data were original, the experiments had been out-sourced to a biotechnology company. Using search engine queries, automatic text-analysis, different similarity measures, and further visual inspection, we identified 48 examples of highly similar papers describing single gene knockdowns in 1-2 human cancer cell lines that were all published by investigators from China. The incorrect use of a particular TPD52L2 shRNA sequence as a negative or non-targeting control was identified in 30/48 (63\%) of these publications, using a combination of Google Scholar searches and visual inspection. Overall, these results suggest that some publications describing the effects of single gene knockdowns in human cancer cell lines may include the results of experiments that were not performed by the authors. This has serious implications for the validity of such results, and for their application in future research.|Gene knockdown; Cancer; Cell lines; Publications; Intertextual distance; China|AUTHORSHIP ATTRIBUTION; RESEARCH MISCONDUCT; FAKE PAPERS; PROLIFERATION; SCIENTISTS; QUALITY; SCIENCE; TPD52; FRAUD; COMPETITION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|3|6|17
Highlighting Relationships of a Smartphone's Social Ecosystem in Potentially Large Investigations|2016|Social media networks are becoming increasingly popular because they can satisfy diverse needs of individuals (both personal and professional). Modern mobile devices are empowered with increased capabilities, taking advantage of the technological progress that makes them smarter than their predecessors. Thus, a smartphone user is not only the phone owner, but also an entity that may have different facets and roles in various social media networks. We believe that these roles can be aggregated in a single social ecosystem, which can be derived by the smartphone. In this paper, we present our concept of the social ecosystem in contemporary devices and we attempt to distinguish the different communities that occur from the integration of social networking in our lives. In addition, we propose techniques to highlight major actors within the ecosystem. Moreover, we demonstrate our suggested visualization scheme, which illustrates the linking of entities that live in separate communities using data taken from the smartphone. Finally, we extend our concept to include various parallel ecosystems during potentially large investigations and we link influential entities in a vertical fashion. We particularly examine cases where data aggregation is performed by specific applications, producing volumes of textual data that can be analyzed with text mining methods. Our analysis demonstrates the risks of the rising ``bring your own device{''} trend in enterprise environments.|Bring your own device (BYOD); digital forensics; enterprise mobility management; entity linking; network analysis; sentiment analysis|NETWORKS; INTELLIGENCE; MANAGEMENT; FORENSICS; DEVICES; SYSTEM; MEDIA|Automation \& Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics|1|2|17
A longitudinal linguistic analysis of written text production in a case of semantic variant primary progressive aphasia|2016|The semantic variant of primary progressive aphasia (svPPA) presents with a degradation of semantic knowledge due to atrophy of the anterior temporal lobe and is characterized by impaired confrontation naming and impaired single-word comprehension. So far, little is known about the development of symptoms and their order of occurrence in the pre-clinical phase, and information regarding written text production is scarce. We had the unique opportunity to analyze the diary of a man written over a time span of 12 years before he was diagnosed with svPPA. We sought to identify the earliest indicators of cognitive change in his diary entries, and to track the important changes over time. Based on transcripts of the entries (one week every six months) we assessed the overall structure, vocabulary, surface dysgraphia and semantic paraphasia, syntax, and morphology. We found changes in all domains up to seven years before the clinical diagnosis. The earliest changes concerned the vocabulary, with decreased variety and increased use of high frequency words. This was followed by syntactic and morphological errors. We found no increase of surface dysgraphia. Semantic paraphasias increased only during the last three years but characterized the entries of the last year. We were therefore able to further corroborate recent findings regarding difficulties in the morpho-syntactic domain in this patient group. In this natural context for written text production, such errors seem, in addition to changes in vocabulary, to be the first error types to appear, possibly as a result of compensating for the degradation of semantic representations. (C) 2015 Elsevier Ltd. All rights reserved.|Semantic dementia; Semantic variant of primary progressive aphasia; Written text production; Semantics; Syntax; Morphology|EARLY ALZHEIMERS-DISEASE; INFLECTIONAL MORPHOLOGY; FRONTOTEMPORAL DEMENTIA; SPEECH PRODUCTION; LANGUAGE; CLASSIFICATION; DEGENERATION; IMPAIRMENT; MEMORY|Linguistics; Neurosciences; Psychology, Experimental|2|1|17
A Survey and Comparative Study of Tweet Sentiment Analysis via Semi-Supervised Learning|2016|Twitter is a microblogging platform in which users can post status messages, called ``tweets,{''} to their friends. It has provided an enormous dataset of the so-called sentiments, whose classification can take place through supervised learning. To build supervised learning models, classification algorithms require a set of representative labeled data. However, labeled data are usually difficult and expensive to obtain, which motivates the interest in semi-supervised learning. This type of learning uses unlabeled data to complement the information provided by the labeled data in the training process; therefore, it is particularly useful in applications including tweet sentiment analysis, where a huge quantity of unlabeled data is accessible. Semi-supervised learning for tweet sentiment analysis, although appealing, is relatively new. We provide a comprehensive survey of semi-supervised approaches applied to tweet classification. Such approaches consist of graph-based, wrapper-based, and topic-based methods. A comparative study of algorithms based on self-training, co-training, topic modeling, and distant supervision highlights their biases and sheds light on aspects that the practitioner should consider in real-world applications.|Co-training; self-training; semi-supervised learning; topic modeling; tweet sentiment analysis|TWITTER; CLASSIFIER; ENSEMBLES; TEXT|Computer Science, Theory \& Methods|1|5|17
Cardiac catheterization laboratory inpatient forecast tool: a prospective evaluation|2016|Objective To develop and prospectively evaluate a web-based tool that forecasts the daily bed need for admissions from the cardiac catheterization laboratory using routinely available clinical data within electronic medical records (EMRs). Methods The forecast model was derived using a 13-month retrospective cohort of 6384 catheterization patients. Predictor variables such as demographics, scheduled procedures, and clinical indicators mined from free-text notes were input to a multivariable logistic regression model that predicted the probability of inpatient admission. The model was embedded into a web-based application connected to the local EMR system and used to support bed management decisions. After implementation, the tool was prospectively evaluated for accuracy on a 13-month test cohort of 7029 catheterization patients. Results The forecast model predicted admission with an area under the receiver operating characteristic curve of 0.722. Daily aggregate forecasts were accurate to within one bed for 70.3\% of days and within three beds for 97.5\% of days during the prospective evaluation period. The web-based application housing the forecast model was used by cardiology providers in practice to estimate daily admissions from the catheterization laboratory. Discussion The forecast model identified older age, male gender, invasive procedures, coronary artery bypass grafts, and a history of congestive heart failure as qualities indicating a patient was at increased risk for admission. Diagnostic procedures and less acute clinical indicators decreased patients' risk of admission. Despite the site-specific limitations of the model, these findings were supported by the literature. Conclusion Data-driven predictive analytics may be used to accurately forecast daily demand for inpatient beds for cardiac catheterization patients. Connecting these analytics to EMR data sources has the potential to provide advanced operational decision support.|cardiac catheterization; hospital; forecasting; patient admission; cardiac care unit|EXPERT CONSENSUS DOCUMENT; PERCUTANEOUS CORONARY INTERVENTION; AMERICAN-HEART-ASSOCIATION; HEALTH-CARE VALUE; EMERGENCY-DEPARTMENT; AMBULATORY SURGERY; CARDIOVASCULAR ANGIOGRAPHY; VARIABILITY METHODOLOGY; UNANTICIPATED ADMISSION; HOSPITAL ADMISSION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|0|17
A Sciento-text framework to characterize research strength of institutions at fine-grained thematic area level|2016|This paper presents a Sciento-text framework to characterize and assess research performance of leading world institutions in fine-grained thematic areas. While most of the popular university research rankings rank universities either on their overall research performance or on a particular subject, we have tried to devise a system to identify strong research centres at a more fine-grained level of research themes of a subject. Computer science (CS) research output of more than 400 universities in the world is taken as the case in point to demonstrate the working of the framework. The Sciento-text framework comprises of standard scientometric and text analytics components. First of all every research paper in the data is classified into different thematic areas in a systematic manner and then standard scientometric methodology is used to identify and assess research strengths of different institutions in a particular research theme (say Artificial Intelligence for CS domain). The performance of framework components is evaluated and the complete system is deployed on the Web at url: www. universityselectplus. com. The framework is extendable to other subject domains with little modification.|Computer science research; Research competitiveness; Field-based ranking; Scientometrics; UniversitySelectPlus|RESEARCH OUTPUT; INTERNATIONAL COLLABORATION; BIBLIOMETRIC INDICATORS; IMPACT; PERCENTILES; PERFORMANCE; CITATIONS; RANKING; FIELDS; INDEX|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|2|4|17
Input modality and working memory: Effects on second language text comprehension in a multimedia learning environment|2015|This study investigated the modality effect in relation to verbal working memory capacity and time of testing within a computerized second language multimedia learning environment. Twenty-nine advanced learners of English with Turkish as the first language were randomly assigned to audiovisual or visual-only presentations about an unfamiliar topic and completed immediate and delayed tests to assess retention and transfer of information performance. They also completed a reading span test as a measure of working memory capacity. Results revealed a significant combined effect of time, input modality and working memory capacity on participants' retention performance while the only significant effect observed on transfer performance was that of time. Analyses on the significant three-way interaction revealed that although input modality and working memory capacity play some role in retention performance, their effects emerged dependent upon one other and time of testing. (C) 2015 Elsevier Ltd. All rights reserved.|L2 multimedia learning; Working memory; Visual-only presentation; Audiovisual presentation; Input modality|COGNITIVE LOAD THEORY; DUAL-TASK METHODOLOGY; READING SPAN TESTS; INSTRUCTIONAL-DESIGN; INFERENTIAL COMPREHENSION; INDIVIDUAL-DIFFERENCES; DOMAIN KNOWLEDGE; SPLIT-ATTENTION; LANGUAGE; CAPACITY|Education \& Educational Research; Linguistics|5|7|17
Trend analysis of academic research and technical development pertaining to gas hydrates|2015|Recently, many countries have shown considerable interest in gas hydrates as an alternative energy source and have conducted many studies for exploring, drilling, and producing gas hydrates. In this paper, we investigate international R\&D trend in gas hydrates in order to provide research direction by applying text clustering to the published papers and patent documents. In particular, our study examines research in the United States, where the most active research has been undertaken; Japan, a country that leads in technological development; and China, which has enormous resources of gas hydrates. This study delineates these countries' expertise and changing R\&D trends in gas hydrates. Our findings can provide insights for academic research and technical development regarding gas hydrates.|Gas hydrates; Trend analysis; Academic research; Technical development; Text clustering|SEDIMENT; CHINA; SLOPE; MODEL|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|2|1|17
Research Article Abstracts in Applied Linguistics and Economics: Functional Analysis of the Grammatical Subject|2015|The aims of this paper are to analyse and compare the discourse functions of grammatical subjects used in research article abstracts in the disciplines of Applied Linguistics and Economics. The data for this study consisted of 60 research article abstracts published in 2010 and 2011 in the journals of Applied Linguistics and Oxford Economic Papers. The corpus was analysed using the classification of discourse functions of grammatical subjects established by Gosden. The analysis revealed disciplinary differences concerning the discourse functions enacted by the application of the grammatical subject. These findings add to the claim that academic writing (research article abstract writing in this study) is shaped by the writer's disciplinary background with particular reference to the use of the grammatical subject as a theme in text development.|Grammatical Subject; Discourse Function; Disciplinary Difference; Research Article Abstract; Text Development|RHETORICAL STRUCTURE; METADISCOURSE; DISCIPLINARY; ENGLISH; PRAGMATICS; DISCOURSE; READER; GENRE|Linguistics; Language \& Linguistics|4|3|17
Does the redundancy effect exist in electronic slideshow assisted lecturing?|2015|This study investigated the occurrence of the redundancy effect in a normal classroom when presenting multiple formats of information with the assistance of electronic slideshows. A virtual classroom that simulates a normal classroom was developed as the experimental platform in this study. One hundred and twenty undergraduates and graduated students were randomly assigned to the following three experimental conditions with varying presentation formats: audio only condition, visual only condition, and audiovisual condition. Test accuracy scores and cognitive load self-rating scales on both the recall and the comprehension tests were used to measure differences between various conditions. Analyses revealed a reverse audiovisual redundancy effect. For the recall test, the presentation of on-screen textual information accompanied by spoken narrations outperformed the presentation with the audio only source on test accuracy scores and indicated lower self-ratings of cognitive load. For the comprehension test, the presentation of on-screen textual information accompanied by spoken narrations outperformed the presentations with either of these two sources with higher test accuracy scores and lower cognitive load self-ratings. Classroom interference and segmented presentation were hypothesized to be two possible factors in determining the presence or absence of the redundancy effect. (C) 2015 Elsevier Ltd. All rights reserved.|Media in education; Improving classroom teaching; Pedagogical issues|COGNITIVE LOAD THEORY; VIRTUAL CLASSROOM; ENVIRONMENT; ATTENTION; INSTRUCTION; PERFORMANCE; KNOWLEDGE; DESIGN; FORMAT; TEXT|Computer Science, Interdisciplinary Applications; Education \& Educational Research|3|0|17
The effects of strategy-based writing instruction in Singapore primary schools|2015|This study reports on a longitudinal intervention study of writing strategies in Singapore primary schools. The purpose of the study was to assess the impact of writing strategy instruction on Singapore primary school students' writing competence. Nine writing strategy-based lessons were taught to 442 primary five students. Both quantitative and qualitative analyses were performed to complement the possible inadequacy of either analytical method and for the purpose of data triangulation. The findings show that the intervention achieved a significant treatment effect on both the participants' writing competence and their strategy use, namely, text-generating, feedback handling, and revising. The qualitative analyses also suggest the experimental students orchestrated their strategy use better than before. (C) 2015 Elsevier Ltd. All rights reserved.|Second language writing; Strategy-based instruction; Young learners; Mixed-methods; Treatment effects|STUDENTS; ENGLISH; ESL; QUALITY; PROGRAM|Education \& Educational Research; Linguistics|1|0|17
The use of models as a written feedback technique with young EFL learners|2015|The difficulties involved in learning to write in a second language (L2) are well known and there has been much debate on the usefulness of written feedback in improving 12 learners' writing. The purpose of this study was to explore the role of model texts as a written corrective feedback technique through the analysis of what Grade 5 EFL child learners (aged 10-11) noticed as they (i) wrote a composition in pairs in response to a picture-based story, (ii) compared their texts to a model of the story, and (iii) rewrote their original texts. In order to isolate the effect of the feedback technique, the participants were divided into an experimental group (who completed all three tasks) and a control group (who only completed the tasks at stages 1 and 3). The results indicate that while models were useful for attracting children's attention to lexis and chunks of language rather than to grammar, task repetition may also have been responsible for improved performance in the revised written output in both groups. Proficiency levels were found to influence noticing and uptake from the feedback. This paper concludes with pedagogical implications for the use of model texts as a feedback technique with young language learners. (C) 2015 Elsevier Ltd. All rights reserved.|Noticing; L2 writing; Written corrective feedback; Models; Young learners|CORRECTIVE FEEDBACK; 2ND LANGUAGE; HONG-KONG; CLASSROOMS; ATTENTION; OUTPUT; 2ND-LANGUAGE; TASK; FORM|Education \& Educational Research; Linguistics|2|4|17
Automatic Identification and Classification of Noun Argument Structures in Biomedical Literature|2012|The accelerating increase in the biomedical literature makes keeping up with recent advances challenging for researchers thus making automatic extraction and discovery of knowledge from this vast literature a necessity. Building such systems requires automatic detection of lexico-semantic event structures governed by the syntactic and semantic constraints of human languages in sentences of biomedical texts. The lexico-semantic event structures in sentences are centered around the predicates and most semantic role labeling (SRL) approaches focus only on the arguments of verb predicates and neglect argument taking nouns which also convey information in a sentence. In this article, a noun argument structure (NAS) annotated corpus named BioNom and a SRL system to identify and classify these structures is introduced. Also, a genetic algorithm-based feature selection (GAFS) method is introduced and global inference is applied to significantly improve the performance of the NAS Bio SRL system.|Natural language processing; semantic role labeling; nominalizations; genetic algorithms; biomedical text mining|SUPPORT VECTOR MACHINES; FEATURE-SELECTION; ANNOTATED CORPUS; SEMANTIC ROLES|Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics \& Probability|1|0|17
Enhancing clinical concept extraction with distributional semantics|2012|Extracting concepts (such as drugs, symptoms, and diagnoses) from clinical narratives constitutes a basic enabling technology to unlock the knowledge within and support more advanced reasoning applications such as diagnosis explanation, disease progression modeling, and intelligent analysis of the effectiveness of treatment. The recent release of annotated training sets of de-identified clinical narratives has contributed to the development and refinement of concept extraction methods. However, as the annotation process is labor-intensive, training data are necessarily limited in the concepts and concept patterns covered, which impacts the performance of supervised machine learning applications trained with these data. This paper proposes an approach to minimize this limitation by combining supervised machine learning with empirical learning of semantic relatedness from the distribution of the relevant words in additional unannotated text. The approach uses a sequential discriminative classifier (Conditional Random Fields) to extract the mentions of medical problems, treatments and tests from clinical narratives. It takes advantage of all Medline abstracts indexed as being of the publication type ``clinical trials{''} to estimate the relatedness between words in the i2b2/VA training and testing corpora. In addition to the traditional features such as dictionary matching, pattern matching and part-of-speech tags, we also used as a feature words that appear in similar contexts to the word in question (that is, words that have a similar vector representation measured with the commonly used cosine metric, where vector representations are derived using methods of distributional semantics). To the best of our knowledge, this is the first effort exploring the use of distributional semantics, the semantics derived empirically from unannotated text often using vector space models, for a sequence classification task such as concept extraction. Therefore, we first experimented with different sliding window models and found the model with parameters that led to best performance in a preliminary sequence labeling task. The evaluation of this approach, performed against the i2b2/VA concept extraction corpus, showed that incorporating features based on the distribution of words across a large unannotated corpus significantly aids concept extraction. Compared to a supervised-only approach as a baseline, the micro-averaged F-score for exact match increased from 80.3\% to 82.3\% and the micro-averaged F-score based on inexact match increased from 89.7\% to 91.3\%. These improvements are highly significant according to the boot-strap resampling method and also considering the performance of other systems. Thus, distributional semantic features significantly improve the performance of concept extraction from clinical narratives by taking advantage of word distribution information obtained from unannotated data. (C) 2011 Elsevier Inc. All rights reserved.|NLP; Information extraction; NER; Distributional semantics; Clinical informatics|SPACE MODELS; FREE-TEXT; INFORMATION; DOCUMENTS|Computer Science, Interdisciplinary Applications; Medical Informatics|31|3|17
Dynamic grammar in adults: Incidental learning of natural syntactic structures extends over 48 h|2012|Three experiments examine whether a naturalistic reading task can induce long-lasting changes of syntactic patterns in memory. judgment of grammatical acceptability is used as an indirect test of memory for sentences that are identical or only syntactically similar to those read earlier. In previous research (Luka \& Barsalou, 2005) both sorts of sentences were found more acceptable, yielding a structural preference for recently encountered syntactic patterns. The effect is evident across a very diverse set of some 60 distinct sentence constructions. This phenomenon may be similar to implicit learning paradigms using evaluative ratings as dependent measures, but also resembles a variety of shorter-lived structural priming effects observed for a handful of syntactic constructions that occur in binary alternate forms. Here we examine the duration of the structural preference effect to determine whether it is fleeting (suggesting transient priming) or long-lasting (suggesting enduring changes in representation). Experiments 1 and 2 show that the effect is evident after a 48-h delay between initial exposure (simple reading aloud) and test. Experiment 3 shows a persistent effect after 7 days, despite unrestricted exposure to natural language in the interim. Larger effects were observed for comparatively novel sentence constructions than common syntactic patterns. Experiments 2 and 3 also examine the role of the evaluation process itself, and find that reading for comprehension produces greater facilitation than reading while performing an evaluative categorization (grammaticality rating). These observations suggest that incremental adjustments to the language processing system occur on a continuous basis and may extend to acquisition of novel syntactic structures. We discuss whether and in what ways the structural preference effect can be integrated with the literature on structural priming. We interpret our results in the context of models of language comprehension, emphasize the dynamic nature of grammatical knowledge in memory, and argue that the current paradigm offers several advantages for elaborating the various systems of memory upon which linguistic representations depend. (C) 2011 Elsevier Inc. All rights reserved.|Structural facilitation; Structural priming; Acceptability judgment; Grammaticality judgment; Evaluative categorization; Sentence processing|LANGUAGE-ACQUISITION; CRITICAL PERIOD; MERE EXPOSURE; GRAMMATICALITY JUDGMENTS; BEHAVIORAL EVIDENCE; CONSTRUCTION NEEDS; IMPLICIT MEMORY; LIFE-SPAN; COMPREHENSION; PERSISTENCE|Linguistics; Psychology; Psychology, Experimental|9|0|17
`It actually painted a picture of the village and the sea and the bottom of the sea': Reading groups, cultural legitimacy, and description in narrative (with particular reference to John Steinbeck's The Pearl)|2011|This article proposes a form of research that integrates reader study with textual analysis. Its purpose is to investigate the social production of literary value, potentially providing cultural sociology with a systematic means by which to study the formal features of texts in relation to their social significance: a means arguably required by (but not necessarily supplied in) the work of Pierre Bourdieu. Quantitative and qualitative analysis of reading group (or `book club') discussions reveals an association between descriptive writing, cultural legitimacy, and a focus on the form, rather than the content, of fictional texts. In order to understand this association, the analysis then turns to two paragraphs from John Steinbeck's The Pearl (2000 {[}1946]), which had been read by most of the groups involved and which many group members had referred to as involving `description'. It is argued that a long-standing tradition of association between descriptive writing and visual art has served as a resource both for consumers and for producers in distinguishing literature from popular fiction.|book clubs; description; emic categories; legitimate culture; narratology; The Pearl; reading groups; reception; sociology of literature; Steinbeck|CONSUMPTION; INTENTIONS; FICTION|Linguistics; Language \& Linguistics|13|5|17
Summarization of clinical information: A conceptual model|2011|Background: To provide high-quality and safe care, clinicians must be able to optimally collect, distill, and interpret patient information. Despite advances in text summarization, only limited research exists on clinical summarization, the complex and heterogeneous process of gathering, organizing and presenting patient data in various forms. Objective: To develop a conceptual model for describing and understanding clinical summarization in both computer-independent and computer-supported clinical tasks. Design: Based on extensive literature review and clinical input, we developed a conceptual model of clinical summarization to lay the foundation for future research on clinician workflow and automated summarization using electronic health records (EHRs). Results: Our model identifies five distinct stages of clinical summarization: (1) Aggregation, (2) Organization, (3) Reduction and/or Transformation, (4) Interpretation and (5) Synthesis (AORTIS). The AORTIS model describes the creation of complex, task-specific clinical summaries and provides a framework for clinical workflow analysis and directed research on test results review, clinical documentation and medical decision-making. We describe a hypothetical case study to illustrate the application of this model in the primary care setting. Conclusion: Both practicing physicians and clinical informaticians need a structured method of developing, studying and evaluating clinical summaries in support of a wide range of clinical tasks. Our proposed model of clinical summarization provides a potential pathway to advance knowledge in this area and highlights directions for further research. (C) 2011 Elsevier Inc. All rights reserved.|Clinical summarization; Concept-oriented views; Problem-oriented medical record|DISCHARGE SUMMARIES; PRESENTATION SKILLS; HEALTH-CARE; ORDER ENTRY; UNINTENDED CONSEQUENCES; LITERATURE ABSTRACTS; MEDICAL-RECORDS; PATIENT DATA; SIGN-OUT; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|34|1|17
An investigation of data and text mining methods for real world deception detection|2011|Uncovering lies (or deception) is of critical importance to many including law enforcement and security personnel. Though these people may try to use many different tactics to discover deception, previous research tells us that this cannot be accomplished successfully without aid. This manuscript reports on the promising results of a research study where data and text mining methods along with a sample of real-world data from a high-stakes situation is used to detect deception. At the end, the information fusion based classification models produced better than 74\% classification accuracy on the holdout sample using a 10-fold cross validation methodology. Nonetheless, artificial neural networks and decision trees produced accuracy rates of 73.46\% and 71.60\% respectively. However, due to the high stakes associated with these types of decisions, the extra effort of combining the models to achieve higher accuracy is well warranted. (C) 2011 Elsevier Ltd. All rights reserved.|Deception detection; Data mining; Text mining; Information fusion; Classification; Credibility assessment|COMPUTER-MEDIATED COMMUNICATION; CLASSIFICATION; CUES|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|21|2|17
Writing from news sources: The case of Apple TV|2011|This paper is a case study of reproductive newswriting, i.e. writing from news sources. We offer a multimethodological writing process analysis of a news article announcing the product launch of Apple TV on the Belgian market. By combining interview data, keystroke logging data, frame and corpus analysis, we reconstruct the discursive strategies a senior business reporter, the third author of this paper, employs as he writes a news article from a corporate press release. Our process data highlight how reliance on ready-made source texts prompt news frames which enable reporters to write fast and efficiently while also forcing them to introduce new frames which balance the story, establish authority and maximize news value. Taken together, these analytical dimensions lay bare both the interpretive creativity and professional routines of reproductive newswriting. (C) 2010 Elsevier B.V. All rights reserved.|News production; Reproductive writing; Writing process analysis; Recontextualization; Framing; Business news|JOURNALISM; DISCOURSE; ENGLISH|Linguistics; Language \& Linguistics|16|0|17
A narrative-based reasoning with applications in decision support for social service organizations|2011|Nowadays, there is an increasing demand for incorporating unstructured narratives in decision support for knowledge-intensive industries such as healthcare and social service organizations. However, most of the current research on decision support systems (DSS) mainly focused on dealing with structured data and are inadequate to dealing with unstructured narratives such as clients' records and stories. This paper presents a narrative-based reasoning (NBR) algorithm which incorporates the technologies of knowledge-based system (KBS), computational linguistics, and artificial intelligence (AI) for automatic processing unstructured narratives and inferring useful knowledge for decision support. A NBR enabled DSS has been built and was evaluated through a series of experiments conducted in early intervention of mental health of a social service company in Hong Kong. The performance of NBR was measured based on recall and precision and encouraging results were obtained. High recall and precision are achieved in the reasoning of unstructured data, and high recall is achieved for the association analysis. The results show that it is possible for inferring recommendations for problem solving from unstructured narratives automatically. Based on the approach, it helps to support knowledge workers with reliable suggestions on decision making so as to increase the quality of their solutions. (C) 2010 Elsevier Ltd. All rights reserved.|Concept association; Knowledge-based systems; Narrative-based reasoning; Natural language processing; Decision support system; Health care; Social service organizations|KNOWLEDGE-BASED-SYSTEM; MEDICAL DIAGNOSIS; RISK-ASSESSMENT; EXPERT-SYSTEM; DESIGN; CARE; TOOL; PERSPECTIVE|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|4|0|17
Complementing human judgment of essays written by English language learners with e-rater (R) scoring|2010|E-rater (R) is an automated essay scoring system that uses natural language processing techniques to extract features from essays and to model statistically human holistic ratings. Educational Testing Service has investigated the use of e-rater, in conjunction with human ratings, to score one of the two writing tasks on the TOEFL-iBT (R) writing section. In this article we describe the TOEFL iBT writing section and an e-rater model proposed to provide one of two ratings for the Independent writing task. We discuss how the evidence for a process that uses both human and e-rater scoring is relevant to four components in a validity argument: (a) Evaluation - observations of performance on the writing task are scored to provide evidence of targeted writing skills; (b) Generalization - scores on the writing task provide estimates of expected scores over relevant parallel versions of the task and across raters; (c) Extrapolation - expected scores on the writing task are consistent with other measures of writing ability; and (d) Utilization - scores on the writing task are useful in educational contexts. Finally, we propose directions for future research that will strengthen the case for using complementary methods of scoring to improve the assessment of EFL writing.|automated essay scoring; e-rater; educational measurement; ESL/EFL writing assessment; TOEFL writing; validity of writing assessment|FLUENCY; QUALITY|Linguistics; Language \& Linguistics|20|4|17
Coding coherence relations: Reliability and validity|2010|This paper tackles the issue of the validity and reliability of coding discourse phenomena in corpus-based analyses. On the basis of a sample analysis of coherence relation annotation that resulted in a poor kappa score, we describe the problem and put it into the context of recent literature from the field of computational linguistics on required intercoder agreement. We describe our view on the consequences of the current state of the art and suggest three routes to follow in the coding of coherence relations: double coding (including discussion of disagreements and explicitation of the coding decisions), single coding (including the risk of coder bias, and a lack of generalizability), and enriched kappa statistics (including observed and specific agreement, and a discussion of the (possible reasons for) disagreement). We end with a plea for complimentary techniques for testing the robustness of our data with the help of automatic (text mining) techniques.|coherence relations; discourse; reliability; interrater agreement; corpus analysis|INTERRATER AGREEMENT; KAPPA; CORPUS; DISCOURSE; COEFFICIENT|Linguistics; Language \& Linguistics|22|2|17
Knowledge acquisition method from domain text based on theme logic model and artificial neural network|2010|In order to acquire knowledge from domain text such as failure analysis text of aviation product, a framework is proposed to enhance the efficiency and accuracy of knowledge acquisition. In this framework, sentence templates are defined to extract the meta-knowledge and RDF is used to describe the extracted knowledge. After the preprocessing steps, the authors propose a new model: theme logic model (TLM) to present all the themes of a piece of text and the logical relations among different themes. In this model, the text of each theme can be represented as an attribute-value vector based on domain ontology. Meanwhile, the logical relations are the domain knowledge to be acquired. The theme logic model then will be transformed to the training set of the artificial neural network to acquire the failure analysis knowledge. After training process, acquired knowledge will be extracted by SD method from the artificial neural network and represented by rules. Therefore. a prototype is developed to acquire knowledge from failure analysis reports of aviation product. Empirical results show that the framework can acquire knowledge from domain text efficiently. (C) 2009 Elsevier Ltd. All rights reserved.|Knowledge acquisition; Domain text; Theme logic model; Artificial neural network; Failure analysis report|VECTOR-SPACE MODEL; FAILURE-MECHANISM IDENTIFICATION; EXPERT-SYSTEM; INFORMATION-RETRIEVAL; INTEGRATED DATABASE; MANAGEMENT; DOCUMENTS; DESIGN|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|8|0|17
A comparison of the linguistic and interactional features of language learning websites and textbooks|2009|Self-study is playing an increasingly important role in the learning and instruction of many subjects, including second and foreign languages. With the rapid development of the internet, language websites for self-study are flourishing. While the language of print-based teaching materials has received some attention, the linguistic and interactional features of websites are largely ignored by educationists, and online learning materials are regarded as simply duplicates of their print-based counterparts. This is far from satisfactory because web-based and print-based materials are very different tools with which participants negotiate their learning activities. This paper examines the linguistic and interactional features of English learning websites in terms of (1) their lexical density/clause length; (2) referential cohesion, particularly the use of personal pronouns; and (3) the presence of involvement strategies and other interactional features. These features are compared with those in textbooks to examine how websites deviate from traditional instructional texts. It is found that both clause and lexical density are greater on websites than in traditional textbooks. Websites make more use of the personal pronouns `I' and `you', whereas textbooks make more use of the authoritative `we'. Websites are also more interactional in terms of their use of involvement strategies, imperative structures and modals. These findings highlight the different contexts of textbooks and websites, particularly the different nature of the two channels and their credibility as information sources. This has practical implications for the design of appropriate online instructional resources.|web-based learning; self-access; textbook; discourse analysis; language of instruction|INSTRUCTION; WEB|Education \& Educational Research; Linguistics; Language \& Linguistics|7|2|17
``But it's all true !{''}: commercialism and commitment in the discourse of organic food promotion|2009|Debates over food politics provide insight into the convergence of commercial and political discourses. As the organic food market has grown, campaigners and independent producers have faced the dilemma of how far they should promote their cause using standard marketing language. We report on a research project which combined corpus analysis, interviews, and focus group discussions to investigate the discourse of organic food promotion in Britain, the thinking behind it, and how people react to it. We found growing convergence across the sector. Whether produced by super-markets, small politically committed producers, or environmentalist campaign groups, the language used tends to be poetic, vague, dialogic, narrative, and emotive, with an emphasis upon bucolic imagery and consumer self-interest. Text producers assume that consumer attitudes can be easily manipulated by such an approach. Our focus group data however suggest both a critical resistance to marketing language in general, and that attitudes to food may be less amenable to manipulation through standard promotional techniques than is commonly assumed. Our findings contribute not only to an understanding of food politics and persuasive discourse more generally, but also to the development of discourse analytic methodology which integrates textual analysis with investigation of sender and receiver perceptions.|organic food; food politics; discourse analysis; public relations; corpus linguistics; persuasive language|SCIENTISTS; EXPERT; FUTURE|Communication; Linguistics; Language \& Linguistics|8|3|17
High-dimensional semantic space accounts of priming|2006|A broad range of priming data has been used to explore the structure of semantic memory and to test between models of word representation. In this paper, we examine the computational mechanisms required to learn distributed semantic representations for words directly from unsupervised experience with language. To best account for the variety of priming data, we introduce a holographic model of the lexicon that learns word meaning and order information from experience with a large text corpus. Both context and order information are learned into the same composite representation by simple summation and convolution mechanisms (cf. Murdock, B.B. (1982). A theory for the storage and retrieval of item and associative information. Psychological Review, 89, 609-626). We compare the similarity structure of representations learned by the holographic model, Latent Semantic Analysis (LSA; Landauer, T.K., \& Dumais, ST. (1997). A solution to Plato's problem: The latent semantic analysis theory of acquisition, induction and representation of knowledge. Psychological Review, 104, 211-240), and the Hyperspace Analogue to Language (HAL; Lund, K., \& Burgess, C., (1996). Producing high-dimensional semantic spaces from lexical co-occurrence. Behavior Research Methods, Instrumentation, and Computers, 28, 203-208) at predicting human data in a variety of semantic, associated, and mediated priming experiments. We found that both word context and word order information are necessary to account for trends in the human data. The representations learned from the holographic system incorporate both types of structure, and are shown to account for priming phenomena across several tasks. (c) 2006 Elsevier Inc. All rights reserved.|semantic space models; models of word meaning; semantic priming; mediated priming|AUTOMATIC SPREADING ACTIVATION; SIMPLE RECURRENT NETWORKS; LEXICAL DECISION TASK; ASSOCIATIVE INFORMATION; MODEL; REPRESENTATIONS; MEMORY; COOCCURRENCE; RETRIEVAL; ACQUISITION|Linguistics; Psychology; Psychology, Experimental|81|0|17
An investigation of incidental vocabulary acquisition in relation to learner proficiency level and word frequency|2006|This study examined the relationship between learners' incidental vocabulary acquisition and their level of proficiency, and between acquisition and word frequency in a text. Participants were Turkish learners of English at three proficiency levels. One reading text and four vocabulary tests were administered over a two-week period. Analyses of the data revealed that lexical gains from reading were significant for each group (p < .05). The higher proficiency groups were able to acquire more words than lower level groups. Word frequency in the text was also a significant factor in vocabulary acquisition (p < .05), with 29\% of the variance in acquisition being accounted for by frequency. However, frequency did not play a greater role in the vocabulary acquisition of lower level learners than in that of higher level learners.|implicit and explicit instruction; incidental acquisition; reading; vocabulary acquisition; word frequency|2ND LANGUAGE; KNOWLEDGE; EXPOSURE; PRINT|Education \& Educational Research; Linguistics|22|0|17
`So what is the problem this book addresses?': Interactions in academic book reviews|2006|Metadiscourse is the term used for self-reflective linguistic expressions that refer to the evolving text, to the writer, and to the imagined readers of that text. It is based on a view of writing as social engagement and in academic contexts reveals the ways writers project themselves into their discourse to signal their attitudes and commitments to matters in the text and to their disciplinary communities. This paper examines the frequencies and pragmatic purposes of metadiscourse in the relatively neglected academic genre of the book review. On the basis of a corpus of 84 reviews from three contrasting disciplines and interviews with journal editors and reviewers, we describe the ways these writers use metadiscourse to offer a credible representation of themselves and their work in different fields. The analysis shows how metadiscourse use can be seen as pragmatic strategies through which writers shape their social purposes to the formal constraints of the genre and the preferred practices of their disciplines. It therefore suggests how this genre not only draws on readers' familiarity with disciplinary knowledge of the field, but also an interpretive framework that includes appropriate social interactions.|metadiscourse; academic texts; book reviews; text interactions|METADISCOURSE; DISCOURSE|Communication; Linguistics; Language \& Linguistics|8|2|17
The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text|2003|Interpretation of semantic propositions in free-text documents such as MEDLINE citations would provide valuable support for biomedical applications, and several approaches to semantic interpretation are being pursued in the biomedical informatics community. In this paper, we describe a methodology for interpreting linguistic structures that encode hypernymic propositions, in which a more specific concept is in a taxonomic relationship with a more general concept. In order to effectively process these constructions, we exploit underspecified syntactic analysis and structured domain knowledge from the Unified Medical Language System (UMLS). After introducing the syntactic processing on which our system depends, we focus on the UMLS knowledge that supports interpretation of hypernymic propositions. We first use semantic groups from the Semantic Network to ensure that the two concepts involved are compatible; hierarchical information in the Metathesaurus then determines which concept is more general and which more specific. A preliminary evaluation of a sample based on the semantic group Chemicals and Drugs provides 83\% precision. An error analysis was conducted and potential solutions to the problems encountered are presented. The research discussed here serves as a paradigm for investigating the interaction between domain knowledge and linguistic structure in natural language processing, and could also make a contribution to research on automatic processing of discourse structure. Additional implications of the system we present include its integration in advanced semantic interpretation processors for biomedical text and its use for information extraction in specific domains. The approach has the potential to support a range of applications, including information retrieval and ontology engineering. Published by Elsevier Inc.|natural language processing; semantic processing; knowledge representation; information extraction|UMLS SEMANTIC NETWORK; INFORMATION EXTRACTION; CLINICAL-DATA; SYSTEM; MEDSYNDIKATE; RADIOLOGY; MEDICINE|Computer Science, Interdisciplinary Applications; Medical Informatics|160|2|17
Recognition of affective communicative intent in robot-directed speech|2002|Human speech provides a natural and intuitive interface for both communicating with humanoid robots as well as for teaching them. In general, the acoustic pattern of speech contains three kinds of information: who the speaker is, what the speaker said, and how the speaker said it. This paper focuses on the question of recognizing affective communicative intent in robot-directed speech without looking into the linguistic content. We present an approach for recognizing four distinct prosodic patterns that communicate praise, prohibition, attention, and comfort to preverbal infants. These communicative intents are well matched to teaching a robot since praise, prohibition, and directing the robot's attention to relevant aspects of a task, could be used by a human instructor to intuitively facilitate the robot's learning process. We integrate this perceptual ability into our robot's ``emotion{''} system, thereby allowing a human to directly manipulate the robot's affective state. This has a powerful organizing influence on the robot's behavior, and will ultimately be used to socially communicate affective reinforcement. Communicative efficacy has been tested with people very familiar with the robot as well as with naive subjects.|affective computing; human computer interaction; humanoid robots; sociable robots; speech recognition|MATERNAL SPEECH; INFANTS; MOTHERESE; LANGUAGE|Computer Science, Artificial Intelligence; Robotics|102|2|17
Sentiment analysis of player chat messaging in the video game StarCraft 2: Extending a lexicon-based model|2017|There is a growing need for automated tools which make predictions about the positivity or negativity of sentiment conveyed by text. Such tools have a number of important applications in game user research. They are useful for understanding users generally, as they may give Big Data researchers access to a new source of information about player learning environments. Sentiment analysis methods are also applicable to the detection of toxicity, and the identification of players or player messages that are a potential threat to the player experience. A major challenge in sentiment analysis, however, is developing portable models that can be applied to new domains with relatively little effort. In the present study we extend a lexicon based sentiment extractor, SO-CAL, to the analysis of instant messages across 1000 games of StarCraft 2. We show that, with updates to dictionary entries that are tailored to the classification task at hand, SO-CAL constitutes a respectable classifier of sentiment and toxicity that is robust across differences in player region and league. We verify the performance of our toxicity detector against a sample of 2025 additional games. Our results support the proposal that lexicon-based sentiment extraction is a useful and portable method of sentiment analysis, and that it can be deployed to identify toxicity. (C) 2017 Elsevier B.V. All rights reserved.|Sentiment analysis; Video game chat; Instant messaging; Toxicity|STRENGTH DETECTION; DEFECT DISCOVERY; REVIEWS; CLASSIFICATION|Computer Science, Artificial Intelligence|0|16|16
User emotion for modeling retweeting behaviors|2017|Twitter and other microblogs have rapidly become a significant mean of information propagation in today's web. Understanding the main factors that make certain pieces of information spread quickly in these platforms has emerged as a popular topic. Therefore, as a simple yet powerful way of disseminating useful information, retweeting has attracted much interest. Existing methods for retweets have been conducted for analyzing the social network structure, or understanding the retweeting mechanism. However, little attention is paid to whether users' emotion will affect users' retweeting behavior. In this paper, we study the user emotion problem in a large social network. Particularly, we consider users' retweet behaviors and focus on investigating whether users with a certain emotional status will retweet the tweet corresponding with users' current mood from their friends. In order to achieve this goal, we propose a retweeting prediction framework. First, we construct a model of emotion detection via considering two kinds of emotional signals; second, we extract possible retweeted friends and tweets; third, based on the first two steps, we obtain Top-N retweets using Learn-to-Rank method. Experiments are performed on two real-world datasets, the Twitter network and Obama-McCain Debate dataset, with comprehensive measurements. Experimental results demonstrate that our retweeting prediction framework has substantial advantages over commonly used retweeting prediction approaches in predicting retweeting behaviors. Consider Precision in Twitter network as an example. For the Top-N stage, our method can, on average, increase by 15.2\% and 11.2\% in relation to Tweet(+SV) and User(+ED), respectively. We find that emotion is a vital feature which affects retweetability. (C) 2017 Elsevier Ltd. All rights reserved.|Retweeting behavior; Emotion; Social network; Twitter; Factor analysis|TEXT|Computer Science, Artificial Intelligence; Neurosciences|0|16|16
EliIE: An open-source information extraction system for clinical trial eligibility criteria|2017|To develop an open-source information extraction system called Eligibility Criteria Information Extraction (EliIE) for parsing and formalizing free-text clinical research eligibility criteria (EC) following Observational Medical Outcomes Partnership Common Data Model (OMOP CDM) version 5.0. EliIE parses EC in 4 steps: (1) clinical entity and attribute recognition, (2) negation detection, (3) relation extraction, and (4) concept normalization and output structuring. Informaticians and domain experts were recruited to design an annotation guideline and generate a training corpus of annotated EC for 230 Alzheimer's clinical trials, which were represented as queries against the OMOP CDM and included 8008 entities, 3550 attributes, and 3529 relations. A sequence labeling-based method was developed for automatic entity and attribute recognition. Negation detection was supported by NegEx and a set of predefined rules. Relation extraction was achieved by a support vector machine classifier. We further performed terminology-based concept normalization and output structuring. In task-specific evaluations, the best F1 score for entity recognition was 0.79, and for relation extraction was 0.89. The accuracy of negation detection was 0.94. The overall accuracy for query formalization was 0.71 in an end-to-end evaluation. This study presents EliIE, an OMOP CDM-based information extraction system for automatic structuring and formalization of free-text EC. According to our evaluation, machine learning-based EliIE outperforms existing systems and shows promise to improve.|natural language processing; machine learning; clinical trials; patient selection; common data model; named entity recognition|OF-THE-ART; BIOMEDICAL TEXT; DISCHARGE SUMMARIES; REPRESENTATION; ASSERTIONS; CHALLENGES; LANGUAGE; FEATURES; PROGRESS; NETWORK|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|16|16
The lexical coverage of popular songs in English language teaching|2017|Songs are popular among language learners and a text genre that is yet to be fully exploited in language teaching. Questions arise regarding their lexical demand and vocabulary-learning opportunities they afford. Two pop song corpora were analyzed to determine the vocabulary size necessary to comprehend 95\% and 98\% of words in pop songs. The first corpus comprised 408 songs listed in recent US billboard charts. The second corpus consisted of 635 songs selected by teachers for language-teaching purposes. Results of an analysis using RANGE and 20 BNC word-frequency lists showed that the lexical demand of charts songs is overall clearly lower compared to other written genres but similar to spoken genres, as the most frequent 3000 word families plus proper nouns provided 95.1\% coverage of tokens, and knowledge of 6000 word families plus proper nouns was necessary to reach 98.2\% coverage. Teacher-selected songs have a lower lexical demand: Knowledge of the most frequent 2000 word families plus proper nouns was necessary to reach 95.5\% coverage, while a vocabulary size of 4000 word families plus proper nouns provided coverage of 98.2\% of words in the pedagogical corpus. Implications for the use of songs in ESL and EFL classrooms are discussed. (C) 2017 Elsevier Ltd. All rights reserved.|Vocabulary; Corpus; Song; TESOL; Teaching materials; Text comprehension; Lexical load; Coverage; Word frequency; Lyrics|READING-COMPREHENSION; VOCABULARY; FREQUENCY; WORDS; TEXT|Education \& Educational Research; Linguistics|0|13|16
A design for a common-sense knowledge-enhanced decision-support system: Integration of high-frequency market data and real-time news|2017|According to efficient markets theory, information is an important factor that affects market performance and serves as a source of first-hand evidence in decision making, in particular with the rapid rise of Internet technologies in recent years. However, a lack of knowledge and inference ability prevents current decision support systems from processing the wide range of available information. In this paper, we propose a common-sense knowledge-supported news model. Compared with previous work, our model is the first to incorporate broad common-sense knowledge into a decision support system, thereby improving the news analysis process through the application of a graphic random-walk framework. Prototype and experiments based on Hong Kong stock market data have demonstrated that common-sense knowledge is an important factor in building financial decision models that incorporate news information.|decision support; financial application; knowledge engineering; text mining|RISK-MANAGEMENT; STOCK; WEB|Computer Science, Artificial Intelligence; Computer Science, Theory \& Methods|0|12|16
The beauty of brimstone butterfly: novelty of patents identified by near environment analysis based on text mining|2017|The novelty of a patent may be seen as those patterns that distinguishes it from other patents and scientific literature. Its understanding may serve for many purposes, both in scientometric research and in the management of technological information. While many methods exist that deal with a patent's meta-information like citation networks or co-classification analysis, the analysis of novelty in the full text of a patent is still at the beginning of research and in practice a time-consuming manual task. The question we pose is whether computer-based text mining methods are able to identify those elements of such a patent that make it novel from a technological and application/market perspective. For this purpose we introduce and operationalize the concept of near environment analysis and use a three-step text mining approach on one of the patents nominated as finalist in the 2012 European Inventor Award contest. We demonstrate that such an approach is able to single out, content-wise in a near environment, the novelty of the patent. The method can be used also for other patents and-with adaption of the near environment analysis-for scientific literature.|Novelty (patent); Semantic analysis; Patent analysis; Text mining; n-grams; Inventor profile; Human resource management; Similarity measurement|TECHNOLOGY|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|5|16
Developing oral proficiency with VoiceThread: Learners' strategic uses and views|2017|This study explored Russian as a foreign language (RFL) learners' self-reported strategic uses of VoiceThread (VT)-a multimodal asynchronous computer-mediated communication tool-in order to gain insights into learner perceived effectiveness of VT for second language (L2) oral skills development and to determine the factors that contributed to those perceptions. The participants were eight undergraduate students who attended six weekly tutoring sessions that combined face-to-face (F2F) RFL instruction with VT activities. VT allowed them to access text-based, graphic, video, and aural linguistic input; record and store audio/video-recorded output; listen and comment on peers' recordings; and receive individualized teacher feedback on oral performance. Data from activity logs and researcher field notes were triangulated with participants' responses to two surveys and a semi-structured oral interview. Findings indicated that participants believed that VT supported their oral proficiency development through the provision of additional time and resources for independent planning, rehearsal, and controlled production of L2 forms. Most participants also agreed that VT's playback and record features were the most beneficial for developing language skills, enhancing the reflection process, and facilitating self-assessment and creativity in the L2. Yet, despite VT's multimodal affordances and the availability of communicative tasks via VT, participants did not perceive VT as a social environment that could promote peer-to-peer interaction or replace F2F communication. A thematic data analysis suggested that participants' preferences for language learning tasks influenced their strategic uses of VT's features, which ultimately affected their perceptions of VT's value for promoting meaningful language learning interactions. Pedagogical considerations are discussed.|VoiceThread; Russian learners' views; language learning and teaching; computer-mediated communication; oral skills|COMPUTER-MEDIATED COMMUNICATION; LANGUAGE; TALK|Education \& Educational Research; Linguistics; Language \& Linguistics|1|6|16
The role of emails and covering letters in negotiating a legal contract: A case study from Turkey|2016|Negotiation is fundamental to legal practice. Previous analyses of this important interactional and discursive process have often focused on negotiation as a form of bargaining carried on by business people. In this case study we examine legal negotiation of a commercial contract undertaken primarily by two counterpart lawyers; one based in Istanbul and the other in London. These lawyers are centrally concerned with reaching mutual agreement on the terms and conditions of a particular Distribution Agreement through the exchange of a small set of emails and covering letters recording the negotiations. These two genres help to stabilise and progress the negotiation process and account for negotiation activities recorded in successive marked-up drafts of the Distribution Agreement. We use Swalesian analyses of functional Moves and Steps to identify structural similarities and differences between the documents. We also identify certain salient discursive features of these documents and the use of the Track Changes software function and mark-up to negotiate proposed changes within the contract. Intertextuality and discursive hybridity emerge as important dimensions of all of these text types. Our findings should contribute to developing more authentic English for Legal Purposes (ELP) pedagogies for law students and legal practitioners. (C) 2016 Elsevier Ltd. All rights reserved.|Legal contract negotiation; Email communication; Genre analysis; Intertextuality and interdiscursivity; English for Legal Purposes|GENRE ANALYSIS; BUSINESS COMMUNICATION; INTERNATIONAL-BUSINESS; HONG-KONG; ENGLISH; DISCOURSE; INTERTEXTUALITY; FACE|Linguistics|0|2|16
Same language, different functions: A cross-genre analysis of Chinese EFL learners' writing performance|2016|Secondary-school learners of English as a foreign language (EFL) in China constitute a rapidly growing yet understudied population. This study examined Chinese secondary-school EFL learners' writing performance in two genres, argumentative essays and narratives. Crossgenre research on native language writing has documented that, at the macro-text level, secondary-school students' narratives are typically of higher quality than their written essays; while at the lexico-syntactic level, essays display higher complexity than narratives. To investigate cross-genre differences in EFL learners, 200 English written texts (100 essays; 100 narratives) were collected from 100 EFL Chinese secondary school learners and scored for quality, lexico-syntactic, and genrespecific discourse features. Unlike prior research on native language writing, no significant differences in quality ratings were found across the two genres. However, in line with prior research, results revealed that argumentative essays displayed a higher lexico-syntactic complexity. Regression analyses identified distinct sets of predictors of writing quality ratings for each genre. Controlling for length, lexico-syntactic complexity and diversity of organizational markers were identified as predictors of argumentative essay quality. Conversely, controlling for length, narrative quality was only predicted by the frequency of stance markers. Results are discussed in relation to pedagogical implications and directions for future research. (C) 2016 Elsevier Inc. All rights reserved.|Chinese EFL learners; EFL writing; School genre; Narrative writing; Argumentative writing; Sociocultural pragmatics|SYNTACTIC COMPLEXITY; LEARNING DISABILITIES; TEXT CONSTRUCTION; QUALITY; DISCOURSE; LITERACY; STUDENTS; FEATURES; AGE; ORGANIZATION|Linguistics|3|6|16
Genre and technicality in analogical explanations: Hong Kong's English language textbooks for junior secondary science|2016|This paper examines how a core topic from junior secondary science, the use of analogy to teach the electric circuit, is presented in three English-language textbooks commonly used in Hong Kong's schools. Tools from systemic functional linguistics and semiotics were used in consultation with a science education specialist to compare the books' treatment of the topic. The analysis considered four interlocking aspects: genre, the use of the analogy to introduce the target knowledge, the construction of scientific knowledge in language, and the relations between the language and associated images. Differences were found in all these areas, with textbooks varying in how much support they gave students in the construction of technical knowledge. A key difference was the use of explanation versus procedure and/or report genres, resulting in a focus on the workings versus the compbnents of the electric circuit. The books also varied in the role of the analogy in the construction of technicality, and in the extent to which they relied on images to convey meaning. These differences suggest that in some cases the teacher may need to provide additional support to make the textbook material accessible to students. (C) 2016 Elsevier Ltd. All rights reserved.|Secondary science; Textbooks; Genre; Explanation; Analogy; Systemic functional linguistics|KNOWLEDGE; LITERACY; TEXTS|Education \& Educational Research; Linguistics; Language \& Linguistics|0|2|16
Negation scope detection in sentiment analysis: Decision support for news-driven trading|2016|Decision support for financial news using natural language processing requires robust methods that process all sentences correctly, including those that are negated. To predict the corresponding negation scope, related literature commonly utilizes rule-based algorithms and generative probabilistic models. In contrast, we propose the use of a tailored reinforcement learning method, since it can conquer learning task of arbitrary length. We then perform a thorough comparison with a two-pronged evaluation. First, we compare the predictive performance using a manually-labeled dataset. Here, reinforcement learning outperforms common approaches from the related literature, leading to a balanced classification accuracy of up to 70.17\%. Second, we examine how detecting negation scopes can improve the accuracy of sentiment analysis for financial news, leading to an improvement of up to 10.63\% in the correlation between news sentiment and stock market returns. This reveals negation scope detection as a crucial leverage in decision support from sentiment. (C) 2016 Elsevier B.V. All rights reserved.|Decision support; Machine learning; Sentiment analysis; Negation scope detection; Financial news|TEXTUAL ANALYSIS; MARKET; RECOGNITION; PREDICTION|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|2|3|16
An ensemble method for extracting adverse drug events from social media|2016|Objective: Because adverse drug events (ADEs) are a serious health problem and a leading cause of death, it is of vital importance to identify them correctly and in a timely manner. With the development of Web 2.0, social media has become a large data source for information on ADEs. The objective of this study is to develop a relation extraction system that uses natural language processing techniques to effectively distinguish between ADEs and non-ADEs in informal text on social media. Methods and materials: We develop a feature-based approach that utilizes various lexical, syntactic, and semantic features. Information-gain-based feature selection is performed to address high-dimensional features. Then, we evaluate the effectiveness of four well-known kernel-based approaches (i.e., subset tree kernel, tree kernel, shortest dependency path kernel, and all-paths graph kernel) and several ensembles that are generated by adopting different combination methods (i.e., majority voting, weighted averaging, and stacked generalization). All of the approaches are tested using three data sets: two health-related discussion forums and one general social networking site (i.e., Twitter). Results: When investigating the contribution of each feature subset, the feature-based approach attains the best area under the receiver operating characteristics curve (AUC) values, which are 78.6\%, 72.2\%, and 79.2\% on the three data sets. When individual methods are used, we attain the best AUC values of 82.1\%, 73.2\%, and 77.0\% using the subset tree kernel, shortest dependency path kernel, and feature-based approach on the three data sets, respectively. When using classifier ensembles, we achieve the best AUC values of 84.5\%, 77.3\%, and 84.5\% on the three data sets, outperforming the baselines. Conclusions: Our experimental results indicate that ADE extraction from social media can benefit from feature selection. With respect to the effectiveness of different feature subsets, lexical features and semantic features can enhance the ADE extraction capability. Kernel-based approaches, which can stay away from the feature sparsity issue, are qualified to address the ADE extraction problem. Combining different individual classifiers using suitable combination methods can further enhance the ADE extraction effectiveness. (C) 2016 Elsevier B.V. All rights reserved.|Relation extraction; Feature-based approach; Feature selection; Kernel-based approaches; Social media; Adverse drug event extraction|PROTEIN INTERACTION EXTRACTION; STACKED GENERALIZATION; BIOMEDICAL LITERATURE; CLASSIFICATION TASKS; BIG DATA; KERNEL; INFORMATION; HEALTH; PHARMACOVIGILANCE; SURVEILLANCE|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|5|1|16
Machine learning classification of surgical pathology reports and chunk recognition for information extraction noise reduction|2016|Background and aims: Machine learning techniques for the text mining of cancer-related clinical documents have not been sufficiently explored. Here some techniques are presented for the pre-processing of free-text breast cancer pathology reports, with the aim of facilitating the extraction of information relevant to cancer staging. Materials and methods: The first technique was implemented using the freely available software Rapid Miner to classify the reports according to their general layout: `semi-structured' and `unstructured'. The second technique was developed using the open source language engineering framework GATE and aimed at the prediction of chunks of the report text containing information pertaining to the cancer morphology, the tumour size, its hormone receptor status and the number of positive nodes. The classifiers were trained and tested respectively on sets of 635 and 163 manually classified or annotated reports, from the Northern Ireland Cancer Registry. Results: The best result of 99.4\% accuracy - which included only one semi-structured report predicted as unstructured - was produced by the layout classifier with the k nearest algorithm, using the binary term occurrence word vector type with stopword filter and pruning. For chunk recognition, the best results were found using the PAUM algorithm with the same parameters for all cases, except for the prediction of chunks containing cancer morphology. For semi-structured reports the performance ranged from 0.97 to 0.94 and from 0.92 to 0.83 in precision and recall, while for unstructured reports performance ranged from 0.91 to 0.64 and from 0.68 to 0.41 in precision and recall. Poor results were found when the classifier was trained on semi-structured reports but tested on unstructured. Conclusions: These results show that it is possible and beneficial to predict the layout of reports and that the accuracy of prediction of which segments of a report may contain certain information is sensitive to the report layout and the type of information sought. (C) 2016 Elsevier B.V. All rights reserved.|Natural language processing; Information extraction; Supervised machine learning; Surgical pathology report; Cancer staging|MEDICATION INFORMATION; CLINICAL NOTES; TEXT|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|1|1|16
``Sleeping beauty'' and her restless sleep: Charles Dotter and the birth of interventional radiology|2016|Charles Dotter has been described as the father of interventional radiology, a medical specialty born at the interface between radiology and cardiology. Before 1979, it was relatively difficult to find citations to a landmark paper that Dotter had first published in 1964-qualifying this study, from a scientometric perspective, as a sleeping beauty. Sleeping beauties are texts that suffer due to delayed recognition. The present paper explores the Dotter case study's bibliometric characteristics while analyzing the Van Raan criteria's usefulness for defining sleeping beauties in science. Citation network analysis using CitNetExplorer has proven helpful in identifying the ``Prince'' in this fairy tale. The duration of sleep is viewed here as a period of restlessness marked by science and social controversies that are often documented in publication databases using a wide range of bibliographic references. Hence the idea of introducing alongside this sleeping beauty construct the idea of ``restless sleep''. These observations should open new avenues in identifying sleeping beauties while nurturing scientific controversy studies revolving around the use of scientometric approaches.|Sleeping beauty; Co-referencing; Network; History of science; Sociology of science; Innovation|SCIENCE|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|5|6|16
Rapping in Catalan in class and the empowerment of the learner|2016|Despite the well-known educational possibilities afforded by Rhythm And Poetry (RAP) for the development of musical, lyrical and critical skills {[}Morrell, E., \& Duncan-Andrade, J. M. R. (2002). Promoting Academic Literacy with Urban Youth through Engaging Hip-hop Culture. The English Journal, 91(6), 88-92. Retrieved from {[}GRAPHICS] ; Hill, M. L. (2009). Beats, Rhymes, and Classroom Life: Hip Hop Pedagogy and the Politics of Identity. New York, NY: Teachers College Press; Low, B. E. (2011). Slam School: Learning Through Conflict in the Hip-Hop and Spoken Word Classroom. Chicago, IL: Stanford University Press], it remains a lyrical genre often excluded from Catalan secondary education. This paper focuses on a four-day series of rap workshops given in 2012 by a famous local Catalan rap artist in a multicultural and multilingual state school in Catalonia. It analyses the impact that the workshops had, above all in terms of classroom engagement, linguistic empowerment and textual `agency' {[}Moje, E. B., \& Lewis, C. (2007). Examining Opportunities to Learn Literacy: The role of critical sociocultural literacy research. In E. B. Moje, C. Lewis, \& P. Enciso (Eds.), Reframing sociocultural research on literacy: identity, agency and power (pp. 15-48). Mahwah, N. J.: Lawrence Erlbaum], on a range of students with varying degrees of command of the Catalan language and with different degrees of experience with rap music. Through the classroom activity described herein, we show the pedagogical opportunities that rap music offers as a hybrid text in-between oral and written codes that makes it a powerful vehicle for self-expression, whilst enabling the acknowledgement of real uses of languages and genres related to the cultural practices of urban students, in the classroom. In particular, we argue that bridging Catalan rap culture to the goals of the school curriculum, especially in highly multilingual and multicultural school contexts, helps to promote the socialisation of the Catalan language in and beyond the school.|linguistic empowerment; youth vernacular literacies; secondary education; Hip-hop pedagogy; third space theory|HIP-HOP; LITERACY; ADOLESCENTS; KNOWLEDGE; FUNDS; AREA; RAP|Education \& Educational Research; Linguistics; Language \& Linguistics|1|4|16
The future in reports Prediction, commitment and legitimization in CSR|2016|Company disclosures are often looked at as narrative rather than argumentative or directive texts. And yet `irrealis' statements - references to future or hypothetical processes - do play a role and contribute greatly to the construction of corporate identity. Combining a corpus and a discourse perspective, the paper looks at references to the future in a corpus of CSR (corporate social responsibility) reports. After a preliminary analysis of frequency data, a case study of markers of futurity is presented, focusing on ways of expressing prediction or commitment, together with attitudinal values or evaluations of importance. Keywords and phraseology are studied to highlight how prediction and commitment statements are used to legitimize the company's (past) conduct.|business discourse; CSR reporting; futurity; genre analysis; corpus linguistics; semantic sequence|CORPORATE SOCIAL-RESPONSIBILITY; DISCLOSURES; ENVIRONMENT; LEGITIMACY; CULTURE; VIEW; WEB|Linguistics; Language \& Linguistics|1|2|16
Power distance and persuasion: The tension between imposition and legitimation in international legal genres|2016|The present study is aimed at the analysis of three major legal documents applied widely in international trade: The London Court of International Arbitration Rules, the Geneva Convention for the International Carriage of Goods by Road and Lloyd's Institute Cargo Clauses. It has been carried out under the umbrella of genre analysis, with the aim of scrutinizing the internal communicative mechanisms deployed by the members of the very specialized communities that integrate the legal one as a whole. Our work introduces the concept of `power distance' to study the asymmetries between the interactants of the texts, with a view to unveiling the hidden nuances of power and imposition concealed in their discursive devices. Secondly, this paper has analyzed the presence of metadiscourse markers in these texts as the textual and interactional devices deployed by their senders or writers to influence the attitude and behavior of their recipients. Our application of speech acts and metadiscourse markers to these three paradigmatic texts has attempted to shed some light on the tension between persuasion and power distance in legal discourse. (C) 2015 Elsevier B.V. All rights reserved.|Power distance; Persuasion; Legitimation; Legal genres; Metadiscourse; Legal texts|METADISCOURSE; ACTS|Linguistics; Language \& Linguistics|1|0|16
Exploring author name disambiguation on PubMed-scale|2015|Author name disambiguation (AND) creates a daunting challenge in that disambiguation techniques often draw false conclusions when applied to incomplete or incorrect publication data. It becomes a more critical issue in the biomedical domain where PubMed articles are written by a wide range of researchers internationally. To tackle this issue, we create a carefully hand-crafted training set drawn from the entire PubMed collection by going through multiple iterations. We assess the quality of our training set by comparing it with SCOPUS-based training set. In addition, for the performance enhancement of the AND techniques, we propose a new set of publication features extracted by text mining techniques. The results of the experiments show that all four supervised learning techniques (Random Forest, C4.5, KNN, and SVM) with the new publication features (called NER model) achieve improved performance over the baseline and hybrid edit distance model. (C) 2015 Elsevier Ltd. All rights reserved.|Author name disambiguation; Named entity recognition; Keyphrase extraction; Machine learning; PubMed|MODEL|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|2|16
Challenges in clinical natural language processing for automated disorder normalization|2015|Background: Identifying key variables such as disorders within the clinical narratives in electronic health records has wide-ranging applications within clinical practice and biomedical research. Previous research has demonstrated reduced performance of disorder named entity recognition (NER) and normalization (or grounding) in clinical narratives than in biomedical publications. In this work, we aim to identify the cause for this performance difference and introduce general solutions. Methods: We use closure properties to compare the richness of the vocabulary in clinical narrative text to biomedical publications. We approach both disorder NER and normalization using machine learning methodologies. Our NER methodology is based on linear-chain conditional random fields with a rich feature approach, and we introduce several improvements to enhance the lexical knowledge of the NER system. Our normalization method - never previously applied to clinical data - uses pairwise learning to rank to automatically learn term variation directly from the training data. Results: We find that while the size of the overall vocabulary is similar between clinical narrative and biomedical publications, clinical narrative uses a richer terminology to describe disorders than publications. We apply our system, DNorm-C, to locate disorder mentions and in the clinical narratives from the recent ShARe/CLEF eHealth Task. For NER (strict span-only), our system achieves precision = 0.797, recall = 0.713, f-score = 0.753. For the normalization task (strict span + concept) it achieves precision = 0.712, recall = 0.637, f-score = 0.672. The improvements described in this article increase the NER f-score by 0.039 and the normalization f-score by 0.036. We also describe a high recall version of the NER, which increases the normalization recall to as high as 0.744, albeit with reduced precision. Discussion: We perform an error analysis, demonstrating that NER errors outnumber normalization errors by more than 4-to-1. Abbreviations and acronyms are found to be frequent causes of error, in addition to the mentions the annotators were not able to identify within the scope of the controlled vocabulary. Conclusion: Disorder mentions in text from clinical narratives use a rich vocabulary that results in high term variation, which we believe to be one of the primary causes of reduced performance in clinical narrative. We show that pairwise learning to rank offers high performance in this context, and introduce several lexical enhancements - generalizable to other clinical NER tasks - that improve the ability of the NER system to handle this variation. DNorm-C is a high performing, open source system for disorders in clinical text, and a promising step toward NER and normalization methods that are trainable to a wide variety of domains and entities. (DNorm-C is open source software, and is available with a trained model at the DNorm demonstration website: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/ \#DNorm.) Published by Elsevier Inc.|Natural language processing; Electronic health records; Information extraction|ELECTRONIC HEALTH RECORDS; TEXT; METAMAP; UMLS; FEASIBILITY; RECOGNITION|Computer Science, Interdisciplinary Applications; Medical Informatics|13|0|16
Hybrid affective computing-keyboard, mouse and touch screen: from review to experiment|2015|Emotions play an important role in human interactions. They can be integrated into the computer system to make human-computer interaction (HCI) more effective. Affective computing is an innovative computational modeling and detecting user's emotions to optimize system responses in HCI. However, there is a trade-off between recognition accuracy and real-time performance in some of the methods such as processing the facial expressions, human voice and body gestures. Other methods lack efficiency and usability in real-world applications such as natural language processing and electroencephalography signals. To accomplish a reliable, usable and high-performance system, this paper proposes an intelligent hybrid approach to recognize users' emotions by using easily accessible and low computational cost input devices including keyboard, mouse (touch pad: single touch) and touch screen display (single touch). Using the proposed approach, the system is developed and trained in a supervised mode by artificial neural network and support vector machine (SVM) techniques. The result shows an increase in accuracy of 6 \% (93.20 \%) by SVM in comparison with the currently existing methods. It is a significant contribution to show new directions of future research in emotion recognition, user modeling and emotional intelligence.|Affective computing; Human emotion recognition; Keyboard keystroke dynamics; Mouse touch pad movement; Touch screen monitor; Human-computer interaction (HCI)|OPTIMIZATION PROBLEMS; AMBIENT INTELLIGENCE; EMOTION RECOGNITION; ENVIRONMENTS; EXPRESSIONS; SYSTEM|Computer Science, Artificial Intelligence|3|4|16
Automated text analysis in psychology: methods, applications, and future developments|2015|Recent years have seen rapid developments in automated text analysis methods focused on measuring psychological and demographic properties. While this development has mainly been driven by computer scientists and computational linguists, such methods can be of great value for social scientists in general, and for psychologists in particular. In this paper, we review some of the most popular approaches to automated text analysis from the perspective of social scientists, and give examples of their applications in different theoretical domains. After describing some of the pros and cons of these methods, we speculate about future methodological developments, and how they might change social sciences. We conclude that, despite the fact that current methods have many disadvantages and pitfalls compared to more traditional methods of data collection, the constant increase of computational power and the wide availability of textual data will inevitably make automated text analysis a common tool for psychologists.|automated text analysis; psychological variables; demographics; technology; big data; psycho-informatics|LATENT SEMANTIC ANALYSIS; LANGUAGE USE; AUTHORSHIP ATTRIBUTION; MORAL FOUNDATIONS; LINGUISTIC STYLES; SEPTEMBER 11; KNOWLEDGE; WORDS; DOCUMENTS; SCIENCES|Linguistics; Language \& Linguistics; Psychology, Experimental|12|3|16
Linguistic dimensions of impromptu test essays compared with successful student disciplinary writing: Effects of language background, topic, and L2 proficiency|2015|One important validity question with regard to writing assessment is the degree to which performance on a timed writing test can predict performance on future academic writing. Recent developments in corpus linguistics have allowed scholars to describe in detail the linguistic features of a variety of academic texts, including genres of disciplinary writing and writing on essay tests, which can aid in answering this question. The purpose of this paper is to compare the linguistic features of test essays written by native and non-native speakers with a comparison corpus of successful student writing across a range of disciplines using Biber's (1988) multidimensional analysis framework. Essays written on two different test prompts were analyzed along dimensions of successful student writing revealed by an analysis of the Michigan Corpus of Upper-level Student Writing (MICUSP) conducted by Hardy and Romer (2013). Results demonstrated that test essays differed in significant ways from disciplinary writing, particularly in the natural and health sciences. Furthermore, language background (native vs. non-native), prompt, and language proficiency (i.e., essay scores) were systematically related to scores on all four dimensions. Implications for pedagogy and language assessment are discussed. (C) 2015 Published by Elsevier Ltd.|Multi-dimensional analysis; Writing assessment; Validation|COMPLEXITY; GRAMMAR; ENGLISH; GENRE|Education \& Educational Research; Linguistics; Language \& Linguistics|6|2|16
A comparative study of evolving fuzzy grammar and machine learning techniques for text categorization|2015|Several methods have been studied in text categorization and mostly are inspired by the statistical distribution features in the texts, such as the implementation of Machine Learning (ML) methods. However, there is no work available that investigates the performance of ML-based methods against the text expression-based method, especially for incident and medical case categorization. Meanwhile, these two domains are becoming ever more popular, due to a growing interest of automation in security intelligence and health services. This paper presents a text expression-based method called Evolving Fuzzy Grammar (EFG) and evaluates its performance against the conventional ML methods of Na < ve Bayes, support vector machine, -nearest neighbor, adaptive booting, and decision tree. The incident dataset used is a real dataset that was taken from the World Incidents Tracking System, while ImageCLEF 2009 was used as the source for radiology case reports. The results suggested variations of strength and weakness of each method in both categorization tasks, where a standard evaluation technique (i.e., recall, precision, and -measure) was used. In both domains, the SMO and IBk methods were the best, while AdaBoost was the worst. It was also observed that the medical dataset was easier to categorize than the incident. Although EFG was ranked second lowest, it obtained the highest precision score in the bombing categorization, the highest score in armed attack recall, and was averagely ranked in the top three for the medical case categorization. It was also noted that the text expression-based method used in EFG was the most verbose and expressive, when compared to the ML methods. This indicates that EFG is a viable method in text categorization and may serve as an alternative approach to such a task.|Text categorization; Text expression; Evolving fuzzy grammar; Machine learning; Incidents; Medical|INFORMATION EXTRACTION; WIKIPEDIA KNOWLEDGE; SEMANTIC ANALYSIS; CLASSIFICATION; SYSTEM; FEATURES; MODEL; RULE|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|0|2|16
Exploring Political Ideologies of Senators With Semantic Analysis Tools: Further Validation of CASS|2015|Phrase counting is an effective approach to capturing individual differences in language use. Specific phrases (e.g., war on terrorism) powerfully predict a congressperson's political ideology. The question addressed in this study is whether there is additional information that can be extracted from the indirect relations among words in large Senatorial speech databases. Given that direct co-occurrence of target words is a very low likelihood event, we focus on higher-order co-occurrence (e.g., whether two target words appear in similar semantic contexts), using the free software Contrast Analysis of Semantic Similarity (CASS) to compute individual differences (www.casstools.org). We describe how we used CASS in detail and provide a tutorial. Using text transcripts from 86 Senators, totaling over 150 million words, we demonstrate that CASS can account for political ideology above and beyond phrase counts. By complementing phrase count methods, CASS may be a useful method for the digital humanities and social sciences more generally.|CASS; co-occurrence; political ideology; semantic space models|PERSONALITY; INFORMATION|Communication; Linguistics; Psychology, Social|2|2|16
Data Richness Trade-Offs Between Face-to-Face, Online Audiovisual, and Online Text-Only Focus Groups|2015|This study offers an examination of data richness (i.e., topic-related data, topic unrelated data, researcher ratings of data richness, word count, and linguistic characteristics of data richness) trade-offs between face-to-face (FTF), online text-only and online audiovisual focus group mediums. Two focus group sessions were held for each type of medium. Data were analyzed using systematic content analysis and Linguistic Inquiry and Word Count. Findings showed that although online audiovisual focus groups show potential for producing data similar in richness to FTF focus groups, researchers should carefully consider the potential distractions that manifested in this study as a result of the medium itself, likely due to its novelty as a group communication medium. Online text-only groups did not facilitate rich data, as operationalized in this study, and also had a lower amount of data related to the topic of the groups due to more socializing and off-topic discussion. As the first study to empirically examine the potential of data from focus groups facilitated via webcam (online audiovisual), it concludes, the technology offers similar data richness to FTF focus groups.|focus groups; online research; qualitative data richness; data quality; computer-based qualitative data collection|QUALITATIVE RESEARCH; DECISION-MAKING; COMMUNICATION; RESEARCHERS; VALIDITY|Computer Science, Interdisciplinary Applications; Information Science \& Library Science; Social Sciences, Interdisciplinary|6|3|16
Lexical difficulty and diversity of American elementary school reading textbooks Changes over the past century|2014|This paper reports the results of a detailed historical analysis of changes in lexical difficulty and diversity of the language used in elementary school reading textbooks widely adopted in the United States during the period 1905-2004. Applying a variety of analytical measures to a 5-million-word corpus of third-grade reading texts, we revisit the patterns of change in lexical complexity reported in previous research and examine the trends in more recent decades that have not yet been thoroughly explored. Our findings provide us with rich evidence for challenging some of the historical critiques of the American reading curriculum, and they have important implications for both educational history and policy.|educational history; lexical difficulty; lexical diversity; reading textbooks|SYNTACTIC COMPLEXITY; VOCABULARY; COMPREHENSION; INSTRUCTION; LANGUAGE; SCORES; TEXT|Linguistics; Language \& Linguistics|0|5|16
SEED Framework of Early Language Development: The Dynamic Coupling of Infant-Caregiver Perceiving and Acting Forms a Continuous Loop during Interaction|2013|The research and theory described here evolved from fine-grained descriptions of early word learning based on videotapes of infants and their families in the US and Mexico. This naturalistic approach led to theorizing about the perceptual processes underlying the caregiver's role in assisting infants' early word learning. Caregivers educate infants' attention by synchronizing the saying of a word with a dynamic gesture, a show, in which they display the object/referent to the infant. By making this perceptual information prominent, infants can detect an amodal invariant across gesture and speech. Doing so brackets the word and object within the auditory and visual flow of events and constitutes the basis for perceiving them as belonging together. Stemming from the earlier naturalistic work, we designed eye-tracking experiments to test three hypotheses: 1) infants will attend more to an object when the referring word is said if the speaker uses a dynamic, synchronized show gesture, rather than a static or asynchronous gesture; 2) a show gesture will be most effective in drawing attention away from the mouth to the object when the referring word is spoken; and 3) the use of a show gesture will lead to enhanced word learning. These experiments confirmed our hypotheses, establishing that infants detected referent-word relations best when the speaker used a show gesture. These results support the SEED Framework of early language development which delineates how the situated, culturally embodied, emergent, and distributed character of caregiver-infant interaction nurtures communicative behavior. The ability to communicate germinates and takes root during social interaction, as the dynamically-coupled perceiving-and-acting of infants and caregivers forms a continuous loop, each of them unceasingly affecting the other. These findings have implications for the design of cognitive systems in autonomous robots, especially ``tutor spotting{''} and detecting ``acoustic packages.{''|Human voice; learning system; natural language processing; psychology; speech processing|JOINT VISUAL-ATTENTION; SPEECH; COMPREHENSION; PERCEPTION; SYNCHRONY; ORIGINS; OBJECTS; MODEL|Computer Science, Artificial Intelligence; Robotics; Neurosciences|3|0|16
Independent component analysis for near-synonym choice|2013|Despite their similar meanings, near-synonyms may have different usages in different contexts, and the development of algorithms that can verify whether near-synonyms do match their given contexts has been the focus of increasing concern. Such algorithms have many applications such as query expansion for information retrieval (IR), alternative word selection for writing support systems, and (near-)duplicate detection for text summarization. In this paper, we propose a framework that incorporates latent semantic analysis (ISA) and independent component analysis (ICA) to automatically select suitable near-synonyms according to the given context. LSA is used to discover useful latent features that do not frequently occur in the contexts of near-synonyms, and ICA is used to estimate a set of independent components by minimizing the dependence between features. An SVM classifier is then trained with the independent components for best near-synonym prediction. In experiments, we evaluate the proposed method on both Chinese and English sentences, and compare its performance to state-of-the-art supervised and unsupervised methods. Experimental results show that training on the independent components that contain useful contextual features with minimized term dependence can improve the classifiers' ability to discriminate among near-synonyms, thus yielding better performance. (C) 2013 Elsevier B.V. All rights reserved.|Near-synonym choice; Independent component analysis; Information retrieval; Natural language processing|EXPANSION; TEXT; ONTOLOGY; INTERNET|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|6|1|16
Assessing reading comprehension in adolescent low achievers: Subskills identification and task specificity|2013|On the basis of a validation study of a new test for assessing low-achieving adolescents' reading comprehension skills - the SALT-reading - we analyzed two issues relevant to the field of reading test development. Using the test results of 200 seventh graders, we examined the possibility of identifying reading comprehension subskills and the effects of task specificity on test reliability. Regarding the former, we distinguished three subskills indicating different levels of understanding ('retrieving', `interpreting', `reflecting'). However, confirmatory factor analyses did not support the presence of these subskills. Task specificity refers to the situation that different tasks within a test are not uniformly difficult for individual test takers, which constitutes a form of error negatively influencing test reliability. However, Generalizability Theory analysis showed that such task-specific effects did not occur: the reliability of the SALT-reading was primarily affected by error associated with the score variance within tasks.|Generalizability Theory; low achievers; reading assessment; reading comprehension; reading subskills; Structural Equation Modeling; task specificity|QUESTION; MODEL; TEXT|Linguistics; Language \& Linguistics|6|3|16
A classification of errors in lay comprehension of medical documents|2012|Emphasis on participatory medicine requires that patients and consumers participate in tasks traditionally reserved for healthcare providers. This includes reading and comprehending medical documents, often but not necessarily in the context of interacting with Personal Health Records (PHRs). Research suggests that while giving patients access to medical documents has many benefits (e.g., improved patient-provider communication), lay people often have difficulty understanding medical information. Informatics can address the problem by developing tools that support comprehension: this requires in-depth understanding of the nature and causes of errors that lay people make when comprehending clinical documents. The objective of this study was to develop a classification scheme of comprehension errors, based on lay individuals' retellings of two documents containing clinical text: a description of a clinical trial and a typical office visit note. While not comprehensive, the scheme can serve as a foundation of further development of a taxonomy of patients' comprehension errors. Eighty participants, all healthy volunteers, read and retold two medical documents. A data-driven content analysis procedure was used to extract and classify retelling errors. The resulting hierarchical classification scheme contains nine categories and 23 subcategories. The most common error made by the participants involved incorrectly recalling brand names of medications. Other common errors included misunderstanding clinical concepts, misreporting the objective of a clinical research study and physician's findings during a patient's visit, and confusing and misspelling clinical terms. A combination of informatics support and health education is likely to improve the accuracy of lay comprehension of medical documents. Published by Elsevier Inc.|Information literacy; Clinical documentation; Consumer health; Patients; Classification; Content analysis|PERSONAL HEALTH RECORDS; SELF-REPORTED HISTORY; INFORMED-CONSENT; INFORMATION; PHYSICIANS; CARE; TAXONOMY; CANCER; EXPERIENCES; READABILITY|Computer Science, Interdisciplinary Applications; Medical Informatics|13|1|16
Contested Collective Intelligence: Rationale, Technologies, and a Human-Machine Annotation Study|2012|We propose the concept of Contested Collective Intelligence (CCI) as a distinctive subset of the broader Collective Intelligence design space. CCI is relevant to the many organizational contexts in which it is important to work with contested knowledge, for instance, due to different intellectual traditions, competing organizational objectives, information overload or ambiguous environmental signals. The CCI challenge is to design sociotechnical infrastructures to augment such organizational capability. Since documents are often the starting points for contested discourse, and discourse markers provide a powerful cue to the presence of claims, contrasting ideas and argumentation, discourse and rhetoric provide an annotation focus in our approach to CCI. Research in sensemaking, computer-supported discourse and rhetorical text analysis motivate a conceptual framework for the combined human and machine annotation of texts with this specific focus. This conception is explored through two tools: a social-semantic web application for human annotation and knowledge mapping (Cohere), plus the discourse analysis component in a textual analysis software tool (Xerox Incremental Parser: XIP). As a step towards an integrated platform, we report a case study in which a document corpus underwent independent human and machine analysis, providing quantitative and qualitative insight into their respective contributions. A promising finding is that significant contributions were signalled by authors via explicit rhetorical moves, which both human analysts and XIP could readily identify. Since working with contested knowledge is at the heart of CCI, the evidence that automatic detection of contrasting ideas in texts is possible through rhetorical discourse analysis is progress towards the effective use of automatic discourse analysis in the CCI framework.|collective intelligence; discourse; human annotation; knowledge mapping; machine annotation; learning; sensemaking; network visualization; social software; social annotation|ARGUMENTATION; REFLECTION; COGNITION; DESIGN; WORLD; SENSE; TOOLS|Computer Science, Interdisciplinary Applications|9|0|16
Supporting geographically-aware web document foraging and sensemaking|2011|This paper reports on the development and application of strategies and tools for geographic information seeking and knowledge building that leverages unstructured text resources found on the web. Geographic knowledge building from unstructured web sources starts with web document foraging during which the quantity, scope and diversity of web-based information create incredible cognitive burdens on an analyst's or researcher's ability to judge information relevancy. Determining information relevancy is ultimately a process of sensemaking. In this paper, we present our research on visually supporting web document foraging and sensemaking. In particular, we present the Sense-of-Place (SensePlace) analytic environment. The scientific goal of SensePlace is to visually and computationally support analyst sensemaking with text artifacts that have potential place, time, and thematic relevance to an analytical problem through identification and visual highlighting of named entities (people, places, times, and organizations) in documents, automated inference to determine document relevance using stored knowledge, and a visual interface with coupled geographic map, timeline, and concept graph displays that are used to contextualize the contexts of potentially relevant documents. We present the results of a case study analysis using SensePlace to uncover potential population migration, geopolitical, and other infectious disease dynamics drivers for measles and other epidemics in Niger. Our analysis allowed us to demonstrate how our approach can support analysis of complex situations along (a) multi-scale geographic dimensions (i.e., vaccine coverage areas), (b) temporal dimensions (i.e., seasonal population movement and migrations), and (c) diverse thematic dimensions (effects of political upheaval, food security, transient movement, etc.). (C) 2011 Elsevier Ltd. All rights reserved.|Visual analytics; Sensemaking; Information foraging; Geographic information retrieval; Infectious disease dynamics; Niger|INFORMATION; DYNAMICS; SYSTEMS; MODEL|Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research \& Management Science|10|1|16
Working at cross-purposes: multiple producers and text-image relations|2011|This paper examines how linguistic and image elements in a text may work at cross-purposes, so that, despite an apparent overall visual-verbal coherence, one semiotic resource undermines the message of another. This effect has implications for the study of intersemiosis and the making of meaning that occurs when semiotic resources, such as language, image, and sound combine in multimodal discourse, and also indicates that a multimodal approach, involving the study of language with other resources, is necessary to fully analyze contemporary discourse practices. In addition, the analysis in this paper aims to situate the competing discourses of science and the media at work in the analyzed text within the context of existing research findings on the communication of information relevant to the climate change debate. Our argument is illustrated by an analysis of an article appearing in New Scientist magazine and its Web site, and makes use of three established semiotic frameworks of analysis: Halliday and Matthiessen's (2004) systemic functional theory, Martin and White's (2005) appraisal theory, and Kress and van Leeuwen's (2006) visual grammar.|semiotic resource; multimodal analysis; intersemiosis; text-image relations; climate change|GLOBAL CLIMATE-CHANGE; MASS-MEDIA; UNCERTAINTY; DISCOURSES; KNOWLEDGE; SCIENCE; CLAIMS|Communication; Linguistics; Language \& Linguistics|1|2|16
Leveraging bilingualism to accelerate English reading comprehension|2011|The purpose of this study was to examine how fourth-grade Spanish-English speaking bilingual students in the USA participated differently in English-as-a-second-language (ESL) literature groups when they were invited to use all of their linguistic resources vs. when they were restricted to communicate in English only. The theoretical underpinning was that a student's learning burden is lessened when text comprehension is facilitated by access to all previous knowledge regardless of the language of acquisition. This mixed methods study employed a within group repeated measures design in which each student experienced all treatment conditions and completed a comprehension measurement activity following each literacy event. Data included 21 hours of audio-taped student dialog and analyses of 172 written recalls. Findings include the understanding that the opportunity to teach and learn is stifled when educators insist on strict separation of languages, and there is a strong interaction between language of recall and the topic of the reading.|biliteracy; ESL; language choice|LANGUAGE; STRATEGIES; CLASSROOM|Education \& Educational Research; Linguistics; Language \& Linguistics|7|1|16
The analysis of Toulmin elements in Chinese EFL university argumentative writing|2010|This descriptive study aims to analyze structures of argumentative papers written by second language (L2) university students, based on the adapted Toulmin (1958, 2003) model of argument structure constituting six elements (i.e., claim, data, counterargument claim, counterargument data, rebuttal claim, and rebuttal data). It also investigates how the uses of these Toulmin elements are related to the overall quality of argumentative papers. One hundred and thirty-three second-year university English-majors in a Chinese university wrote an argumentative paper in English after reading two preselected English opinion pieces with opposing views on the same controversial topic. The Toulmin elements in the students' papers were analyzed and the quality of papers was assessed. It was found that an average paper had at least one claim supported by four pieces of data. However, there were far fewer uses of counterargument claim, counterargument data, rebuttal claim, and rebuttal data in the papers, although their uses were significant predictors of the overall quality of argumentative papers. Potential implications of the findings are discussed as they pertain to L2 argumentative writing pedagogy. (C) 2010 Elsevier Ltd. All rights reserved.|Argumentative writing; The Toulmin model of argument structure; Chinese undergraduate English-majors|STUDENTS; GOAL; AGREEMENT; KNOWLEDGE; EDUCATION; THINKING; TEXT; L1|Education \& Educational Research; Linguistics|10|3|16
Learning to assign lexical stress during reading aloud: Corpus, behavioral, and computational investigations|2010|Models of reading aloud have tended to focus on the mapping between graphemes and phonemes in monosyllables. Critical adaptations of these models are required when considering the reading of polysyllables, which constitute over 90\% of word types in English. In this paper, we examined one such adaptation - the process of stress assignment in learning to read. We used a triangulation of corpus, behavioral, and computational modeling techniques. A corpus analysis of age-appropriate reading materials for children aged 5-12 years revealed that the beginnings and endings of English bisyllabic words are highly predictive of stress position, but that endings are more reliable cues in texts for older children. Children aged 5-12 years revealed sensitivity to both the beginnings and endings when reading nonwords, but older children relied more on endings for determining stress assignment. A computational model that learned to map orthography onto stress showed the same age-related trajectory as the children when assigning stress to nonwords. These results reflect the gradual process of learning the statistical properties of written input and provide key constraints for adequate models of reading aloud. Crown Copyright (C) 2010 Published by Elsevier Inc. All rights reserved.|Lexical stress; Stress assignment; Probabilistic cues; Statistical learning; Orthography; Reading; Reading aloud; Reading acquisition; Reading development; Visual word recognition|SPELLING-SOUND CONSISTENCY; VISUAL WORD RECOGNITION; DEVELOPMENTAL DYSLEXIA; LANGUAGE IMPAIRMENT; ORTHOGRAPHIC CUES; ENGLISH; MODEL; SENSITIVITY; CHILDREN; GREEK|Linguistics; Psychology; Psychology, Experimental|67|0|16
Commercial Internet filters: Perils and opportunities|2010|Organizations are becoming increasingly aware of Internet abuse in the workplace. Such abuse results in loss of workers' productivity, network congestion, security risks, and legal liabilities. To address this problem, organizations have started to adopt Internet usage policies, management training, and filtering software. Several commercial Internet filters are experiencing an increasing number of organizational adoptions. These products mainly rely on black lists, white lists, and keyword/profile matching to filter out undesired web pages. In this paper, we describe three top-ranked commercial Internet filters - CYBERSitter, Net Nanny. and CyberPatrol - and evaluate their performance in the context of an Internet abuse problem. We then propose a text mining approach to address the problem and evaluate its performance using six different classification algorithms: naive Bayes, multinominal naive Bayes, support vector machine, decision tree, k-nearest neighbor, and neural network. The evaluation results point to the perils of using commercial Internet filters on one hand, and to the prospects of using text mining on the other. The proposed text mining approach Outperforms the commercial filters. We discuss the possible reasons for the relatively poor performance of the filters and the steps that could be taken to improve their performance. (C) 2009 Elsevier B.V. All rights reserved.|Internet abuse; Internet filters; Text mining; Text classification|TEXT CATEGORIZATION; LEARNING APPROACH; WEB USAGE; CLASSIFICATION; WORKPLACE; ABUSE; SYSTEM; WORK|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|10|1|16
L1 use during L2 writing: An empirical study of a complex phenomenon|2009|This study examined writers' use of their first language (L1) while writing in their second language (L2). Twenty students each wrote four short argumentative essays in their L1 (Dutch) and four in their L2 (English) under think-aloud conditions. We analysed whether L1 use varied between writers and tasks, and whether it was related to general writing proficiency, L2 proficiency, and L2 text quality. The analysis focused on the occurrence of a number of conceptual activities, including Generating ideas, planning, and Metacomments. Results indicate that all participants used their L1 while writing in their L2 to some extent, although this varied among conceptual activities. In addition, L2 proficiency was directly related to L2 text quality but was not related to the occurrence of conceptual activities either in L1 or L2. General writing proficiency, on the other hand, has a negative influence oil L1 Use during L2 writing and a positive effect on L2 use during L2 writing. L1 use during L2 writing is negatively related to L2 text quality, at least for Metacomments. Finally, L2 use appears to be positively related to L2 text quality for Goal setting, Generating ideas. and Structuring, but negatively related to L2 text quality for Self-instructions and Metacomments. The theoretical relevance of these findings is also discussed. (C) 2009 Elsevier Inc. All rights reserved.|Cognitive activities; Conceptual activities; Generating ideas; Language switching; L1 use; L1 writing; L2 proficiency; L2 writing; Metacomments; Planning; Text quality; Writing process|1ST LANGUAGE; 2ND-LANGUAGE PROFICIENCY; LINGUISTIC KNOWLEDGE; COMPOSING PROCESSES; FOREIGN-LANGUAGE; WRITERS; STRATEGIES; TEXT|Linguistics|33|1|16
Pair versus individual writing: Effects on fluency, complexity and accuracy|2009|The assessment of oral language is now quite commonly done in pairs or groups, and there is a growing body of research which investigates the related issues (e.g. May, 2007). Writing generally tends to be thought of as an individual activity, although a small number of studies have documented the advantages of collaboration in writing in the second language Classroom (e.g. DiCamilla \& Anton, 1997 Storch, 2005; Swain \& Lapkin, 1998). Particularly in university contexts, group or pair assignments are widely used in many disciplines. In addition, collaborative writing Could be used in second language classroom assessment contexts as formative assessment. However, research which compares texts produced by learners collaboratively to texts produced individually, and the implications of this for assessment practices, is rare. This study is a first step in the investigation of using collaborative writing in second language contexts and comparing the performance of two groups of second language learners: one group worked individually, and the other group worked in pairs. When writing in pairs, each pair produced a single text. All participants completed one writing task: an argumentative essay. The performances of the individuals (N = 49) and the pairs (N = 48) were compared on detailed discourse analytic measures of fluency, complexity and accuracy. This comparison revealed that collaboration impacted positively on accuracy, but did not affect fluency and complexity. A detailed analysis of the pair transcripts recorded during the writing activity provides insights into the ways in which pairs work together, and the foci of their endeavour. The implications of these findings for in-class assessment of second language writing are discussed.|classroom assessment; pairwork; writing|STUDENTS|Linguistics; Language \& Linguistics|61|3|16
Annotating expressions of opinions and emotions in language|2005|This paper describes a corpus annotation project to study issues in the manual annotation of opinions, emotions, sentiments, speculations, evaluations and other private states in language. The resulting corpus annotation scheme is described, as well as examples of its use. In addition, the manual annotation process and the results of an inter-annotator agreement study on a 10,000-sentence corpus of articles drawn from the world press are presented.|affect; attitudes; corpus annotation; emotion; natural language processing; opinions; sentiment; subjectivity|REPRESENTATION; BELIEF; TEXT|Computer Science, Interdisciplinary Applications|281|3|16
Automatic recognition of disorders, findings, pharmaceuticals and body structures from clinical text: An annotation and machine learning study|2014|Automatic recognition of clinical entities in the narrative text of health records is useful for constructing applications for documentation of patient care, as well as for secondary usage in the form of medical knowledge extraction. There are a number of named entity recognition studies on English clinical text, but less work has been carried out on clinical text in other languages. This study was performed on Swedish health records, and focused on four entities that are highly relevant for constructing a patient overview and for medical hypothesis generation, namely the entities: Disorder, Finding, Pharmaceutical Drug and Body Structure. The study had two aims: to explore how well named entity recognition methods previously applied to English clinical text perform on similar texts written in Swedish; and to evaluate whether it is meaningful to divide the more general category Medical Problem, which has been used in a number of previous studies, into the two more granular entities, Disorder and Finding. Clinical notes from a Swedish internal medicine emergency unit were annotated for the four selected entity categories, and the inter-annotator agreement between two pairs of annotators was measured, resulting in an average F-score of 0.79 for Disorder, 0.66 for Finding, 0.90 for Pharmaceutical Drug and 0.80 for Body Structure. A subset of the developed corpus was thereafter used for finding suitable features for training a conditional random fields model. Finally, a new model was trained on this subset, using the best features and settings, and its ability to generalise to held-out data was evaluated. This final model obtained an F-score of 0.81 for Disorder, 0.69 for Finding, 0.88 for Pharmaceutical Drug, 0.85 for Body Structure and 0.78 for the combined category Disorder + Finding. The obtained results, which are in line with or slightly lower than those for similar studies on English clinical text, many of them conducted using a larger training data set, show that the approaches used for English are also suitable for Swedish clinical text. However, a small proportion of the errors made by the model are less likely to occur in English text, showing that results might be improved by further tailoring the system to clinical Swedish. The entity recognition results for the individual entities Disorder and Finding show that it is meaningful to separate the general category Medical Problem into these two more granular entity types, e.g. for knowledge mining of co-morbidity relations and disorder-finding relations. (C) 2014 The Authors. Published by Elsevier Inc.|Named entity recognition; Corpora development; Clinical text processing; Disorder; Finding; Swedish|MEDICATION INFORMATION; DISCHARGE SUMMARIES; EXTRACTION; CHALLENGE; AGREEMENT|Computer Science, Interdisciplinary Applications; Medical Informatics|14|1|15
Tracking movement toward academic language in multilingual classrooms|2014|Learning history depends heavily on language and cultural references that students supposedly already know. Understanding how young people from multilingual backgrounds develop language in content area classrooms can help us better assist students to achieve higher levels of literacy needed to understand discipline-specific knowledge. Using the conceptual framework and analytic tools of Systemic Functional Linguistics (Halliday, 1994) we analyze the changes in lexico-grammatical and discourse-semantic choices in learners' responses to two primary source history texts as indexes of academic language development. The data comes from a larger study that explored the integration of text analysis to history lessons focusing on primary sources and documenting the impact of the intervention on students' disciplinary literacy development. In this paper, we focus on the configuration of linguistic indices that serve to track academic language development. The analysis shows changes in students' linguistic choices that realize ways of reasoning and arguing typical of history. The findings show that it is important to document academic language development in qualitative ways that capture the complexity of development considering constellations of linguistic features and how they function to serve discipline-specific ways of making meaning. (C) 2014 Elsevier Ltd. All rights reserved.|Disciplinary literacy; History; Functional grammar; English for academic purposes; Secondary school; Multilingual classrooms|CONTENT-AREA LITERACY; HISTORY; DISCOURSE|Education \& Educational Research; Linguistics; Language \& Linguistics|7|1|15
Resisting marginalisation changing representations of migrants and refugees in UK text and talk since the 1960s|2014|In this article, I chart ways in which changing representations of migrants and refugees in the UK have contributed to their marginalisation. The article shows the findings from a study of the role immigrant organisations played in discussions of immigration control since the 1960s. The findings suggest that language about migrants and refugees has become both more marginalising and more difficult to challenge due to its increased complexity, with the increasing division of migrants into `good' and `bad' subgroups; an increased emphasis on `the nation'; and the increasing dissociation of discussions of immigration control from issues of race and racism, accompanied by `antiracist' argumentation strategies and a denial of racism. The findings also suggest that speakers wishing to challenge such language, although able to present oppositional voices, may have difficulty getting those voices heard unless they in turn adopt aspects of the marginalising text and talk they wish to oppose.|migrants; refugees; representation; opposition; resistance; language; race; racism; antiracism; immigrant organisations|CRITICAL DISCOURSE ANALYSIS; ASYLUM-SEEKERS; MULTICULTURALISM; CONSTRUCTIONS; PRESS|Linguistics; Language \& Linguistics|0|2|15
Gender-specification and occupational nouns: has linguistic change occurred in job advertisements since the French feminisation reforms?|2014|This article examines the representation of the sexes in the language of job advertisements in France, given legislation outlawing gender discrimination in employment and the consequent feminist language reform initiatives. Specifically, it analyses a data set collected from the employment sections of the French national newspapers Le Figaro, Le Monde and Aujourd'hui en France, focusing on linguistic strategies that reflect that the advertised position is open to both female and male applicants. The analysis shows that in most cases the gender bias has been removed by means of the minimalist strategy of adding the descriptor H/F (homme/femme = man/woman) to a masculine occupational noun. The analysis also reveals that a mere one-third of the advertisements are truly gender-inclusive, using epicene occupational nouns, or nouns in both the feminine and the masculine forms, and gender-inclusive text, or focusing on the tasks to be accomplished rather than on the job applicant.|FEMINIST LANGUAGE PLANNING; FRENCH LANGUAGE; JOB ADVERTISEMENTS; LANGUAGE AND GENDER; OCCUPATIONAL NOUNS|FEMININE|Linguistics; Language \& Linguistics; Women's Studies|4|2|15
Zipf's law and the grammar of languages: A quantitative study of Old and Modern English parallel texts|2014|This paper reports a quantitative analysis of the relationship between word frequency distributions and morphological features in languages. We analyze a commonly-observed process of historical language change: The loss of inflected forms in favour of `analytic' periphrastic constructions. These tendencies are observed in parallel translations of the Book of Genesis in Old English and Modern English. We show that there are significant differences in the frequency distributions of the two texts, and that parts of these differences are independent of total number of words, style of translation, orthography or contents. We argue that they derive instead from the trade-off between synthetic inflectional marking in Old English and analytic constructions in Modern English. By exploiting the earliest ideas of Zipf, we show that the syntheticity of the language in these texts can be captured mathematically, a property we tentatively call their grammatical fingerprint. Our findings suggest implications for both the specific historical process of inflection loss and more generally for the characterization of languages based on statistical properties.|Zipf's law; vocabulary growth curves; diachronic corpus linguistics; syntheticity; analyticity; parallel texts; historical linguistics; Old English|DISTRIBUTIONS|Linguistics; Language \& Linguistics|5|0|15
What can software tell us about political candidates? A critical analysis of a computerized method for political discourse|2014|This study evaluates a computerized text analysis program, Linguistic Inquiry and Word Count (LIWC), by investigating the relationship between the discourse and personalities of presidential and vice presidential candidates in the 2008 presidential election in the United States. Analyses of speech samples (N = 141) from Barack Obama, Joe Biden, John McCain, and Sarah Palin were conducted using LIWC. The results show that in the context of political speech events, such as media interviews, political candidates make unique linguistic choices, which may be interpreted as displaying distinct personality traits. Yet, despite the statistical significance of the results, there are salient limitations of utilizing computerized methodologies to analyze political speech events, such as the limited interpretative capacity of the software to understand pragmatic and contextual language use.|LIWC; political discourse; personality; political election|LANGUAGE USE; PRESS-CONFERENCES; LINGUISTIC STYLES; TEXT ANALYSIS; WORDS; PERSONALITY|Linguistics; Language \& Linguistics|4|2|15
Prior and contextual emotion of words in sentential context|2014|A set of words labeled with their prior emotion is an obvious place to start on the automatic discovery of the emotion of a sentence, but it is clear that context must also be considered. It may be that no simple function of the labels on the individual words captures the overall emotion of the sentence; words are interrelated and they mutually influence their affect-related interpretation. It happens quite often that a word which invokes emotion appears in a neutral sentence, or that a sentence with no emotional word carries an emotion. This could also happen among different emotion classes. The goal of this work is to distinguish automatically between prior and contextual emotion, with a focus on exploring features important in this task. We present a set of features which enable us to take the contextual emotion of a word and the syntactic structure of the sentence into account to put sentences into emotion classes. The evaluation includes assessing the performance of different feature sets across multiple classification methods. We show the features and a promising learning method which significantly outperforms two reasonable baselines. We group our features by the similarity of their nature. That is why another facet of our evaluation is to consider each group of the features separately and investigate how well they contribute to the result. The experiments show that all features contribute to the result, but it is the combination of all the features that gives the best performance. (C) 2013 Elsevier Ltd. All rights reserved.|Sentiment analysis; Polarity; Emotion; Prior emotion; Contextual emotion; Syntactic features; Natural language processing; Machine learning|EXPRESSIONS; MODEL; TEXT|Computer Science, Artificial Intelligence|15|0|15
Inferring social nature of conversations from words: Experiments on a corpus of everyday telephone conversations|2014|Language is being increasingly harnessed to not only create natural human-machine interfaces but also to infer social behaviors and interactions. In the same vein, we investigate a novel spoken language task, of inferring social relationships in two-party conversations: whether the two parties are related as family, strangers or are involved in business transactions. For our study, we created a corpus of all incoming and outgoing calls from a few homes over the span of a year. On this unique naturalistic corpus of everyday telephone conversations, which is unlike Switchboard or any other public domain corpora, we demonstrate that standard natural language processing techniques can achieve accuracies of about 88\%, 82\%, 74\% and 80\% in differentiating business from personal calls, family from non-family calls, familiar from unfamiliar calls and family from other personal calls respectively. Through a series of experiments with our classifiers, we characterize the properties of telephone conversations and find: (a) that 30 words of openings (beginnings) are sufficient to predict business from personal calls, which could potentially be exploited in designing context sensitive interfaces in smart phones; (b) our corpus-based analysis does not support Schegloff and Sack's manual analysis of exemplars in which they conclude that pre-closings differ significantly between business and personal calls - closing fared no better than a random segment; and (c) the distribution of different types of calls are stable over durations as short as 1-2 months. In summary, our results show that social relationships can be inferred automatically in two-party conversations with sufficient accuracy to support practical applications. (C) 2013 Elsevier Ltd. All rights reserved.|Conversation telephone speech; Social networks; Social relationships|EMOTION; SPEECH|Computer Science, Artificial Intelligence|2|0|15
Unsupervised mining of frequent tags for clinical eligibility text indexing|2013|Clinical text, such as clinical trial eligibility criteria, is largely underused in state-of-the-art medical search engines due to difficulties of accurate parsing. This paper proposes a novel methodology to derive a semantic index for clinical eligibility documents based on a controlled vocabulary of frequent tags, which are automatically mined from the text. We applied this method to eligibility criteria on Clinical-Trials.gov and report that frequent tags (1) define an effective and efficient index of clinical trials and (2) are unlikely to grow radically when the repository increases. We proposed to apply the semantic index to filter clinical trial search results and we concluded that frequent tags reduce the result space more efficiently than an uncontrolled set of UMLS concepts. Overall, unsupervised mining of frequent tags from clinical text leads to an effective semantic index for the clinical eligibility documents and promotes their computational reuse. (C) 2013 Elsevier Inc. All rights reserved.|Information storage and retrieval; Clinical trials; Tags; Information filtering; Eligibility criteria; Controlled vocabulary|INFORMATION-RETRIEVAL; BIOMEDICAL TEXT; CRITERIA; REPRESENTATION; EXTRACTION; TRIALS; SEARCH; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|11|0|15
Cultural, linguistic and cognitive issues in teaching the language of literature for emergent bilingual pupils|2013|This article investigates the premise that literary texts use language in aesthetic, imaginative and engaging ways that have considerable potential to extend the learning of bilingual pupils. It draws on research findings from a qualitative study that examined the value of developing pedagogic practices for emergent bilingual learners at the interface between language and literature. The educational research is framed from an ethnographic perspective and employs critical discourse analysis of classroom interaction. The research addresses the current gap in studies of bilingual pupils' learning in majority language classrooms at secondary level. The findings show the risk of placing bilingual learners in low-ability sets where their exposure to literature may be limited and language skills are frequently taught in isolation. In contrast, bilingual learners who were given the opportunity to use language creatively and had access to a range of texts slowly became attuned to the musicality of the new language and developed deeper word knowledge. The findings indicate that through drawing on bilingual learners' contextual knowledge and making space for cross-cultural discourses around texts, these learners can understand both the local and global in acts of reading. The research points to the need for a pluralistic pedagogy in learning literacies.|pedagogy; emergent bilingual learners; language of literature; classroom interaction; acts of reading|MULTILITERACIES|Education \& Educational Research; Linguistics; Language \& Linguistics|2|0|15
Variation of English business e-mails in Asian countries|2013|The overall aim of this paper is to detect whether there is language variation in a setting such as international business communication, in which interaction is expected to be precise and concise. In order to achieve this, the research aims of this paper are, first, to detect whether there is variation in the internal organization of e-mails; second, to analyse the moves and steps in the e-mails (Swales, 1990; Bhatia, 1993) and the changes in the organization patterns; and, third, to establish whether the variation in the internal organization and the moves of the e-mails interfered with the exchange of ideas. The corpus used in this study was made up of authentic texts, consisting of one hundred e-mails, written by business managers from India and China, who communicate in English with their counterparts in order to report business issues at their offices, which are subsidiaries of an international company specialising in the manufacture of machinery. Firstly, we analysed the moves of the corpus taking into consideration the standard structure of e-mails, following the proposal made by Bhatia (1993). Secondly, we detailed the steps used in Moves 5 and 6 as the non-native speakers of English varied the structure of these moves. Thirdly; we contrasted the results obtained in the analysis of the moves and steps in the e-mails and discussed whether move variation in international business communication is due to the influence of the cultural or linguistic background of the writer. The conclusions show that the influence of the mother tongue of the speakers of English as an international language is changing the use of English in Asian countries.|business English; e-mails; variation; moves; steps|INTERNATIONAL-BUSINESS; NONNATIVE SPEAKERS; GENRE ANALYSIS; LINGUA-FRANCA; COMMUNICATION; STRATEGIES; STUDENTS; CHINESE; MOVES|Linguistics; Language \& Linguistics|2|0|15
Eventual situations for timeline extraction from clinical reports|2013|Objective To identify the temporal relations between clinical events and temporal expressions in clinical reports, as defined in the i2b2/VA 2012 challenge. Design To detect clinical events, we used rules and Conditional Random Fields. We built Random Forest models to identify event modality and polarity. To identify temporal expressions we built on the HeidelTime system. To detect temporal relations, we systematically studied their breakdown into distinct situations; we designed an oracle method to determine the most prominent situations and the most suitable associated classifiers, and combined their results. Results We achieved F-measures of 0.8307 for event identification, based on rules, and 0.8385 for temporal expression identification. In the temporal relation task, we identified nine main situations in three groups, experimentally confirming shared intuitions: within-sentence relations, section-related time, and across-sentence relations. Logistic regression and Naive Bayes performed best on the first and third groups, and decision trees on the second. We reached a 0.6231 global F-measure, improving by 7.5 points our official submission. Conclusions Carefully hand-crafted rules obtained good results for the detection of events and temporal expressions, while a combination of classifiers improved temporal link prediction. The characterization of the oracle recall of situations allowed us to point at directions where further work would be most useful for temporal relation detection: within-sentence relations and linking History of Present Illness events to the admission date. We suggest that the systematic situation breakdown proposed in this paper could also help improve other systems addressing this task.|Natural Language Processing; Information Extraction; Medical Records; Chronology as Topic; Text Mining|INFORMATION EXTRACTION; TEMPORAL INFORMATION; MEDICAL DOCUMENTS; TEXT; IDENTIFICATION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|9|0|15
Towards comprehensive syntactic and semantic annotations of the clinical narrative|2013|Objective To create annotated clinical narratives with layers of syntactic and semantic labels to facilitate advances in clinical natural language processing (NLP). To develop NLP algorithms and open source components. Methods Manual annotation of a clinical narrative corpus of 127606 tokens following the Treebank schema for syntactic information, PropBank schema for predicate-argument structures, and the Unified Medical Language System (UMLS) schema for semantic information. NLP components were developed. Results The final corpus consists of 13091 sentences containing 1772 distinct predicate lemmas. Of the 766 newly created PropBank frames, 74 are verbs. There are 28539 named entity (NE) annotations spread over 15 UMLS semantic groups, one UMLS semantic type, and the Person semantic category. The most frequent annotations belong to the UMLS semantic groups of Procedures (15.71\%), Disorders (14.74\%), Concepts and Ideas (15.10\%), Anatomy (12.80\%), Chemicals and Drugs (7.49\%), and the UMLS semantic type of Sign or Symptom (12.46\%). Inter-annotator agreement results: Treebank (0.926), PropBank (0.891-0.931), NE (0.697-0.750). The part-of-speech tagger, constituency parser, dependency parser, and semantic role labeler are built from the corpus and released open source. A significant limitation uncovered by this project is the need for the NLP community to develop a widely agreed-upon schema for the annotation of clinical concepts and their relations. Conclusions This project takes a foundational step towards bringing the field of clinical NLP up to par with NLP in the general domain. The corpus creation and NLP components provide a resource for research and application development that would have been previously impossible.|Gold Standard Annotations; UMLS; Treebank; Propbank; Natural Language Processing; cTAKES|CORPUS; TEXT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|25|0|15
Improving performance of natural language processing part-of-speech tagging on clinical narratives through domain adaptation|2013|Objective Natural language processing (NLP) tasks are commonly decomposed into subtasks, chained together to form processing pipelines. The residual error produced in these subtasks propagates, adversely affecting the end objectives. Limited availability of annotated clinical data remains a barrier to reaching state-of-the-art operating characteristics using statistically based NLP tools in the clinical domain. Here we explore the unique linguistic constructions of clinical texts and demonstrate the loss in operating characteristics when out-of-the-box part-of-speech (POS) tagging tools are applied to the clinical domain. We test a domain adaptation approach integrating a novel lexical-generation probability rule used in a transformation-based learner to boost POS performance on clinical narratives. Methods Two target corpora from independent healthcare institutions were constructed from high frequency clinical narratives. Four leading POS taggers with their out-of-the-box models trained from general English and biomedical abstracts were evaluated against these clinical corpora. A high performing domain adaptation method, Easy Adapt, was compared to our newly proposed method ClinAdapt. Results The evaluated POS taggers drop in accuracy by 8.5-15\% when tested on clinical narratives. The highest performing tagger reports an accuracy of 88.6\%. Domain adaptation with Easy Adapt reports accuracies of 88.3-91.0\% on clinical texts. ClinAdapt reports 93.2-93.9\%. Conclusions ClinAdapt successfully boosts POS tagging performance through domain adaptation requiring a modest amount of annotated clinical data. Improving the performance of critical NLP subtasks is expected to reduce pipeline error propagation leading to better overall results on complex processing tasks.|Natural Language Processing; NLP; POS Tagging; Domain Adaptation; Clinical Narratives|SAMPLE SELECTION; TEXT; SYSTEM; TAGGER; CORPUS; NLP|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|8|1|15
Development and evaluation of an ensemble resource linking medications to their indications|2013|Objective To create a computable MEDication Indication resource (MEDI) to support primary and secondary use of electronic medical records (EMRs). Materials and methods We processed four public medication resources, RxNorm, Side Effect Resource (SIDER) 2, MedlinePlus, and Wikipedia, to create MEDI. We applied natural language processing and ontology relationships to extract indications for prescribable, single-ingredient medication concepts and all ingredient concepts as defined by RxNorm. Indications were coded as Unified Medical Language System (UMLS) concepts and International Classification of Diseases, 9th edition (ICD9) codes. A total of 689 extracted indications were randomly selected for manual review for accuracy using dual-physician review. We identified a subset of medication-indication pairs that optimizes recall while maintaining high precision. Results MEDI contains 3112 medications and 63343 medication-indication pairs. Wikipedia was the largest resource, with 2608 medications and 34911 pairs. For each resource, estimated precision and recall, respectively, were 94\% and 20\% for RxNorm, 75\% and 33\% for MedlinePlus, 67\% and 31\% for SIDER 2, and 56\% and 51\% for Wikipedia. The MEDI high-precision subset (MEDI-HPS) includes indications found within either RxNorm or at least two of the three other resources. MEDI-HPS contains 13304 unique indication pairs regarding 2136 medications. The mean +/- SD number of indications for each medication in MEDI-HPS is 6.22 +/- 6.09. The estimated precision of MEDI-HPS is 92\%. Conclusions MEDI is a publicly available, computable resource that links medications with their indications as represented by concepts and billing codes. MEDI may benefit clinical EMR applications and reuse of EMR data for research.|medication indications; electronic medical records; Terminology; International Classification of Diseases; Unified Medical Language System; Ontology|ELECTRONIC HEALTH RECORDS; TYPE-2 DIABETES-MELLITUS; RHEUMATOID-ARTHRITIS; PHENOME-WIDE; QUALITY; GENOME; DRUGS; CARE; METAANALYSIS; CHOLESTEROL|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|21|1|15
Automatically extracting sentences from Medline citations to support clinicians' information needs|2013|Objective Online health knowledge resources contain answers to most of the information needs raised by clinicians in the course of care. However, significant barriers limit the use of these resources for decision-making, especially clinicians' lack of time. In this study we assessed the feasibility of automatically generating knowledge summaries for a particular clinical topic composed of relevant sentences extracted from Medline citations. Methods The proposed approach combines information retrieval and semantic information extraction techniques to identify relevant sentences from Medline abstracts. We assessed this approach in two case studies on the treatment alternatives for depression and Alzheimer's disease. Results A total of 515 of 564 (91.3\%) sentences retrieved in the two case studies were relevant to the topic of interest. About one-third of the relevant sentences described factual knowledge or a study conclusion that can be used for supporting information needs at the point of care. Conclusions The high rate of relevant sentences is desirable, given that clinicians' lack of time is one of the main barriers to using knowledge resources at the point of care. Sentence rank was not significantly associated with relevancy, possibly due to most sentences being highly relevant. Sentences located closer to the end of the abstract and sentences with treatment and comparative predications were likely to be conclusive sentences. Our proposed technical approach to helping clinicians meet their information needs is promising. The approach can be extended for other knowledge resources and information need types.|clinical decision support; information needs; knowledge summary; natural language processing|CLASSIFICATION MODELS; PHYSICIANS; QUESTIONS; CARE; SEARCH; MET|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|11|0|15
Are complex function words processed as semantically empty strings? A reading time and ERP study of collocational complex prepositions|2013|Collocational complex prepositions (CCPs, e.g., in the hands of) are prefabricated strings of words that play a prepositional role in natural language. Typically, CCPs are formed by a first preposition (P-1) followed by a content word (N-1) and a second, final preposition (P-2) (in the - P-1 - hands - N-1 - of - P-2). Despite their default structure stored in semantic memory, some CCPs allow internal modification (e.g., adjective insertion). In this study, two experiments tested the comprehension of CCPs in which we modified their default structure inserting an adjective before the noun. This modification preserved the semantic well-formedness of the string. The self-paced reading time study (Experiment 1) showed that readers took significantly longer to read the CCP constituents after the inserted adjective (N-1 and P-2). The ERP (Experiment 2) showed a smaller N400 response to the noun when preceded by the adjective, suggesting that the insertion did not disrupt the online processing of the CCP. Critically, the adjective insertion increased the processing load of the prepositional phrase introduced by the CCP, as evidenced by a LAN in response to the complement noun (N-2). Overall, these findings showed that processing CCPs was not disrupted by insertions despite their predefined default word order. Rather, their interpretation was semantically enriched, correlating with an increase in the processing load when the CCP was integrated with the complement noun.|Collocational complex prepositions; Sentence processing; N400; LAN|CLOSED-CLASS WORDS; BRAIN POTENTIALS; LANGUAGE COMPREHENSION; IDIOMATIC EXPRESSIONS; N400; SENTENCES; RECOGNITION; ASSOCIATION; INTEGRATION; MECHANISMS|Linguistics; Psychology, Experimental|8|0|15
L1/L2/L3 writing development: Longitudinal case study of a Japanese multicompetent writer|2013|This longitudinal case study, supplemented by cross-sectional comparisons among five groups of writers with differing backgrounds, investigates how Natsu, a Japanese multilingual writer, developed her L1, L2 (English), and L3 (Chinese) writing competence over two and a half years. To create a comprehensive picture of this multilingual writer, the study examines three aspects of writing: written essays (linguistic development and text features), composing processes, and individual/social factors (attitude and identity). Multiple data sources, both elicited and naturally occurring, include argumentation essays written in the three languages, retrospective stimulated recall of pausing behavior, interviews, and natural observations. Qualitative and quantitative analyses of the data reveal the writing development of the multilingual writer in the three languages over time and influential factors, affecting that development, including past experience and individual perceptions. The findings suggest that: (1) both commonalities and distinctions co-exist in the textual, process, and social aspects of her writing, (2) the writer's personal and cultural identity affect her text construction and composing process, and (3) boundaries become blurred among both the textual and the linguistic features in the three languages. The results imply that partially overlapping theories of multicompetence, genre, and identity can help elucidate the unique character of multilingual writers. (C) 2012 Elsevier Inc. All rights reserved.|Cultural/writer identity; L1/L2/L3 argumentation writing; Merged writing knowledge; Multilingual writing development|L1; LANGUAGE; COMPLEXITY; ACQUISITION; KNOWLEDGE; LITERACY; ACCURACY; SCHOOL; GENRE; MODEL|Linguistics|15|1|15
Concept comparison engines: A new frontier of search|2013|In a traditional search engine interaction scenario, a user begins with a certain concept and finds documents that are similar to their concept. However, the user may wish to compare alternatives and a search capability should compare concepts and present the best alternatives. This task can be difficult without proper decision aids. We propose a concept comparison engine as a decision support tool that may be used to compare attributes of different alternatives and aid in making an informed selection. We describe an architecture and an interaction scenario and implement a prototype. We propose a number of evaluation metrics for measuring the viability of different terms for the purpose of comparing concepts. In scripted experiments, orderings for candidate terms from the prototype are compared to gold standard ranking lists from structured external sources. Our results indicate that a Rankor analysis may be promising as a measure of the differentiating power of candidate terms a user might choose to support concept comparison. (C) 2012 Elsevier B.V. All rights reserved.|Preferential choice; Search engine; Text mining|TEXT CATEGORIZATION; INFORMATION EXTRACTION; EXPLORATORY SEARCH; WEB; CLASSIFICATION; DOCUMENTS; DISCOVERY; ONLINE; COLLECTION; RULES|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|3|0|15
Using Wikipedia and Conceptual Graph Structures to Generate Questions for Academic Writing Support|2012|In this paper, we present a novel approach for semiautomatic question generation to support academic writing. Our system first extracts key phrases from students' literature review papers. Each key phrase is matched with a Wikipedia article and classified into one of five abstract concept categories: Research Field, Technology, System, Term, and Other. Using the content of the matched Wikipedia article, the system then constructs a conceptual graph structure representation for each key phrase and the questions are then generated based the structure. To evaluate the quality of the computer generated questions, we conducted a version of the Bystander Turing test, which involved 20 research students who had written literature reviews for an IT methods course. The pedagogical values of generated questions were evaluated using a semiautomated process. The results indicate that the students had difficulty distinguishing between computer-generated and supervisor-generated questions. Computer-generated questions were also rated as being as pedagogically useful as supervisor-generated questions, and more useful than generic questions. The findings also suggest that the computer-generated questions were more useful for the first-year students than for second or third-year students.|Automatic question generation; writing support; natural language processing|COMPUTER|Computer Science, Interdisciplinary Applications; Education \& Educational Research|10|0|15
Interaction in the Genre of Popular Science Writer, Translator and Reader|2011|Scientific texts are often treated as neutral and objective, and their translators are assumed to be invisible. This paper takes an opposing view and argues that the translator's role in the process of communicating popular science is worthy of investigation. It first explores the notion of interaction in popular science texts, before operationalizing the concept of translation shift for the analysis of interactive features in source texts and their translations. The analysis uses a parallel corpus compiled from the Chinese and English editions of the popular science magazine Scientific American. Interactive features in the Chinese translations were found to occur much more frequently than in a Chinese reference corpus, and in some cases even more frequently than in the English source texts. The dominant trends identified in the corpus are discussed in terms of readers `participation, writer-reader solidarity, and writer's and translator's presence in the text. The textual findings are further discussed against the background of popular science writings in the target culture and the views of editors and translators. The paper concludes by suggesting that the social responsibility assumed by translators and expected of them by society may explain their active participation in the process of interaction with target readers.|Deixis; Interaction; Interference; Personal pronouns; Junctives; Popular science; Translation shifts|ARTICLES|Communication; Linguistics; Language \& Linguistics|2|0|15
Changes in Alan Greenspan's Language Use Across the Economic Cycle: A Text Analysis of His Testimonies and Speeches|2011|This study examined changes in Alan Greenspan's language use across the economic cycle by analyzing his testimonies and speeches using the Linguistic Inquiry and Word Count Program (LIWC), which is a widely used text analysis program. Consistent with expectations, Greenspan showed an increase in the composite measure of psychological distancing as well as a decline in the measure of cognitive complexity between the economic expansion and downturn periods. Interestingly, these patterns of changes became more pronounced during the purported economic recovery period. In contrast to the measures of psychological distancing and cognitive complexity, the measure of emotionality remained relatively stable across the economic cycle.|Greenspan; LIWC; computerized text analysis; psychological distancing; cognitive complexity|INTEGRATIVE COMPLEXITY; WORDS; WAR|Communication; Linguistics; Psychology, Social|13|3|15
Machine Transliteration Survey|2011|Machine transliteration is the process of automatically transforming the script of a word from a source language to a target language, while preserving pronunciation. The development of algorithms specifically for machine transliteration began over a decade ago based on the phonetics of source and target languages, followed by approaches using statistical and language-specific methods. In this survey, we review the key methodologies introduced in the transliteration literature. The approaches are categorized based on the resources and algorithms used, and the effectiveness is compared.|Algorithms; Experimentation; Languages; Automatic translation; machine learning; machine transliteration; natural language processing; transliteration evaluation|LINGUAL SPELLING VARIANTS; INFORMATION-RETRIEVAL; ENGLISH; MODELS; WORDS; ALGORITHMS; GRAPHEME|Computer Science, Theory \& Methods|5|5|15
Measurement of Negativity Bias in Personal Narratives Using Corpus-Based Emotion Dictionaries|2011|This study presents a novel methodology for the measurement of negativity bias using positive and negative dictionaries of emotion words applied to autobiographical narratives. At odds with the cognitive theory of mood dysregulation, previous text-analytical studies have failed to find significant correlation between emotion dictionaries and negative affectivity or dysphoria. In the present study, an a priori list dictionary of emotion words was refined based on the actual use of these words in personal narratives collected from close to 500 college students. Half of the corpus was used to construct, via concordance analysis, the grammatical structures associated with the words in their emotional sense. The second half of the corpus served as a validation corpus. The resulting dictionary ignores words that are not used in their intended emotional sense, including negated emotions, homophones, frozen idioms etc. Correlations of the resulting corpus-based negative and positive emotion dictionaries with self-report measures of negative affectivity were in the expected direction, and were statistically significant, with medium effect size. The potential use of these dictionaries as implicit measures of negativity bias and in the analysis of psychotherapy transcripts is discussed.|Text-analysis; Dysphoria; Negativity bias; Personal narratives; Corpus linguistics|BECK DEPRESSION INVENTORY; NATURAL-LANGUAGE USE; DYSFUNCTIONAL ATTITUDES; COGNITIVE VULNERABILITY; PSYCHOMETRIC PROPERTIES; COMPUTER-ANALYSIS; SOCIAL COGNITION; MENTAL-HEALTH; TEXT-ANALYSIS; SELF-ESTEEM|Linguistics; Psychology, Experimental|8|0|15
Interplay between acoustic/phonetic and semantic processes during spoken sentence comprehension: An ERP study|2011|When listening to speech in everyday-life situations, our cognitive system must often cope with signal instabilities such as sudden breaks, mispronunciations, interfering noises or reverberations potentially causing disruptions at the acoustic/phonetic interface and preventing efficient lexical access and semantic integration. The physiological mechanisms allowing listeners to react instantaneously to such fast and unexpected perturbations in order to maintain intelligibility of the delivered message are still partly unknown. The present electroencephalography (EEG) study aimed at investigating the cortical responses to real-time detection of a sudden acoustic/phonetic change occurring in connected speech and how these mechanisms interfere with semantic integration. Participants listened to sentences in which final words could contain signal reversals along the temporal dimension (time-reversed speech) of varying durations and could have either a low- or high-doze probability within sentence context. Results revealed that early detection of the acoustic/phonetic change elicited a fronto-central negativity shortly after the onset of the manipulation that matched the spatio-temporal features of the Mismatch Negativity (MMN) recorded in the same participants during an oddball paradigm. Time reversal also affected late event-related potentials (ERPs) reflecting semantic expectancies (N400) differently when words were predictable or not from the sentence context. These findings are discussed in the context of brain signatures to transient acoustic/phonetic variations in speech. They contribute to a better understanding of natural speech comprehension as they show that acoustic/phonetic information and semantic knowledge strongly interact under adverse conditions. (C) 2010 Elsevier Inc. All rights reserved.|Sentence comprehension; Connected speech; Degraded speech; Event-related potentials; Mismatch Negativity (MMN); N400|MISMATCH NEGATIVITY MMN; MEDIAL TEMPORAL-LOBE; HUMAN BRAIN; LANGUAGE COMPREHENSION; SPEECH SOUNDS; FEATURE CONJUNCTIONS; COGNITIVE-PROCESSES; STIMULUS DEVIANCE; NEURAL MECHANISMS; FIELD POTENTIALS|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|10|2|15
Emotion Recognition in Text for 3-D Facial Expression Rendering|2010|Emotions are a key semantic component of human communication. This study focuses on automatic emotion detection in descriptive sentences and how this can be used to tune facial expression parameters for 3-D character generation. A comparison of manual and automatic word feature selection approaches is performed to determine the influence of word features on classification accuracy using support vector machines (SVM). The automatic emotion feature selection algorithm presented here builds on the framework used by mutual information for feature selection. Results of the study indicate that the set of automatically selected features was as good as the set of manually selected features. The proposed automatic feature selection algorithm implemented in this study helped to detect new words from the training corpus which were relevant to the classification task but were not considered by the researchers. An example of potential outcomes from facial expression tuning is also presented. The analysis includes initial results for dealing with the class imbalance challenge present in the data.|Machine learning; natural language processing; semantic analysis; text-to-scene processing|REPRESENTATION; LANGUAGE|Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications|14|0|15
Choosing the best tools for comparative analyses of texts|2010|What measurements should linguists use when comparing texts written by different writers? We report aspects of a systematic evaluation of 381 different language measures derived from 200 analytic tools, carried out during the pilot for a study exploring genetic contributions to language variation. The measures covered lexis, structure, meaning, and discourse features, and were evaluated with a focus on capturing numerically the qualitative features that linguists consider central to differentiating one text from another. We review principles for selecting analytic tools, and the choices faced by the researcher in processing and analysing data. We then identify and demonstrate five of the measures, which between them provide a useful profile of different linguistic features, and note correlations with psychometric measures taken for each writer. We conclude with some caveats regarding general issues of validity and some indications about potential links between our work and research into authorship attribution for forensic purposes.|text analysis; profiling; variation; quantitative analysis; lexis|LATENT SEMANTIC ANALYSIS; CORE SKILLS TEST; LINGUISTIC ABILITY; EARLY-LIFE; METAPHOR COMPREHENSION; ALZHEIMERS-DISEASE; COGNITIVE FUNCTION; LANGUAGE; NUN; SPEECH|Linguistics; Language \& Linguistics|2|0|15
Developing argumentation processing agents for computer-supported collaborative learning|2009|In this study, ail intelligent argumentation processing agent for computer-supported cooperative learning is proposed. Learners are first assigned to heterogeneous groups based oil their learning styles questionnaire given right before the beginning of learning activities oil the c-learning platform. The proposed argumentation processing agent then scrutinizes each learner's learning portfolio on c-learning platform and automatically issues feedback messages in case devious argument or abnormal behavior that is unfitted to the learners' learning style is detected. The Moodle (http://moodle.org), ail open source software e-learning platform, is used to establish the cooperative learning environment for this study. The experimental results revealed that the learners benefited by the argumentation activity with the assistance of the proposed learning style aware argumentation processing agent. (C) 2008 Elsevier Ltd. All rights reserved.|Argumentation; Conversation analysis; Text mining; Exception maximum (EM); Assessment; e-Learning; Learning style|SOCIOSCIENTIFIC ISSUES; CLASSIFICATION; ELECTRICITY; CLASSROOM|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|14|0|15
Producing culturally appropriate narratives in English as a foreign language - A discourse analysis of Korean EFL learners' written narratives|2006|Cross-cultural and second/foreign language (L2) studies on oral narratives have suggested that one's native language and culture affect discourse production in an L2 and have detected areas of difficulty for L2 learners in producing extended discourse. However, written narrative has received less attention, although it can provide rich data on cross-cultural differences and hold important implications for L2 literacy acquisition and pedagogy. This study was designed to investigate culturally preferred written discourse styles and their effects on L2 writing of personal narratives. It explored cross-cultural differences in the use of narrative structural features including evaluation between first language written narratives produced by native speakers of American English and first- and second-language narratives written by Koreans learning English. Differences in first language narrative styles were used to explain how Korean EFL learners' narrative discourse in English could vary from native English speakers' discourse norms. Participants were Korean adult EFL (English as a Foreign Language) learners and American native-English speakers in the U.S. The findings show that specifically Korean cultural strategies were evident in the Korean English learners' English narrative discourse rather than the preferred discourse style of the target language and culture. The findings hold implications for L2 writing pedagogy and L2 training in discourse production.|written narratives; narrative discourse; cross-cultural narrative analysis; second/foreign language|PERSONAL NARRATIVES; AUTOBIOGRAPHICAL MEMORY; TEXT COMPREHENSION; AMERICAN CHILDREN; ABILITY; STORY; TELL; CONSTRUCTION; VARIABLES; COHESION|Communication; Linguistics; Language \& Linguistics|3|1|15
Traditional and emotional stylometric analysis of the songs of Beatles Paul McCartney and John Lennon|1996|Traditional stylometric measures such as word usage, word length, and word repetition were paired with six new measures that described word emotionality in terms of a word's pleasantness, its activation level, and the combination of these factors. All measurements were applied to the songs composed by Beatles Paul McCartney and John Lemon between 1962 and 1970. Stylistic and emotional differences between composers and across years were found to be in agreement with observations made by critics and analysts of Beatles' songs, suggesting that emotional stylometry is a valid instrument for the analysis of text. Lennon was the less pleasant and the sadder lyricist, and the Lennon-McCartney lyrics became less pleasant, less active, and less cheerful over time. Several other differences were observed and reported. A technique for summary emotional description (the emotion clock) was also introduced.|stylometric analysis; emotional stylometric analysis; music; Beatles|OBJECTIVE ANALYSIS; VALIDITY; STORIES|Computer Science, Interdisciplinary Applications|17|0|15
A Survey on Visual Approaches for Analyzing Scientific Literature and Patents|2017|The increasingly large number of available writings describing technical and scientific progress, calls for advanced analytic tools for their efficient analysis. This is true for many application scenarios in science and industry and for different types of writings, comprising patents and scientific articles. Despite important differences between patents and scientific articles, both have a variety of common characteristics that lead to similar search and analysis tasks. However, the analysis and visualization of these documents is not a trivial task due to the complexity of the documents as well as the large number of possible relations between their multivariate attributes. In this survey, we review interactive analysis and visualization approaches of patents and scientific articles, ranging from exploration tools to sophisticated mining methods. In a bottom-up approach, we categorize them according to two aspects: (a) data type (text, citations, authors, metadata, and combinations thereof), and (b) task (finding and comparing single entities, seeking elementary relations, finding complex patterns, and in particular temporal patterns, and investigating connections between multiple behaviours). Finally, we identify challenges and research directions in this area that ask for future investigations.|Visualization; scientific literature; patents; documents|COCITATION NETWORKS; CITATION NETWORKS; RESEARCH FRONTS; INTELLECTUAL STRUCTURE; DOCUMENT COLLECTION; DYNAMIC NETWORKS; KNOWLEDGE DOMAIN; VISUALIZATION; ANALYTICS; EXPLORATION|Computer Science, Software Engineering|3|10|14
Building a comprehensive syntactic and semantic corpus of Chinese clinical texts|2017|Objective: To build a comprehensive corpus covering syntactic and semantic annotations of Chinese clinical texts with corresponding annotation guidelines and methods as well as to develop tools trained on the annotated corpus, which supplies baselines for research on Chinese texts in the clinical domain. Materials and methods: An iterative annotation method was proposed to train annotators and to develop annotation guidelines. Then, by using annotation quality assurance measures, a comprehensive corpus was built, containing annotations of part-of-speech (POS) tags, syntactic tags, entities, assertions, and relations. Inter-annotator agreement (IAA) was calculated to evaluate the annotation quality and a Chinese clinical text processing and information extraction system (CCTPIES) was developed based on our annotated corpus. Results: The syntactic corpus consists of 138 Chinese clinical documents with 47,426 tokens and 2612 full parsing trees, while the semantic corpus includes 992 documents that annotated 39,511 entities with their assertions and 7693 relations. IAA evaluation shows that this comprehensive corpus is of good quality, and the system modules are effective. Discussion: The annotated corpus makes a considerable contribution to natural language processing (NLP) research into Chinese texts in the clinical domain. However, this corpus has a number of limitations. Some additional types of clinical text should be introduced to improve corpus coverage and active learning methods should be utilized to promote annotation efficiency. Conclusions: In this study, several annotation guidelines and an annotation method for Chinese clinical texts were proposed, and a comprehensive corpus with its NLP modules were constructed, providing a foundation for further study of applying NLP techniques to Chinese texts in the clinical domain. (C) 2017 Published by Elsevier Inc.|Chinese clinical texts; Corpus construction; Guideline development; Annotation method; Natural language processing|NAMED ENTITY RECOGNITION; INFORMATION|Computer Science, Interdisciplinary Applications; Medical Informatics|1|13|14
Identity and publication in non-university settings: academic co-authorship and collaboration|2017|Increased collaboration between researchers working in university, industry, and governmental settings is changing the landscape of academic science. Traditional models of the interaction between these sectors, such as the triple helix concept, draw clear distinctions between academic and non-academic settings and actors. This study surveyed scientists (n = 469) working outside of university settings who published articles indexed in the Web of Science about their modes of collaboration, perceptions about publishing, workplace characteristics, and information sources. We study the association between these variables, and use text analysis to examine the roles, duties, sites, topics, and workplace missions among non-university based authors. Our analysis shows that 72\% of authors working in non-university settings who collaborate and publish with other scientists self-identify as academics. Furthermore, their work life resembles that of those working in university settings in that the majority report doing fundamental research in government research organizations and laboratories. Contrary to our initial hypothesis, this research suggests that peer-reviewed publications are much more dominated by non-university academics than we previously thought and that collaboration as co-authors on academic publications is not likely to be a primary conduit for the transfer of scientific knowledge between academe and industry.|Collaboration; Academia; Publishing; Knowledge transfer|TRIPLE-HELIX; INDUSTRY; SCIENCE; GOVERNMENT; CORPORATIONS; IMPACT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|3|14
Processing Affect in Social Media: A Comparison of Methods to Distinguish Emotions in Tweets|2017|Emotion analysis in social media is challenging. While most studies focus on positive and negative sentiments, the differentiation between emotions is more difficult. We investigate the problem as a collection of binary classification tasks on the basis of four opposing emotion pairs provided by Plutchik. We processed the content of messages by three alternative methods: structural and lexical features, latent factors, and natural language processing. The final prediction is suggested by classifiers deriving from the state of the art in machine learning. Results are convincing in the possibility to distinguish the emotions pairs in social media.|Probabilistic methods; lexical approach; latent factors|SENTIMENT ANALYSIS; INFORMATION; LEXICON; SPACES|Computer Science, Information Systems; Computer Science, Software Engineering|1|6|14
Modeling user interests from web browsing activities|2017|Browsing sessions are rich in elements useful to build profiles of user interests, but at the same time HTML pages include noisy data such as advertisements, navigation menus and privacy notes. Moreover, some pages cover several different topics making it difficult to identify the most relevant to the user. For these reasons, they are often ignored by personalized search and recommender systems. We propose a novel approach for recognizing valuable text descriptions of current user information needs-namely cues-based on the data mined from browsing interactions over the web. The approach combines page clustering techniques based on Document Object Model-based representations for acquiring evidence about relevant correlations between text contents. This evidence is exploited for better filtering out irrelevant information and facilitating the construction of interest profiles. A comparative framework proves the accuracy of the extracted cues in the personalize search task, where results are re-ranked according to the last browsed resources.|Information needs; User modeling; Clustering; Web browsing|SEARCH; PERSONALIZATION; CLASSIFICATION; DESIGN|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|6|14
A comparison of US-based and Iraqi English research article abstracts using corpora|2017|This paper explores the linguistic characteristics of English research article (RA) abstracts published in the United States (U.S.) and those published in Iraq, written by Iraqi authors. Because of their brevity, well-established purpose, and explicit format requirements, RA abstracts are ideal for genre-based studies (Hyland, 2004; Swales \& Feak, 2009a) and cross-linguistic analyses. Eight parallel sub-corpora were used in this study, comprised of RA abstracts in four disciplines (Agriculture, Nursing, Engineering, and Languages) from the U.S. and Iraq. Overall, the texts collected in the eight corpora were written during the period from 1995 to 2016 across a wide-range of publications and research approaches. This study follows Biber's (1988, 1995) multi-dimensional analytical (MDA) approach in comparing and contrasting these U.S.-based and Iraqi RA abstracts. Specifically, extracted dimensions of academic writing from Hardy and Romer's (2013) MDA of NS and NNS upper-level academic written texts from the Michigan Corpus of Upper-Level Student Papers (MICUSP) are utilized as primary points of comparison. Results suggest similarities and interesting differences in how U.S.-based and Iraqi writers structure their abstracts, specifically in (1) how information is packaged and shared, (2) the expression of procedural discourse in abstract writing, and (3) how directness and argumentation are articulated by writers. Published by Elsevier Ltd.|RA abstracts; Multi-dimensional analysis; Corpus linguistics; English for academic purposes|RHETORICAL STRUCTURE; CONTRASTIVE ANALYSIS; APPLIED LINGUISTICS|Education \& Educational Research; Linguistics; Language \& Linguistics|1|5|14
Repair and codeswitching for learning in online intercultural talk|2016|This study examines the role of repair and code switching for language learning in online written interaction between two speakers of both Italian and English as, respectively, either an Ll or L2. Specifically, during episodes of general repair and corrective feedback, these geographically dispersed university language students used both languages in their repertoire as key interactional and learning resources to co-construct a language learning partnership and pursue affiliation. Despite the face-threatening nature of corrective feedback, also known as other-initiated other-repair, participants managed to construct and maintain intersubjectivity in the text chat environment by availing themselves of the reciprocal possibilities of their bilingual expertise, thus overcoming linguistic asymmetries. In this way both social and learning objectives were achieved during written talk-in-interaction, suggesting that online language learning partnerships with multilingual intercultural speakers of the target language rather than monolingual native speaker partners should be given a more prominent role in languages programs across sectors. Crown Copyright (C) 2016 Published by Elsevier Ltd. All rights reserved.|Conversation analysis; Code switching; Repair; Corrective feedback; Written talk-in-interaction|CONVERSATION; COMMUNICATION|Education \& Educational Research; Linguistics|1|3|14
Linguistic Obfuscation in Fraudulent Science|2016|The rise of scientific fraud has drawn significant attention to research misconduct across disciplines. Documented cases of fraud provide an opportunity to examine whether scientists write differently when reporting on fraudulent research. In an analysis of over two million words, we evaluated 253 publications retracted for fraudulent data and compared the linguistic style of each paper to a corpus of 253 unretracted publications and 62 publications retracted for reasons other than fraud (e.g., ethics violations). Fraudulent papers were written with significantly higher levels of linguistic obfuscation, including lower readability and higher rates of jargon than unretracted and nonfraudulent papers. We also observed a positive association between obfuscation and the number of references per paper, suggesting that fraudulent authors obfuscate their reports to mask their deception by making them more costly to analyze and evaluate. This is the first large-scale analysis of fraudulent papers across authors and disciplines to reveal how changes in writing style are related to fraudulent data reporting.|text analysis; deception; scientific fraud; LIWC; Coh-Metrix|DECEPTION; LANGUAGE; READABILITY; ACCURACY; WORDS|Communication; Linguistics; Psychology, Social|2|0|14
Comparing writing performance in TOEFL-iBT and academic assignments: An exploration of textual features|2016|This paper reports an exploratory study in which the written texts produced by postgraduate students in test and real-life academic situation are compared in terms of the linguistic and discoursal features. Data were collected from 20 international English as a second language (ESL) postgraduate students from different first language backgrounds and three general disciplines of science and engineering, arts and humanities, and business and economics. The participants were studying in postgraduate programs in five universities in New South Wales, Australia. These participants completed two writing test tasks of the TOEFL-iBT (integrated and independent tasks) and an academic assignment for one of the university courses they enrolled, in. Textual features of the test and academic assignment texts were compared on 20 linguistic and discoursal features. These textual features are related to syntactic complexity (five variables), lexical sophistication (nine variables) and cohesion (six variables). Results of a series of repeated measures Analysis of Covariance (ANCOVA) indicated similarities and differences in the linguistic and discoursal features of the three writing task texts. Findings are reported and discussed and implications are made for the extrapolation inference claim in the validity argument of the Writing section of the TOEFL-iBT. (C) 2016 Elsevier Inc. All rights reserved.|Writing; Academic writing; Writing assessment; Validity of writing tests; Text analysis; TOEFL-iBT-Coh-Metrix|COH-METRIX; L2; COHESION|Education \& Educational Research; Linguistics|3|2|14
Optimization of naphtha purchase price using a price prediction model|2016|In order to meet company needs, various models of naphtha price forecasting and optimization models of average naphtha purchase price have been developed. However, these general models are limited in their ability to predict future trends as they only include quantitative data. Furthermore, naphtha price predictions based on fluctuation trends have not been published in the literature. Thus, we developed a system dynamics (SD) model considering time-series data, mathematical formulations, and qualitative factors. The results obtained from our model were compared with the published literature. The best result of the SD is the European naphtha forecasting price model, and the forecasting accuracy percentage shows 92.82\%. Furthermore, a nonlinear programming (NLP) model was developed to optimize the purchase price by considering the naphtha price of the forecasting models. In addition, the average optimization value was approximately 45.07 USD/ton cheaper than that of the heuristic approach. (C) 2015 Elsevier Ltd. All rights reserved.|Purchase price optimization; Artificial neural network; Forecasting model; System dynamics; Heuristics|ARTIFICIAL NEURAL-NETWORKS; SYSTEM DYNAMICS APPROACH; CRUDE-OIL PRICE; TIME-SERIES; SHORT-TERM; ENERGY; VOLATILITY; MARKET; CONSUMPTION; FORECAST|Computer Science, Interdisciplinary Applications; Engineering, Chemical|3|3|14
A method for systematic discovery of adverse drug events from clinical notes|2015|Objective Adverse drug events (ADEs) are undesired harmful effects resulting from use of a medication, and occur in 30\% of hospitalized patients. The authors have developed a data-mining method for systematic, automated detection of ADEs from electronic medical records. Materials and Methods This method uses the text from 9.5 million clinical notes, along with prior knowledge of drug usages and known ADEs, as inputs. These inputs are further processed into statistics used by a discriminative classifier which outputs the probability that a given drug-disorder pair represents a valid ADE association. Putative ADEs identified by the classifier are further filtered for positive support in 2 independent, complementary data sources. The authors evaluate this method by assessing support for the predictions in other curated data sources, including a manually curated, time-indexed reference standard of label change events. Results This method uses a classifier that achieves an area under the curve of 0.94 on a held out test set. The classifier is used on 2 362 950 possible drug-disorder pairs comprised of 1602 unique drugs and 1475 unique disorders for which we had data, resulting in 240 high-confidence, well-supported drug-AE associations. Eighty-seven of them (36\%) are supported in at least one of the resources that have information that was not available to the classifier. Conclusion This method demonstrates the feasibility of systematic post-marketing surveillance for ADEs using electronic medical records, a key component of the learning healthcare system.|post market drug safety surveillance; pharmacovigilance; machine learning; EMR mining|EVIDENCE-BASED PHARMACOVIGILANCE; ELECTRONIC HEALTH RECORDS; SIGNAL-DETECTION; SAVANNA CHOICE; HOSPITALIZED-PATIENTS; ZOO; REGRESSION; PUZZLE; PIECE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|14|4|14
Desiderata for computable representations of electronic health records-driven phenotype algorithms|2015|Background Electronic health records (EHRs) are increasingly used for clinical and translational research through the creation of phenotype algorithms. Currently, phenotype algorithms are most commonly represented as noncomputable descriptive documents and knowledge artifacts that detail the protocols for querying diagnoses, symptoms, procedures, medications, and/or text-driven medical concepts, and are primarily meant for human comprehension. We present desiderata for developing a computable phenotype representation model (PheRM). Methods A team of clinicians and informaticians reviewed common features for multisite phenotype algorithms published in PheKB.org and existing phenotype representation platforms. We also evaluated well-known diagnostic criteria and clinical decision-making guidelines to encompass a broader category of algorithms. Results We propose 10 desired characteristics for a flexible, computable PheRM: (1) structure clinical data into queryable forms; (2) recommend use of a common data model, but also support customization for the variability and availability of EHR data among sites; (3) support both human-readable and computable representations of phenotype algorithms; (4) implement set operations and relational algebra for modeling phenotype algorithms; (5) represent phenotype criteria with structured rules; (6) support defining temporal relations between events; (7) use standardized terminologies and ontologies, and facilitate reuse of value sets; (8) define representations for text searching and natural language processing; (9) provide interfaces for external software algorithms; and (10) maintain backward compatibility. Conclusion A computable PheRM is needed for true phenotype portability and reliability across different EHR products and healthcare systems. These desiderata are a guide to inform the establishment and evolution of EHR phenotype algorithm authoring platforms and languages.|electronic health records; phenotype algorithms; computable representation; phenotype standardization; data models|GENOME-WIDE ASSOCIATION; COMMON DATA MODEL; MEDICINE RESEARCH-PROJECT; PHENOME-WIDE; PERSONALIZED MEDICINE; EMERGE NETWORK; RHEUMATOID-ARTHRITIS; CARE DATABASES; DNA BIOBANK; DRUG|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|20|4|14
Collective intelligence applied to legal e-discovery: A ten-year case study of Australia franchise and trademark litigation|2015|The purpose of this research is to develop a formal knowledge e-discovery methodology, using advanced information technology and decision support analysis, to define legal case evolution based on Collective Litigation Intelligence (CLI). In this research, a decade of Australia's retail franchise and trademark litigation cases are used as the corpus to analyze and synthesize the evolution of modern retail franchise law in Australia. The formal processes used in the legal e-discovery research include a LexisNexis search strategy to collect legal documents, text mining to find key concepts and their representing key phrases in the documents, clustering algorithms to aSsociate the legal cases into groups, and concept lattice analysis to trace the evolutionary trends of the main groups. The case analysis discovers the fundamental issues for retail modernization, advantages and disadvantages of retail franchising systems, and the potential litigation hazards to be avoided in the Australian market. Given the growing number of legal documents in global court systems, this research provides a systematic and generalized CLI methodology to improve the efficiency and efficacy of research across international legal systems. In the context of the case study, the results demonstrate the critical importance of quickly processing and interpreting existing legal knowledge using the CLI approach. For example, a brand management company, which purchases a successful franchise in one market is under limited time constraints to evaluate the legal environment across global markets of interest. The proposed CLI methodology can be applied to derive market entry strategies to secure growth and brand expansion of a global franchise. (C) 2015 Elsevier Ltd. All rights reserved.|Collective litigation intelligence; Legal e-discovery; Retail franchise; Trademark infringement|KNOWLEDGE DISCOVERY; DATABASES|Computer Science, Artificial Intelligence; Engineering, Multidisciplinary|0|2|14
Domain adaptation for semantic role labeling of clinical text|2015|Objective Semantic role labeling (SRL), which extracts a shallow semantic relation representation from different surface textual forms of free text sentences, is important for understanding natural language. Few studies in SRL have been conducted in the medical domain, primarily due to lack of annotated clinical SRL corpora, which are time-consuming and costly to build. The goal of this study is to investigate domain adaptation techniques for clinical SRL leveraging resources built from newswire and biomedical literature to improve performance and save annotation costs. Materials and Methods Multisource Integrated Platform for Answering Clinical Questions (MiPACQ), a manually annotated SRL clinical corpus, was used as the target domain dataset. PropBank and NomBank from newswire and BioProp from biomedical literature were used as source domain datasets. Three state-of-the-art domain adaptation algorithms were employed: instance pruning, transfer self-training, and feature augmentation. The SRL performance using different domain adaptation algorithms was evaluated by using 10-fold cross-validation on the MiPACQ corpus. Learning curves for the different methods were generated to assess the effect of sample size. Results and Conclusion When all three source domain corpora were used, the feature augmentation algorithm achieved statistically significant higher F-measure (83.18\%), compared to the baseline with MiPACQ dataset alone (F-measure, 81.53\%), indicating that domain adaptation algorithms may improve SRL performance on clinical text. To achieve a comparable performance to the baseline method that used 90\% of MiPACQ training samples, the feature augmentation algorithm required < 50\% of training samples in MiPACQ, demonstrating that annotation costs of clinical SRL can be reduced significantly by leveraging existing SRL resources from other domains.|semantic role labeling; shallow semantic parsing; clinical natural language processing; domain adaptation; transfer learning|BIOMEDICAL LITERATURE; ANNOTATED CORPUS; LANGUAGE; CLASSIFICATION; INFORMATION; EXTRACTION; NARRATIVES; KNOWLEDGE; SYSTEM|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|1|1|14
Using natural language processing to provide personalized learning opportunities from trainee clinical notes|2015|Objective: Assessment of medical trainee learning through pre-defined competencies is now commonplace in schools of medicine. We describe a novel electronic advisor system using natural language processing (NLP) to identify two geriatric medicine competencies from medical student clinical notes in the electronic medical record: advance directives (AD) and altered mental status (AMS). Materials and methods: Clinical notes from third year medical students were processed using a general-purpose NLP system to identify biomedical concepts and their section context. The system analyzed these notes for relevance to AD or AMS and generated custom email alerts to students with embedded supplemental learning material customized to their notes. Recall and precision of the two advisors were evaluated by physician review. Students were given pre and post multiple choice question tests broadly covering geriatrics. Results: Of 102 students approached, 66 students consented and enrolled. The system sent 393 email alerts to 54 students (82\%), including 270 for AD and 123 for AMS. Precision was 100\% for AD and 93\% for AMS. Recall was 69\% for AD and 100\% for AMS. Students mentioned ADs for 43 patients, with all mentions occurring after first having received an AD reminder. Students accessed educational links 34 times from the 393 email alerts. There was no difference in pre (mean 62\%) and post (mean 60\%) test scores. Conclusions: The system effectively identified two educational opportunities using NLP applied to clinical notes and demonstrated a small change in student behavior. Use of electronic advisors such as these may provide a scalable model to assess specific competency elements and deliver educational opportunities. (C) 2015 Elsevier Inc. All rights reserved.|Medical education; Natural language processing; Decision support; Geriatric education; Altered mental status; Advanced directives|ELECTRONIC HEALTH RECORDS; COMPETENCE-BASED CURRICULUM; MEDICAL-STUDENTS; PRIMARY-CARE; GERIATRICS KNOWLEDGE; INTERNAL-MEDICINE; DECISION-SUPPORT; EDUCATION; SYSTEM; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|0|2|14
Young children talk about their popular cartoon and TV heroes' speech styles: media reception and language attitudes|2015|Considering the role of popular cultural texts in shaping sociolinguistic reality, it makes sense to explore how children actually receive those texts and what conceptualisations of sociolinguistic diversity they form through those texts. Therefore, the aim of the present study was to examine Greek young children's views on sociolinguistic diversity in popular cartoons and TV series. Drawing upon a framework of media reception, we explored how attention to the ways children at age six interpret mediated representations of sociolinguistic difference might provide a methodological addition to tools used for investigating language attitudes and ideologies. From the analysis of children's interviews, it was found that they can easily distinguish between different dimensions of sociolinguistic difference, showing an enhanced sociolinguistic awareness. On the other hand, their reading positions seemed to be in acceptance with the meanings conveyed in the texts. Moreover, our findings suggest that children tended to make hegemonic readings of popular cultural texts, premising many of their evaluations on the ways in which sociolinguistic diversity was represented in the text (e.g. plot, characterisation). The implications of these findings for the role of popular culture in the shaping of children's language attitudes are discussed.|standard language ideology; feminine style; masculine style; geographical dialect; sociolinguistic awareness|GREEK TELEVISION; IDEOLOGIES; WOMEN; CONSTRUCTION; DIALECT|Linguistics; Language \& Linguistics|0|4|14
A META-SYNTHESIS OF EMPIRICAL RESEARCH ON THE EFFECTIVENESS OF COMPUTER-MEDIATED COMMUNICATION (CMC) IN SLA|2015|This meta-analysis reports the results of a systematic synthesis of primary studies on the effectiveness of computer-mediated communication (CMC) in second language acquisition (SLA) for the period 2000-2012. By extracting information on 21 features from each primary study, this meta-analysis intends to summarize the CMC research literature for the past decade by calculating an average effect size and performing a series of moderator analyses to factor out elements that might mediate the effect of such media in SLA. In total, 59 studies were identified as eligible after excluding three outlier studies, covering both published and unpublished studies. All studies were coded for learner characteristics (5 features), methodological characteristics (14 features) and publication characteristics (2 features), six of which were further analyzed as moderator variables. The results show that (a) there was a positive and medium overall effect for CMC used for instructional/learning purposes in SLA, (b) among the four language skills which CMC was intended to facilitate, writing skills produced the largest effect size, as did pragmatic competence, among the three language components, i.e. pragmatics, vocabulary and pronunciation explored in this meta-analysis; however this result should be interpreted as tentative since only one study measured pragmatic competence in the current meta-analysis, and (c) smaller group studies produced a larger effect size than those using larger groups or no grouping.|Meta-Analysis; Computer-Mediated Communication (CMC); Second Language Acquisition; ESL; EFL|FACE-TO-FACE; L2 INSTRUCTION; METAANALYSIS; LANGUAGE; 2ND-LANGUAGE; ACQUISITION; PROFICIENCY; TEXT; PERFORMANCE; TECHNOLOGY|Education \& Educational Research; Linguistics|11|4|14
Screening Internet forum participants for depression symptoms by assembling and enhancing multiple NLP methods|2015|Depression is a disease that can dramatically lower quality of life. Symptoms of depression can range from temporary sadness to suicide. Embarrassment, shyness, and the stigma of depression are some of the factors preventing people from getting help for their problems. Contemporary social media technologies like Internet forums or micro-blogs give people the opportunity to talk about their feelings in a confidential anonymous environment. However, many participants in such networks may not recognize the severity of their depression and their need for professional help. Our approach is to develop a method that detects symptoms of depression in free text, such as posts in Internet forums, chat rooms and the like. This could help people appreciate the significance of their depression and realize they need to seek help. In this work Natural Language Processing methods are used to break the textual information into its grammatical units. Further analysis involves detection of depression symptoms and their frequency with the help of words known as indicators of depression and their synonyms. Finally, similar to common paper-based depression scales, e.g., the CESD, that information is incorporated into a single depression score. In this evaluation study, our depressive mood detection system, Depre SD (Depression Symptom Detection), had an average precision of 0.84 (range 0.72-1.0 depending on the specific measure) and an average F measure of 0.79 (range 0.72-0.9). (C) 2015 Elsevier Ireland Ltd. All rights reserved.|Depression; Automatic screening; Natural Language Processing; Social Internet communication|SELF-HELP; SCALE; AGREEMENT; IDF|Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods; Engineering, Biomedical; Medical Informatics|2|4|14
Constructing English as a Ugandan language through an English textbook|2015|English is a national language in Uganda and is widely used in elite areas such as politics and business, but most Ugandans master English to only a limited degree. In this situation, English can be seen as either a foreign language or a second language - influencing how English is taught. One goal of language teaching espoused in this article is for students to develop intercultural communicative competence, and the article discusses the extent to which text and images invite conversations and discussions on culture and English as an international language. The framework for analysis is Weninger and Kiss's {[}2013. Culture in English as a foreign language (EFL) textbooks: A semiotic approach. TESOL Quarterly. doi:10.1002/tesq.87] framework for a Peircean semiotic approach to textual and visual analysis, and the material chosen for the study is a Ugandan English secondary textbook. The textbook has few references to foreign culture or English as an international language, and these references do not lend themselves to critical or exploratory queries or discussions on these issues. This paucity can be seen as an expression of the desire to emphasise English as a Ugandan language, and as such the textbook serves nationalistic purposes, a finding shared by other research. Teachers should be cognisant of the potential of images for spurring curiosity and discussions in the classroom.|textbook analysis; English language teaching; Uganda; semiotics; EFL|INTERNATIONAL LANGUAGE; AFRICAN CLASSROOMS; ESL TEXTBOOKS; CULTURE|Education \& Educational Research; Linguistics; Language \& Linguistics|0|0|14
Automated confidence ranked classification of randomized controlled trial articles: an aid to evidence-based medicine|2015|Objective: For many literature review tasks, including systematic review (SR) and other aspects of evidence-based medicine, it is important to know whether an article describes a randomized controlled trial (RCT). Current manual annotation is not complete or flexible enough for the SR process. In this work, highly accurate machine learning predictive models were built that include confidence predictions of whether an article is an RCT. Materials and Methods: The LibSVM classifier was used with forward selection of potential feature sets on a large human-related subset of MEDLINE to create a classification model requiring only the citation, abstract, and MeSH terms for each article. Results: The model achieved an area under the receiver operating characteristic curve of 0.973 and mean squared error of 0.013 on the held out year 2011 data. Accurate confidence estimates were confirmed on a manually reviewed set of test articles. A second model not requiring MeSH terms was also created, and performs almost as well. Discussion: Both models accurately rank and predict article RCT confidence. Using the model and the manually reviewed samples, it is estimated that about 8000 (3\%) additional RCTs can be identified in MEDLINE, and that 5\% of articles tagged as RCTs in Medline may not be identified. Conclusion: Retagging human-related studies with a continuously valued RCT confidence is potentially more useful for article ranking and review than a simple yes/no prediction. The automated RCT tagging tool should offer significant savings of time and effort during the process of writing SRs, and is a key component of a multistep text mining pipeline that we are building to streamline SR workflow. In addition, the model may be useful for identifying errors in MEDLINE publication types. The RCT confidence predictions described here have been made available to users as a web service with a user query form front end at: http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith\_uic/RCT\_Tagger.cgi.|Support Vector Machines; Natural Language Processing; Randomized Controlled Trials as Topic; Evidence-Based Medicine; Systematic Reviews; Information Retrieval|SYSTEMATIC REVIEWS; RETRIEVAL; WORKLOAD; MEDLINE; UPDATE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|3|3|14
College students' awareness in organizational strategy use in English writing A Taiwan-based study|2015|Purpose - The purpose of the study is to look at Chinese English as a foreign language (EFL) learners' organizational strategy use in English writing at universities in Taiwan. One significant area that has been indicated in contrastive rhetoric studies spins around the notion of culturally constructed organizational patterns. It is claimed that second language (L2) writers may have implicit culturally driven presuppositions and values about academic writing in the first language (L1) that may transfer straightforwardly to academic writing in English. Design/methodology/approach - Data were from 50 high- and 50 low-achieving EFL students' and 50 native English speakers' (NESs') written texts, and semi-structured interviews with EFL students and their teachers. Findings - Based on text analysis, when high- achieving EFL students and NESs were compared, they were similar in location of thesis, existence of introduction, existence of topic sentences, macro-level patterns, existence of conclusion, existence of a concluding sentence and existence of a final comment, but different in existence of background information. Nonetheless, it is noted that low-achieving EFL students were quite different from high- achieving EFL students and NESs in several aspects, such as location of thesis, existence of introduction, existence of topic sentences, macro-level patterns, existence of conclusion, existence of a concluding sentence, and existence of a final comment. In addition, the written texts and interview findings suggest that while cultural differences do, in fact, exist, Chinese writers' English organizational strategy use were to some extent intertwined with their writing experiences and teachers' writing instructions. The results also suggest the flexibility of writers and multiplicity of writing experiences within a cultural group. Originality/value - The study makes original recommendations for language pedagogy.|Awareness; Writing; English language arts; English teaching; Teaching writing; NESs; EFL; L1/L2; Contrastive rhetoric; Organizational strategy use|PATTERNS; JAPANESE; L1; INTRODUCTIONS; LANGUAGE|Education \& Educational Research; Linguistics; Language \& Linguistics|0|4|14
Examining genre effects on test takers' summary writing performance|2014|The task demands of summarization are closely related to the characteristics of source texts, and genre is an essential characteristic. This paper reports an empirical study that examines how text type (genre) affects test takers' performance on summarization tasks. A sample of 86 students was drawn from an undergraduate program in a Chinese university. The students first wrote summaries of a narrative text and subsequently wrote summaries of an expository text. Genre effects were examined from three perspectives: students' summary scores, summary scripts, and perception of these effects as reflected in questionnaire surveys and post-test interviews. MFRM analysis showed that participants performed better on expository writing than on narrative text summarization overall. The difficulties of the rubric components differed, with several differing significantly across the tasks. However, the participants generally considered the narrative text summarization to be easier than the expository task according to the results of the questionnaire surveys and interviews. Factors that led to this contradiction between performance and perception were explored by examining the participants' summaries and their accounts of the task difficulty and test-taking processes. Implications are discussed with reference to summarization task design, summarization teaching, and the relevance of genre effects in the creation of equivalent versions of tests. (C) 2014 Elsevier Ltd. All rights reserved.|Genre effect; Summarization performance; Task difficulty; Task design|DISCOURSE; COMPREHENSION; INSTRUCTION; FRAMEWORK; STUDENTS; STRATEGY; TASKS|Education \& Educational Research; Linguistics|2|1|14
Patients' involvement in e-health services quality assessment: A system for the automatic interpretation of SMS-based patients' feedback|2014|Purpose: Effective communication between patients and health services providers is a key aspect for optimizing and maintaining these services. This work describes a system for the automatic evaluation of users' perception of the quality of SmsCup, a reminder system for outpatient visits based on short message service (SMS). The final purpose is the creation of a closed-loop control system for the outpatient service, where patients' complaints and comments represent a feedback that can be used for a better implementation of the service itself. Methods: SmsCup was adopted since about eight years by an Italian healthcare organization, with very good results in reducing the no-show (missing visits) phenomenon. During these years, a number of citizens, even if not required, sent a message back, with comments about the service. The automatic interpretation of the content of those SMS may be useful for monitoring and improving service performances.Yet, due to the complex nature of SMS language, their interpretation represents an ongoing challenge. The proposed system uses conditional random fields as the information extraction method for classifying messages into several semantic categories. The categories refer to appreciation of the service or complaints of various types. Then, the system analyzes the extracted content and provides feedback to the service providers, making them learning and acting on this basis. Results: At each step, the content of the messages reveals the actual state of the service as well as the efficacy of corrective actions previously undertaken. Our evaluations showed that: (i) the SMS classification system has achieved good overall performance with an average F1-measure and an overall accuracy of about 92\%; (ii) the notification of the patients' feedbacks to service providers showed a positive impact on service functioning. Conclusions: Our study proposed an interactive patient-centered system for continuous monitoring of the service quality. It has demonstrated the feasibility of a tool for the analysis and notification of the patients' feedback on their service experiences, which would support a more regular access to the service. (C) 2014 Elsevier Inc. All rights reserved.|e-Health; Patients' feedback; Health service assessment; SMS; Information extraction; Conditional random fields|E-MAIL COMMUNICATION; BIOMEDICAL TEXT; CARE; PHONES; APPOINTMENTS; ATTENDANCE; PROVIDERS; MESSAGE; IMPACT|Computer Science, Interdisciplinary Applications; Medical Informatics|3|0|14
Mechanix: A natural sketch interface tool for teaching truss analysis and free-body diagrams|2014|Massive open online courses, online tutoring systems, and other computer homework systems are rapidly changing engineering education by providing increased student feedback and capitalizing upon online systems' scalability. While online homework systems provide great benefits, a growing concern among engineering educators is that students are losing both the critical art of sketching and the ability to take a real system and reduce it to an accurate but simplified free-body diagram (FBD). For example, some online systems allow the drag and drop of forces onto FBDs, but they do not allow the user to sketch the FBDs, which is a vital part of the learning process. In this paper, we discuss Mechanix, a sketch recognition tool that provides an efficient means for engineering students to learn how to draw truss FBDs and solve truss problems. The system allows students to sketch FBDs into a tablet computer or by using a mouse and a standard computer monitor. Using artificial intelligence, Mechanix can determine not only the component shapes and features of the diagram but also the relationships between those shapes and features. Because Mechanix is domain specific, it can use those relationships to determine not only whether a student's work is correct but also why it is incorrect. Mechanix is then able to provide immediate, constructive feedback to students without providing final answers. Within this manuscript, we document the inner workings of Mechanix, including the artificial intelligence behind the scenes, and present studies of the effects on student learning. The evaluations have shown that Mechanix is as effective as paper-and-pencil-based homework for teaching method of joints truss analysis; focus groups with students who used the program have revealed that they believe Mechanix enhances their learning and that they are highly engaged while using it.|Engineering Courseware; Engineering Education; Engineering Statics|REPRESENTATION; CONSTRUCTION; STATICS; MODEL; TEXT|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary; Engineering, Manufacturing|2|3|14
Measuring Moral Rhetoric in Text|2014|In this paper we present a computational text analysis technique for measuring the moral loading of concepts as they are used in a corpus. This method is especially useful for the study of online corpora as it allows for the rapid analysis of moral rhetoric in texts such as blogs and tweets as events unfold. We use latent semantic analysis to compute the semantic similarity between concepts and moral keywords taken from the Moral foundation Dictionary. This measure of semantic similarity represents the loading of these concepts on the five moral dimensions identified by moral foundation theory. We demonstrate the efficacy of this method using three different concepts and corpora.|moral rhetoric; moral foundations theory; discourse analysis; latent semantic analysis; moral foundations dictionary|LATENT SEMANTIC ANALYSIS; FOUNDATIONS; CONFLICT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science; Social Sciences, Interdisciplinary|9|0|14
Responding to student writing: Teachers' philosophies and practices|2014|Reviewers and researchers have been investigating response to student writing for several decades. To what extent have these research findings influenced teachers' real-world practices? Beyond investigating teachers' mechanisms for providing feedback, this study aimed to examine what is behind those choices: What principles guide teachers, and how were those philosophies formed? Do their practices appear to be consistent with their views about response? The teachers' voices have been the missing link in the research base to date. There have been surveys of student opinion about response and text analyses of teachers' comments, but only rarely have teachers themselves been utilized as primary informants in studies on response. The present study utilized a mixed-methods approach to examine the research questions. A team of researchers surveyed (N=129) and interviewed (N=23) community college and university writing instructors from the same geographic region-volunteers who had responded to an online survey-about a wide range of practices and analyzed examples (3-5 texts per interview participant) of these informants' written responses to students. The results showed variation across instructors and some discontinuity between teachers' self-reported response principles and their actual practices, as demonstrated in their own written commentary. (C) 2013 Elsevier Ltd. All rights reserved.|Response; Feedback; Teacher philosophies|WRITTEN FEEDBACK; PERFORMANCE; CLASSROOMS|Education \& Educational Research; Linguistics|21|4|14
Using rule-based natural language processing to improve disease normalization in biomedical text|2013|Background and objective In order for computers to extract useful information from unstructured text, a concept normalization system is needed to link relevant concepts in a text to sources that contain further information about the concept. Popular concept normalization tools in the biomedical field are dictionary-based. In this study we investigate the usefulness of natural language processing (NLP) as an adjunct to dictionary-based concept normalization. Methods We compared the performance of two biomedical concept normalization systems, MetaMap and Peregrine, on the Arizona Disease Corpus, with and without the use of a rule-based NLP module. Performance was assessed for exact and inexact boundary matching of the system annotations with those of the gold standard and for concept identifier matching. Results Without the NLP module, MetaMap and Peregrine attained F-scores of 61.0\% and 63.9\%, respectively, for exact boundary matching, and 55.1\% and 56.9\% for concept identifier matching. With the aid of the NLP module, the F-scores of MetaMap and Peregrine improved to 73.3\% and 78.0\% for boundary matching, and to 66.2\% and 69.8\% for concept identifier matching. For inexact boundary matching, performances further increased to 85.5\% and 85.4\%, and to 73.6\% and 73.3\% for concept identifier matching. Conclusions We have shown the added value of NLP for the recognition and normalization of diseases with MetaMap and Peregrine. The NLP module is general and can be applied in combination with any concept normalization system. Whether its use for concept types other than disease is equally advantageous remains to be investigated.|Text mining; Biomedical concept identification; Natural language processing; Dictionary-based system; Rule-based system|INFORMATION EXTRACTION; TERM IDENTIFICATION; NAME IDENTIFICATION; GENE NORMALIZATION; PROTEIN; RECOGNITION; TASK|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|19|0|14
Applying active learning to supervised word sense disambiguation in MEDLINE|2013|Objectives This study was to assess whether active learning strategies can be integrated with supervised word sense disambiguation (WSD) methods, thus reducing the number of annotated samples, while keeping or improving the quality of disambiguation models. Methods We developed support vector machine (SVM) classifiers to disambiguate 197 ambiguous terms and abbreviations in the MSH WSD collection. Three different uncertainty sampling-based active learning algorithms were implemented with the SVM classifiers and were compared with a passive learner (PL) based on random sampling. For each ambiguous term and each learning algorithm, a learning curve that plots the accuracy computed from the test set as a function of the number of annotated samples used in the model was generated. The area under the learning curve (ALC) was used as the primary metric for evaluation. Results Our experiments demonstrated that active learners (ALs) significantly outperformed the PL, showing better performance for 177 out of 197 (89.8\%) WSD tasks. Further analysis showed that to achieve an average accuracy of 90\%, the PL needed 38 annotated samples, while the ALs needed only 24, a 37\% reduction in annotation effort. Moreover, we analyzed cases where active learning algorithms did not achieve superior performance and identified three causes: (1) poor models in the early learning stage; (2) easy WSD cases; and (3) difficult WSD cases, which provide useful insight for future improvements. Conclusions This study demonstrated that integrating active learning strategies with supervised WSD methods could effectively reduce annotation cost and improve the disambiguation models.|Active Learning; Word Sense Disambiguation; Natural Language Processing; Machine Learning; Uncertainty Sampling; Annotation|CLASSIFICATION; TEXT; ABBREVIATIONS; UMLS; GENE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|8|0|14
COMPUTER LEARNER CORPORA: ANALYSING INTERLANGUAGE ERRORS IN SYNCHRONOUS AND ASYNCHRONOUS COMMUNICATION|2013|This study focuses on the computer-aided analysis of interlanguage errors made by the participants in the telematic simulation IDEELS (Intercultural Dynamics in European Education through on-Line Simulation). The synchronous and asynchronous communication analysed was part of the MiLC Corpus, a multilingual learner corpus of texts written by language learners from different language backgrounds. The main research questions centred on the differences in the amount and types of errors found in both the synchronous and asynchronous modes of communication, and whether different L1 groups committed certain errors more than their counterparts from other mother tongue backgrounds. As we hypothesised, more errors were found in the synchronous mode of communication than in the asynchronous; however, when examining the exact types of errors, some categories were more frequent in the synchronous mode (the formal and grammatical errors, among others), while in the asynchronous, errors of style and lexis occurred more frequently. A analysis of the data revealed that the frequency of error types varied with each different L1 group participating in the simulation, this same analysis also showed that highly relevant associations could be established the participants' L1 and specific error types.|Learner Corpora; Error Analysis; Correspondence Analysis; Technology-Mediated Communication; Writing in English as a Foreign Language|WRITTEN DISCOURSE; GRAVITY; WRITERS|Education \& Educational Research; Linguistics|6|1|14
Narrative and Expository Writing of Adolescents With Language-Learning Disabilities: A Pilot Study|2013|We evaluated the narrative and expository writing samples of 12 adolescents with language-learning disabilities (LLD) in Grades 6 to 12 for elements of microstructure (e. g., productivity, grammatical complexity) and macrostructure (genrespecific text structure elements) using an experimental measure. Writing samples were elicited with genre-specific prompts via paper and pencil and transcribed according to Systematic Analysis of Language Transcripts (SALT) conventions. Wilcoxon signed ranks tests indicate that levels of productivity and grammatical complexity were significantly greater in the narrative genre than in the expository genre. However, participants' writing samples demonstrated equally impoverished text structure for both genres. Positive correlations were found between microstructure and macrostructure performance. Findings confirm the effects of discourse genre on measures of microstructure and further elucidate the use of microstructure and macrostructure elements in the writing of adolescents with LLD. Future research, comprehensive writing assessment, and interventionists should consider direct measurement of both microstructure and macrostructure components across genres for this population.|language-learning disorder; writing assessment; language/linguistics|COMPOSITION SKILLS; DISABLED STUDENTS; CHILDREN; DISCOURSE; DISORDERS|Linguistics; Rehabilitation|5|1|14
Soft power, ideology and symbolic manipulation in Summer Olympic Games opening ceremonies: a semiotic analysis|2013|This paper is a semiotic analysis of Summer Olympic Games Opening ceremonies as performative texts. Owing to massive media attention, these events have become eagerly awaited global spectacles. However, with such a wide audience, the challenge is to convey both an Olympic welcome and something truly unique about the host city and nation. This creates a communication challenge and some interesting questions in terms of symbolism. Research into the content of Olympic Games ceremonies reveals an exercise both in forging internal cohesion and in projecting soft power. Soft power is an increasingly valuable currency in a multipolar world and opening ceremonies are a prime soft power opportunity. The paper seeks to uncover the ways successive Olympics Games organising committees have sought to balance the competing communicational objectives of opening ceremonies through double coding. The author considers every ceremony from Moscow 1980 to London 2012 in this comparative semiotic analysis.|Olympics; soft power; nation branding; codes; ideology|GLOBALIZATION|Humanities, Multidisciplinary; Communication; Linguistics|0|1|14
Fronto-temporal mapping and connectivity using NIRS for language-related paradigms|2013|NIRS studies were performed on 15 normal right-handed adults to understand the hemodynamic response of the fronto-temporal cortex in response to language paradigms. A 32-channel NIRS system (Imagent ISS Inc.) was used to perform NIRS studies in response to word expression and word reception language paradigms. Activation, functional connectivity, and lateralization analyses were carried out and correlated across all subjects and for each paradigm/stimuli. It was observed that Broca's region plays a major role and Wernicke's region plays a supporting role when responding to word expression paradigm (as observed in past NIRS studies). On the contrary, it is the right homolog of Wernicke's (and partly right homolog of Broca's region) that plays a major role during word reception of comprehensible text (as observed from fMRI studies). This is the first NIRS study that images the entire fronto-temporal regions to understand language from various analyses, towards future work in epileptic/schizophrenic populations. (C) 2012 Elsevier Ltd. All rights reserved.|Near infrared spectroscopy (NIRS); Functional connectivity; Hemodynamic response; Fronto-temporal; Brain activation; Cortical lateralization; Language; Broca; Wernicke|NEAR-INFRARED SPECTROSCOPY; VERBAL-FLUENCY; OXYGENATION CHANGES; FRONTAL ACTIVATION; OPTICAL TOPOGRAPHY; BRAIN; CORTEX; ADULTS; TASK|Linguistics; Neurosciences; Psychology, Experimental|4|1|14
QUANTITATIVE TYPOLOGICAL ANALYSIS OF ROMANCE LANGUAGES|2012|Based on real-text corpora with syntactic annotation, this study quantitatively addressed the following two questions: whether quantitative methods and indexes can point to the diachronic syntactic drifts characterizing the evolution from Latin to Romance languages and whether these methods and indexes can provide evidences to evince the shared syntactic features among Romance languages and define them as a distinctive language subgroup. Our study shows that the distributions of dependency directions are suggestive of positive answers to the above two questions. In addition, the dependency syntactic networks extracted from the dependency treebanks reflect the degree of inflectional variation of a language, and the clustering analysis shows that these parameters, in spite of some imperfections, can also help differentiate Romance languages from Latin diachronically and from other languages synchronically.|Romance languages; quantitative analysis; dependency syntax; complex network; typology|SYNTACTIC DEPENDENCY NETWORKS; COMPLEX NETWORKS|Linguistics; Language \& Linguistics|8|2|14
Ontology-guided feature engineering for clinical text classification|2012|In this study we present novel feature engineering techniques that leverage the biomedical domain knowledge encoded in the Unified Medical Language System (UMLS) to improve machine-learning based clinical text classification. Critical steps in clinical text classification include identification of features and passages relevant to the classification task, and representation of clinical text to enable discrimination between documents of different classes. We developed novel information-theoretic techniques that utilize the taxonomical structure of the Unified Medical language System (UMLS) to improve feature ranking, and we developed a semantic similarity measure that projects clinical text into a feature space that improves classification. We evaluated these methods on the 2008 Integrating Informatics with Biology and the Bedside (I2B2) obesity challenge. The methods we developed improve upon the results of this challenge's top machine-learning based system, and may improve the performance of other machine-learning based clinical text classification systems. We have released all tools developed as part of this study as open source, available at http://code.google.com/p/ytex. (C) 2012 Elsevier Inc. All rights reserved.|Natural language processing; Semantic similarity; Feature selection; Kernel methods; Information gain; Information content|SEMANTIC SIMILARITY; BIOMEDICAL DOMAIN; EXTRACTION; SELECTION|Computer Science, Interdisciplinary Applications; Medical Informatics|10|0|14
Artificial language learning and feature-based generalization|2009|representations such as subsegmental phonological features play such a vital role in explanations of phonological processes that many assume that these representations play an equally prominent role in the learning process. This assumption is tested in three artificial grammar experiments involving a mini language with morpho-phonological alternations based on back vowel harmony. In Experiments 1 and 2, adult participants were trained using positive data from four vowels in a six-vowel inventory: the two remaining vowels appeared at test only. If participants use subsegmental phonological features and natural classes for learning, they should generalize to the novel test segments. Results support a subsegmental feature-based learning strategy that makes use of phonetic information and knowledge of phonological principles. A third experiment (Experiment 3) tests for generalizations to novel suffixes, providing further evidence for the generality of learning. (C) 2009 Elsevier Inc. All rights reserved.|Vowel harmony; Phonological features; Artificial grammar learning|PHONOTACTIC CONSTRAINTS; 12-MONTH-OLD INFANTS; WORD IDENTIFICATION; 8-MONTH-OLD INFANTS; FLUENT SPEECH; PHONOLOGY; VOWELS; SEGMENTATION; PROBABILITY; RECOGNITION|Linguistics; Psychology; Psychology, Experimental|36|1|14
Aspects of lexical proficiency in writing summaries in a foreign language|2009|This study investigated the impact of aspects of the lexical proficiency of EFL students on their summary writing in English (L2) by controlling for the impact of a range of linguistic abilities in English and Japanese (L1). Sixty-eight Japanese undergraduate students wrote two summaries of English texts in English. Their English lexical proficiency, English reading comprehension, English proficiency, knowledge of Japanese vocabulary, and writing proficiency in Japanese as well as the length of summaries were assessed. Multiple regression analysis of the data showed that the effect of L2 lexical proficiency as a whole on summary writing performance was not pronounced compared to the effect of reading comprehension and the length of summaries. However, the ability to write definitions made a unique contribution over and above the other variables including reading comprehension and the length of summaries. It is suggested that different aspects of L2 lexical proficiency have a differential impact on EFL learners' summary writing, and that two factors in particular (structure of semantic network of words, and the ability to metalinguistically manipulate words) may constitute the construct of summary writing in L2. (c) 2009 Elsevier Inc. All rights reserved.|Lexical proficiency; Summary writing; EFL writers; Multiple regression; Word definition; Reading and writing; Writing in academic contexts; Second language writing|WORD KNOWLEDGE; ESL STUDENTS; 2ND-LANGUAGE; DEFINITIONS; VOCABULARY; CLASSROOM; SKILL|Linguistics|28|2|14
GA, MR, FFNN, PNN and GMM based models for automatic text summarization|2009|This work proposes an approach to address the problem of improving content selection in automatic text summarization by using some statistical tools. This approach is a trainable summarizer, which takes into account several features, including sentence position, positive keyword, negative keyword, sentence centrality, sentence resemblance to the title, sentence inclusion of name entity, sentence inclusion of numerical data, sentence relative length, Bushy path of the sentence and aggregated similarity for each sentence to generate summaries. First, we investigate the effect of cacti sentence feature on the summarization task. Then we use all features in combination to train genetic algorithm (GA) and mathematical regression (MR) models to obtain a suitable combination of feature weights. Moreover, we use all feature parameters to train feed forward neural network (FFNN), probabilistic neural network (PNN) and Gaussian mixture model (GMM) in order to construct a text summarizer for each model. Furthermore, we use trained models by one language to test summarization performance in the other language. The proposed approach performance is measured at several compression rates on a data corpus composed of 100 Arabic political articles and 100 English religious articles. The results of the proposed approach are promising, especially the GMM approach. (C) 2008 Elsevier Ltd. All rights reserved.|Automatic summarization; Genetic algorithm; Mathematical regression; Feed forward neural network; Probabilistic neural network; Gaussian mixture model|LATENT SEMANTIC ANALYSIS; SPEAKER IDENTIFICATION; SENTENCE COMPRESSION; TRAINABLE SUMMARIZER; RANDOM-FIELDS; VERIFICATION|Computer Science, Artificial Intelligence|89|2|14
TRANSLATING METADISCOURSE IN RESEARCH ARTICLES|2008|Translating research articles is common practice, although relatively little data exists on the problems in this type of translation. This study examines the translation of textual metadiscourse in academic writing, using the example of translating Slovene research articles into English. The main part of the analysis examines textual metadiscourse in 30 geography articles in Slovene and their translations into English. In addition, the same investigation is conducted in a corpus of 30 English-original geography articles. The translation strategies are analysed at two levels. At the first level, the overall strategy is analysed: the metadiscourse items are compared in the originals and the translations and instances of matching expressions, omissions, and insertions are identified. At the second level, the corresponding expressions are compared and changes made in the translation are noted. The overall results are then compared to those of the comparable target language subcorpus. The results show that not all metadiscourse items found in the original texts are translated, while, at the same time, a significant number of items are inserted in the translation. For those metadiscourse items which are translated, literal translation is chosen in over half of the cases. The results for the comparable target language corpus reveal that metadiscourse is used more frequently in English originals than in translations from Slovene.|academic discourse; scientific translation; contrastive analysis; Slovene-English; metadiscourse|ENGLISH; GERMAN|Linguistics; Language \& Linguistics|1|1|14
Accounting for regressive eye-movements in models of sentence processing: A reappraisal of the Selective Reanalysis hypothesis|2008|When people read temporarily ambiguous sentences, there is often an increased prevalence of regressive eye-movements launched from the word that resolves the ambiguity. Traditionally, such regressions have been interpreted at least in part as reflecting readers' efforts to re-read and reconfigure earlier material, as exemplified by the Selective Reanalysis hypothesis {[}Frazier, L., \& Rayner, K. (1982). Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences. Cognitive Psychology, 14, 178-210]. Within such frameworks it is assumed that the selection of saccadic landing-sites is linguistically supervised. As an alternative to this proposal, we consider the possibility (dubbed the Time Out hypothesis) that regression control is partly decoupled from linguistic operations and that landing-sites are instead selected on the basis of low-level spatial properties such as their proximity to the point from which the regressive saccade was launched. Two eye-tracking experiments were conducted to compare the explanatory potential of these two accounts. Experiment I manipulated the formatting of linguistically identical sentences and showed, contrary to purely linguistic supervision, that the landing site of the first regression from a critical word was reliably influenced by the physical layout of the text. Experiment 2 used a fixed physical format but manipulated the position in the display at which reanalysis-relevant material was located. Here the results showed a highly reliable linguistic influence on the overall distribution of regression landing sites (though with few effects being apparent on the very first regression). These results are interpreted as reflecting mutually exclusive forms of regression control with fixation sequences being influenced both by spatially constrained, partially decoupled supervision systems as well as by some kind of linguistic guidance. The findings are discussed in relation to existing computational models of eye-movements in reading. (C) 2008 Elsevier Inc. All rights reserved.|Syntactic ambiguity resolution; Human parsing; Regressions; Eye-movements; Selective Reanalysis; Computational models|SYNTACTIC AMBIGUITY RESOLUTION; GARDEN-PATH SENTENCES; Z-READER MODEL; LANGUAGE COMPREHENSION; MODIFIER ATTACHMENT; CONNECTIONIST MODEL; SACCADE GENERATION; LEXICAL AMBIGUITY; DISCOURSE CONTEXT; WORD RECOGNITION|Linguistics; Psychology; Psychology, Experimental|36|2|14
Effects of working memory capacity on inference generation during story comprehension in adults with Parkinson's disease|2008|A group of non-demented adults with Parkinson's disease (PD) were Studied to investigate how PD affects pragmatic-language processing, and, specifically, to test the hypothesis that the ability to draw inferences from discourse in PD is critically tied to the underlying working memory (WM) capacity of individual patients {[}Monetta, L., \& Pell, M. D. (2007). Effects of verbal working memory deficits on metaphor comprehension in patients with Parkinson's disease. Brain (aid Language, 101, 80-89]. Thirteen PD patients and a matched group of 16 healthy control (HQ participants performed the Discourse Comprehension Test {[}Brookshire, R. H., \& Nicholas, L. E. (1993). Discourse comprehension lest. Tucson, AZ: Communication Skill Builders], a standardized test which evaluates the ability to generate inferences based on explicit or implied information relating to main ideas or details presented in short stories. initial analyses revealed that the PD group as a whole was significantly less accurate than the HC group when comprehension questions pertained to implied as opposed to explicit information in the stories, consistent with previous findings {[}Murray, L. L., \& Stout, J. C. (1999). Discourse comprehension in Huntington's and Parkinson's diseases. American Journal of Speech-Language Pathology, 8, 137-148]. However, subsequent analyses showed that only a subgroup of PD patients with WM deficits. and not PD patients with WM capacity within the control group range, were significantly impaired for drawing inferences (especially predictive inferences about implied details in the stories) when compared to the control group. These results build oil a growing body of literature, which demonstrates that compromise of frontal-striatal systems and subsequent reductions in processing/WM capacity in PD are a major source of pragmatic-language deficits in many PD patients. (C) 2007 Elsevier Ltd. All rights reserved.|language processing; discourse comprehension; pragmatics; resource allocation; frontal-striatal disorders; Parkinson's disease|INDIVIDUAL-DIFFERENCES; DISCOURSE COMPREHENSION; SENTENCE COMPREHENSION; TEXT COMPREHENSION; PROCESSING SPEED; FRONTAL-CORTEX; BRAIN-DAMAGE; DEFICITS; COMMUNICATION; HEMISPHERES|Linguistics; Neurosciences; Psychology, Experimental|9|1|14
A collaborative filtering-based approach to personalized document clustering|2008|Document clustering is an intentional act that reflects individual preferences with regard to the semantic coherency and relevant categorization of documents. Hence, effective document clustering must consider individual preferences and needs to support personalization in document categorization. Most existing document-clustering techniques, generally anchoring in pure content-based analysis, generate a single set of clusters for all individuals without tailoring to individuals' preferences and thus are unable to support personalization. The partial-clustering-based personalized document-clustering approach, incorporating a target individual's partial clustering into the document-clustering process, has been proposed to facilitate personalized document clustering. However, given a collection of documents to be clustered, the individual might have categorized only a small subset of the collection into his or her personal folders. In this case, the small partial clustering would degrade the effectiveness of the existing personalized document-clustering approach for this particular individual. In response, we extend this approach and propose the collaborative-filtering-based personalized document-clustering (CFC) technique that expands the size of an individual's partial clustering by considering those of other users with similar categorization preferences. Our empirical evaluation results suggest that when given a small-sized partial clustering established by an individual, the proposed CFC technique generally achieves better clustering effectiveness for the individual than does the partial-clustering-based personalized document-clustering technique. (c) 2007 Elsevier B.V. All rights reserved.|document clustering; personalization; collaborative filtering; hierarchical agglomerative clustering (HAC); text mining|INFORMATION-RETRIEVAL; CATEGORIZATION; ORGANIZATION; CONTEXT; SYSTEMS; MODEL; TEXT; WEB|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|17|1|14
Did our ancestors speak a holistic protolanguage?|2007|The dominant theory of the evolution of complex language from protolanguage can be termed the SYNTHETIC approach. Under this view, single words arose first in evolution, and were combined as syntax evolved. More recently, an alternative scenario for protolanguage has been proposed, which we can term the HOLISTIC approach. Scholars subscribing to this view propose that words emerge from longer, entirely arbitrary strings of sounds - non-compositional utterances - via a process of fractionation. Such holistic utterances initially have no internal structure, but represent whole messages. The idea is that over time, chance phonetic similarities are observed between sections of utterances, and that if similar meanings can be ascribed to these strings, then ``words{''} will emerge. This paper dissects the main ideas found in the holistic approach, and argues on a number of grounds that it is conceptually and empirically flawed. A proposal that protolanguage developed out of an earlier holistic primate communication system is hard to sustain, in view of differences between primate vocalization and language. Evidence against the holistic approach is offered on the basis of known facts about the historical development of natural languages, and a conclusion is drawn in favour of synthetic models of protolanguage. (c) 2005 Elsevier B.V. All rights reserved.|protolanguage; holistic protolanguage; synthetic protolanguage; formulaic language; fractionation; primate calls|LANGUAGE; FACULTY; INFANTS|Linguistics; Language \& Linguistics|34|1|14
Reexamining the relationship between working memory and comprehension: The role of available long-term memory|2007|Two individual differences studies tested relationships between listening comprehension and two conceptualizations of working memory (WM) capacity. Recently, some theorists have stressed that the empirically indicated limits of rehearsal-based WM storage components are inconsistent with the amounts of information needed to accomplish complex cognitive tasks, including language comprehension. Accordingly, they have proposed models of WM that include available long-term memory (ALTM) as part of the cognitive workspace. We tested structural equation models (SEM) depicting relationships among factors representing ALTM, content specific background knowledge, listening comprehension, and conventional WM. The analyses revealed that ALTM mediated the relationships of both WM and background knowledge with listening comprehension. The incongruity posed by small-capacity, attention-controlled WM components and theoretical models of comprehension that depict the integration of text information and background knowledge can, at least in part, be resolved by the models presented here. (C) 2006 Elsevier Inc. All rights reserved.|working memory; background knowledge; priming|INDIVIDUAL-DIFFERENCES; READING-COMPREHENSION; SEMANTIC COMPARISONS; CAPACITY; KNOWLEDGE; SPEED; INFORMATION; RETRIEVAL; TEXT; DETERMINANTS|Linguistics; Psychology; Psychology, Experimental|26|1|14
Corpus-based approaches and discourse analysis in relation to reduplication and repetition|2005|Reduplication is important in language studies. Its linguistic form at the lexical level has long been explored in terms of various formalist theories. However, the linguistic function at other levels such as the discourse layer tends to be ignored. A reduplication corpus (ongoing compilation; 1687 items in total thus far) has been constructed as the baseline for an integrated approach to the interplay of various kinds of repetition in the use of language. The frequency of each token was calculated based on its occurrence in the British National Corpus (BNC). Then a wordlist with the top 102 items was proposed for related research topics such as frequency, percentage coverage, concordance, and collocation in terms of McCarthy's framework (1990 and later) using MonoConc Pro, WordSmith 4.0 and the SARA 3.2 software. The probability of collocation was calculated in terms of mutual information (NU). The higher the MI score, the more genuine the association between two items (Church and Hanks, 1990). A powerful search engine, Google, was further employed to locate relevant texts on websites for the analysis of reduplication from lexical to discourse levels. Both reduplication and repetition do play a significant role and exhibit extensively a certain language musicality in our everyday life. (C) 2004 Elsevier B.V. All rights reserved.|corpus linguistics; British National Corpus (BNC); Mutual Information (MI); form and function; reduplication; discourse analysis; advertising|CHILD PHONOLOGY; WORD ORDER; LANGUAGE|Linguistics; Language \& Linguistics|8|0|14
FEEL: a French Expanded Emotion Lexicon|2017|Sentiment analysis allows the semantic evaluation of pieces of text according to the expressed sentiments and opinions. While considerable attention has been given to the polarity (positive, negative) of English words, only few studies were interested in the conveyed emotions (joy, anger, surprise, sadness, etc.) especially in other languages. In this paper, we present the elaboration and the evaluation of a new French lexicon considering both polarity and emotion. The elaboration method is based on the semi-automatic translation and expansion to synonyms of the English NRC Word Emotion Association Lexicon (NRC-EmoLex). First, online translators have been automatically queried in order to create a first version of our new French Expanded Emotion Lexicon (FEEL). Then, a human professional translator manually validated the automatically obtained entries and the associated emotions. She agreed with more than 94 \% of the pre-validated entries (those found by a majority of translators) and less than 18 \% of the remaining entries (those found by very few translators). This result highlights that online tools can be used to get high quality resources with low cost. Annotating a subset of terms by three different annotators shows that the associated sentiments and emotions are consistent. Finally, extensive experiments have been conducted to compare the final version of FEEL with other existing French lexicons. Various French benchmarks for polarity and emotion classifications have been used in these evaluations. Experiments have shown that FEEL obtains competitive results for polarity, and significantly better results for basic emotions.|Sentiment analysis; Opinion mining; Sentiment lexicon; Polarity detection; Emotion classification; Semi-automatic translation|SENTIMENT ANALYSIS; SUICIDE NOTES|Computer Science, Interdisciplinary Applications|0|12|13
``Call for papers{''}: Analysis of the schematic structure and lexico-grammar of CFPs for academic conferences|2015|Many studies analysing generic structures and linguistic features in academic settings have focussed on a single genre, while the structures of inter-related genres are relatively understudied. `Calls for papers' (CFPs), as one example of the ignition of a genre chain of academic activities, could play a rather crucial role in attracting prospective submitters' attention and also determining the quality of contributions. Yet, compared with the research on other academic texts, CFPs have received little attention from analysts. Thus, in this study 40 ``Calls for papers{''} from various language and education-related conferences announced on the Internet were collected and their schematic structure and lexico-grammatical features were analysed. A manual multi-level move analysis as well as a computerised analysis of the textual elements was performed, followed by qualitative interviews with several conference organisers. Six major moves together with their sub-steps were identified, namely: Drawing attention, Identifying the discourse community coverage, Soliciting contributions, Presenting incentives for participation, Clarifying miscellanea, and Signing off. (C) 2014 Elsevier Ltd. All rights reserved.|Generic structures; Lexico-grammatical analysis; Call for papers (CFP); Promotional genre; Evaluative genre|RESEARCH ARTICLES; GENRE ANALYSIS; JOURNAL DESCRIPTIONS; INTRODUCTIONS; INSTITUTIONS; DISCIPLINES; LINGUISTICS; PROSPECTUS; ABSTRACTS; LANGUAGE|Linguistics|4|1|13
A comparison of video- and audio-mediated listening tests with many-facet Rasch modeling and differential distractor functioning|2015|The rise in the affordability of quality video production equipment has resulted in increased interest in video-mediated tests of foreign language listening comprehension. Although research on such tests has continued fairly steadily since the early 1980s, studies have relied on analyses of raw scores, despite the growing prevalence of item response theory in the field of language testing as a whole. The present study addresses this gap by comparing data from identical, counter-balanced multiple-choice listening test forms employing three text types (monologue, conversation, and lecture) administered to 164 university students of English in Japan. Data were analyzed via many-facet Rasch modeling to compare the difficulties of the audio and video formats; to investigate interactions between format and text-type, and format and proficiency level; and to identify specific items biased toward one or the other format. Finally, items displaying such differences were subjected to differential distractor functioning analyses. No interactions between format and text-type, or format and proficiency level, were observed. Four items were discovered displaying format-based differences in difficulty, two of which were found to correspond to possible acting anomalies in the videos. The author argues for further work focusing on item-level interactions with test format.|differential distractor functioning; language assessment; listening assessment; many-facet Rasch measurement; nonverbal communication; video listening test|COMPREHENSION; PERFORMANCE; QUESTIONS; STUDENTS; BEHAVIOR; GESTURES|Linguistics; Language \& Linguistics|5|0|13
Microblogging as a mechanism for human-robot interaction|2014|This paper presents a novel approach to social data analysis, exploring the use of microblogging to manage interaction between humans and robots, and presenting and evaluating an architecture that extends the use of social networks to connect humans and devices. The approach uses natural language processing - in the form of simple grammar-based techniques - to extract features of interest from textual data retrieved from a microblogging platform in real-time and generate appropriate executable code for the robot. The simple rule-based solution exploits some of the `natural' constraints imposed by microblogging platforms to manage the potential complexity of the interactions and create bi-directional communication. In order to evaluate the developed system, an analysis of real-time, user-generated social media data is presented. The analysis demonstrates the feasibility of producing programmes from the social media data which lead to executable actions by a front-end application - an approach of immediate relevance to web-based systems, like question-answering engines, personal digital assistants, and smart home/office devices. (C) 2014 The Authors. Published by Elsevier B.V.|Twitter; Human-robot interfaces; Architectures for social robotics; Computational intelligence for knowledge acquisition; Social media retrieval|USABILITY|Computer Science, Artificial Intelligence|6|0|13
(New) participatory framework on You Tube? Commenter interaction in US political speeches|2014|This article examines the various participant roles adopted by users on You Tube, when watching and commenting on Barack Obama's Inaugural Address (January 2009). Based on the notion that You Tube has become a powerful medium for (re)broadcasting institutional texts and genres, the article argues that text commenting practices allow for the co-creation of distinct participatory roles. Drawing on a quantitative and qualitative corpus-assisted analysis of the comments to the speech, the article examines how roles are defined and participatory positions delimited through linguistic and non-linguistic means. It addresses the different types of production and reception roles (Goffmann, 1981; Levinson, 1988) exploited by users for communication and how they differ from the traditional ones, `ratified' and `unratified' participants in the medium, and the ways in which the You Tube medium affects participation. A reworking of the traditional participatory framework categories is proposed on the basis of the new online environments. Specifically, it proposes a multi-level representation of production, with the original speech and speaker (Obama) seen as the first level of production, and the comments as a secondary level. Both levels entail various reception roles, which are exploited to various degrees by YouTube participants. (C) 2014 Elsevier B.V. All rights reserved.|Participation framework; YouTube; Text commenting; Ratification; Political discourse|YOUTUBE; TEXT|Linguistics; Language \& Linguistics|9|2|13
Meaning construction in verbomusical environments: Conceptual disintegration and metonymy|2014|In this paper I explore the workings of meaning (re)construction strategies in programmatic musical works, where the music stands for a broader extra-musical narration. The analysis of ten fragments of classical and contemporary music involving text and music reveals that conceptual disintegration in connection to metonymy emerges as a crucial tool for meaning (re)construction in programmatic music. This research presents four major contributions to the field. First, this paper holds for the complementariness of networks of conceptual disintegration and metonymic mappings in order to convincingly account for conceptual disintegration as a product (i.e., the multimodal expression) and as a process (i.e., the conceptual operation). Second, concerning the product, this paper provides a theoretical categorization of conceptual disintegration in terms of the ``degree of disintegration{''} and ``degree of subsidiarity{''} between the represented part and the whole conceptual package. Third, conceming the process, this work claims that metonymy arises as powerful analytical tool because it counts on a higher degree of constraint than blends. A view from Conceptual Metonymy Theory allows us to expand the inventory of possible meaning reconstruction processes in multimodal use: metonymic echoing, metaphtonymy, metonymic cueing, source-in-target metonymies and multiple source-in-target metonymies. Fourth, this paper deals with musical and verbomusical examples, largely unexplored in cognitive-linguistic studies. (C) 2014 Elsevier B.V. All rights reserved.|Conceptual disintegration; Inference; Meaning construction; Music; Multimodal metonymy; Patterns of interaction|MULTIMODAL METAPHOR|Linguistics; Language \& Linguistics|5|3|13
Academic Language Socialization in High School Writing Conferences|2014|This study examines multilingual high school writers' individual talk with their teachers in two advanced English language development classes to obsenie how such talk shapes linguistically diverse adolescents' writing. Addressing adolescent writers' language socialization through microethnographic discourse analysis, the author argues that teachers' oral responses during writing conferences can either scaffold or deter students' socialization into valued ways of using academic language for school writing. She suggests what forms of oral response provide scaffolding and what forms might limit multilingual adolescent learners' academic literacy. Constructive interactions engaged students in dialogue about their writing, and students included content or phrasing from the interaction in their texts. Unhelpful interactions failed to foster students' language development in observable ways. Although teachers attempted to scaffold ideas and language, they often did not guide students' discovery of appropriate forms or points. These interactions represent restrictive academic language socialization: while some students did create academic texts, they learned little about academic language use.|adolescent literacy; language socialization; scaffolding; second language writing|CLASSROOMS; STUDENT; MAINSTREAM; LITERACIES; KNOWLEDGE; IDENTITY; ENGLISH|Linguistics|2|2|13
Is less more? Effectiveness and perceived usefulness of keyword and full captioned video for L2 listening comprehension{*|2014|The aim of this study was twofold: we investigated (a) the effect of two types of captioned video (i.e., on-screen text in the same language as the video) on listening comprehension; (b) L2 learners' perception of the usefulness of captions while watching L2 video. The participants, 226 university-level students from a Flemish university, watched three short French clips in one of three conditions: the control group watched the clips without captions (N = 70), the second group had fully captioned clips (N = 81), the third group had keyword captioned clips (N = 75). After each clip, all participants took a listening comprehension test, which consisted of global and detailed questions. To answer the detailed questions, participants had access to an audio passage of the corresponding clip. At the end of the experiment, participants completed a questionnaire and open-ended survey questions about their perception of captions. Our findings revealed that the full captioning group outperformed both the no captioning and the keyword captioning group on the global comprehension questions. However, no difference was found between the keyword captioning and the no captioning group. Results of the detailed comprehension questions (with audio) revealed no differences between the three conditions. A content-analysis approach to the questionnaire indicated that learners' perceived need for full captions is strong. Participants consider captions useful for speech decoding and meaning-making processes. Surprisingly, keyword captions were considered highly distracting. These findings suggest that full rather than keyword captioning should be considered when proposing video-based listening comprehension activities to L2 learners.|listening comprehension; perceived usefulness; video; full captions; effectiveness; keyword captions|HELP OPTIONS; LANGUAGE; VOCABULARY; INPUT|Education \& Educational Research; Linguistics; Language \& Linguistics|8|4|13
Semantic spaces for improving language modeling|2014|Language models are crucial for many tasks in NLP (Natural Language Processing) and n-grams are the best way to build them. Huge effort is being invested in improving n-gram language models. By introducing external information (morphology, syntax, partitioning into documents, etc.) into the models a significant improvement can be achieved. The models can however be improved with no external information and smoothing is an excellent example of such an improvement. In this article we show another way of improving the models that also requires no external information. We examine patterns that can be found in large corpora by building semantic spaces (HAL, COALS, BEAGLE and others described in this article). These semantic spaces have never been tested in language modeling before. Our method uses semantic spaces and clustering to build classes for a class-based language model. The class-based model is then coupled with a standard n-gram model to create a very effective language model. Our experiments show that our models reduce the perplexity and improve the accuracy of n-gram language models with no external information added. Training of our models is fully unsupervised. Our models are very effective for inflectional languages, which are particularly hard to model. We show results for five different semantic spaces with different settings and different number of classes. The perplexity tests are accompanied with machine translation tests that prove the ability of proposed models to improve performance of a real-world application. (C) 2013 Elsevier Ltd. All rights reserved.|Class-based language models; Semantic spaces; HAL; COALS; BEAGLE; Random Indexing; Purandare and Pedersen; Clustering; Inflectional languages; Machine translation|SPEECH RECOGNITION; MAXIMUM-LIKELIHOOD; INFORMATION; ALGORITHM|Computer Science, Artificial Intelligence|12|0|13
Evaluating measures of semantic similarity and relatedness to disambiguate terms in biomedical text|2013|Introduction: In this article, we evaluate a knowledge-based word sense disambiguation method that determines the intended concept associated with an ambiguous word in biomedical text using semantic similarity and relatedness measures. These measures quantify the degree of similarity or relatedness between concepts in the Unified Medical Language System (UMLS). The objective of this work is to develop a method that can disambiguate terms in biomedical text by exploiting similarity and relatedness information extracted from biomedical resources and to evaluate the efficacy of these measure on WSD. Method: We evaluate our method on a biomedical dataset (MSH-WSD) that contains 203 ambiguous terms and acronyms. Results: We show that information content-based measures derived from either a corpus or taxonomy obtain a higher disambiguation accuracy than path-based measures or relatedness measures on the MSH-WSD dataset. Availability: The WSD system is open source and freely available from http://search.cpan.org/dist/UMLS-SenseRelate/. The MSH-WSD dataset is available from the National Library of Medicine http://wsd.nlm.nih.gov. (C) 2013 Elsevier Inc. All rights reserved.|Natural language processing; NLP; Word sense disambiguation; WSD; Semantic similarity and relatedness; Biomedical documents|WORD SENSE DISAMBIGUATION; INFORMATION; DOCUMENTS; UMLS|Computer Science, Interdisciplinary Applications; Medical Informatics|18|0|13
Knowledge-based biomedical word sense disambiguation: an evaluation and application to clinical document classification|2013|Background Word sense disambiguation (WSD) methods automatically assign an unambiguous concept to an ambiguous term based on context, and are important to many text-processing tasks. In this study we developed and evaluated a knowledge-based WSD method that uses semantic similarity measures derived from the Unified Medical Language System (UMLS) and evaluated the contribution of WSD to clinical text classification. Methods We evaluated our system on biomedical WSD datasets and determined the contribution of our WSD system to clinical document classification on the 2007 Computational Medicine Challenge corpus. Results Our system compared favorably with other knowledge-based methods. Machine learning classifiers trained on disambiguated concepts significantly outperformed those trained using all concepts. Conclusions We developed a WSD system that achieves high disambiguation accuracy on standard biomedical WSD datasets and showed that our WSD system improves clinical document classification. Data sharing We integrated our WSD system with MetaMap and the clinical Text Analysis and Knowledge Extraction System, two popular biomedical natural language processing systems. All codes required to reproduce our results and all tools developed as part of this study are released as open source, available under .|Word Sense Disambiguation; Semantic similarity; Natural Language Processing|SEMANTIC SIMILARITY; RELATEDNESS; PERSPECTIVE; EXTRACTION; DOMAIN; SYSTEM|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|11|0|13
Applying a newswriting research approach to translation|2013|Translation is a situated activity that involves more than simply producing target texts from source texts. In order to understand what translators actually do when they translate, their psycho-biographies as well as the social setting of the workplace and the contextual resources must be considered. In this paper, we outline how a mixed-method approach originally developed to study the newswriting processes of journalists at their workplaces can be applied in translation process research. We argue that progression analysis, which combines keystroke logging, screen recordings, eye-tracking, and cue-based retrospective verbalization, can be profitably used along with version analysis to gain insights into cognitive aspects of the translation process.|translation process; newswriting research; progression analysis; eye-tracking; version analysis|PROGRESSION ANALYSIS|Linguistics; Language \& Linguistics|10|0|13
Conceptualist semantics: explanatory power, scope and uniqueness|2013|A familiar assumption in much linguistic semantics is that meanings are to be identified conceptually as, or as subparts of, the conceptual representations deployed in general cognitive processes. However, this assumption has increasingly come into question as a result of developments in the study of cognition both within and outside linguistics. This article reassesses the place of concept-based explanation in semantics in light of these developments, concentrating on the explanatory about the mental architecture supporting meaning. It concludes that while concept-based explanations of meaning are viable for a certain class of referents, their role in a cognitively natural account of the lexicon is subject to significant but little appreciated limitations. (C) 2012 Elsevier Ltd. All rights reserved.|Conceptualization; Semantic explanation; Situated cognition; Simulation; Expressive function of language; Expressive/descriptive contrast|OPTIMALITY THEORY; CONTEXTUAL FACILITATION; COGNITIVE SCIENCE; LANGUAGE; ILLUSION; DEPTH; REPRESENTATION; MEMORY; COMPREHENSION; EXPRESSIVES|Linguistics; Language \& Linguistics|8|0|13
Natural language technology and query expansion: issues, state-of-the-art and perspectives|2012|The availability of an abundance of knowledge sources has spurred a large amount of effort in the development and enhancement of Information Retrieval techniques. Users' information needs are expressed in natural language and successful retrieval is very much dependent on the effective communication of the intended purpose. Natural language queries consist of multiple linguistic features which serve to represent the intended search goal. Linguistic characteristics that cause semantic ambiguity and misinterpretation of queries as well as additional factors such as the lack of familiarity with the search environment affect the users' ability to accurately represent their information needs, coined by the concept ``intention gap{''}. The latter directly affects the relevance of the returned search results which may not be to the users' satisfaction and therefore is a major issue impacting the effectiveness of information retrieval systems. Central to our discussion is the identification of the significant constituents that characterize the query intent and their enrichment through the addition of meaningful terms, phrases or even latent representations, either manually or automatically to capture their intended meaning. Specifically, we discuss techniques to achieve the enrichment and in particular those utilizing the information gathered from statistical processing of term dependencies within a document corpus or from external knowledge sources such as ontologies. We lay down the anatomy of a generic linguistic based query expansion framework and propose its module-based decomposition, covering topical issues from query processing, information retrieval, computational linguistics and ontology engineering. For each of the modules we review state-of-the-art solutions in the literature categorized and analyzed under the light of the techniques used.|Query expansion systems; Linguistic analysis; Term dependency; Knowledge based processing|INFORMATION-RETRIEVAL; RELEVANCE; SEARCH; WEB; ENVIRONMENTS|Computer Science, Artificial Intelligence; Computer Science, Information Systems|2|1|13
TopicNets: Visual Analysis of Large Text Corpora with Topic Modeling|2012|We present TopicNets, a Web-based system for visual and interactive analysis of large sets of documents using statistical topic models. A range of visualization types and control mechanisms to support knowledge discovery are presented. These include corpus- and document-specific views, iterative topic modeling, search, and visual filtering. Drill-down functionality is provided to allow analysts to visualize individual document sections and their relations within the global topic space. Analysts can search across a dataset through a set of expansion techniques on selected document and topic nodes. Furthermore, analysts can select relevant subsets of documents and perform real-time topic modeling on these subsets to interactively visualize topics at various levels of granularity, allowing for a better understanding of the documents. A discussion of the design and implementation choices for each visual analysis technique is presented. This is followed by a discussion of three diverse use cases in which TopicNets enables fast discovery of information that is otherwise hard to find. These include a corpus of 50,000 successful NSF grant proposals, 10,000 publications from a large research center, and single documents including a grant proposal and a PhD thesis.|Design; Performance; Human Factors; Topic modeling; text visualization; graph visualization|LATENT SEMANTIC ANALYSIS; VISUALIZATION|Computer Science, Artificial Intelligence; Computer Science, Information Systems|29|0|13
Developing a visual temporal modeller: applying an extensible nlp system to support learners' understanding of tense and aspect in English|2012|This paper reports on the development of a prototype tool which shows how learners can be helped to reflect upon the accuracy of their writing. Analysis of samples of freely written texts by intermediate and advanced learners of English as a foreign language (EFL) showed evidence of weakness in the use of tense and aspect. Computational discourse modelling techniques were applied to the data to generate semantic models of fragments of the narratives with particular focus on their temporal structure. These models have been converted into dynamic graphical representations of the temporal relationships between discourse events as the narratives are written. The system also provides access to the ontology devised to model individual events and this offers learners insights into the events' semantic properties. These techniques provide the basis for a stimulating learning tool capable of capturing key elements of written narratives, and prompting learners' awareness of language use, particularly tense and aspect.|Computational discourse modelling; tense and aspect in English; graphical representation of learner narratives; language awareness; learner autonomy|GRAMMAR; DESIGN|Education \& Educational Research; Linguistics; Language \& Linguistics|0|1|13
Bringing Japan and Taiwan closer electronically: A look at an intercultural online synchronic chat task and its effect on motivation|2012|This study examines the motivation of 20 Japanese students of English as a foreign language (EFL) who chatted electronically with 19 Taiwanese EFL students using online synchronous chat software. In particular, we were interested in four factors that affect task-based motivation: the willingness to communicate, task attractiveness, task innovativeness, and the need to communicate in the target language. Qualitative analysis of a posttest questionnaire and the texts that students produced during their online task reveal that students were generally motivated throughout the task with respect to all four of the factors. It is suggested that well-designed online chat tasks, whereby students need to arrive at a consensus via interaction, can be very motivating to students. For teachers, electronic synchronous chat represents one more valuable tool for language teachers to facilitate interaction in the target language.|online chat; motivation; task innovativeness; task attractiveness; willingness to communicate; need|INTRINSIC MOTIVATION; FOREIGN-LANGUAGE; NATIVE SPEAKERS; 2ND-LANGUAGE; WILLINGNESS; COMMUNICATE; CLASSROOM; ATTITUDES; MODEL; ACQUISITION|Education \& Educational Research; Linguistics|12|0|13
Investigating Speech Perception in Children With Dyslexia: Is There Evidence of a Consistent Deficit in Individuals?|2011|Purpose: The claim that speech perception abilities are impaired in dyslexia was investigated in a group of 62 children with dyslexia and 51 average readers matched in age. Method: To test whether there was robust evidence of speech perception deficits in children with dyslexia, speech perception in noise and quiet was measured using 8 different tasks involving the identification and discrimination of a complex and highly natural synthetic ``bee{''}-{''}pea{''} contrast (copy synthesized from natural models) and the perception of naturally produced words. Results: Children with dyslexia, on average, performed more poorly than did average readers in the synthetic syllables identification task in quiet and in across-category discrimination (but not when tested using an adaptive procedure). They did not differ from average readers on 2 tasks of word recognition in noise or identification of synthetic syllables in noise. For all tasks, a majority of individual children with dyslexia performed within norms. Finally, speech perception generally did not correlate with pseudoword reading or phonological processing-the core skills related to dyslexia. Conclusions: On the tasks and speech stimuli that the authors used, most children with dyslexia did not appear to show a consistent deficit in speech perception.|dyslexia; speech perception; noise; reading; categorical perception|DEVELOPMENTAL DYSLEXIA; PHONOLOGICAL REPRESENTATIONS; PROCESSING DEFICITS; POOR READERS; DISCRIMINATION; LANGUAGE; IMPAIRMENTS; DISORDERS; IDENTIFICATION; HYPOTHESIS|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|26|1|13
Toward automated consumer question answering: Automatically separating consumer questions from professional questions in the healthcare domain|2011|Objective: Both healthcare professionals and healthcare consumers have information needs that can be met through the use of computers, specifically via medical question answering systems. However, the information needs of both groups are different in terms of literacy levels and technical expertise, and an effective question answering system must be able to account for these differences if it is to formulate the most relevant responses for users from each group. In this paper, we propose that a first step toward answering the queries of different users is automatically classifying questions according to whether they were asked by healthcare professionals or consumers. Design: We obtained two sets of consumer questions (similar to 10,000 questions in total) from Yahoo answers. The professional questions consist of two question collections: 4654 point-of-care questions (denoted as PointCare) obtained from interviews of a group of family doctors following patient visits and 5378 questions from physician practices through professional online services (denoted as OnlinePractice). With more than 20,000 questions combined, we developed supervised machine-learning models for automatic classification between consumer questions and professional questions. To evaluate the robustness of our models, we tested the model that was trained on the Consumer-PointCare dataset on the Consumer-OnlinePractice dataset. We evaluated both linguistic features and statistical features and examined how the characteristics in two different types of professional questions (PointCare vs. OnlinePractice) may affect the classification performance. We explored information gain for feature reduction and the back-off linguistic category features. Results: The 10-fold cross-validation results showed the best F1-measure of 0.936 and 0.946 on Consumer-PointCare and Consumer-OnlinePractice respectively, and the best F1-measure of 0.891 when testing the Consumer-PointCare model on the Consumer-OnlinePractice dataset. Conclusion: Healthcare consumer questions posted at Yahoo online communities can be reliably classified from professional questions posted by point-of-care clinicians and online physicians. The supervised machine-learning models are robust for this task. Our study will significantly benefit further development in automated consumer question answering. (C) 2011 Elsevier Inc. All rights reserved.|Question classification; Medical question answering; Supervised machine learning; Support vector machines; Natural language processing|CLINICAL QUESTIONS; LITERACY; ASKING|Computer Science, Interdisciplinary Applications; Medical Informatics|8|0|13
Patent Registration Prediction Methodology Using Multivariate Statistics|2011|Whether a patent is registered or not is usually based on the subjective judgment of the patent examiners. However, the patent examiners may determine whether the patent is registered or not according to their personal knowledge, backgrounds etc. In this paper, we propose a novel patent registration method based on patent data. The method estimates whether a patent is registered or not by utilizing the objective past history of patent data instead of existing methods of subjective judgments. The proposed method constructs an estimation model by applying multivariate statistics algorithm. In the prediction model, the application date, activity index, IPC code and similarity of registration refusal are set to the input values, and patent registration and rejection are set to the output values. We believe that our method will contribute to improved reliability of patent registration in that it achieves highly reliable estimation results through the past history of patent data, contrary to most previous methods of subjective judgments by patent agents.|patent; neural network; pattern recognition; data mining; text mining|INNOVATION; SCIENCE|Computer Science, Information Systems; Computer Science, Software Engineering|1|1|13
Before the N400: Effects of lexical-semantic violations in visual cortex|2011|There exists an increasing body of research demonstrating that language processing is aided by context-based predictions. Recent findings suggest that the brain generates estimates about the likely physical appearance of upcoming words based on syntactic predictions: words that do not physically look like the expected syntactic category show increased amplitudes in the visual M100 component, the first salient MEG response to visual stimulation. This research asks whether violations of predictions based on lexical-semantic information might similarly generate early visual effects. In a picture-noun matching task, we found early visual effects for words that did not accurately describe the preceding pictures. These results demonstrate that, just like syntactic predictions, lexical-semantic predictions can affect early visual processing around 100 ms, suggesting that the M100 response is not exclusively tuned to recognizing visual features relevant to syntactic category analysis. Rather, the brain might generate predictions about upcoming visual input whenever it can. However, visual effects of lexical-semantic violations only occurred when a single lexical item could be predicted. We argue that this may be due to the fact that in natural language processing, there is typically no straightforward mapping between lexical-semantic fields (e.g., flowers) and visual or auditory forms (e.g., tulip, rose, magnolia). For syntactic categories, in contrast, certain form features do reliably correlate with category membership. This difference may, in part, explain why certain syntactic effects typically occur much earlier than lexical-semantic effects. (C) 2011 Elsevier Inc. All rights reserved.|Language processing; Lexical-semantic processing; Magnetoencephalography; N400; Visual cortex; Lexical priming; M100; Prediction; Top-down processing|LANGUAGE COMPREHENSION; BRAIN POTENTIALS; WORD RECOGNITION; MEG; PREDICTION; INFORMATION; ACTIVATION; COMPONENT|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|22|1|13
Formally analysing the concepts of domestic violence|2011|The types of police inquiries performed these days are incredibly diverse. Often data processing architectures are not suited to cope with this diversity since most of the case data is still stored as unstructured text. In this paper Formal Concept Analysis (FCA) is showcased for its exploratory data analysis capabilities in discovering domestic violence intelligence from a dataset of unstructured police reports filed with the Amsterdam-Amstelland police in the Netherlands. From this data analysis it is shown that FCA can be a powerful instrument to operationally improve policing practice. For one, it is shown that the definition of domestic violence employed by the police is not always as clear as it should be, making it hard to use it effectively for classification purposes. In addition, this paper presents newly discovered knowledge for automatically classifying certain cases as either domestic or non-domestic violence. Moreover, it provides practical advice for detecting incorrect classifications performed by police officers. A final aspect to be discussed is the problems encountered because of the sometimes unstructured way of working of police officers. The added value of this paper resides in both using FCA for exploratory data analysis, as well as with the application of FCA for the detection of domestic violence. (C) 2010 Elsevier Ltd. All rights reserved.|Formal Concept Analysis (FCA); Domestic violence; Knowledge discovery in databases; Text mining; Exploratory data analysis; Knowledge enrichment; Concept discovery|KNOWLEDGE DISCOVERY; DATABASES|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|9|0|13
A SURVEY OF TOOLS SUPPORTING DESIGN AND EVALUATION OF WEBSITES BASED ON MODELS OF HUMAN INFORMATION INTERACTION|2010|This paper presents and discusses a survey of existing tools to support design and evaluation of websites, with special emphasis on improving the information navigation process. The amount of information of today's websites, the continuous evolution of the medium and the heterogeneity of typical users' profiles, make the website design task particularly hard. The presented tools are mainly based on recent models of Web usage behavior, and involve various natural language and semantic similarity modeling methods. Validation studies of the presented tools have shown that they can support effectively various phases of the website design lifecycle including information structuring, hyperlink evaluation and assessment of alternative designs. In this paper, existing techniques are discussed, the aspects of Web design that (should and) could be better supported are identified and suggestions are made on extensions of existing approaches to better support the usability evaluation process.|Semantic similarity algorithms; cognitive models; automated tools; Web design; usability evaluation|COMPREHENSION-BASED MODEL; WORLD-WIDE-WEB; NAVIGATION; SITE; ARCHITECTURE; USERS; SCENT|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|5|2|13
Phonological development in children aged 3 and 4 years considering the use of processes and the influence of gender|2010|Natural phonology puts forward that children simplify words in their utterances through strategies known as Phonological Processes (PP). According to this theory, phonological development consists of the gradual fading of PP. Evidence suggests the existence of numerous and diverse PP between 3 and 4 years of age; however, no exact description of this age period is available yet. In Chile, very few phonological development studies consider this theory. In addition, gender influences have been scarcely explored. Therefore, the following objectives were proposed: a) to describe phonological development in 3-4-year-old children by considering their use of PP; and b) to establish gender influences on this development. A sample of 180 participants was organized into two different age groups: a 3-year-old group (n 90; 42 girls and 48 boys) and a 4-year-old group (n 90; 45 girls and 45 boys). Both groups were tested with TEPROSIF-R to identify phonological processes. It was found that 3 year olds use significantly more PP than 4 year olds. Structural PP was more frequent in both groups. Regarding gender, no influence was found for phonological development. Findings suggest that girls and boys in this age period focus more on the acquisition of the structure of words, rather than on phonological oppositions.|Phonological development; language development; natural phonology; Phonological Processes|SPANISH-SPEAKING CHILDREN; VOCABULARY DEVELOPMENT; SEX-DIFFERENCES; LANGUAGE; SENSITIVITY; PRODUCTIONS; DISORDERS; PATTERNS|Linguistics; Language \& Linguistics|6|0|13
College English learners' discursive motivation construction in China|2009|There are abundant studies of second/foreign language learning motivation. However, there appears to be insufficient research into how language learners' discourses mediate the construction of their learning/motivation. This paper investigated the discursive construction of two English language learners' motivation in a comprehensive university in the People's Republic of China. Employing a critical discourse analysis framework, this paper illustrated how learner motivation was discursively constructed in the constant interaction between the individual and the social environment, and through a complex process involving learners' interpersonal relationships, their imaginative projections about the future, and an alignment with social discourses. The paper argues for more discourse-based studies that view motivation as a social and historical construct dynamically emerging from individual learners' interaction with contextual conditions and construed in learners' language in use. This paper starts by locating this study within the L2 motivation literature and then provides an interpretation of the interview and diary study texts in light of the sociocultural context where the investigation occurred. (c) 2009 Elsevier Ltd. All rights reserved.|English learning; Motivation; Identity; Discourse; China|LEARNING-MOTIVATION; LANGUAGE; 2ND-LANGUAGE|Education \& Educational Research; Linguistics|11|1|13
Negation and the creation of implicit meaning in poetry|2009|Creating meaning through the use of negation is a cooperative process between speaker and hearer or writer and reader; at surface level, negation acts as an instruction that a proposition should be understood as an unrealized state, event or existence. However, this unrealized state of affairs appears to add no positive information to an ongoing discourse, and approaches based on an analysis of formal semantics and predicate logic are limited in their ability to account for how negated propositions are meaningful in discourse. A reader must infer the intended relevant meaning of a negated proposition based on the assumption that it functions explicitly to deny its opposite, positive counterpart. Further, in order to understand a negated proposition we must be able to conceptualize the positive proposition that is being denied, and this concept, though understood as an unrealized state of affairs, adds to the ongoing discourse both as a concept and as an expectation. A cognitive approach to the analysis of negation in natural language provides the tools to examine how readers and writers cooperate to make meaning. In this article, I use a cognitive stylistic approach, Text World Theory (Werth, 1999), as a framework in my analysis of a small selection of poems, `The Tyre' (Simon Armitage), `The Listeners' (Walter de la Mare) and `Talking in Bed' (Philip Larkin) to explore how negation, as a pragmatic phenomenon, creates unrealized worlds, which far from being discarded are integral to the construction of meaning and effect.|antonymy; Simon Armitage; cognitive stylistics; Walter de la Mare; Philip Larkin; negation; poetry; pragmatics; Text World Theory|TEXT; METAPHORS; SENTENCES|Linguistics; Language \& Linguistics|16|1|13
Computational linguistics for metadata building (CLiMB): using text mining for the automatic identification, categorization, and disambiguation of subject terms for image metadata|2009|In this paper, we present a system using computational linguistic techniques to extract metadata for image access. We discuss the implementation, functionality and evaluation of an image catalogers' toolkit, developed in the Computational Linguistics for Metadata Building (CLiMB) research project. We have tested components of the system, including phrase finding for the art and architecture domain, functional semantic labeling using machine learning, and disambiguation of terms in domain-specific text vis a vis a rich thesaurus of subject terms, geographic and artist names. We present specific results on disambiguation techniques and on the nature of the ambiguity problem given the thesaurus, resources, and domain-specific text resource, with a comparison of domain-general resources and text. Our primary user group for evaluation has been the cataloger expert with specific expertise in the fields of painting, sculpture, and vernacular and landscape architecture.|Natural language processing (NLP); Word sense disambiguation (WSD); Lexical disambiguation; Image access; Metadata extraction; Subject cataloging|MACHINES ANALYZE MESSAGES; NATURAL-LANGUAGE; RETRIEVAL; HISTORY; HUMANS|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|4|5|13
Political scientists on the functions of personal pronouns in their writing: An interview-based study of `I' and `we'|2007|In contrast to the numerous corpus-based studies of pronouns in academic writing, this paper uses qualitative interviews in an attempt to account for academic writers' motivations for using the pronouns `I' and `we' and to describe the textual effects that each case of `I' and `we' helps to create. Five political scientists took part in the research, commenting upon their pronoun use in one of their own journal articles and also in the other informants' texts. Seven textual effects that `I' and `we' help to construct are identified and described. `I' and `we' are said to help (i) make the readership feel included and involved in the writers' argument; (ii) make the text more accessible; (iii) convey a tentative tone and hedge writers' claims; (iv) explicate the writers' logic or method regarding their arguments or procedures; (v) signal writers' intentions and arguments; (vi) indicate the contribution and newsworthiness of the research; and (vii) allow the writer to inject a personal tenor into the text. The insights and implications of the study are discussed and the paper closes by proposing that similar interview-based studies could be used for pedagogical purposes in English for academic purposes (EAP) contexts.|academic writing; personal pronouns; political science; discourse analysis; interview-based research; persuasion|MULTILINGUAL SCHOLARS; RESEARCH ARTICLES; SCIENCE; METADISCOURSE; PERSUASION; PRAGMATICS; DISCOURSE; CONTEXT; ENGLISH; READER|Communication; Linguistics; Language \& Linguistics|13|2|13
The influence of animacy on relative clause processing|2002|In previous research it has been shown that subject relative clauses are easier to process than object relative clauses. Several theories have been proposed that explain the difference on are basis of different theoretical perspectives. However, previous research tested relative clauses only with animate protagonists. In a corpus study of Dutch and German newspaper texts, we show that animacy is an important determinant of the distribution of subject and object relative clauses. In two experiments in Dutch, in which the animacy of the object of the relative clause is varied. no difference in reading time is obtained between subject and object relative clauses when the object is inanimate. The experiments show that animacy influences the processing difficulty of relative clauses, These results can only be accounted for by Current major theories of relative clause processing when additional assumptions are introduced, and at the same time show that the possibility of semantically driven analysis can be considered as a serious alternative. (C) 2002 Elsevier Science (USA).|parsing; animacy; relative clauses|EYE-MOVEMENTS; WORKING-MEMORY; SENTENCES; INFORMATION; COMPLEXITY; GERMAN; DUTCH|Linguistics; Psychology; Psychology, Experimental|141|1|13
Wine descriptive language supports cognitive specificity of chemical senses|2001|In order to understand wine perception we analyzed tasting notes of four expert wine tasters. The analysis is based on co-occurrence calculations of words within the tasting notes using ALCESTE software. The results of such an analysis of one subject's notes give us word classes reflecting main text ideas and organization of the text. In the present paper we interpret these ``results as follows: (1) Class number and organization are different among experts so that each expert has his own discourse strategy. (2) Wine language is based on prototypes and not on detailed analytical description. (3) Prototypes include not only sensory but also idealistic and hedonistic information. These results are in agreement with recent neurophysiological data. (C) 2001 Academic Press.|wine; representation; prototypes; right hemisphere; chemosensory; description; tasting; experts; hedonistic|MULTICOMPONENT ODOR MIXTURES; OLFACTION|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|57|0|13
Microblog sentiment analysis with weak dependency connections|2018|With the rise of microblogging services like Twitter and Sina Weibo, users are able to post their real-time mood and opinions conveniently and swiftly. At the same time, the ubiquitous social media results in abundant social relations such as following and follower relations. Social relations create a new source for microblog sentiment analysis, which attracts a great amount of attention in recent years. There are two theories that support the use of social relations for sentiment analysis - sentiment consistency and emotional contagion. However, most existing microblog sentiment analysis methods only employ direct connections which cannot fully use the heterogeneous connections in social media. As online social networks consist of communities and nodes in the same community which form weak dependency connections usually share similarities, we investigate how to exploit weak dependency connections as an aspect of social contexts for microblog sentiment analysis in this paper. In particular, we employ community detection methods to capture weak dependency connections and propose a new model for microblog sentiment analysis which incorporates weak dependency connections, sentiment consistency, and emotional contagion together with text information. Experimental results on two real Twitter datasets demonstrate that our proposed model can outperform baseline methods consistently and significantly. (C) 2017 Elsevier B.V. All rights reserved.|Sentiment analysis; Microblog; Social relation; Community detection; Twitter|COMMUNITY STRUCTURE; COMPLEX NETWORKS; RANDOM-WALKS; STRENGTH; TIES|Computer Science, Artificial Intelligence|0|12|12
The effectiveness and efficiency of extensive reading at developing reading rates|2017|Few studies have examined the development of foreign language learners' reading rates through extensive reading. The previous studies conducted have methodological limitations with regards to their research design or interpretation of results. To address these limitations, this study investigated the impact of extensive reading and grammar-translation on reading rate development using an experimental research design with evidence that time spent conducting the respective treatments was similar. First-year Japanese university students (N - 50) were randomly assigned to one of two treatment groups. To measure reading rate improvements over an academic year, pre- and post-treatment reading rate measurements were used where comprehension was maintained above 70\%. The between-groups analysis revealed that the extensive reading group participants (n = 23) increased their reading rate significantly relative to the grammar-translation group participants (n = 27). This study provides evidence of both the effectiveness and efficiency of developing reading rates through extensive reading relative to traditional reading instruction with grammar-translation exercises. Pedagogical implications include allocating more time for extensive reading and questioning the value of the grammar-translation approach. In addressing the call for stronger evidence than quasi-experimental studies, this research demonstrates that classroom-based experimental reading studies which control for time-on-task are feasible. (C) 2017 Elsevier Ltd. All rights reserved.|Extensive reading; Intensive reading; Grammar-translation; Reading rate; Comprehension; Time-on-task; Experimental design|COMPREHENSION; FLUENCY; ENGLISH; TEXTS; EFL|Education \& Educational Research; Linguistics|0|12|12
What are the levels and mechanisms/processes of language evolution?|2017|Modern evolutionary biology is currently characterized by epistemological divergence because, beyond organisms and genes, scholars nowadays investigate a plurality of units of evolution, they recognize multilevel selection, and especially from within the Extended Synthesis, scholars have identified a plurality of evolutionary mechanisms that besides natural selection can explain how the evolution of anatomical form and functional behavior occur. Evolutionary linguists have also implicated a multitude of units, levels and mechanisms involved in (aspects of) language evolution, which has also brought forth epistemological divergence on how language possibly evolved. Here, we examine how a general evolutionary methodology can become abstracted from how biologists study evolution, and how this methodology can become implemented into the field of Evolutionary Linguistics. Applied Evolutionary Epistemology (AEE) involves a systematic search and analysis of the units (that what evolves), levels (loci where evolution takes place), and mechanisms (means whereby evolution occurs) of language evolution, allocating them into ontological hierarchies, and distinguishing them from other kinds of evolution. In this paper in particular, we give an in-depth analysis of how AEE enables an identification, examination, and evaluation of levels and mechanisms of language evolution, and we hone in on how hierarchies and mechanisms of language (evolution) can and have been defined differentially. For an in-depth analysis of units of language evolution, we refer the reader to Gontier (2017) for which this paper functions as a follow-up. Thus, rather than present a specific theory of how language evolved, we present a methodology that enables us to unite existing research programs as well as to develop theories on the subject at hand. (C) 2017 Elsevier Ltd. All rights reserved.|Evolutionary Linguistics; Origin and evolution of language; Units and levels of evolution; Evolutionary mechanisms; Processes; Hierarchies; Extended Synthesis; Applied Evolutionary Epistemology; Philosophy of biology|SOCIAL BRAIN; SELECTION; BIOLOGY; CONSEQUENCES; HIERARCHIES; HYPOTHESIS; EXPANSION; FACULTY; EVOLVE; SPEECH|Linguistics; Language \& Linguistics|1|12|12
Literary research article abstracts: An analysis of rhetorical moves and their linguistic realizations|2017|Research article abstracts are the most effective means of sharing research results. This function and the evolution of the research article genre have kept the abstract in the focus of academic investigations. However, despite the impressive research output on abstracts, research addressing specifically literature research article (LRA) abstracts is scarce. This study, therefore, describes the move structure of the LRA abstract, defines the functions of the identified moves, and discusses their linguistic realizations. To conduct the research, a corpus consisting of 135 abstracts from four international journals with high impact factors was compiled and subjected (a) to move analysis performed by a human analyst and (b) to software-driven analyses involving text analysis software. The results reveal that LRA abstracts have a non-hierarchical eight-move structure with four stable moves, whose functions are to present the background, purpose, methodology and outcomes of the research. LRA abstracts are a mix of the descriptive and informative abstracts and structurally overlap with the rhetorical structure of RA introductions. They have high syntactic complexity and lexical density and contain primarily low frequency words. These features and their high information content make them difficult to process. (C) 2017 Elsevier Ltd. All rights reserved.|Abstracts; Move analysis; Lexico-grammatical features; Corpus analysis; Literature research article|SYNTACTIC COMPLEXITY-MEASURES; STRUCTURED ABSTRACTS; GENRE; JOURNALS; QUALITY|Education \& Educational Research; Linguistics; Language \& Linguistics|0|9|12
A move/step model for methods sections: Demonstrating Rigour and Credibility|2017|In the tradition of Swalesian genre theory, this manuscript explores the rhetorical composition of research article Methods sections through a top-down analysis of a corpus of nine hundred texts representative of thirty academic fields. The analysis resulted in a comprehensive cross-disciplinary model, called Demonstrating Rigour and Credibility (DRaC). The model contains three moves and sixteen steps, which are defined in terms of functional and content realizations. DRaC further served as the analytic framework for corpus annotation. Manually annotated corpus data revealed the moves and steps with high distributional prominence as well as those that are not frequent but occur consistently within and across disciplines. Visualizations of individual texts in a sample of disciplines demonstrated inter-disciplinary and intra-disciplinary patterns and variation in move sequencing. Additionally, algorithmic analysis of the annotated corpus showed that soft and hard sciences form clusters based on their use of DRaC steps, providing a deeper understanding of how shared conventions of rhetorical composition distinguish cross disciplinary similarities in Methods discourse. The findings lend themselves to application in genre writing pedagogy and, more broadly, hold implications for theories of social and cognitive genres. (C) 2017 Elsevier Ltd. All rights reserved.|Move analysis; Methods; Social and cognitive genres; Annotated corpus; Disciplinary writing; Research article|RESEARCH ARTICLE INTRODUCTIONS; APPLIED LINGUISTICS; GENRE; PEDAGOGY; ORGANIZATION; DISCIPLINE; LANGUAGE; ENGLISH|Linguistics|2|7|12
Assessing the usefulness of online message board mining in automatic stock prediction systems|2017|We provide evidence of the usefulness of exploiting online text data in stock prediction systems. We do this by mining a popular Argentinian stock message board and empirically answering two questions. First, is there information in the online stock message board useful for predicting stock returns? Second, if useful information is found, is it novel or it is simply a different way of expressing information already available in the past behavior of stock prices? To address these questions, we build and validate a series of predictive models using state-of-the-art machine learning and topic discovery techniques. Running experiments in which the models are trained with different combinations of features extracted from the past behavior of stock prices, or mined from the online message boards. Evidence suggests that it is possible to extract predictive information from stock message boards. Furthermore, we find that adding this information improves the performance of classification systems trained solely on technical indicators. Our results suggest that information from online text data is complementary to the one available in the past evolution of stock prices. Additionally, we find that highly predictive features derived from the message board data seem to have an importarit and relevant semantic content. (C) 2017 Elsevier B.V. All rights reserved.|Stock market; Text mining; Latent semantic analysis; Ridge regression; Random forest|EXCHANGE; NEWS|Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods|1|8|12
SAO Semantic Information Identification for Text Mining|2017|A Subject-Action-Object (SAO) is a triple structure which can be used to both describe topics in detail and explore the relationship between them. SAO analysis has become popular in bibliometrics, however there are two challenges in the identification of SAO structures: low relevance of SAOs to domain topics; and synonyms in SAO. These problems make the identification of SAO greatly dependent upon domain experts, limiting the further usage of SAO and influencing further the mining of SAO characteristics. This paper proposes a parse tree-based SAO identification method that includes (1) a model to identify the core components (candidate terms for subject \& object) of SAO structures, where term clumping processes and co-word analysis are involved; (2) a parse tree-based hierarchical SAO extraction model to divide entire SAO structures into a collection of simpler sub-tasks for separate subject, action, and object identification; and (3) an SAO weighting model to rank SAO structures for result selection. The proposed method is applied to publications in the Journal of Scientometrics (SCIM), to identify and rank significant SAO structures. Our experiment results demonstrate the validity and feasibility of the proposed method.|Semantic Analysis; Technology Intelligence; Computational Intelligence; Topic Model; Subject-Action Object|SENSITIZED SOLAR-CELLS; PATENT ANALYSIS; TECHNOLOGY; KNOWLEDGE; SCIENCE; INTELLIGENCE; INNOVATION; RETRIEVAL|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|1|6|12
The application of terms mining technique to clustering participant's character patterns in the enterprise management|2016|The participant's character patterns are different in different progresses of enterprise management innovation at various stages of advanced lean management. Term mining technique is used to analyze the text of the results of interviews to detect participant's character patterns in the enterprise management innovation process (EMIP). Five levels of fuzzy language variables-very low, low, normal, high and very high, are used to differentiate the participant's character patterns in the EMIP at the stages of advanced lean management of point, line, plane and cube. The main conclusions from this research are: (1) Participant's character patterns in the EMIP are developed from the four stages (point, line, panel, cube)of the advanced lean management, providing the gist for more targeted designing of the promotion mechanism in the progress of advanced enterprise lean management. (2) The application of text mining method can be extended to analyze participant's character patterns. (3) Get the participant's character patterns can provide the basis for company management.|Enterprise management innovation; Term mining approach; Lean management|ORGANIZATIONAL INNOVATION; IMPLEMENTATION; PERFORMANCE; ADOPTION; SYSTEMS|Computer Science, Information Systems; Computer Science, Theory \& Methods|0|2|12
Multiple Audiences as Text Stakeholders: A Conceptual Framework for Analyzing Complex Rhetorical Situations|2016|In public communication contexts, such as when a company announces the proposal for an important organizational change, argumentation typically involves multiple audiences, rather than a single and homogenous group, let alone an individual interlocutor. In such cases, an exhaustive and precise characterization of the audience structure is crucial both for the arguer, who needs to design an effective argumentative strategy, and for the external analyst, who aims at reconstructing such a strategic discourse. While the peculiar relevance of multiple audience is often emphasized in the argumentation literature and in rhetorical studies, proposals for modelling multi-audience argumentative situations remain scarce and unsystematic. To address this gap, we propose an analytical framework which integrates three conceptual constructs: (1) Rigotti and Rocci's notion of communicative activity type, understood as the implementation of an interaction scheme into a piece of institutional reality, named interaction field; (2) the stakeholder concept, originally developed in strategic management and public relations studies to refer to any actor who affects and/or is affected by the organizational actions and who, accordingly, carries an interest in them; (3) the concept of participant role as it emerges from Goffman's theory of conversation analysis and related linguistic and media studies. From this integration, we derive the notion of text stakeholder for referring to any organizational actor whose interest (stake) becomes an argumentative issue which the organizational text must account for in order to effectively achieve its communicative aim. The text stakeholder notion enables a more comprehensive reconstruction and characterization of multiple audience by eliciting the relevant participants staged in a text and identifying, for each of them, the interactional role they have, the peculiar interest they bear and the related argumentative issue they create. Considering as an illustrative case the defense document issued by a corporation against a hostile takeover attempt made by another corporation, we show how this framework can support the analysis of strategic maneuvering by better defining the audience demand and, so, better explaining how real arguers design and adapt their topical and presentational choices.|Addressee; Activity type; Argumentation; Audience analysis; Interaction field; Multiple audience; Polylogue; Ratified participants; Rhetorical situation; Stakeholders; Strategic communication; Takeovers|SPEECH ACTS; PEDAGOGY; AGENCY|Communication; Linguistics; Language \& Linguistics; Philosophy|1|1|12
Translating hedging devices in news discourse|2016|Though pragmatic elements such as hedging have been recognised as potentially challenging in intercultural communication, translation of hedging devices has received limited research attention. To gain a better insight into the impact of translating on the use of hedging, it is necessary to explore both translated texts and the reasons for modifications. The paper investigates trainee translators' performance in translating hedging devices; it also investigates their perceptions of the pragmatic role that these devices play In a journalistic text. The translation task analysis reveals a considerable degree of omission and modification of hedging devices In translation. The analysis of the target texts, combined with subsequent discourse-based interviews, showed that several factors, including pragmatic competence, the discourse position and form of hedging devices, as well as intentional interventions, contributed to modifications. Our findings offer important insight into the challenges that pragmatic elements may present in translation. (C) 2016 Elsevier B.V. All rights reserved.|Translation; Hedging; News discourse; Intercultural communication|INTERPERSONAL METADISCOURSE; ILLOCUTIONARY FORCE; ENGLISH; MARKERS; ARTICLES; STUDENTS; SCIENCE; MODEL; TEXT|Linguistics; Language \& Linguistics|0|8|12
Coranking the Future Influence of Multiobjects in Bibliographic Network Through Mutual Reinforcement|2016|Scientific literature ranking is essential to help researchers find valuable publications from a large literature collection. Recently, with the prevalence of webpage ranking algorithms such as PageRank and HITS, graph-based algorithms have been widely used to iteratively rank papers and researchers through the networks formed by citation and coauthor relationships. However, existing graph-based ranking algorithms mostly focus on ranking the current importance of literature. For researchers who enter an emerging research area, they might be more interested in new papers and young researchers that are likely to become influential in the future, since such papers and researchers are more helpful in letting them quickly catch up on the most recent advances and find valuable research directions. Meanwhile, although some works have been proposed to rank the prestige of a certain type of objects with the help of multiple networks formed of multiobjects, there still lacks a unified framework to rank multiple types of objects in the bibliographic network simultaneously. In this article, we propose a unified ranking framework MRCoRank to corank the future popularity of four types of objects: papers, authors, terms, and venues through mutual reinforcement. Specifically, because the citation data of new publications are sparse and not efficient to characterize their innovativeness, we make the first attempt to extract the text features to help characterize innovative papers and authors. With the observation that the current trend is more indicative of the future trend of citation and coauthor relationships, we then construct time-aware weighted graphs to quantify the importance of links established at different times on both citation and coauthor graphs. By leveraging both the constructed text features and time-aware graphs, we finally fuse the rich information in amutual reinforcement ranking framework to rank the future importance of multiobjects simultaneously. We evaluate the proposed model through extensive experiments on the ArnetMiner dataset containing more than 1,500,000 papers. Experimental results verify the effectiveness of MRCoRank in coranking the future influence of multiobjects in a bibliographic network.|Design; Algorithms; Performance; Influence mining; mutual reinforcement; literature ranking|RANKING AUTHORS; JOURNALS; PAGERANK; INDEX|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|6|12
The utility of web mining for epidemiological research: studying the association between parity and cancer risk|2016|Background The World Wide Web has emerged as a powerful data source for epidemiological studies related to infectious disease surveillance. However, its potential for cancer-related epidemiological discoveries is largely unexplored. Methods Using advanced web crawling and tailored information extraction procedures, the authors automatically collected and analyzed the text content of 79 394 online obituary articles published between 1998 and 2014. The collected data included 51 911 cancer (27 330 breast; 9470 lung; 6496 pancreatic; 6342 ovarian; 2273 colon) and 27 483 non-cancer cases. With the derived information, the authors replicated a case-control study design to investigate the association between parity (i.e., childbearing) and cancer risk. Age-adjusted odds ratios (ORs) with 95\% confidence intervals (CIs) were calculated for each cancer type and compared to those reported in large-scale epidemiological studies. Results Parity was found to be associated with a significantly reduced risk of breast cancer (OR = 0.78, 95\% CI, 0.75-0.82), pancreatic cancer (OR = 0.78, 95\% CI, 0.72-0.83), colon cancer (OR = 0.67, 95\% CI, 0.60-0.74), and ovarian cancer (OR = 0.58, 95\% CI, 0.54-0.62). Marginal association was found for lung cancer risk (OR = 0.87, 95\% CI, 0.81-0.92). The linear trend between increased parity and reduced cancer risk was dramatically more pronounced for breast and ovarian cancer than the other cancers included in the analysis. Conclusion This large web-mining study on parity and cancer risk produced findings very similar to those reported with traditional observational studies. It may be used as a promising strategy to generate study hypotheses for guiding and prioritizing future epidemiological studies.|digital epidemiology; web mining; cancer risk; parity|ORAL-CONTRACEPTIVE USE; REPRODUCTIVE FACTORS; OVARIAN-CANCER; BREAST-CANCER; COLORECTAL-CANCER; POSTMENOPAUSAL WOMEN; SEARCH BEHAVIOR; UNITED-STATES; SOCIAL MEDIA; WHITE WOMEN|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|1|12
Summarization of films and documentaries based on subtitles and scripts|2016|We assess the performance of generic text summarization algorithms applied to films and documentaries, using extracts from news articles produced by reference models of extractive summarization. We use three datasets: (i) news articles, (ii) film scripts and subtitles, and (iii) documentary subtitles. Standard ROUGE metrics are used for comparing generated summaries against news abstracts, plot summaries, and synopses. We show that the best performing algorithms are LSA, for news articles and documentaries, and LexRank and Support Sets, for films. Despite the different nature of films and documentaries, their relative behavior is in accordance with that obtained for news articles. (C) 2016 Elsevier B.V. All rights reserved.|Automatic text summarization; Generic summarization; Summarization of films; Summarization of documentaries|LATENT SEMANTIC ANALYSIS|Computer Science, Artificial Intelligence|0|1|12
Robust semantic text similarity using LSA, machine learning, and linguistic resources|2016|Semantic textual similarity is a measure of the degree of semantic equivalence between two pieces of text. We describe the SemSim system and its performance in the {*}SEM 2013 and SemEval-2014 tasks on semantic textual similarity. At the core of our system lies a robust distributional word similarity component that combines latent semantic analysis and machine learning augmented with data from several linguistic resources. We used a simple term alignment algorithm to handle longer pieces of text. Additional wrappers and resources were used to handle task specific challenges that include processing Spanish text, comparing text sequences of different lengths, handling informal words and phrases, and matching words with sense definitions. In the {*}SEM 2013 task on Semantic Textual Similarity, our best performing system ranked first among the 89 submitted runs. In the SemEval-2014 task on Multilingual Semantic Textual Similarity, we ranked a close second in both the English and Spanish subtasks. In the SemEval-2014 task on Cross-Level Semantic Similarity, we ranked first in Sentence-Phrase, Phrase-Word, and Word-Sense subtasks and second in the Paragraph-Sentence subtask.|Latent semantic analysis; WordNet; Term alignment; Semantic similarity|CONTEXT; WORDS|Computer Science, Interdisciplinary Applications|4|2|12
Trajectory analysis of drug-research trends in pancreatic cancer on PubMed and ClinicalTrials.gov|2016|Increasing interest in developing treatments for pancreatic cancer has led to a surge in publications in the field. Analyses of drug-research trends are needed to minimize risk in anti-cancer drug development. Here, we analyzed publications on anti-cancer drugs extracted from PubMed records and ClinicalTrials datasets. We conducted a drug cluster analysis by proposing the entity Dirichlet Multinomial Regression (eDMR) technique and in-depth network analysis of drug cluster and target proteins. The results show two distinct research clusters in both the ClinicalTrials dataset and the PubMed records. Specifically, various targets associated with anti-cancer drugs are investigated in new drug testing while the diverse chemicals are studied together with a standard therapeutic agent in the academic literature. In addition, our study confirms that drug research published in PubMed is preceded by clinical trials. Although we only evaluate drugs for pancreatic cancer in the present study, our method can be applied to drug-research trends of other diseases. (C) 2016 Elsevier Ltd. All rights reserved.|Pancreatic cancer; Text mining; Bibliometric analysis; Data analysis; Information extraction|CONTINUOUS-INFUSION 5-FLUOROURACIL; COOPERATIVE-ONCOLOGY-GROUP; PHASE-II TRIAL; EUROPEAN-UNION; CELL ADHESION; GEMCITABINE; CAPECITABINE; CORPUS; CHEMOTHERAPY; RECOGNITION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|2|12
Constrained language A multidimensional analysis of translated English and a non-native indigenised variety of English|2016|Translation and non-native indigenised varieties of English are produced in contexts where heightened constraints operate on them. Recurrent features of translated language include explicitation, normalisation or conventionalisation, simplification, and homogenisation. Similar features in non-native indigenised varieties of English include hyperclarity, anti-deletion, regularisation, simplification and register shifts. This article adopts a multidimensional approach to analyse a translation corpus and a parallel set of texts from ICE East Africa, with ICE Great Britain as control corpus. The aim is to determine whether translated and non-native indigenised varieties of English resemble each other due to shared constraints related to bilingual language production. The results demonstrate three shared sets of features between translated and non-native indigenised varieties of English: increased formality, explicitation of information through elaboration and specification, and features resulting from processing strain. The most important difference is that translated English uses more complex, compressed syntactic structures for elaboration while the non-native indigenised variety relies more on clausal structures.|constrained language; translation; East African English; contact varieties; bilingualism; British English; translation universals; multidimensional analysis; Afrikaans; South Africa|UNIVERSALS; REGISTER|Linguistics; Language \& Linguistics|3|6|12
Auditory word recognition, passive vocabulary and comprehension of oral expository texts in preschoolers|2015|The relationship between vocabulary and memory, on the one hand, and comprehension of oral descriptive texts, on the other, is investigated in preschoolers. We hypothesized that lexical development and memory not only have a significant correlation with performance in comprehension, but these variables can also predict the performance at the discursive level. A study was conducted with 36 children (age range 4; 5 and 5; 7). Participants were tested in passive vocabulary, lexical discrimination, memory, and oral comprehension of descriptive texts developed ad hoc for this study. The results confirmed that both memory and the lexicon are significantly correlated with comprehension. In a regression analysis, however, only the lexicon (in the measures used) was a statistically significant predictor of text comprehension skills development. Taken together, the evidence supports those theoretical proposals that emphasize the role of vocabulary in the early development of discourse skills.|Discourse comprehension; language development; vocabulary|WORKING-MEMORY; LISTENING COMPREHENSION; READING-COMPREHENSION; LANGUAGE COMPREHENSION; INDIVIDUAL-DIFFERENCES; CHILDREN; SKILLS; ABILITY; KNOWLEDGE; EVENT|Linguistics; Language \& Linguistics|0|1|12
ERP evidence for memory and predictive mechanisms in word-to-text integration|2015|During reading, word-to-text integration (WTI) proceeds quickly and incrementally through both prediction and memory processes. We tested predictive and memory mechanisms with event-related potentials (ERPs) recorded on critical words that were across a sentence boundary from co-referential words that differed in dominant direction of lexical association. For comparison of text comprehension, participants performed meaning judgements on a matched set of word pairs. In both tasks, reduced N400 amplitudes were elicited over central scalp electrodes by words associated in either direction relative to task-specific baseline conditions. A temporal principal component analysis of the ERP data extracted a component reflecting this central N400. Additionally, for the text comprehension task early (N200) and late (parietal N400 and P600) discriminated between forward associated and backward associated conditions. The results demonstrate that, beyond N400 indicators of prediction, ERPs reflect the role of memory processes in WTI across sentences.|text comprehension; integration; lexical association; meaning judgements; ERPs|EVENT-RELATED POTENTIALS; SENTENCE-LEVEL CONTEXT; BRAIN POTENTIALS; LANGUAGE COMPREHENSION; SEMANTIC CONTEXT; HEMISPHERIC-DIFFERENCES; SPREADING ACTIVATION; LEXICAL DECISION; WORKING-MEMORY; MESSAGE-LEVEL|Audiology \& Speech-Language Pathology; Behavioral Sciences; Linguistics; Psychology, Experimental|4|0|12
Opinion summarization on spontaneous conversations|2015|In this study we explore opinion summarization on spontaneous conversations using unsupervised and supervised approaches. We annotate a phone conversation corpus with reference extractive and abstractive summaries for a speaker's opinion on a given topic. We investigate two methods: the first is an unsupervised graph-based method, which incorporates topic and sentiment information, as well as sentence-to-sentence relations extracted based on dialogue structure; the second is a supervised method that casts the summarization problem as a classification problem. Furthermore, we investigate the use of pronoun resolution in this summarization task. We develop various features based on pronoun coreference and incorporate them in the supervised opinion summarization system. Our experimental results show that both the graph-based method and the supervised method outperform the baseline approach, and the pronoun related features can help to generate better summaries. (C) 2015 Elsevier Ltd. All rights reserved.|Opinion summarization; Switchboard corpus; Sentiment analysis; Graph-based summarization; Pronoun resolution|TEXT|Computer Science, Artificial Intelligence|0|3|12
What Goes Around Comes Around: Learning Sentiments in Online Medical Forums|2015|It has been shown that online health-related discussions significantly influence the attitudes and behavioral intentions of the discussion participants. Although empirical evidence strongly supports the importance of emotions in health-related online discussions, there are few studies of the relationship between a subjective language and online discussions of personal health. In this work, we study sentiments expressed on online medical forums. Individual posts are classified into one of five categories. We identified three categories as sentimental (encouragement, gratitude, confusion) and two categories as neutral (facts, endorsement). A total of 1438 messages were annotated manually by two annotators with a strong inter-annotator agreement (Fleiss kappa = 0.737 when the posts were annotated in the context of discussion and Fleiss kappa = 0.763 when the posts were annotated as individual entities). Using machine learning multi-class classification approach, we assess the feasibility of automated recognition of the five sentiment categories. As well as considering the predominant sentiments expressed in individual posts, we analyze transitions between sentiments in online discussions.|Natural language processing; Sentiment analysis; Machine learning; Discourse analysis; Sentiment transitions|CLASSIFICATION; EMOTIONS; LANGUAGE; BEHAVIOR; CONTEXT|Computer Science, Artificial Intelligence; Neurosciences|4|0|12
Without his shirt off he saved the child from almost drowning: interpreting an uncertain input|2015|Unedited speech and writing often contains errors, e.g., the blending of alternative ways of expressing a message. As a result comprehenders are faced with decisions about what the speaker may have intended, which may not be the same as the grammatically-licensed compositional interpretation of what was said. Two experiments investigated the comprehension of inputs that may have resulted from blending two syntactic forms. The results of the experiments suggest that readers and listeners tend to repair such utterances, restoring them to the presumed intended structure, and they assign the interpretation of the corrected utterance. Utterances that are repaired are expected to also be acceptable when they are easy to diagnose/repair and they are `familiar', i.e., they correspond to natural speech errors. The results of the experiments established a continuum ranging from outright linguistic illusions with no indication that listeners and readers detected the error (the inclusion of almost in A passerby rescued a child from almost being run over by a bus.), to a majority of unblended interpretations for doubled quantifier sentences (Many students often turn in their assignments late) to only a third undoubled implicit negation (I just like the way the president looks without his shirt off.) The repair or speech error reversal account offered here is contrasted with the noisy channel approach and the good enough processing approach.|acceptability judgements; noisy channel; speech error reversal; syntactic blends; syntactic processing; linguistic illusions|LANGUAGE COMPREHENSION; SPEECH ERRORS; SENTENCES|Audiology \& Speech-Language Pathology; Behavioral Sciences; Linguistics; Psychology, Experimental|0|0|12
Inferring Difficulty: Flexibility in the Real-time Processing of Disfluency|2015|Upon hearing a disfluent referring expression, listeners expect the speaker to refer to an object that is previously unmentioned, an object that does not have a straightforward label, or an object that requires a longer description. Two visual-world eye-tracking experiments examined whether listeners directly associate disfluency with these properties of objects, or whether disfluency attribution is more flexible and involves situation-specific inferences. Since in natural situations reference to objects that do not have a straightforward label or that require a longer description is correlated with both production difficulty and with disfluency, we used a mini-artificial lexicon to dissociate difficulty from these properties, building on the fact that recently learned names take longer to produce than existing words in one's mental lexicon. The results demonstrate that disfluency attribution involves situation-specific inferences; we propose that in new situations listeners spontaneously infer what may cause production difficulty. However, the results show that these situation-specific inferences are limited in scope: listeners assessed difficulty relative to their own experience with the artificial names, and did not adapt to the assumed knowledge of the speaker.|Disfluency; reference; inferences; artificial words; eye-tracking|SPONTANEOUS SPEECH; FILLED PAUSES; LANGUAGE COMPREHENSION; SPOKEN LANGUAGE; DISCOURSE; UH; INFORMATION; LISTENERS; PROSODY; MEMORY|Audiology \& Speech-Language Pathology; Linguistics; Psychology, Experimental|1|1|12
Mobilizing clinical decision support to facilitate knowledge translation: A case study in China|2015|Background: A wide gulf remains between knowledge and clinical practice. Clinical decision support has been demonstrated to be an effective knowledge tool that healthcare organizations can employ to deliver the ``right knowledge to the right people in the right form at the right time{''}. How to adopt various clinical decision support (CDS) systems efficiently to facilitate evidence-based practice is one challenge faced by knowledge translation research. Method: A computer-aided knowledge translation method that mobilizes evidence-based decision supports is proposed. The foundation of the method is a knowledge representation model that is able to cover, coordinate and synergize various types of medical knowledge to achieve centralized and effective knowledge management. Next, web-based knowledge-authoring and natural language processing based knowledge acquisition tools are designed to accelerate the transformation of the latest clinical evidence into computerized knowledge content. Finally, a batch of fundamental services, such as data acquisition and inference engine, are designed to actuate the acquired knowledge content. These services can be used as building blocks for various evidence-based decision support applications. Results: Based on the above method, a computer-aided knowledge translation platform was constructed as a CDS infrastructure. Based on this platform, typical CDS applications were developed. A case study of drug use check demonstrates that the CDS intervention delivered by the platform has produced observable behavior changes (89.7\% of alerted medical orders were revised by physicians). Discussion: Computer-aided knowledge translation via a CDS infrastructure can be effective in facilitating knowledge translation in clinical settings. (C) 2015 Elsevier Ltd. All rights reserved.|Knowledge translation; Clinical decision support; Knowledge representation; Knowledge acquisition; Inference engine; Context-aware knowledge retrieval; Natural language processing|INFORMATION TECHNOLOGY; ORDER ENTRY; SYSTEMS; MEDICINE; REPRESENTATION; MANAGEMENT; QUALITY; IMPLEMENTATION; PERFORMANCE; CHALLENGES|Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical \& Computational Biology|2|2|12
Evaluation of court interpreting A case study of metadiscourse in interpreter-mediated expert witness examinations|2015|The present paper examines the metadiscourse of court interpreting, with a focus on the evaluative language used in relation to interpreting of expert witness testimony. The study explores interactional resources such as hedges, boosters, attitude markers, self-mentions and engagement markers, employed by participants in the interpreter-mediated South Korean courtroom examinations of three English-speaking expert witnesses. Extracts analysed for this paper, involving a total of four interpreters, are taken from two court cases (four extracts each from a civil case, featuring experienced conference interpreters, and a criminal case, with unskilled interpreters). In courtroom settings, where the interpretation of expert testimony is frequently contested, this study demonstrates metadiscursive representation of stance management during professional communication, which is closely linked with facework and rapport management. The analysis indicates that hedging is far more frequently used than boosters, and that various attitude markers and engagement markers are used in evaluating interpretations and ensuring their accuracy. Legal professionals and interpreters alike display their evaluative, affective and epistemic orientation in the interdisciplinary professional discourse, and personal interaction, of the courtroom examinations analysed here.|court interpreting; expert witness; evaluation; metadiscourse; stance|PARTICIPANT ROLES; STANCE; DISCOURSE; TRANSLATION; IDENTITY; PRAGMATICS; LANGUAGE; ARGUMENT; TEXTS; ICTY|Linguistics; Language \& Linguistics|1|2|12
Peddling a semiotics of fear: a critical examination of scare tactics and commercial strategies in public health promotion|2015|In this study, we critically examine the ways in which a nationwide health promotion campaign - the 2013 Diabetes UK/Tesco diabetes campaign, the largest of its kind in the UK - seeks to raise the general public's awareness of Type 2 diabetes. We subject a series of six campaign images (including their layout and accompanying text) to a multimodal discourse analysis, identifying the presence of a range of fear-inducing, stigmatising and commercial strategies, through which the campaign emphasises the dangers of diabetes and advocates personal responsibility for assessing both individual and others' risk of the disease. Specifically, we describe, in multi-semiotic detail, three discursive techniques deployed in the campaign to achieve these ends: (1) the depiction of grief and amplification of diabetes-related danger, (2) the promotion of diabetes risk and localisation of individuals' responsibility for their health and (3) the commercial branding and framing of the Diabetes UK/Tesco partnership - including the promotion of goods and services - as a means of diabetes prevention and management. Our findings raise concerns about the moral legitimacy of using fear-inducing and commercial strategies in order to (effectively) raise public awareness of and responses to Type 2 diabetes, strategies which do little to address the environmental factors which are associated with increasing rates of the disease.|fear and risk; health promotion; diabetes; commercialisation of health; neoliberalism; critical multimodal discourse analysis|OBESITY; DISCOURSE; LIFE|Humanities, Multidisciplinary; Communication; Linguistics|5|3|12
Causality and subjectivity in discourse: The meaning and use of causal connectives in spontaneous conversation, chat interactions and written text|2015|Many languages of the world have connectives to express causal relations at the discourse level. Often, language users systematically prefer one lexical item (because) over another (even highly similar) one (since) to express a causal relationship. Such choices provide a window on speakers' cognitive categorizations, and have been modeled in previous work in terms of subjectivity. However, a broader empirical basis and a more specific operationalization of subjectivity are urgently needed. This paper provides in these needs by developing an integrative empirical approach to the analysis of the Dutch connectives ( whit `because' and want `since/for' in written text, conversation, and chat interactions. These can be considered a case in point for linguistic categorization since related European languages show similar distinctions. The construct of subjectivity is decomposed into characteristics like type of relation and subject of consciousness (who can be considered responsible for the causality?). The use of statistical methods specifically suitable for hypothesis testing in natural language corpora produces results that provide new insights into the division of labor between the two connectives, as well as into the notion of subjectivity.|causality; connectives; subjectivity; Dutch; discourse|COHERENCE RELATIONS; COGNITIVE-COMPLEXITY; DUTCH; CATEGORIZATION; ACQUISITION; PERSPECTIVE; CONTEXT; ORDER|Linguistics; Language \& Linguistics|5|1|12
Assessing obliteration by incorporation in a full-text database: JSTOR, Economics, and the concept of ``bounded rationality{''|2014|To evaluate the usefulness of a full-text database as a source for assessing obliteration by incorporation (OBI), 3,707 article records including the catchphrases ``bounded rationality{''} and/or ``boundedly rational{''} (connected with the work of H. A. Simon) in the article text were retrieved from JSTOR, a full-text database with broad disciplinary coverage. Two subsets were analyzed-a 10 \% systematic sample of all records and a set of all articles in Economics journals (with the addition of the Journal of Economic Theory). A majority of articles in the 10 \% sample came from Economics and Management journals, while Psychology was poorly represented. In the 10 \% sample, based on the percentage of true implicit citations between 1992 and 2009 in the 80 \% of records that had a catchphrase in the body of the article, rather than just in the reference list, annual OBI ranged from 0 to 70 \% (mean 33 \%) with no discernible trend. The Economics articles showed a narrower range of OBI-fluctuating around 40 \% implicit citations over the same time period. In both data sets, a large proportion of indirect citations were to sources that themselves cited a relevant work by Simon. Over 90 \% of the articles in both the 10 \% sample and the economics journal set would not have been retrieved with a database record search because they lacked the catchphrase in the record fields.|Obliteration by incorporation; Economics; Full-text databases; Citation-in-context analysis|CUMULATIVE ADVANTAGE; CITATION ANALYSIS; SCIENCE; PUBLICATION; DOCUMENTS; JOURNALS; EPONYMY|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|5|2|12
Academic discourse in translation: Trainee translators' performance, experience and perception of rhetorical conventions|2014|In translation of academic discourse intended for publication, rhetorical conventions present specific challenges to the translator who is not a member of the academic discourse community. This paper addresses the issue of translation of rhetorical conventions in academic discourse from the perspective of translator training. The study uses translation task analysis, questionnaires and interviews to examine trainee translators' translation performance, their awareness and perception of academic rhetorical conventions, as well as their assumptions and experiences relating to the translation of academic discourse. The translation task analysis reveals issues related to the translation of rhetorical conventions. Questionnaire and interview data are used to explore potential reasons for these issues. The findings identify several pedagogical challenges that need to be addressed in translator training, including trainee translators' familiarity with the social and discursive practices of the academic community, and their awareness of rhetorical elements used in academic texts in the two languages. (C) 2014 Elsevier Ltd. All rights reserved.|Academic discourse; Specialized translation; Translator training; Rhetorical conventions|RESEARCH ARTICLES; ENGLISH; SPANISH; COMPETENCE; GERMAN; TEXT|Linguistics|0|1|12
Tests of a dual-system model of speech category learning|2014|In the visual domain, more than two decades of work has argued for the existence of dual category learning systems. The REFLECTIVE system uses working memory in an explicit fashion to develop and test rules for classifying. The REFLEXIVE system operates by implicitly associating perception with actions that lead to reinforcement. Dual-system models posit that in learning natural categories, learners initially use the reflective system and with practice, transfer control to the reflexive system. The role of reflective and reflexive systems in second language (L2) speech learning has not been systematically examined. In the study reported in this paper, monolingual native speakers of American English were trained to categorize Mandarin tones produced by multiple speakers. Our computational modeling approach demonstrates that learners use reflective and reflexive strategies during tone category learning. Successful learners use speaker-dependent, reflective analysis early in training and reflexive strategies by the end of training. Our results demonstrate that dual-learning systems are operative in L2 speech learning. Critically, learner strategies directly relate to individual differences in successful category learning.|L2 acquisition; dual-learning systems; reflexive processing; reflective processing; individual differences|TRAINING JAPANESE LISTENERS; R-VERTICAL-BAR; SUPERIOR TEMPORAL REGION; MULTIPLE MEMORY-SYSTEMS; CROSS-LINGUISTIC PET; LONG-TERM RETENTION; INDIVIDUAL-DIFFERENCES; INFORMATION-INTEGRATION; LANGUAGE EXPERIENCE; TONE PERCEPTION|Linguistics; Psychology, Experimental|13|1|12
Experiment on sentiment embedded comparison interface|2014|Because the large amount of product reviews has been appearing in the current e-commerce sites, it becomes increasingly important to summarize these reviews, so as to support online buyers' information-seeking and decision-making process. However, little work has investigated how to present the sentiment information (as extracted from reviews) on the user interface, especially in the interface of supporting users to compare products. In this manuscript, we design three alternative sentiment-embedded comparison interfaces based on popular techniques, respectively called opinion table, opinion bar chart, opinion cloud. We then report results from two user studies on the developed interfaces. The first user study verified (1) the important role of comparison matrix in users' decision process, (2) the benefit of incorporating reviews into the comparison interface, and (3) the positive effect of showing features' sentiment info on aiding users' product comparison. Motivated by the first study's results, we performed the second user study to in depth compare the three alternative designs empirically. It turns out that the opinion bar chart, that mainly visualizes numerical feature sentiment scores via bars and qualitative adjective words via tool tip window, achieved significantly higher user assessments in terms of perceived information sufficiency, perceived ease of use and perceived cognitive effort. Users also behaved more active in opinion bar chart by manipulating the extracted features while less frequently viewing the raw textual reviews. The opinion cloud, that primarily visualizes the feature-associated opinion words in form of adjusted tags, was shown with better performance than opinion table, but slightly lower favor than opinion bar chart. In addition, this study revealed the effectiveness of showing opinion features (i.e., features with sentiment) in allowing users to examine the similarity and contrast across multiple products, and hence enabling them to make an informed and confident decision at the end. (c) 2014 Elsevier B.V. All rights reserved.|Consumer reviews; E-commerce; Product comparison; Sentiment analysis; Feature-based review summarization; User study|DECISION-MAKING; CONSUMER; BEHAVIOR; REVIEWS; TEXT; COMMERCE|Computer Science, Artificial Intelligence|4|0|12
Multidimensional topic analysis in political texts|2014|Automatic content analysis is more and more becoming an accepted research method in social science. In political science researchers are using party manifestos and transcripts of political speeches to analyze the positions of different actors. Existing approaches are limited to a single dimension, in particular, they cannot distinguish between the positions with respect to a specific topic. In this paper, we propose a method for analyzing and comparing documents according to a set of predefined topics that is based on an extension of Latent Dirichlet Allocation (LDA) for inducing knowledge about relevant topics. We validate the method by showing that it can guess which member of a coalition was assigned a certain ministry based on a comparison of the parties' election manifestos with the coalition contract. We apply the method to German National Elections since 1990 and show that the use of our method consistently outperforms a baseline method that-simulates manual annotation of individual sentences based on keywords and standard text comparison. In our experiments, we compare two different extensions of LDA and investigate the influence of the used seed set. Finally, we give a brief illustration of how the output of our method can be interpreted to compare positions towards specific topics across several parties. (C) 2013 Elsevier B.V. All rights reserved.|Topic models; Political science; Text Analysis|POLICY POSITIONS|Computer Science, Artificial Intelligence; Computer Science, Information Systems|2|2|12
Through the looking glass: a social semiotic and linguistic perspective on the study of video chats|2014|This paper provides a theoretical framework for the study of the video chat, a spontaneous web-based synchronous text that allows forms of communication in which social semiotic resources come into play and produce a new terrain of investigation for researchers in the field of linguistics, multimodality, communication and media studies, visual ethnography, and digital literacy. In particular, the paper singles out some aspects for analysis, such as the alternation of speech and writing, new proxemic and kinetic patterns, gaze management, and impossibility of eye contact and discusses some examples from digital field work on multiparty video-based interactions. Speech and writing are technologically integrated, allowing participants to mode-switch, i.e., to alternate between spoken and written discourse. New arrangements of verbal and nonverbal resources attempt to simulate face-to-face conversations. However, the illusion of a face-to-face conversation dissolves as soon as video chat-specific resources are unpacked. Despite growing research into nonverbal behavior, video chat data challenge visual analysts and researchers for a number of reasons. A transcription model, developed for the purpose of analyzing these specific texts, will be sketched to give a brief account of significant data that need to be incorporated into multimodal transcription and annotation. Reflections and conclusions are drawn according to the contribution that intersemiotic studies can potentially provide for web text analysis, given the constant expansion of web-based texts and the challenge it brings as regards new notions of textuality.|video chat; mode switching; digital speech; digital writing; multimodal transcription; synchronous video-based interaction|GAZE|Communication; Linguistics; Language \& Linguistics|4|2|12
Computer models for identifying instrumental citations in the biomedical literature|2013|The most popular method for evaluating the quality of a scientific publication is citation count. This metric assumes that a citation is a positive indicator of the quality of the cited work. This assumption is not always true since citations serve many purposes. As a result, citation count is an indirect and imprecise measure of impact. If instrumental citations could be reliably distinguished from non-instrumental ones, this would readily improve the performance of existing citation-based metrics by excluding the non-instrumental citations. A citation was operationally defined as instrumental if either of the following was true: the hypothesis of the citing work was motivated by the cited work, or the citing work could not have been executed without the cited work. This work investigated the feasibility of developing computer models for automatically classifying citations as instrumental or non-instrumental. Instrumental citations were manually labeled, and machine learning models were trained on a combination of content and bibliometric features. The experimental results indicate that models based on content and bibliometric features are able to automatically classify instrumental citations with high predictivity (AUC = 0.86). Additional experiments using independent hold out data and prospective validation show that the models are generalizeable and can handle unseen cases. This work demonstrates that it is feasible to train computer models to automatically identify instrumental citations.|Bibliometrics; Citation analysis; Machine learning; Information retrieval|TEXT CATEGORIZATION; AGREEMENT; COUNTS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|3|2|12
Leveraging concept-based approaches to identify potential phyto-therapies|2013|The potential of plant-based remedies has been documented in both traditional and contemporary biomedical literature. Such types of text sources may thus be sources from which one might identify potential plant-based therapies ({''}phyto-therapies{''}). Concept-based analytic approaches have been shown to uncover knowledge embedded within biomedical literature. However, to date there has been limited attention towards leveraging such techniques for the identification of potential phyto-therapies. This study presents concept-based analytic approaches for the retrieval and ranking of associations between plants and human diseases. Focusing on identification of phyto-therapies described in MEDLINE, both MeSH descriptors used for indexing and MetaMap inferred UMLS concepts are considered. Furthermore, the identification and ranking consider both direct (i.e., plant concepts directly correlated with disease concepts) and inferred (i.e., plant concepts associated with disease concepts based on shared signs and symptoms) relationships. Based on the two scoring methodologies used in this study, it was found that a Vector Space Model approach outperformed probabilistic reliability based inferences. An evaluation of the approach is provided based on therapeutic interventions catalogued in both ClinicalTrials.gov and NDF-RT. The promising findings from this feasibility study highlight the challenges and applicability of concept-based analytic strategies for distilling phyto-therapeutic knowledge from text based knowledge sources like MEDLINE. (C) 2013 Elsevier Inc. All rights reserved.|Phyto-therapies; Concept-based text analytics; Translational bioinformatics; Drug discovery|CO-WORD ANALYSIS; NATURAL-PRODUCTS; DRUG DISCOVERY; TEXT; ONTOLOGIES; KNOWLEDGE; UMLS; TERMINOLOGY; BIOMEDICINE; INFORMATION|Computer Science, Interdisciplinary Applications; Medical Informatics|2|0|12
Story visualization of novels with multi-theme keyword density analysis|2013|A new method for visualization of stories in literary works was explored. Our story visualization method consists of two parts: keyword-based statistical analysis for multiple themes and imagery expression of the results for visual understanding. In this study, we focused on novels as the targets, and discussed ways in which complex structures can be simultaneously visualized using multiple themes. The method was applied for the comparison of Charles Dickens' novels with Shakespeare's plays in order to identify any existing evidence concerning literal interest created by the overlapping of multiple scenarios in a single story. We also applied the method to non-literary documents such as newspaper articles, and showed that these documents contain simple statistic patterns regarding a given theme, which contrasts with the case involving novels that include the dynamic fluctuation of individual story elements.|Story visualization; William Shakespeare; Charles Dickens; Digital text analysis; Literary work; Keyword detection|NARRATIVE VISUALIZATION; LANGUAGE; TRACKING|Computer Science, Interdisciplinary Applications; Imaging Science \& Photographic Technology|0|0|12
Learning by Conceptual Modeling-Changes in Knowledge Structure and Content|2013|The DynaLearn interactive learning environment enables learning by having learners create conceptual models of system's behavior. This paper reports on exploratory evaluation studies using the DynaLearn software, carried out with learners studying environmental science. Two three-day modeling sessions were conducted in two consecutive years with two students exploring the evolving prototype of the software. The learners worked on assignments designed to achieve specific learning goals. To investigate conceptual changes on behalf of the learner, a set of parameters was applied for semantic text analysis of written pre- and posttests. The evaluation results show key changes occurring in knowledge structure and content in both years for both students. Indications of an effect of prior knowledge on the magnitude of conceptual change were found. The results confirm the potential of DynaLearn for inducing causal and interlinked understanding of environmental systems.|Evaluation study; conceptual knowledge change; learning by modeling; science education|SCIENCE; STUDENTS; FRAMEWORK; THINKING; PHYSICS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|1|0|12
LIVE SUBTITLING WITH SPEECH RECOGNITION. CAUSES AND CONSEQUENCES OF TEXT REDUCTION|2013|Speech technology has made it possible to use speech recognition for the simultaneous subtitling of live television broadcasts using the technique of respeaking. Analyses show that live subtitles, like pre-recorded subtitles, are nearly always a reduced form of the spoken comments. However, the live-subtitling process in itself may have an effect on the reduction strategies used by live subtitlers. The aim of this study is to gain a better understanding of the causes and consequences of quantitative text reduction in live subtitling. Three excerpts of an infotainment talk show were subtitled by twelve respeakers of the Flemish public television channel, VRT. They were instructed to complete the task using three different reduction conditions. Various subtitle features, such as reduction percentages and delay, as well as measures of the respeakers' working memory were collected. In a hierarchical multilevel analysis we defined which external factors affect the degree of reduction. The results show that reduction is not a random process. In contrast, its occurrence and form are largely determined by a number of external factors, viz. delay, amount of source text and the proportion of `full' deletions. A large volume of evidence suggests that respeakers opt to omit certain comments rather than reducing them. It also appears that the decision to delete a comment seems not to be primarily based on the amount of input, while the decision to reduce partially is.|delay; live subtitling; respeaking; voice-writing; speech recognition; key-stroke logging; reduction|WORKING-MEMORY; INDIVIDUAL-DIFFERENCES; TELEVISION PROGRAMS; ERROR-CORRECTION; CAPACITY|Linguistics; Language \& Linguistics|5|0|12
Anchoring time-space mappings and their emotions: The timeline blend in poetic metaphors|2013|Conceptual Integration theorists have recently revised the time is space conceptual metaphor, and proposed a more complex structure of mappings. The result of that network of mappings is a particular event of motion through space, conditioned by its goal to represent time. Coulson and Pagan Canovas (forthcoming) have studied the timeline as a material anchor for this time-space blend. The timeline facilitates navigation of the time-space blend by presenting temporal relations directly as spatial relations. Through the analysis of Kavafis' simile of life as a row of candles and Manrique's metaphor of life as a river, we show that poetic texts can rely on the timeline to build powerful affective meanings.|Borges; conceptual integration; conceptual metaphor; emotion; Kavafis; Manrique; material anchors; poetic metaphor; spatial cognition; timeline; time-space mappings|LANGUAGE; MANDARIN; ENGLISH; THINK; MIND|Linguistics; Language \& Linguistics|4|0|12
A human-computer collaborative approach to identifying common data elements in clinical trial eligibility criteria|2013|Objective: To identify Common Data Elements (CDEs) in eligibility criteria of multiple clinical trials studying the same disease using a human-computer collaborative approach. Design: A set of free-text eligibility criteria from clinical trials on two representative diseases, breast cancer and cardiovascular diseases, was sampled to identify disease-specific eligibility criteria CDEs. In this proposed approach, a semantic annotator is used to recognize Unified Medical Language Systems (UMLSs) terms within the eligibility criteria text. The Apriori algorithm is applied to mine frequent disease-specific UMLS terms, which are then filtered by a list of preferred UMLS semantic types, grouped by similarity based on the Dice coefficient, and, finally, manually reviewed. Measurements: Standard precision, recall, and F-score of the CDEs recommended by the proposed approach were measured with respect to manually identified CDEs. Results: Average precision and recall of the recommended CDEs for the two diseases were 0.823 and 0.797, respectively, leading to an average F-score of 0.810. In addition, the machine-powered CDEs covered 80\% of the cardiovascular CDEs published by The American Heart Association and assigned by human experts. Conclusion: It is feasible and effort saving to use a human-computer collaborative approach to augment domain experts for identifying disease-specific CDEs from free-text clinical trial eligibility criteria. (C) 2012 Elsevier Inc. All rights reserved.|Clinical research informatics; Clinical trial eligibility criteria; Common data elements; Knowledge management; Human-computer collaboration; Text mining|KEY DATA ELEMENTS; WRITING COMMITTEE; ASSOCIATION RULES; DATA STANDARDS; TASK-FORCE; CANCER; TEXT; DEFINITIONS; MANAGEMENT; OUTCOMES|Computer Science, Interdisciplinary Applications; Medical Informatics|12|2|12
Visual metonymy in children's picture books|2013|This article aims to explore how the use of visual metonymies in picture books contributes to children's understanding of stories and, in turn, attracts their attention towards relevant aspects of the plot. The two picture books selected for analysis are Gorilla, by Browne, and The Tale of Peter Rabbit, by Potter, intended for children under 9 years of age. A multimodal and cognitive perspective is adopted here to apply the nonverbal trope of visual metonymy to the two picture books that form the sample texts (Forceville, 2009, 2010; Forceville \& Urios-Aparisi, 2009). The results of the analysis show that visual metonymies are essentially used in children's tales to create narrative tension in certain stages of the plot and, in turn, to establish a bond between the represented participants and the child-viewer.|multimodality; visual metonymy; picture books; systemic functional grammar|METAPHORS|Linguistics; Language \& Linguistics|3|4|12
Agentivity as a determinant of lexico-grammatical variation in L2 academic writing|2013|This paper examines novice writers' strategies in the (non-)representation of authorship in academic writing drawing on data from the Corpus of Academic Learner English and a native-speaker control corpus. The analysis focuses on the quantitative and qualitative use of pronouns, subject placeholders, as well as verbs and inanimate nouns that frequently occur in academic writing. The findings indicate that even advanced learners are insecure about the (non-)representation of authorship in academic texts, but lack the resources to report events and findings without mentioning an author-agent. The learner data evidence a significant overrepresentation of first person pronouns and subject placeholders as default strategies to suppress the author-agent. This imbalanced clustering is argued to be due to a significant underrepresentation of constructions with inanimate nouns as subjects that are preferred reporting devices in abstracts and research articles in the humanities. The paper concludes by addressing implications for language teaching, testing and assessment.|academic writing; advancedness; agentivity; inanimate subjects; lexico-grammatical variation|LEARNER CORPORA; REPORTING VERBS; ENGLISH; INTERLANGUAGE; PROFICIENCY; DIFFICULT; IDENTITY; WEIGHT; CORPUS|Linguistics; Language \& Linguistics|7|3|12
Wikipedia-based WSD for multilingual frame annotation|2013|Many applications in the context of natural language processing have been proven to achieve a significant performance when exploiting semantic information extracted from high-quality annotated resources. However, the practical use of such resources is often biased by their limited coverage. Furthermore, they are generally available only for English and few other languages. We propose a novel methodology that, starting from the mapping between FrameNet lexical units and Wikipedia pages, automatically leverages from Wikipedia new lexical units and example sentences. The goal is to build a reference data set for the semi-automatic development of new FrameNets. In addition, this methodology can be adapted to perform frame identification in any language available in Wikipedia. Our approach relies on a state-of-the-art word sense disambiguation system that is first trained on English Wikipedia to assign a page to the lexical units in a frame. Then, this mapping is further exploited to perform frame identification in English or in any other language available in Wikipedia. Our approach shows a high potential in multilingual settings, because it can be applied to languages for which other lexical resources such as WordNet or thesauri are not available. (C) 2012 Elsevier B.V. All rights reserved.|Frame annotation; Multilingual FrameNets; Word sense disambiguation; FrameNet-Wikipedia mapping|SEMANTICS; KNOWLEDGE; KERNELS|Computer Science, Artificial Intelligence|1|0|12
Optimizing the analysis of metaphor in discourse How to make the most of qualitative software and find a good research design|2012|This article presents a software-based methodology for studying metaphor in discourse, mainly within the framework of Conceptual Metaphor Theory (CMT). Despite a welcome recent swing towards methodological reflexivity, a detailed explication of the pros and cons of different procedures is still in order as far as qualitative research (i.e. a context-sensitive manual coding of a text corpus) is concerned. Qualitatively oriented scholars have to make difficult decisions revolving around the general research design, the transfer of linguistic theory into method, good workflow management, and the aimed at scope of analysis. My first task is to pinpoint typical tasks and demonstrate how they are optimally dealt with by using qualitative annotation software like ATLAS.ti. Software not only streamlines metaphor tagging itself, it systematizes the interpretive work from grouping text items into systematic/conceptual metaphor sets, via data surveys and checks, to quantitative comparisons and a cohesion-based analysis. My second task is to illustrate how a good research design can provide a step-wise procedure, offer systematic validation checks, keep the code system slim and many analytic options open. When we aim at complex data searches and want to handle high metaphor diversity I recommend compositional coding, i.e. tagging source and target domains separately (instead of adopting a ``one mapping-one code{''} strategy). Furthermore, by tagging metaphors for image-schematic and rich semantic source domains in parallel, i.e. two-tier coding, we get multiple options for grouping metaphors into systematic sets.|metaphor analysis; qualitative methods; software assisted analysis; research design and workflow management; data stratification; EU discourse|LANGUAGE|Linguistics; Language \& Linguistics|4|1|12
Italy's other Mafia A journey into cross-cultural translation|2012|Following its translation into more than thirty languages, Roberto Saviano's non-fiction novel Gomorrah {[}Gomorra], has unveiled to a vast number of readers across the globe the endless saga of Naples' crime syndicate, the Camorra (from which the book's title derives its bitter play on words). Literary critics and reviewers in the UK and in the U. S. have widely acclaimed Saviano's talent in depicting the corruption plaguing Naples' gloomy and degraded hinterland, although the sociocultural context portrayed in Gomorrah is naturally distant from the repertoire of the target culture: the text is widely populated by culture-bound concepts and implicit meanings, which further complicates the translation process. Through a contrastive analysis of the Italian and English versions of the explores this study explores the strategies employed in translating the voices and deeds of Naples' mobsters, as well as the socioeconomic setting of the Camorra. With reference to types of non-equivalence between the two language versions, this article investigates to what extent the English translation contributes to the identity- building process of the Camorra as a separate and far more deadly criminal organization vis-a-vis the Sicilian Mafia.|translation studies; translation and identity; sociology of translation; cultural transfer|SOCIOLOGY|Linguistics; Language \& Linguistics|0|4|12
The use of reformulation markers in Business Management research articles An intercultural analysis|2012|This paper investigates the use of reformulation markers as a common metadiscourse device in L1 English and Spanish and in L2 English research articles of a particular discipline, namely Business Management. These markers are considered procedural items, i.e. they encode information on how to process lexical meaning. The general frequency of use of the markers, the types of markers used, the functions most commonly performed and their (non-)parenthetical uses are compared in order to explore the degree of transference in their use by the L1 Spanish academics writing L2 English articles. The results are compared to similar studies on reformulation markers in general English and Spanish and also to studies in other disciplines. The results lead us to conclude that some general rhetorical L1 features are more likely to be adapted in the L2 English texts written by L1 Spanish academics than other more specific grammatical features.|reformulation markers; metadiscourse; research articles; disciplinary variation; intercultural rhetoric|ACADEMIC DISCOURSE; METADISCOURSE; ENGLISH; LINGUISTICS|Linguistics; Language \& Linguistics|8|0|12
The language of anger in Chinese and English narratives|2009|This article analyses the language of anger used by the bilinguals in Hong Kong, and examines how the functions of L1 and L2 and users' language proficiency may affect emotional expression. Thirty-three university students in Hong Kong participated in the research. Each was asked to write two stories about `an experience in which you were made angry' and `an experience in which you made someone angry', one in Chinese and the other in English. A total of 66 narrative texts were collected. The subjects also provided written comments on their feelings and language preferences in writing life stories. The narrative length, lexical and syntactic richness, and the use of metaphorical expressions in the Chinese and English texts were compared and triangulated with the subjects' perceptions of bilinguality and emotionality. Both the linguistic data and the written comments suggest that to a very large extent language competence affects how emotionally expressive bilinguals can be. The ability to communicate and share one's emotions is an integral part of one's personal life but the language of emotions seems to be an under-developed area in second language education programmes. Measures are suggested to address this problem and help bilinguals to develop their competence in emotional expression.|anger vocabulary; language proficiency; metaphors|EMOTION VOCABULARY|Linguistics; Language \& Linguistics|2|3|12
The green leaves of love: Japanese romantic heroines, authentic femininity, and dialect|2009|How is `authentic' linguistic femininity in Japan manifested in popular texts? We analyze the dialogue of female characters in Wakaba, a 2005 Japanese drama set in two very different parts of `regional' Japan - Miyazaki and Kobe. Through this analysis, we examine two contradictory discourses circulated through popular media. The first is that linguistic femininity is based in Standard Japanese - a surprisingly persistent ideology despite a current trend to examine cases in which language ideology and practice do not match. Other studies reflect another dominant discourse, that of the `authentic' dialect speaker, who expresses local alignment by using dialect forms outside the bounds of ideologically modern linguistic forms. The tension between acting linguistically feminine and `authentically' local raises some interesting questions for Japanese language and gender studies, including studies of gendered representations: are women who are speakers of regional dialects authentically `feminine'? Can they be? Do some dialects express femininity better than others?|Japanese; gender; femininity; ideology; representation; dialect|NOSTALGIA|Linguistics|5|0|12
Identity, `acting interculturally' and aims for bilingual education: an example from China|2009|In major texts on bilingualism and bilingual education, one often finds such notions as biculturalism, multiculturalism, pluralism or interculturalism that are used interchangeably as concepts - as opposed to monoculturalism or cultural assimilation - to address political and sociocultural dimensions in language learning and teaching. Recently, some scholars have begun to make distinctions between them as processes or outcomes of bilingual education. They compare the terms conceptually and evaluate the implications these concepts might have for bilingual education. The notion of `acting interculturally', for example, is such an attempt that aims to shed light on the conceptual perplexity between being bicultural and being intercultural and to argue for learning outcomes that are attainable and desirable in bilingual education. On the basis of an overview of conceptual discussions on these notions and an analysis of key guiding ideas and research on bilingual education in China, this paper argues that a conceptual distinction between these terms is not only necessary for advancing theories of bilingualism in general but also crucial for addressing multifaceted issues in bilingual education, including sociopolitical concerns, in a country like China whose language education policies and curricula are determined by the government's political agenda for maintaining an unwavering state.|bicultural; assimilation; identity; construction; nationalism; interculturalism; China|BICULTURALISM|Linguistics; Language \& Linguistics|4|1|12
A framework for comparing evaluation resources across academic texts|2008|The use of evaluation resources has proven to he an especially difficult area in English for Academic Purposes. Our aim is to propose a methodological framework for identifying recurrent differences in the use of evaluation resources ill academic texts across English and other languages. We argue that for comparisons to be meaningful, studies of independent but comparable successful texts should contrast propositions that are similar in terms of their Pragmatic or discourse function. We narrow the focus of the proposal down to the academic book review genre ill one particular academic discipline and argue for the contrast of propositions functioning as critical acts oil similar things, the academic hooks under review. We reason that for fruitful comparisons it would be necessary to distinguish between evaluation resources occurring oil the propositional, metadiscoursal, and rhetorical planes. We discuss the type of evaluation resources that occur on these three planes in a corpus of twenty recent literary academic book reviews in English. We conclude that applying this framework to the quantitative analysis of comparable, texts and propositions across languages would help to establish the extent to which the use of evaluation resources varies as a function of the language ill a useful way.|English for Academic Purposes; academic writing; academic book reviews; evaluation; metadiscourse; cross-cultural studies|DISCOURSE; METADISCOURSE|Communication; Linguistics; Language \& Linguistics|7|1|12
Partial lexical knowledge in tests of incidental vocabulary learning from L2 reading|2007|This analysis evaluates the receptive tests of targeted lexical knowledge in the written medium, which are typically used in empirical research into lexical acquisition from reading foreign/second language texts. Apart from the types of second language cues or prompts, and the language of the responses, the main issues revolve around: (a) the recognition of partial knowledge, (b) the categorization of different subject responses, in closed and open formats, and (c) their quantification. Variations in response categorizations are questioned in particular on partial lexical knowledge, the capacity for multiple choice formats to cope with partial and correct knowledge, and the conversions of nominal scales to equal interval numerical scales.|vocabulary tests; lexical acquisition; test methods; reading; incidental learning|FOREIGN-LANGUAGE STUDENTS; DICTIONARY USE; ACQUISITION; CONTEXT; COMPREHENSION; RETENTION; WORDS; STRATEGIES; MEANINGS; GLOSSES|Linguistics|1|0|12
Irony and reversal of evaluation|2007|This paper outlines a corpus-assisted investigation into the nature and functions of irony in both spoken interaction and written texts. We begin with a review of some of the principal current debates in irony studies, which have until recently often been conducted with little recourse to authentic examples of use in interactive discourse types. We go on to consider, from an examination of corpus-based real-life data, firstly, how explicit irony operates and then whether there might be a more objective way of identifying and defining episodes of implicit irony than simple reliance on the researcher's unsupported intuition. Potential sites of implicit irony are then examined in the data to see how and why speakers and writers employ it and how hearers and audiences respond. The data analyses afford strong evidence that the principal mechanism driving all irony is an implied reversal of the evaluative meaning of the utterance (rather than of the propositional/ideational meaning, as argued in many traditional theories of irony). In addition, they reveal how irony in discourse always has a strategic argumentative point. Three corpora were employed, the first of semi-spontaneous interactive spoken discourse (WHB: circa 6 million words of White House press briefings in transcription {[}1998-2004]), the second of spoken interviews (Ints: 250,000 words of transcribed televised UK political interviews) and the third of written texts (Papers: 100 million words of UK broadsheet texts). Techniques from Corpus Linguistics, principally concordancing, were employed. Most of the corpus interrogation was conducted using the WordSmith Tools suite of programs. Corpora have only rarely been used to investigate participants' interaction in discourse and this paper is intended as a contribution to the nascent interdisciplinary field of Corpus-Assisted Discourse Studies (CADS). (c) 2007 Elsevier B.V. All rights reserved.|irony; evaluation; corpus linguistics; discourse; laughter; corpus-assisted discourse studies|VERBAL IRONY; CONVERSATION; HYPERBOLE; NEGATION; CONTRAST; LANGUAGE|Linguistics; Language \& Linguistics|56|3|12
Assessing gender authenticity in computer-mediated language use - Evidence from an identity game|2004|Although a substantial body of research exists on gender differences in computermediated communication, relatively little empirical attention has been directed toward how people perform a different gender online, or to what behavioral cues other participants attend in assessing others' real-life gender This study analyzes deceptive gender performances and assessments of their authenticity in The Turing Game, a publicly available synchronous text chat environment that supports spontaneous identity games. Content analysis of game logs shows that contestants produce stereotypical content when attempting to pass as the opposite gender as well as giving off stylistic cues to their real-life gender. However contrary to previous evidence that people judge online gender authenticity on the basis of linguistic styles, the judges in The Turing Game base their assessments mostly on stereotyped content, leading to a high rate of error These findings are interpreted in terms of signal costs and conscious accessibility of cues.|computer-mediated communication (CMC); deception; discourse style; gender; identity; stereotypes|COMMUNICATION|Communication; Linguistics; Psychology, Social|39|3|12
Mining e-cigarette adverse events in social media using Bi-LSTM recurrent neural network with word embedding representation|2018|Recent years have seen increased worldwide popularity of e-cigarette use. However, the risks of e-cigarettes are underexamined. Most e-cigarette adverse event studies have achieved low detection rates due to limited subject sample sizes in the experiments and surveys. Social media provides a large data repository of consumers' e-cigarette feedback and experiences, which are useful for e-cigarette safety surveillance. However, it is difficult to automatically interpret the informal and nontechnical consumer vocabulary about e-cigarettes in social media. This issue hinders the use of social media content for e-cigarette safety surveillance. Recent developments in deep neural network methods have shown promise for named entity extraction from noisy text. Motivated by these observations, we aimed to design a deep neural network approach to extract e-cigarette safety information in social media. Our deep neural language model utilizes word embedding as the representation of text input and recognizes named entity types with the state-of-the-art Bidirectional Long Short-Term Memory (Bi-LSTM) Recurrent Neural Network. Our Bi-LSTM model achieved the best performance compared to 3 baseline models, with a precision of 94.10\%, a recall of 91.80\%, and an F-measure of 92.94\%. We identified 1591 unique adverse events and 9930 unique e-cigarette components (ie, chemicals, flavors, and devices) from our research testbed. Although the conditional random field baseline model had slightly better precision than our approach, our Bi-LSTM model achieved much higher recall, resulting in the best F-measure. Our method can be generalized to extract medical concepts from social media for other medical applications.|E-cigarette adverse event; Bi-LSTM; recurrent neural network; word embedding; deep neural network|NAMED ENTITY RECOGNITION; ELECTRONIC CIGARETTES; METAMAP; IMPACT; SMOKING; TEXT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|1|11|11
Using anchors from free text in electronic health records to diagnose postoperative delirium|2017|Objectives: Postoperative delirium is a common complication after major surgery among the elderly. Despite its potentially serious consequences, the complication often goes undetected and undiagnosed. In order to provide diagnosis support one could potentially exploit the information hidden in free text documents from electronic health records using data-driven clinical decision support tools. However, these tools depend on labeled training data and can be both time consuming and expensive to create. Methods: The recent learning with anchors framework resolves this problem by transforming key observations (anchors) into labels. This is a promising framework, but it is heavily reliant on clinicians knowledge for specifying good anchor choices in order to perform well. In this paper we propose a novel method for specifying anchors from free text documents, following an exploratory data analysis approach based on clustering and data visualization techniques. We investigate the use of the new framework as a way to detect postoperative delirium. Results: By applying the proposed method to medical data gathered from a Norwegian university hospital, we increase the area under the precision-recall curve from 0.51 to 0.96 compared to baselines. Conclusions: The proposed approach can be used as a framework for clinical decision support for postoperative delirium. (C) 2017 Elsevier B.V. All rights reserved.|Electronic health records; Semi-supervised learning; Learning with anchors framework; Postoperative delirium; Data-driven clinical decision support; Clustering|MEAN SHIFT; SURGERY; REGULARIZATION|Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods; Engineering, Biomedical; Medical Informatics|0|11|11
Towards a metaphor-annotated corpus of Mandarin Chinese|2017|Building on the success of the VU Amsterdam Metaphor Corpus, which comprises English texts annotated with metaphor following the Metaphor Identification Procedure Vrjie Universiteit (MIPVU; Steen et al. in Cogn Linguist 21(4):765-796, 2010a; Steen et al. in A method for linguistic metaphor identification: from MIP to MIPVU. John Benjamins, Amsterdam/Philadelphia, 2010b), this study has three aims: (1) to adapt and evaluate the transferability and reliability of MIPVU for Mandarin Chinese; (2) to construct a corpus of Chinese texts annotated for metaphor using the adapted procedure; and (3) to examine the distribution of metaphor-related words across Chinese texts in three different written registers: academic discourse, fiction, and news. The results of our inter-annotator reliability test show that MIPVU can be reliably applied to linguistic metaphor identification in Chinese texts. Our metaphor-annotated corpus consists of texts randomly sampled from the Lancaster Corpus of Mandarin Chinese, totaling 30,012 words (about 10,000 for each register). Data analysis reveals that approximately one out of every nine lexical units in our Chinese corpus is related to metaphor, that there is considerable variation in metaphor density across different registers and lexical categories, and that metaphor density is significantly lower in Chinese than in English texts. Our assessment of the replicability of MIPVU for Mandarin Chinese adds to the groundbreaking methodological contribution that Steen et al. (2010a, b) has made to metaphor research. The metaphor-annotated corpus of Mandarin Chinese contributes a valuable language resource for Chinese metaphor researchers, and our analysis of the distribution of metaphor-related words in the corpus offers useful new insights into the extent and use of metaphor in Chinese discourse.|Corpus annotation; Cross-linguistic comparison; Metaphor; Metaphor density; Metaphor identification; Register variation|DISCOURSE; MIP|Computer Science, Interdisciplinary Applications|0|10|11
Recurrent neural networks for classifying relations in clinical notes|2017|We proposed the first models based on recurrent neural networks (more specifically Long Short-Term Memory - LSTM) for classifying relations from clinical notes. We tested our models on the i2b2/VA relation classification challenge dataset. We showed that our segment LSTM model, with only word embedding feature and no manual feature engineering, achieved a micro-averaged f-measure of 0.661 for classifying medical problem-treatment relations, 0.800 for medical problem-test relations, and 0.683 for medical problem-medical problem relations. These results are comparable to those of the state-ofthe-art systems on the i2b2/VA relation classification challenge. We compared the segment LSTM model with the sentence LSTM model, and demonstrated the benefits of exploring the difference between concept text and context text, and between different contextual parts in the sentence. We also evaluated the impact of word embedding on the performance of LSTM models and showed that medical domain word embedding help improve the relation classification. These results support the use of LSTM models for classifying relations between medical concepts, as they show comparable performance to previously published systems while requiring no manual feature engineering. (C) 2017 Elsevier Inc. All rights reserved.|Natural language processing; Medical relation classification; Recurrent neural network; Long Short-Term Memory; Machine learning|ADVERSE DRUG-REACTIONS; EXTRACTION; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|2|10|11
Automatic detection of satire in Twitter: A psycholinguistic-based approach|2017|In recent years, a substantial effort has been made to develop sophisticated methods that can be used to detect figurative language, and more specifically, irony and sarcasm. There is, however, an absence of new approaches and research works that analyze satirical texts. The recognition of satire by sentiment analysis and Natural Language Processing (NLP) applications is extremely important because it can influence and change the meaning of a statement in varied and complex ways. We used this understanding as a basis to propose a method that employs a wide variety of psycholinguistic features and which detects satirical and non-satirical text. We then went on to train a set of machine learning algorithms that would enable us to classify unknown data. Finally, we conducted several experiments in order to detect the most relevant features that generate a better pattern as regards detecting satirical texts. We evaluated the effectiveness of our method by obtaining a corpus of satirical and non-satirical news from Mexican and Spanish Twitter accounts. Our proposal obtained encouraging results, with an F-measure of 85.5\% for Mexico and one of 84.0\% for Spain. Moreover, the results of the experiment showed that there is no significant difference between Mexican and Spanish satire. (C) 2017 Elsevier B.V. All rights reserved.|Computational psycholinguistics; LIWC; Machine learning; Satire; Twitter|SARCASM; OPTIMIZATION; IRONY|Computer Science, Artificial Intelligence|1|5|11
Lexical analysis of scientific publications for nano-level scientometrics|2017|In earlier studies (e.g. Glanzel and Thijs in Scientometrics, 2017) we have used components of text analysis in combination with link-based techniques to cluster documents spaces and to detect emerging research topics on the large scale. Taking up now the objectives of evaluative scientometrics, we attempt to link the textual analysis of small sets of individual scientific papers to evaluative bibliometrics. The objective is, however, quite similar. We focus on the detection of similarities and on monitoring structural changes but this time on the small scale. We proceed from earlier approaches used in quantitative linguistics applied to bibliometrics (Telcs et al. in Math Soc Sci; 10(2):169-178, 1985). In the present pilot study we have selected 18 papers by Andras Schubert and published in three different periods with 6 papers each: 1983-1985, 1993-1998 and 2010-2013. The objective is twofold: We first try only to detect linguistic regularities in the scientometric text by applying a Waring model to the analysis of Schubert's vocabulary on the basis of all words and nouns. The second goal refers to the identification of changes in the used vocabulary over a period of three decades. The main findings are discussed along with future research tasks, which arise from these result in the context of the analysis of dynamics and emergence of research topics at the micro and nano level.|Quantitative linguistics; Word-frequency; Waring distribution; Natural language processing; Nano-level analysis|SENTENCE-LENGTH|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|7|11
Lexicon based semantic detection of sentiments using expected likelihood estimate smoothed odds ratio|2017|Sentiment analysis is an active research area in today's era due to the abundance of opinionated data present on online social networks. Semantic detection is a sub-category of sentiment analysis which deals with the identification of sentiment orientation in any text. Many sentiment applications rely on lexicons to supply features to a model. Various machine learning algorithms and sentiment lexicons have been proposed in research in order to improve sentiment categorization. Supervised machine learning algorithms and domain specific sentiment lexicons generally perform better as compared to the unsupervised or semi-supervised domain independent lexicon based approaches. The core hindrance in the application of supervised algorithms or domain specific sentiment lexicons is the unavailability of sentiment labeled training datasets for every domain. On the other hand, the performance of algorithms based on general purpose sentiment lexicons needs improvement. This research is focused on building a general purpose sentiment lexicon in a semi-supervised manner. The proposed lexicon defines word semantics based on Expected Likelihood Estimate Smoothed Odds Ratio that are then incorporated with supervised machine learning based model selection approach. A comprehensive performance comparison verifies the superiority of our proposed approach.|Sentiment analysis; Natural language processing; Opinion mining; Machine learning; Support vector machine|CLASSIFICATION|Computer Science, Artificial Intelligence|0|4|11
Mediating between discourse worlds: developing the symbolic competence of advanced-level bilingual learners of Japanese through translation|2017|This paper explores the role that translation may play in developing the symbolic competence of advanced-level bilingual learners. To this end, it examines how a group of bilingual learners engaged with a translation task that was assigned to them as part of their study in an advanced-level Japanese language class at an Australian university. Analysis of the students' translations and their translation processes showed that they were engaging in a complex process of intercultural communication that prompted them to reflect on the symbolic dimensions of the text: how the text is framed, how the author is positioned, and how prior discourses shape the production and reception of the text. The paper thus argues that translation may be an effective approach for developing advanced-level bilingual learners' symbolic competence to mediate between interlocutors who belong to different discourse worlds.'|Translation; intercultural communication; intercultural learning; symbolic competence; bilingual education; Japanese|CLASSROOM|Linguistics; Language \& Linguistics|0|9|11
Textual voice elements and voice strength in EFL argumentative writing|2017|This study examined how the quantity and diversity of textual voice elements contribute to holistic voice strength and essay quality. For the quantification of voice elements, this study used an automated processing tool, the Authorial Voice Analyzer (AVA), which was developed based on categories from Hyland's voice model (i.e., hedges, boosters, attitude markers, self-mentions, reader pronouns, and directives). To explore the relationship between textual voice elements and holistic voice strength, as well as between voice elements and essay quality, this study analyzed 219 argumentative essays written by L1 Greek-speaking EFL students. The results suggested positive, but weak to moderate, correlations between textual voice and holistic voice strength; a regression model with three textual voice features explained 26\% of the variance in voice strength scores. The results also indicated weak correlations between textual voice and essay quality. Interestingly, the textual voice features contributing to voice strength (boosters, attitude markers, and self mentions) were different from those contributing to essay quality (hedges). Interpreting these findings in relation to the context (timed argumentative writing in an EFL context), this study suggests implications for L2 writing assessment and pedagogy. (C) 2017 Elsevier Inc. All rights reserved.|Authorial voice; Second language writing; Writing assessment; Quantification of voice elements; Interactional metadiscourse; Natural language processing|INTERACTIONAL METADISCOURSE; RHETORICAL CONSTRUCTION; RESEARCH ARTICLES; AUTHOR IDENTITY; L1|Education \& Educational Research; Linguistics|1|6|11
Dimensions of empathy in relation to language|2016|This article approaches the relationship between empathy and language, describing the ways in which different dimensions of empathy can be attested in naturally occurring interactional data. The authors adopt the definition of empathy as a multidimensional phenomenon: emotional contagion, as well as the cognitive and affective dimensions of empathy, are all understood to be central to the empathetic process. The article promotes the view that studying the relationship between empathy and language should be grounded in the analysis of real-life interactions. Language evolves in social interaction both phylogenetically and ontogenetically, and is not only an important product but also a means of human sociality. The authors suggest that the best approach for analyzing the empathy-language interface combines the theoretical insights of cognitive grammar with the method of conversation analysis. The paper shows that when empathy is analyzed in natural conversation, we can do sequential and linguistic analysis of the ways in which affect is shown, and through a careful analysis of grammatical devices, offer an explanation of whether the displays of affect are derived from the other person's situation. By analyzing the complex ways in which the interactants orient to the different dimensions of empathy, the paper shows how linguistic analysis can give us concrete tools for forming a deeper understanding of how empathy takes place in real-life encounters.|affect; cognitive grammar; conversation analysis; emotional contagion; empathy; grammar; ground; intersubjectivity; troubles-telling|SYMPATHY; TROUBLES; CARE|Linguistics; Language \& Linguistics|0|1|11
Clinical phenotyping in selected national networks: demonstrating the need for high-throughput, portable, and computational methods|2016|Objective: The combination of phenomic data from electronic health records (EHR) and clinical data repositories with dense biological data has enabled genomic and pharmacogenomic discovery, a first step toward precision medicine. Computational methods for the identification of clinical phenotypes from EHR data will advance our understanding of disease risk and drug response, and support the practice of precision medicine on a national scale. Methods: Based on our experience within three national research networks, we summarize the broad approaches to clinical phenotyping and highlight the important role of these networks in the progression of high-throughput phenotyping and precision medicine. We provide supporting literature in the form of a non-systematic review. Results: The practice of clinical phenotyping is evolving to meet the growing demand for scalable, portable, and data driven methods and tools. The resources required for traditional phenotyping algorithms from expert defined rules are significant. In contrast, machine learning approaches that rely on data patterns will require fewer clinical domain experts and resources. Conclusions: Machine learning approaches that generate phenotype definitions from patient features and clinical profiles will result in truly computational phenotypes, derived from data rather than experts. Research networks and phenotype developers should cooperate to develop methods, collaboration platforms, and data standards that will enable computational phenotyping and truly modernize biomedical research and precision medicine. (C) 2016 Elsevier B.V. All rights reserved.|Machine learning; Clinical phenotyping; Electronic health records; Networked research; Precision medicine|ELECTRONIC HEALTH RECORDS; PHENOME-WIDE ASSOCIATION; MINI-SENTINEL PROGRAM; DATA QUALITY ASSESSMENT; PRECISION MEDICINE; TEXT ANALYSIS; US FOOD; EXTRACTION; ALGORITHMS; GENERATION|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|7|2|11
Exploring EFL literature approaches in Dutch secondary education|2016|There is an increasing awareness that the inclusion of literature in foreign language (FL) curricula can be beneficial to language learners. Especially, the move towards integrated language and literature curricula is gaining ground. In this study we investigated the way English as a foreign language (EFL) is approached in Dutch secondary education at pre-university level. Using a survey study (N = 106 EFL teachers), we investigated (1) how EFL teachers approach literature at pre-university level in Dutch secondary education and also (2) which factors are related to the reported occurrence of four FL literary teaching approaches. Confirmatory factor analysis shows that the four identified approaches represent one underlying construct, which underlines our understanding of a Comprehensive Approach to FL literature teaching. Results indicate that the variation between the ways FL teachers approach literature is enormous. Correlation analyses and t-tests informed us that curricular factors are significantly related to the way literature is approached. The fact that teacher demographics are generally not significantly related to the way FL literature is approached could be ascribed to curricular heritage or the way FL literature curricula are designed. The study concludes by suggesting several directions for future research.|foreign language teaching; Literature education; FL literature approaches; EFL; Dutch secondary education; integrated curriculum|LANGUAGE; 2ND-LANGUAGE; INSTRUCTION; CULTURE; LEVEL; TEXTS|Education \& Educational Research; Linguistics; Language \& Linguistics|2|0|11
Food entries in a large allergy data repository|2016|Methods Using the Medical Text Extraction, Reasoning, and Mapping System (MTERMS), we processed both structured and free-text entries stored in an enterprise-wide allergy repository (Partners' Enterprise-wide Allergy Repository), normalized diverse food allergen terms into concepts, and encoded these concepts using the Systematized Nomenclature of Medicine - Clinical Terms (SNOMED-CT) and Unique Ingredient Identifiers (UNII) terminologies. Concept coverage also was assessed for these two terminologies. We further categorized allergen concepts into groups and calculated the frequencies of these concepts by group. Finally, we conducted an external validation of MTERMS's performance when identifying food allergen terms, using a randomized sample from a different institution. Results We identified 158 552 food allergen records (2140 unique terms) in the Partners repository, corresponding to 672 food allergen concepts. High-frequency groups included shellfish (19.3\%), fruits or vegetables (18.4\%), dairy (9.0\%), peanuts (8.5\%), tree nuts (8.5\%), eggs (6.0\%), grains (5.1\%), and additives (4.7\%). Ambiguous, generic concepts such as ``nuts{''} and ``seafood{''} accounted for 8.8\% of the records. SNOMED-CT covered more concepts than UNII in terms of exact (81.7\% vs 68.0\%) and partial (14.3\% vs 9.7\%) matches. Discussion Adverse sensitivities to food are diverse, and existing standard terminologies have gaps in their coverage of the breadth of allergy concepts. Conclusion New strategies are needed to represent and standardize food adverse sensitivity concepts, to improve documentation in EHRs.|food hypersensitivity; natural language processing; allergy and immunology; electronic health records; systematized nomenclature of medicine; vocabulary; controlled|UNITED-STATES; PREVALENCE; DRUG; FEATURES; CHILDREN; PEANUT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|4|0|11
Active learning: a step towards automating medical concept extraction|2016|Objective This paper presents an automatic, active learning-based system for the extraction of medical concepts from clinical free-text reports. Specifically, (1) the contribution of active learning in reducing the annotation effort and (2) the robustness of incremental active learning framework across different selection criteria and data sets are determined. Materials and methods The comparative performance of an active learning framework and a fully supervised approach were investigated to study how active learning reduces the annotation effort while achieving the same effectiveness as a supervised approach. Conditional random fields as the supervised method, and least confidence and information density as 2 selection criteria for active learning framework were used. The effect of incremental learning vs standard learning on the robustness of the models within the active learning framework with different selection criteria was also investigated. The following 2 clinical data sets were used for evaluation: the Informatics for Integrating Biology and the Bedside/Veteran Affairs (i2b2/VA) 2010 natural language processing challenge and the Shared Annotated Resources/Conference and Labs of the Evaluation Forum (ShARe/CLEF) 2013 eHealth Evaluation Lab. Results The annotation effort saved by active learning to achieve the same effectiveness as supervised learning is up to 77\%, 57\%, and 46\% of the total number of sequences, tokens, and concepts, respectively. Compared with the random sampling baseline, the saving is at least doubled. Conclusion Incremental active learning is a promising approach for building effective and robust medical concept extraction models while significantly reducing the burden of manual annotation.|medical concept extraction; clinical free text; active learning; conditional random fields; robustness analysis|CLINICAL TEXT; CLASSIFICATION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|3|1|11
Impact of Identity on Support for New Roles in Health Care: A Language Inquiry of Doctors' Commentary|2015|Identity threat can be understood from a social identity perspective where people interrelate based on group memberships. Language use may indicate the presence of identity threat. We explored reactions of doctors to planned expanded roles for nurses to perform gastrointestinal endoscopy in Australia. Specialist doctors have traditionally performed endoscopic procedures, yet the level of doctor support for nurse endoscopy is relatively unknown. We present results of our valence and discourse analyses of text box responses in a national survey that explored doctors' attitudes toward this role expansion. We found low levels of support for the role, and frequent expression of identity threat in three main areas: (1) framing nurses as incompetent, (2) use of contracted statements to evoke authority, and (3) emotive expression. Findings indicated that stakeholders should consider intergroup attitudes when facilitating changes in health professional scope of practice.|intergroup communication; interprofessional relations; social identity theory; nurse endoscopy|NURSE; GASTROENTEROLOGISTS; ENDOSCOPISTS; ATTITUDES; QUALITY; ISSUES; VIEWS|Communication; Linguistics; Psychology, Social|4|1|11
Establishing criteria for RST-based discourse segmentation and annotation for texts in Basque|2015|This article presents a discourse annotation methodology based on Rhetorical Structure Theory and an empirical study of annotating a corpus of specialized medical texts in Basque. The annotation process includes two phases: segmentation and annotation of rhetorical relations. Phase one entails an initial study which leads to establishing linguistic criteria for sentence-based segmentation; a second phase focuses on annotation of rhetorical relations. After establishing discourse segments and rhetorical relations, the annotation process is analyzed and evaluated by means of the method commonly used in RST (Marcu 2000). Inconsistencies detected in the evaluation method lead the authors to redefine some criteria of the evaluation method. As a result of this work, a small annotated Basque-language corpus is provided to scientific community.|natural language processing; discourse structure; segmentation; rhetorical relations; evaluation method|RHETORICAL STRUCTURE-THEORY|Linguistics; Language \& Linguistics|0|0|11
Business plan: A preliminary approach to an unknown genre|2015|The business plan has been widely included in the curricula of economics degrees and is key to business practice worldwide, but has not been studied from a socio-discursive perspective yet due to restrictions in its social, spatial, and temporal circulation. Based on interviews and a qualitative analysis of a corpus of 38 texts written in Spanish, I aim to provide a preliminary description of the genre. Results indicate that a chain of four phases is associated to a continuum of social settings organized through entrepreneurial/corporate and expert/training variables; its rhetorical structure includes ``describing present/potential situation of the company and market{''} and ``describing future processes of strategic actions regarding the marketing, production, and financial plans{''}. This analysis offers methodological innovations to account for occluded genres, encourages the contrastive study of the business plan in different cultural and linguistic environments, and assists business teachers with a situated picture of the genre.|professional discourse analysis; genre analysis; Spanish for specific purposes; rhetorical structure; business writing|VENTURES|Linguistics; Language \& Linguistics|0|1|11
Structural Competition in Second Language Production: Towards a Constraint-Satisfaction Model|2015|Second language (L2) learners often show inconsistent production of some aspects of L2 grammar. One view, primarily based on data from L2 article production, suggests that grammatical patterns licensed by learners' native language (L1) and those licensed by their L2 compete for selection, leading to variability in the production of L2 functional morphology. In this study, we show that the idea of structural competition has broader applicability, in correctly predicting certain asymmetries in the production of both the definite article the and plural marking -s by Thai learners of English. At the same time, we recognize that learners' growing sensitivity to structural regularities in the L2 might be an additional contributing factor, and therefore make a novel proposal for how the L1-L2 structural competition model and the sensitivity-to-L2-structural regularities account could be integrated and their respective contributions studied under the constraint-satisfaction model of language processing. We argue that this approach is particularly suited to studying bilingual processing as it provides a natural framework for explaining how highly disparate factors, including partially activated options from both languages, interact during processing.|L2 functional morphology; production; articles; plural; structural competition; cross-linguistic influences|BILINGUAL SENTENCE PRODUCTION; SPOKEN-WORD RECOGNITION; ELICITED IMITATION; ARTICLE PRODUCTION; L2 ENGLISH; ACQUISITION; LANGUAGE; SPANISH; AGREEMENT; KNOWLEDGE|Education \& Educational Research; Linguistics|0|0|11
Argumentation Text Construction by Japanese as a Foreign Language Writers: A Dynamic View of Transfer|2015|This study takes a dynamic view of transfer as reusing and reshaping previous knowledge in new writing contexts to investigate how novice Japanese as a foreign language (JFL) writers draw on knowledge across languages to construct L1 and L2 texts. We analyzed L1 English and L2 Japanese argumentation essays by the same JFL writers (N = 19) and L1 Japanese essays by Japanese university students (N = 21), along with JFL writers' reported reflections. The analysis identified both shared and contrasting L1/L2 text features, including argumentation subtypes (e.g., justification, exploration) and essay introduction/conclusion components. The findings revealed that while constructing L2 essays, the JFL writers took an active role in assessing audience, selecting appropriate text features, and transforming/reshaping selected features, influenced by contextual factors (e.g., audience expectation, purpose, topic). For example, some writers reshaped their L1 justification subtype by softening L2 assertions to meet perceived Japanese reader expectations. Results highlight the centrality of the writer's agency in deciding what previous writing knowledge to reuse or reshape when creating L2 text and also the importance of individual learning trajectories (e.g., L2 proficiency, L1/L2 writing experience) affecting writers' decisions. The study affirms that a dynamic view of transfer provides insights into the L2 writers' text construction process.|dynamic view of transfer; JFL learners; L2 writing; previous writing knowledge; perceived reader expectations; rhetorical features|BIDIRECTIONAL TRANSFER; ADAPTIVE TRANSFER; EFL STUDENTS; L1; PERCEPTIONS; PATTERNS; ENGLISH; INSTRUCTION; KNOWLEDGE; SCHOOL|Education \& Educational Research; Linguistics|1|0|11
BRIDGING THE COMMUNICATION DIVIDE: CMC AND DEAF INDIVIDUALS' LITERACY SKILLS|2015|Deaf individuals frequently capitalize upon communication technologies that increase equitable access to communication in an ongoing, effortless manner. Those communication technologies create conditions that increase direct access to language and literacy. It is the lack of direct access to language that has been historically problematic for deaf individuals, contributing to English literacy achievement gaps that are evidenced in deaf education settings. This study explored the hypothesis that increased access to English through communication technologies would be related to stronger English literacy skills for deaf individuals. A secondary analysis approach using a longitudinal large-scale dataset, the second National Longitudinal Transition Study (NLTS2), was used to assess the frequency of computer-mediated communication as a predictor of English literacy skills in a sample of 510 deaf youths in the United States. Regression analyses demonstrated that deaf adolescents who e-mailed or chatted more frequently exhibited higher reading comprehension skills in the years ahead. These results suggest that communication technologies should be further explored as a potential avenue that may support deaf individuals' English language and literacy development.|Computer-Mediated Communication; Second Language Acquisition; Computer-Assisted Language Learning|HARD-OF-HEARING; COMPUTER-MEDIATED COMMUNICATION; FOREIGN-LANGUAGE CLASSROOM; TEXT COMMUNICATION; SLOW MOTION; STUDENTS; ONLINE; TECHNOLOGY; OUTCOMES; PEOPLE|Education \& Educational Research; Linguistics|2|0|11
A Comparison of Deaf and Hearing Children's Reading Comprehension Profiles|2015|Purpose: Although deaf children typically exhibit severe delays in reading achievement, there is a paucity of research looking at their text-level comprehension skills. We present a comparison of deaf and normally hearing readers' profiles on a commonly used reading comprehension assessment: the Neale Analysis of Reading Ability II. Methods: Comprehension questions were coded into 3 types: literal questions; local cohesion questions; and global coherence questions. Deaf children were matched to 3 groups of hearing children: chronological age-matched controls; reading-age-matched controls; and a group of poor comprehenders. Results: Deaf children had significantly weaker reading comprehension skills than both chronological age-and reading-age-matched controls, but their skills were commensurate with poor comprehenders. All groups found it easier to make inferences to establish local cohesion than those required to establish global coherence. Discussion/Conclusions: These results suggest that deaf children's reading comprehension profiles are remarkably similar to those of poor comprehenders. These findings are discussed in light of the potential differences in underlying causes of reading difficulties in these 2 groups.|comprehension; deafness; inference making; language; literacy; reading|HARD-OF-HEARING; SKILLS; MEMORY; INFERENCE; LITERACY; ABILITY; SPEECH; PERFORMANCE; KNOWLEDGE; FAILURE|Linguistics; Rehabilitation|11|0|11
LONG CHAINS OR STABLE COMMUNITIES? THE ROLE OF EMOTIONAL STABILITY IN TWITTER CONVERSATIONS|2015|In this article, we address the issue of how emotional stability affects social relationships in Twitter. In particular, we focus our study on users' communicative interactions, identified by the symbol @. We collected a corpus of about 200,000 Twitter posts, and we annotated it with our personality recognition system. This system exploits linguistic features, such as punctuation and emoticons, and statistical features, such as follower count and retweeted posts. We tested the system on a data set annotated with personality models produced by human subjects and against a software for the analysis of Twitter data. Social network analysis shows that, whereas secure users have more mutual connections, neurotic users post more than secure ones and have the tendency to build longer chains of interacting users. Clustering coefficient analysis reveals that, whereas secure users tend to build stronger networks, neurotic users have difficulty in belonging to a stable community; hence, they seek for new contacts in online social networks.|data mining; personality recognition; social network analysis; Twitter|SOCIAL NETWORKS; PERSONALITY; TEXT|Computer Science, Artificial Intelligence|1|0|11
Detecting sentiment embedded in Arabic social media - A lexicon-based approach|2015|Sentiment analysis aims at extracting sentiment embedded mainly in text reviews. The prevalence of semantic web technologies has encouraged users of the web to become authors as well as readers. People write on a wide range of topics. These writings embed valuable information for organizations and industries. This paper introduces a novel framework for sentiment detection in Arabic tweets. The heart of this framework is a sentiment lexicon. This lexicon was built by translating the SentiStrength English sentiment lexicon into Arabic and afterwards the lexicon was expanded using Arabic thesauri. To assess the viability of the suggested framework, the authors have collected and manually annotated a set of 4400 Arabic tweets. These tweets were classified according to their sentiment into positive or negative tweets using the proposed framework. The results reveal that lexicons are helpful for sentiment detection. The overall results are encouraging and open venues for future research.|Sentiment analysis; unsupervised learning; text mining; Arabic text; opinion mining|NEGATION; WORDNET|Computer Science, Artificial Intelligence|5|2|11
Information status marking in spontaneous vs. read speech in story-telling tasks - Evidence from intonation analysis using GToBI|2015|Two studies investigated whether speaking mode influences the way German speakers mark the information status of discourse referents in nuclear position. In Study 1, speakers produced narrations spontaneously on the basis of picture stories in which the information status of referents (new, accessible and given) was systematically varied. In Study 2, speakers saw the same pictures, but this time accompanied by text to be read out. Clear differences were found depending on speaking mode: In spontaneous speech, speakers always accented new referents. They did not use different pitch accent types to differentiate between new and accessible referents, nor did they always deaccent given referents. In addition, speakers often made use of low pitch accents in combination with high boundary tones to indicate continuity. In contrast to this, read speech was characterized by low boundary tones, consistent deaccentuation of given referents and the use of H+L{*} and H+IH{*} accents, for both new and accessible referents. The results are discussed in terms of the function of intonational features in communication. It is argued that reading intonation is not comparable to intonation in spontaneous speech, and that this has important consequences also for our choice of methodology in child language acquisition research. (C) 2014 Elsevier Ltd. All rights reserved.|Intonation; Givenness; Information status; Oral reading; Language acquisition; Speaking mode; German|PITCH ACCENT; GERMAN; DISCOURSE; CHILDREN; PROSODY; ACCESSIBILITY; PROMINENCE|Linguistics; Language \& Linguistics|7|1|11
On the function of stance-neutral formulations: Apparent neutrality as a powerful stance constructing resource|2014|This study explores the function of expressing external viewpoints with stance-neutral frames in academic writing. While a growing number of studies have established that appropriately evaluating external viewpoints is vital in advanced academic writing, the function of using stance-neutral formulations has long been unexplored despite the fact that many external viewpoints in academic writing are introduced into the discourse with a stance-neutral formulation. This study performs quantitative and qualitative analyses on the introductory chapters of PhD theses in history to explore the functions of these formulations. It finds that because of their absence of an evaluative stance, external propositions expressed without a specific stance flexibly realize various kinds of evaluative processes. Such processes involve taking into account the reader response to a proposition since the blankness in stance plays a role in constructing a discourse that gradually persuades the reader. This paper concludes that each of the neutrally presented viewpoints in the successfully constructed text uniquely forms an important strategic process of gradual value assignment and that stance-neutrality is not a representation of the writer's failure to clarify stance. This paper emphasizes the need to implement the strategic use of stanceneutral formulations in pedagogic settings. (C) 2014 Elsevier Ltd. All rights reserved.|Stance; Intertextuality; Reader response; History discourse; Thesis writing; Genre|ACADEMIC DISCOURSE; REPORTING CLAUSES; RESEARCH ARTICLES; DISCIPLINARY; CITATIONS; KNOWLEDGE; STUDENTS; THESES; TRANSFORMATION; INTRODUCTIONS|Education \& Educational Research; Linguistics; Language \& Linguistics|0|0|11
Text de-identification for privacy protection: A study of its impact on clinical text information content|2014|As more and more electronic clinical information is becoming easier to access for secondary uses such as clinical research, approaches that enable faster and more collaborative research while protecting patient privacy and confidentiality are becoming more important. Clinical text de-identification offers such advantages but is typically a tedious manual process. Automated Natural Language Processing (NLP) methods can alleviate this process, but their impact on subsequent uses of the automatically de-identified clinical narratives has only barely been investigated. In the context of a larger project to develop and investigate automated text de-identification for Veterans Health Administration (VHA) clinical notes, we studied the impact of automated text de-identification on clinical information in a stepwise manner. Our approach started with a high-level assessment of clinical notes informativeness and formatting, and ended with a detailed study of the overlap of select clinical information types and Protected Health Information (PHI). To investigate the informativeness (i.e., document type information, select clinical data types, and interpretation or conclusion) of VHA clinical notes, we used five different existing text de-identification systems. The informativeness was only minimally altered by these systems while formatting was only modified by one system. To examine the impact of de-identification on clinical information extraction, we compared counts of SNOMED-CT concepts found by an open source information extraction application in the original (i.e., not de-identified) version of a corpus of VHA clinical notes, and in the same corpus after de-identification. Only about 1.2-3\% less SNOMED-CT concepts were found in de-identified versions of our corpus, and many of these concepts were PHI that was erroneously identified as clinical information. To study this impact in more details and assess how generalizable our findings were, we examined the overlap between select clinical information annotated in the 2010 i2b2 NLP challenge corpus and automatic PHI annotations from our best-of-breed VHA clinical text de-identification system (nicknamed `BOB'). Overall, only 0.81\% of the clinical information exactly overlapped with PHI, and 1.78\% partly overlapped. We conclude that automated text de-identification's impact on clinical information is small, but not negligible, and that improved clinical acronyms and eponyms disambiguation could significantly reduce this impact. (C) 2014 Elsevier Inc. All rights reserved.|Natural Language Processing; Medical informatics; Confidentiality, patient data privacy; De-identification, Anonymization; Electronic health records; United States department of veterans affairs|DOCUMENTS; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|4|0|11
Linking communicative functions with linguistic resources in short stories: Implications of a narrative analysis for second language writing instruction|2014|Writing short stories constitutes an art that requires considerable knowledge, experience, skills, and understanding of both the generic structure and language resources needed to convey meaning and arouse readers interest. Previous studies, however, have yet to provide a conclusive approach that shows how language mechanisms can be used to realise writers' wide-ranging communicative intentions in a specific second language context. Based on the argument that second language story-writing instruction needs to incorporate an in-depth study into some texts intended for second language writers in a particular socio-cultural setting, this study investigated the generic structure of short stories written by professional textbook writers for second language learners. Using the Swalesian analytical framework, we analysed a corpus of short stories selected from different education-related sources in a second language context, and subsequently ascertained the language resources needed to accomplish the communicative functions of the stories. We have identified eleven rhetorical steps, each of which has differing and yet inter-connected communicative functions performed by noteworthy language mechanisms. Our findings are useful in helping instructors prepare teaching materials that illustrate how second language writers can comprehend and employ salient communicative resources to write meaningful short stories in a socio-culturally relevant schematic structure. (C) 2014 Elsevier Ltd. All rights reserved.|Genre analysis; Story writing; Socio-cultural contexts; Instructional materials|GENRE; LANGUAGE|Education \& Educational Research; Linguistics|4|0|11
Aptitude-treatment interaction effects on explicit rule learning: A latent growth curve analysis|2014|Finding the match between individuals and educational treatments is the aim of both educators and the aptitude-treatment interaction research paradigm. Using the latent growth curve analysis, the present study investigates the interaction between the type of explicit instructional approaches (deductive vs. explicit-inductive) and the level of foreign language aptitude (high vs. low) in the learning of explicit grammar rules. The results indicate that on the whole the two equally explicit instructional approaches did not differentially affect learning performance. However, when the level of language aptitude, measured by grammatical sensitivity, associative memory, and memory for text (with the last variable being the best measure), was taken into account, low-aptitude learners performed significantly better with the deductive instruction, in the sentence-correction tests. The interaction effects of equally explicit instructional approaches suggest the need for considering aptitude-treatment interaction to maximize learners' potential for success in second language learning.|Aptitude-treatment interaction; deduction; domain knowledge; grammar; induction; language aptitude|INDIVIDUAL-DIFFERENCES; CONCEPTUAL LEVEL; GRAMMAR; INSTRUCTION; 2ND-LANGUAGE; ACQUISITION; KNOWLEDGE; IMPLICIT; FRENCH; INFORMATION|Education \& Educational Research; Linguistics|2|1|11
Intercultural citizenship education in an EFL online project in Argentina|2014|In this article, I describe an online intercultural citizenship experience in an English as a Foreign Language (EFL) classroom in Argentina. An action research project on the Malvinas/Falklands war fought between Argentina and the UK in 1982 was carried out in 2012. Through a comparative methodology involving Argentine and English foreign language classes, students develop a critical perspective on texts while they also create an international identification, different from their national/regional identifications. While the existing body of work on intercultural citizenship and criticality in the foreign language classroom is abundant in Europe, North America and Asia, empirical studies hardly exist in this region and one of the questions to be answered deals with the transferability of curriculum research across continents. After a description of the theoretical framework and the project itself, I present student samples and analysis that provide evidence that this intercultural citizenship project was fruitfully implemented for the first time in Argentinean Higher Education in the foreign language classroom. I then outline the significance of the project from the point of view of online intercultural communication and the theory of intercultural citizenship.|intercultural citizenship; online intercultural communication; foreign language education; comparative methodology; Argentina|LITERACY|Linguistics; Language \& Linguistics|12|0|11
Differential Object Marking and identifiability of the referent: A study of Mandarin Chinese|2014|This paper examines the interaction of DOM with information structure in Mandarin Chinese. Despite the large amount of works on this topic, much remains to be explained, in particular with respect to some alternations that do not easily fit the explanations proposed so far in terms of affectedness, animacy and definiteness. Through the analysis of text excerpts taken from the Corpus of Modern Chinese of the Center for Chinese Linguistics (CCL) of Peking University, we argue that, in addition to previously identified constraints, DOM in Mandarin Chinese performs another important function in discourse, namely that of signalling the high identifiability of the marked referent.|Differential Object Marking; Mandarin Chinese; Cantonese; topic; information structure|GRAMMAR|Linguistics; Language \& Linguistics|0|2|11
Formalization and computation of quality measures based on electronic medical records|2014|Objective Ambiguous definitions of quality measures in natural language impede their automated computability and also the reproducibility, validity, timeliness, traceability, comparability, and interpretability of computed results. Therefore, quality measures should be formalized before their release. We have previously developed and successfully applied a method for clinical indicator formalization (CLIF). The objective of our present study is to test whether CLIF is generalizablethat is, applicable to a large set of heterogeneous measures of different types and from various domains. Materials and methods We formalized the entire set of 159 Dutch quality measures for general practice, which contains structure, process, and outcome measures and covers seven domains. We relied on a web-based tool to facilitate the application of our method. Subsequently, we computed the measures on the basis of a large database of real patient data. Results Our CLIF method enabled us to fully formalize 100\% of the measures. Owing to missing functionality, the accompanying tool could support full formalization of only 86\% of the quality measures into Structured Query Language (SQL) queries. The remaining 14\% of the measures required manual application of our CLIF method by directly translating the respective criteria into SQL. The results obtained by computing the measures show a strong correlation with results computed independently by two other parties. Conclusions The CLIF method covers all quality measures after having been extended by an additional step. Our web tool requires further refinement for CLIF to be applied completely automatically. We therefore conclude that CLIF is sufficiently generalizable to be able to formalize the entire set of Dutch quality measures for general practice.|Quality Measures; Quality Indicators; Electronic Medical Record; Secondary Use of Patient Data; Identification of Patient Cohorts; EMR-driven Phenotyping|ELIGIBILITY CRITERIA; CARE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|5|0|11
A sense inventory for clinical abbreviations and acronyms created using clinical notes and medical dictionary resources|2014|Objective To create a sense inventory of abbreviations and acronyms from clinical texts. Methods The most frequently occurring abbreviations and acronyms from 352267 dictated clinical notes were used to create a clinical sense inventory. Senses of each abbreviation and acronym were manually annotated from 500 random instances and lexically matched with long forms within the Unified Medical Language System (UMLS V.2011AB), Another Database of Abbreviations in Medline (ADAM), and Stedman's Dictionary, Medical Abbreviations, Acronyms \& Symbols, 4th edition (Stedman's). Redundant long forms were merged after they were lexically normalized using Lexical Variant Generation (LVG). Results The clinical sense inventory was found to have skewed sense distributions, practice-specific senses, and incorrect uses. Of 440 abbreviations and acronyms analyzed in this study, 949 long forms were identified in clinical notes. This set was mapped to 17359, 5233, and 4879 long forms in UMLS, ADAM, and Stedman's, respectively. After merging long forms, only 2.3\% matched across all medical resources. The UMLS, ADAM, and Stedman's covered 5.7\%, 8.4\%, and 11\% of the merged clinical long forms, respectively. The sense inventory of clinical abbreviations and acronyms and anonymized datasets generated from this study are available for public use at http://www.bmhi.umn.edu/ihi/research/nlpie/resources/index.htm (Sense Inventories', website). Conclusions Clinical sense inventories of abbreviations and acronyms created using clinical notes and medical dictionary resources demonstrate challenges with term coverage and resource integration. Further work is needed to help with standardizing abbreviations and acronyms in clinical care and biomedicine to facilitate automated processes such as text-mining and information extraction.|Abbreviations as Topic{*}; Medical Records{*}; Natural Language Processing{*}; Word sense disambiguation; Clinical sense inventory|BIOMEDICAL DOMAIN; UMLS; DISAMBIGUATION; KNOWLEDGE; MEDLINE; TEXT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|7|0|11
Eye movements during reading proverbs and regular sentences: the incoming word predictability effect|2014|Reading is an everyday activity requiring the efficient integration of several central cognitive subsystems ranging from attention and oculomotor control to word identification and language comprehension. Effects of frequency, length and cloze predictability of words on reading times reliably indicate local processing difficulty of fixated words; also, a reader's expectation about an upcoming word apparently influences fixation duration even before the eyes reach this word. Moreover, this effect has been reported as non-canonical (i.e., longer fixation durations on word N when word N+1 is of high cloze predictability). However, this effect is difficult to observe because in natural sentences the fluctuations in predictability in content words are very small. To overcome this difficulty we investigated eye movements while reading proverbs as well as sentences constructed for high-and low-average cloze predictability. We also determined for each sentence a word at which predictability of words jumps from a low to high value. Fixation durations while reading proverbs and high-predictable sentences exhibited significant effects of the change in predictability along the sentence (when the successive word is more predictable than the fixated word). Results are in agreement with the proposal that cloze predictability of upcoming words exerts an influence on fixation durations via memory retrieval.|eye movements; reading; proverbs; incoming word predictability effect|PERCEPTUAL-SPAN; FIXATION TIMES; FREQUENCY; INFORMATION; TRACKING; PROBABILITY; POTENTIALS; COMPLEXITY; DIFFICULTY; LENGTH|Audiology \& Speech-Language Pathology; Behavioral Sciences; Linguistics; Psychology, Experimental|6|0|11
Recontextualising `Big Spender': socialising the selling of female sexuality in a middle school drama programme|2014|The main focus of this paper is to show how the rehearsal of `Big Spender' in an American middle school drama programme is embedded in larger social contexts, and thereby contributes to what the American Psychological Association identifies as the `sexualization of girls' in today's world. More specifically, I use complex and ecosystems models in order to illuminate the multilayered way in which the recontextualised use of macro-level cultural texts like `Big Spender' can contribute to the sexualisation of girls in meso-level, formal education-based communities of practice, as well as in micro-level, face-to-face social interactions. Data presented here were collected and analysed by combining (a) ethnographically based language socialisation field research conducted at one middle school, and (b) discourse and multimodal examinations of `Big Spender'-related texts. Based on this multilayered analysis I show how schools and teachers can and do contribute to the language socialisation of sexual objectification and subordination of schoolgirls.|LANGUAGE SOCIALISATION; SEXUALISATION OF GIRLS; COMPLEX SYSTEMS MODELS; INTERTEXTUALITY; MIDDLE SCHOOL|SECONDARY-SCHOOLS; HARASSMENT|Linguistics; Language \& Linguistics; Women's Studies|0|1|11
Security investment in aviation industry: a longitudinal analysis|2014|Purpose - Terrorist attacks have generated interests among practitioners and researchers on transportation security enhancement. This study investigates the role that rationality play in government funding on this important aspect of homeland security. In particular, it examines how environmental changes and project characteristics influence the allocation of security-related Airport Improvement Program (AIP) grants in the aviation industry. The paper aims to discuss these issues. Design/methodology/approach - The central hypothesis is that rationality regulates transportations security investment through the dynamic balancing between type I error and type II error concerns. To empirically validate it, this study conducts various analyses on AIP history data. In particular, it uses text mining to identify the security-related AIP grants and their coverage, trend analysis to compare the trends of security funding and other transportation investment, and classification tree analysis to determine the factors that influence the allocation of security-related grants. Findings - The longitudinal distribution of security-related grants differs from other types of transportation funding in terms of their distinct responses to terrorist and economic events. Project characteristics including project coverage and facility location have secondary yet consistent effects on the allocation of security-related grants. Originality/value - This study empirically validates the concept of rationality in transportation security investment. In particular, the findings support that it in constant moves along both longitudinal and cross-sectional dimensions. The dynamic and multi-facet nature of rationality provides the key for researchers and practitioners to understand security funding in aviation industry.|Data mining; Resource allocation; Aviation industry; Investment rationality; Risk-assessment; Transportation security|FEDERAL-GRANTS|Computer Science, Interdisciplinary Applications; Engineering, Industrial|0|2|11
Prolegomena to a Neurocomputational Architecture for Human Grammatical Encoding and Decoding|2014|This study develops a neurocomputational architecture for grammatical processing in language production and language comprehension (grammatical encoding and decoding, respectively). It seeks to answer two questions. First, how is online syntactic structure formation of the complexity required by natural-language grammars possible in a fixed, preexisting neural network without the need for online creation of new connections or associations? Second, is it realistic to assume that the seemingly disparate instantiations of syntactic structure formation in grammatical encoding and grammatical decoding can run on the same neural infrastructure? This issue is prompted by accumulating experimental evidence for the hypothesis that the mechanisms for grammatical decoding overlap with those for grammatical encoding to a considerable extent, thus inviting the hypothesis of a single ``grammatical coder.{''} The paper answers both questions by providing the blueprint for a syntactic structure formation mechanism that is entirely based on prewired circuitry (except for referential processing, which relies on the rapid learning capacity of the hippocampal complex), and can subserve decoding as well as encoding tasks. The model builds on the ``Unification Space{''} model of syntactic parsing developed by Vosse and Kempen (Cognition 75:105-143, 2000; Cognitive Neurodynamics 3:331-346, 2009a). The design includes a neurocomputational mechanism for the treatment of an important class of grammatical movement phenomena.|Psycholinguistics; Neurocognitive linguistics; Language comprehension; Language production; Grammatical encoding; Grammatical decoding; Parsing; Unification; Sentence processing; Grammatical movement; Competitive structural optimization; Interactive activation and competition; IAC|SHORT-TERM-MEMORY; SENTENCE COMPREHENSION; LANGUAGE PRODUCTION; SPEECH PRODUCTION; BROCAS AREA; DISTRIBUTED REPRESENTATIONS; SYNTACTIC STRUCTURE; VARIABLE BINDING; WORKING-MEMORY; NEURAL BASIS|Computer Science, Interdisciplinary Applications; Neurosciences|9|0|11
Automated identification of drug and food allergies entered using non-standard terminology|2013|Objective An accurate computable representation of food and drug allergy is essential for safe healthcare. Our goal was to develop a high-performance, easily maintained algorithm to identify medication and food allergies and sensitivities from unstructured allergy entries in electronic health record (EHR) systems. Materials and methods An algorithm was developed in Transact-SQL to identify ingredients to which patients had allergies in a perioperative information management system. The algorithm used RxNorm and natural language processing techniques developed on a training set of 24599 entries from 9445 records. Accuracy, specificity, precision, recall, and F-measure were determined for the training dataset and repeated for the testing dataset (24857 entries from 9430 records). Results Accuracy, precision, recall, and F-measure for medication allergy matches were all above 98\% in the training dataset and above 97\% in the testing dataset for all allergy entries. Corresponding values for food allergy matches were above 97\% and above 93\%, respectively. Specificities of the algorithm were 90.3\% and 85.0\% for drug matches and 100\% and 88.9\% for food matches in the training and testing datasets, respectively. Discussion The algorithm had high performance for identification of medication and food allergies. Maintenance is practical, as updates are managed through upload of new RxNorm versions and additions to companion database tables. However, direct entry of codified allergy information by providers (through autocompleters or drop lists) is still preferred to post-hoc encoding of the data. Data tables used in the algorithm are available for download. Conclusions A high performing, easily maintained algorithm can successfully identify medication and food allergies from free text entries in EHR systems.|Natural language processing; Hypersensitivity; Electronic health records; Electronic medical records; Allergies; RxNorm|PHYSICIAN ORDER ENTRY; MEDICATION INFORMATION; EXTRACTION; SYSTEM; ERRORS; RECORD|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|9|0|11
How to identify the trends of services: GTM-TT service map|2013|Recently, due to the explosive increase of services, firms have faced with challenges to analyze patterns and trends in services in an intuitive but objective ways. The notion of service map can be adapted to this end. Maps, in general, have been receiving a great deal of attention because of their potential as visualization tools that can allow people to visualize massive amounts of information. Specifically, the generative topographic mapping through time (GTM-TT) algorithm is suitable for dynamic analysis since GTM-TT provides a time-based clustering and change path. In response, this study proposes an approach for developing and using GTM-TT service maps consisting of a service clustering map and a service sequence map for analyzing service trends. The proposed approach, broadly, is comprised of four steps: (1) the construction of a database, (2) data preprocessing, (3) development of a GTM-TT service map, and (4) interpretation. The proposed approach is expected to aid in the identification of dynamic service trends. (C) 2012 Elsevier Ltd. All rights reserved.|Service map; Generative topographic mapping through time; Visualization; Mobile application services|TEXT; TRANSITION; PRODUCTS; MODELS; TIME|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|3|0|11
Bilingual voicing: A study of code-switching in the reported speech of Finnish immigrants in Estonia|2013|Through a conversation analytic investigation of Finnish-Estonian bilingual (direct) reported speech (i.e., voicing) by Finns who live in Estonia, this study shows how code-switching is used as a double contextualization device. The code-switched voicings are shaped by the on-going interactional situation, serving its needs by opening up a context where the participants can engage in activities such as assessing the voice-persona, and renewing the current speech event by imposing a context of prior texts upon it. The study shows that code-switching can be used in an interactionally meaningful way even when a) the morphosyntactic and lexical border between the two languages is not strictly salient, and b) when the participants do not orient towards the two varieties as indexical of specific social groups or values associated with them. In light of these results, the conclusion is drawn that although the two languages are clearly interrelated for the speakers, Finns in Estonia still orient towards two relatively distinct sets of linguistic features and operate with this difference as a resource in interaction. These findings are discussed in light of recent sociolinguistic theories that find the opposition of two languages in conversation often to lack any meaning for the participants.|conversation analysis; contextualization; code-switching; language mixing; poly-languaging; Ingrian Finns; Finnish; Estonian|TALK|Linguistics; Language \& Linguistics|2|0|11
Idiomatic proclivity and literality of meaning in body-part nouns: Corpus studies of English, German, Swedish, Russian and Finnish|2013|Study 1, a dictionary analysis of English, German, Swedish, Russian and Finnish VP idioms, shows that there is a general trend for these idioms to pick their nouns from among the most frequent body-part nouns. Thus, the same overall cognitive domains tend to be favored in the lexical resources for idiomatic and non-idiomatic language. In Study 2 we used corpora to test the degree of literal versus non-literal use, in terms of textual frequency, of the three most idiom-prone nouns in the five languages, viz., `hand', `head' and `eye'. Moreover, as text genres are expected to differ in their use of literal versus non-literal senses of words, two text types were pitted against each other, viz., fiction and newspaper language, entertaining the hypothesis that fiction would be more non-literal than newspaper texts. The reverse turned out to be the case. We explain the higher degree of non-literal ( mostly metaphorical) use of `hand', `head' and `eye' with the notion that in fiction the authors describe a world constructed in situ, while newspaper writers interpret the world already shared by them and their readers.|body-part nouns; idioms; lexical frequency; literality of meaning; fiction; newspaper language|WORDS|Linguistics; Language \& Linguistics|0|2|11
A Silent Spout: Paul de Man's Moby-Dick|2013|This article discusses a 1945 Flemish translation of Herman Melville's Moby-Dick that has been attributed to the literary critic Paul de Man and yet has been unduly neglected by de Man scholars. The article takes issue with the claim that the Moby-Dick translation entails a radical break with de Man's. newspaper writings of previous years. De Man's motivation for translating Moby-Dick is considered in relation to the reception of the book in the framework of the Conservative Revolution in Europe. It is further shown that de Man probably took inspiration from a 1941 French translation by Jean Giono, which proved a vehicle for warring ideologies in occupied France. Analysis of the de Man translation focuses both on the paratextual framing and on passages where his own perspective disrupts the univocity of the text. The purpose of drawing attention to the continuities between de Man's wartime journalism and the Moby-Dick translation is to arrive at a better understanding of the pervasiveness and fractured nature of the totalizing ideologies shared by many intellectuals in wartime Europe, which offered a fertile breeding ground for, but were by no means reducible to, the Nazi doctrines.|Paul de Man; Jean Giono; Moby-Dick; Deconstruction; National socialism; Indirect translation|TRANSLATION|Communication; Linguistics; Language \& Linguistics|3|0|11
The use of co-textual irony markers in written discourse|2013|Authors of written texts may mark the use of verbal irony in a variety of ways. One possibility for doing so is the use of so-called co-textual markers of irony (i.e., support strategies that open up a non-serious frame). This study aims to classify and categorize these co-textual irony markers. A content analysis of 2,042 co-textual utterances of irony across four text genres (advertisements, newspaper columns, book and film reviews, and letters to the editor) shows that three categories of support strategies could be identified: other ironic utterances, tropes and mood markers. The use of irony support strategies was positively-related to the genre of newspaper columns: columns used more ironic utterances and tropes as irony support strategies than the other genres in the corpus.|verbal irony; natural discourse; irony support strategies; co-textual markers|VERBAL IRONY; HUMOR; SARCASM; LANGUAGE; CONTEXT; GENRES|Language \& Linguistics; Psychology, Multidisciplinary|2|0|11
Anthropomorphic grammar? Some linguistic patterns in the wildlife documentary series Life|2013|Human language inevitably depicts the world from a human point of view. This article briefly reviews key positions on the use of anthropomorphic and anthropocentric language taken by scientists and discourse analysts. It then presents the data used in this investigation - a corpus of transcripts of the television series Life. The methods of analysis are explained, as is the focus adopted, which is less on the more obvious, lexical choices made by the presenter, David Attenborough, and more on the grammatical patterns which we suggest play a significant role in the depiction of the wide range of species represented in the programs. Three grammatical features - pronouns, the connective so, and the to infinitive form - were explored in context, and the results demonstrate how, separately and together, they play a significant role in the representation in these texts of animals' perspectives, connoting in subtle ways both intention and evaluation. We suggest a need for greater dialogue between broadcasters, discourse analysts, and ethologists.|anthropomorphism; TV documentaries; corpus analysis; wildlife; pronouns; infinitives|ANIMALS; CONSTRUCTION; LANGUAGE; HUMANS|Communication; Linguistics; Language \& Linguistics|2|0|11
The epistemics of student problems: Explaining mathematics in a multi-lingual class|2012|Teachers in dyadic explanation interactions in mathematics lessons tailor their explanations to problems they assume, rather than to problems the students formulate. In these interactions, the teacher rather than the student is established as having access to the problem, and as a result it is the teacher's problem that gets to be explained. This analysis adds to recent Conversation Analytical studies of how participants in interaction deal with issues of knowledge (e.g. Stivers et al., 2011a). It also shows a case of educational interaction in a multi-lingual context. The students have diverse linguistic backgrounds, and work-aloud interviews with them have shown that their problem often is not with mathematics, but with understanding the texts of the assignments. As a result of the teacher's epistemic authority these language problems never surface in the interactions. The teacher casts the student's problem invariably as a mathematics problem, not as a language problem. (C) 2012 Elsevier B.V. All rights reserved.|Conversation analysis; Epistemics; Teacher-student explanations; Multi-lingual context; Student problems|CONVERSATION; ORGANIZATION; CALLS; RESPONSES; TALK; HELP|Linguistics; Language \& Linguistics|12|0|11
EmoTales: creating a corpus of folk tales with emotional annotations|2012|Emotions are inherent to any human activity, including human-computer interactions, and that is the reason why recognizing emotions expressed in natural language is becoming a key feature for the design of more natural user interfaces. In order to obtain useful corpora for this purpose, the manual classification of texts according to their emotional content has been the technique most commonly used by the research community. The use of corpora is widespread in Natural Language Processing, and the existing corpora annotated with emotions support the development, training and evaluation of systems using this type of data. In this paper we present the development of an annotated corpus oriented to the narrative domain, called EmoTales, which uses two different approaches to represent emotional states: emotional categories and emotional dimensions. The corpus consists of a collection of 1,389 English sentences from 18 different folk tales, annotated by 36 different people. Our model of the corpus development process includes a post-processing stage performed after the annotation of the corpus, in which a reference value for each sentence was chosen by taking into account the tags assigned by annotators and some general knowledge about emotions, which is codified in an ontology. The whole process is presented in detail, and revels significant results regarding the corpus such as inter-annotator agreement, while discussing topics such as how human annotators deal with emotional content when performing their work, and presenting some ideas for the application of this corpus that may inspire the research community to develop new ways to annotate corpora using a large set of emotional tags.|Text corpora; Corpus annotation; Emotional ontology; Emotional categories; Emotional dimensions|LANGUAGE; SPEECH; EXPRESSIONS; CHALLENGES; TEXT|Computer Science, Interdisciplinary Applications|7|0|11
Cognitive-Affective Styles Associated With Position on War|2012|This study examined cognitive-affective styles associated with position on the Iraq war by analyzing responses posted on an online discussion forum using a computerized text-analysis program (Linguistic Inquiry and Word Count). Overall, the results were consistent with those obtained in narrative-coding studies. The pro-war group was associated with an external focus and a simplistic style of information processing. The anti-war group was associated with an internal focus and high levels of cognitive processing and negative emotion words. The ``neither{''} group scored the highest on cognitive complexity and positive emotion words, and it was also the most balanced in terms of internal and external focus.|attitudes toward Iraq War; affective style; cognitive style; Linguistic Inquiry and Word Count (LIWC)|INTEGRATIVE COMPLEXITY; AGGRESSION; MILITARY|Communication; Linguistics; Psychology, Social|9|2|11
Contextual correlation based thread detection in short text message streams|2012|Short text message streams are produced by Instant Messaging and Short Message Service which are wildly used nowadays. Each stream contains more than one thread usually. Detecting threads in the streams is helpful to various applications, such as business intelligence, investigation of crime and public opinion analysis. Existing works which are mainly based on text similarity encounter many challenges including the sparse eigenvector and anomaly of short text message. This paper introduces a novel concept of contextual correlation instead of the traditional text similarity into single-pass clustering algorithm to cover the challenges of thread detection. We firstly analyze the contextually correlative nature of conversations in short text message streams, and then propose an unsupervised method to compute the correlative degree. As a reference, a single-pass algorithm employing the contextual correlation is developed to detect threads in massive short text stream. Experiments on large real-life online chat logs show that our approach improves the performance by 11\% when compared with the best similarity-based algorithm in terms of F1 measure.|Text stream; Thread detection; Short text; Contextual correlation|SEGMENTATION|Computer Science, Artificial Intelligence; Computer Science, Information Systems|3|2|11
Mining methodologies from NLP publications: A case study in automatic terminology recognition|2012|The task of reviewing scientific publications and keeping up with the literature in a particular domain is extremely time-consuming. Extraction and exploration of methodological information, in particular, requires systematic understanding of the literature, but in many cases is performed within a limited context of publications that can be manually reviewed by an individual or group. Automated methodology identification could provide an opportunity for systematic retrieval of relevant documents and for exploring developments within a given discipline. In this paper we present a system for the identification of methodology mentions in scientific publications in the area of natural language processing, and in particular in automatic terminology recognition. The system comprises two major layers: the first layer is an automatic identification of methodological sentences; the second layer highlights methodological phrases (segments). Each mention is categorised in four semantic categories: Task, Method, Resource/Feature and Implementation. Extraction and classification of the segments is formalised as a sequence tagging problem and four separate phrase-based Conditional Random Fields are used to accomplish the task. The system has been evaluated on a manually annotated corpus comprising 45 full text articles. The results for the segment level annotation show an F-measure of 53\% for identification of Task and Method mentions (with 70\% precision), whereas the F-measures for Resource/Feature and Implementation identification were 61\% (with 67\% precision) and 75\% (with 86\% precision) respectively. At the document-level, an F.-measure of 72\% (with 81\% precision) for Task mentions, 60\% (with 81\% precision) for Method mentions, 74\% (with 78\% precision) for the Resource/Feature and 79\% (with 81\% precision) for the Implementation categories have been achieved. We provide a detailed analysis of errors and explore the impact that the particular groups of features have on the extraction of methodological segments. (C) 2011 Elsevier Ltd. All rights reserved.|Information extraction; Methodology mining; Conditional Random Fields; Automatic terminology mining|BIOMEDICAL TEXT; AGREEMENT; ABSTRACTS; ARTICLES; GENE|Computer Science, Artificial Intelligence|4|1|11
Written Discourse Comprehension: A theoretical and methodological framework for its assessment|2012|During the last decades, assessment of written discourse comprehension has attracted the interest of a large number of specialists from various disciplinary fields, such as psycholinguistics, discourse psychology, applied linguistics, among others. This has led to a significant number of studies, most of which are essentially focused on issues regarding assessment instruments. Such issues include, among other aspects, how pertinent assessment techniques are, how important text's features are in the measuring, the number and the type of procedures required for validating instruments. However, in spite of the great variety of studies in the area, frameworks to guide the creation of assessment tools from a clear theoretical-methodological perspective are scarce. In this paper, we propose a framework for the design and construction of instruments for assessing written text comprehension, based on our theoretical conception of the phenomenon. Besides, in this proposal, we emphasize the importance of corpus studies to support the specialist's decision making during the design and construction of the instrument. Corpus studies can guide the generation and maintenance of a coherent relation among the theoretical constructs to be measured, the texts to be selected, and the assessing techniques to be used. In turn, this should result in a better assessment instrument.|Evaluation; written text comprehension; instruments|LATENT SEMANTIC ANALYSIS; READING-COMPREHENSION; TEXT COMPREHENSION; SITUATION MODELS; KNOWLEDGE; INFERENCE; MEMORY; SKILL|Linguistics; Language \& Linguistics|1|1|11
The reconstruction of feminine values in Mme Lesbazeille-Souvestre's 1854 translation of Jane Eyre|2012|Mme Lesbazeille-Souvestre's translation of Jane Eyre, published in 1854, was the first to appear in French and has been re-edited numerous times, most recently in 2001. This analysis uses both the translator's preface and the translation itself to explore how the translator constructed what was often seen as a problematically ``feminine{''} text into a normatively ``feminine{''} one and, in so doing, asserted herself as an author in her own right. In her translator's preface, Lesbazeille-Souvestre aims to assure her readers that in translating she felt a duty of fidelity to the text and to the text's author, and thus that they are reading a linguistically faithful translation. In the translation itself, however, and in contradiction to her stated goal, she actively attempted to construct Jane Eyre as a text that is proper both for a female writer to have produced and for female readers to consume by consistently negating the so-called ``masculine{''} elements she found in the novel. The character of Jane Eyre is significantly altered in the translation in ways that bring her more in line with conventional feminine values. Lesbazeille-Souvestre's protestations of complete fidelity in her preface must therefore be questioned and viewed through the lens not only of what it meant to translate in the nineteenth century but of what it meant to translate and to write as a woman.|Charlotte Bronte; Jane Eyre; Lesbazeille-Souvestre; translation in France; women's writing|`JANE-EYRE'|Linguistics; Language \& Linguistics|0|0|11
Supervised and semi-supervised infant-directed speech classification for parent-infant interaction analysis|2011|This paper describes the development of an infant-directed speech discrimination system for parent infant interaction analysis. Different feature sets for emotion recognition were investigated using two classification techniques: supervised and semi-supervised. The classification experiments were carried out with short pre-segmented adult-directed speech and infant-directed speech segments extracted from real-life family home movies (with durations typically between 0.5 s and 4 s). The experimental results show that in the case of supervised learning, spectral features play a major role in the infant-directed speech discrimination. However, a major difficulty of using natural corpora is that the annotation process is time-consuming, and the expression of emotion is much more complex than in acted speech. Furthermore, interlabeler agreement and annotation label confidences are important issues to address. To overcome these problems, we propose a new semi-supervised approach based on the standard co-training algorithm exploiting labelled and unlabelled data. It offers a framework to take advantage of supervised classifiers trained by different features. The proposed dynamic weighted co-training approach combines various features and classifiers usually used in emotion recognition in order to learn from different views. Our experiments demonstrate the validity and effectiveness of this method for a real-life corpus such as home movies. (C) 2011 Elsevier B.V. All rights reserved.|Infant-directed speech; Emotion recognition; Face-to-face interaction; Data fusion; Semi-supervised learning|MOTHERESE; PREFERENCE; LANGUAGE|Acoustics; Computer Science, Interdisciplinary Applications|4|1|11
Frequency issues of classifier configurations for processing Mandarin object-extracted relative clauses: A corpus study|2011|Psycholinguistic studies on whether classifiers facilitate processing object-extracted relative clauses (RC) in Mandarin have often made use of a classifier mismatch-match configuration, wherein a preceding classifier mismatches the following RC-subject but matches the modified head noun. However, an examination of the Chinese Treebank corpus 5.0 shows this configuration rarely occurs. None of the 10 tokens of pre-RC classifiers conforms to the mismatch-match configuration in a real sense. Instead, either a dropped RC-subject or some intervening item successfully avoids anticipated lexical disruption effects induced by a mismatching classifier. The results of analysis suggest that the constructed examples used in previous psycholinguistic studies may not realistically test natural language processing procedures.|classifier configuration; mismatching; matching; object-extracted relative clause (RC); frequency; processing|LANGUAGE; COMPREHENSION; DISCOURSE; GRAMMAR; CHINESE; MEMORY; ORDER|Linguistics; Language \& Linguistics|2|2|11
Taxonomy induction based on a collaboratively built knowledge repository|2011|The category system in Wikipedia can be taken as a conceptual network. We label the semantic relations between categories using methods based on connectivity in the network and lexico-syntactic matching. The result is a large scale taxonomy. For evaluation we propose a method which (1) manually determines the quality of our taxonomy, and (2) automatically compares its coverage with ResearchCyc, one of the largest manually created ontologies, and the lexical database WordNet. Additionally, we perform an extrinsic evaluation by computing semantic similarity between words in benchmarking datasets. The results show that the taxonomy compares favorably in quality and coverage with broad-coverage manually created resources. (C) 2011 Elsevier B.V. All rights reserved.|Natural language processing; Knowledge acquisition; Lexical semantics|SEMANTIC SIMILARITY; WORDNET; WIKIPEDIA; RELATEDNESS; WEB|Computer Science, Artificial Intelligence|26|1|11
Bilingual education, metalinguistic awareness, and the understanding of an unknown language|2011|An increasing number of schools offer bilingual programs, where lessons are taught in more than one language. Several theories state that bilinguals have greater metalinguistic awareness than monolinguals. We investigated whether this greater metalinguistic awareness is also related to an increased ability to understand an unknown language. To measure metalinguistic awareness and the ability to understand text written in an unknown language, we designed the Indonesian Language Test (ILT). The ILT consists of items regarding a story in Indonesian. Dutch high school students from monolingual and bilingual classes were administered the ILT, a Dutch Language Test, an English Language Test, and a general intelligence test. The ILT showed promising psychometric properties. Bilingual students scored significantly higher on the ILT than monolingual students. Multi-group confirmatory factor analyses showed (i) that ILT measures the ability to understand an unknown language, and (ii) that bilingual students score significantly higher than monolingual students on this ability. Both observations support the notion that bilingual education increases metalinguistic awareness and therefore the ability to understand an unknown language.|bilingual education; metalinguistic awareness; language acquisition; Indonesian Language Test|MEASUREMENT INVARIANCE; CHILDREN|Linguistics; Psychology, Experimental|4|0|11
A reusable framework for health counseling dialogue systems based on a behavioral medicine ontology|2011|Automated approaches to promoting health behavior change, such as exercise, diet, and medication adherence promotion, have the potential for significant positive impact on society. We describe a theory-driven computational model of dialogue that simulates a human health counselor who is helping his or her clients to change via a series of conversations over time. Applications built using this model can be used to change the health behavior of patients and consumers at low cost over a wide range of media including the web and the phone. The model is implemented using an OWL ontology of health behavior change concepts and a public standard task modeling language (ANSI/CEA-2018). We demonstrate the power of modeling dialogue using an ontology and task model by showing how an exercise promotion system developed in the framework was re-purposed for diet promotion with 98\% reuse of the abstract models. Evaluations of these two systems are presented, demonstrating high levels of fidelity to best practices in health behavior change counseling. (c) 2011 Elsevier Inc. All rights reserved.|Dialogue system; Behavioral informatics; Consumer informatics; Motivational Interviewing; Transtheoretical model; Natural language processing|INTERACTIVE VOICE RESPONSE; CARDIOVASCULAR-DISEASE; CHANGE INTERVENTIONS; PHYSICAL-ACTIVITY; UNITED-STATES; FRUIT; RISK; CARE; GUIDELINES; VEGETABLES|Computer Science, Interdisciplinary Applications; Medical Informatics|24|0|11
Analysis of five cases with neurogenic stuttering following brain injury in the basal ganglia|2011|This study examined stuttering patterns in five patients with basal ganglia injury. None of the patients had a history of developmental stuttering. Four patients were right-handed; one patient was ambidextrous. Stuttering tests administered to patients assessed sentence repetition, reading aloud, explanations of a comic strip, and conversation. Accessory behaviors such as facial grimaces, associated movements of the limbs, and avoidance behaviors were observed. The results of this study differ from those of previous studies of neurogenic stuttering in several respects: (1) blocks were frequently observed. (2) Adaptation was observed. (3) Almost all stuttering occurred at the initiation of words. (4) Across patients, stuttering frequency did not vary in a consistent manner with speaking task. New speech characteristics for neurogenic stuttering without aphasia following injury to the basal ganglia are described. Educational objectives: After reading this text, the reader will be able to: (1) provide characteristics of neurogenic stuttering after the basal ganglia in patients without aphasia; (2) discuss the difference of the features and characteristics of stuttering between previously reported patients and present patients. (C) 2010 Elsevier Inc. All rights reserved.|Neurogenic stuttering; Basal ganglia; Adaptation effect; Accessory behaviors|CLINICAL ENTITY; DISORDER; LESIONS; SPEECH|Audiology \& Speech-Language Pathology; Education, Special; Linguistics; Rehabilitation|18|0|11
Conceptual-driven classification for coding advise in health insurance reimbursement|2011|Objective: With the non-stop increases in medical treatment fees, the economic survival of a hospital in Taiwan relies on the reimbursements received from the Bureau of National Health Insurance, which in turn depend on the accuracy and completeness of the content of the discharge summaries as well as the correctness of their International Classification of Diseases (ICD) codes. The purpose of this research is to enforce the entire disease classification framework by supporting disease classification specialists in the coding process. Methodology: This study developed an ICD code advisory system (ICD-AS) that performed knowledge discovery from discharge summaries and suggested ICD codes. Natural language processing and information retrieval techniques based on Zipf's Law were applied to process the content of discharge summaries, and fuzzy formal concept analysis was used to analyze and represent the relationships between the medical terms identified by MeSH. In addition, a certainty factor used as reference during the coding process was calculated to account for uncertainty and strengthen the credibility of the outcome. Results: Two sets of 360 and 2579 textual discharge summaries of patients suffering from cerebrovascular disease was processed to build up ICD-AS and to evaluate the prediction performance. A number of experiments were conducted to investigate the impact of system parameters on accuracy and compare the proposed model to traditional classification techniques including linear-kernel support vector machines. The comparison results showed that the proposed system achieves the better overall performance in terms of several measures. In addition, some useful implication rules were obtained, which improve comprehension of the field of cerebrovascular disease and give insights to the relationships between relevant medical terms. Conclusion: Our system contributes valuable guidance to disease classification specialists in the process of coding discharge summaries, which consequently brings benefits in aspects of patient, hospital, and healthcare system. (C) 2010 Elsevier B.V. All rights reserved.|Knowledge discovery; Text mining; Fuzzy formal concept analysis; Information retrieval; ICD code; Health insurance|FORMAL CONCEPT ANALYSIS; INFORMATION-RETRIEVAL; DOCUMENT-RETRIEVAL; TEXT RETRIEVAL; SUPPORT; SIMILARITY; DISCOVERY|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|4|0|11
Promoting communities of practice among non-native speakers of English in online discussions|2011|An online discussion involving text-based computer-mediated communication has great potential for promoting equal participation among non-native speakers of English. Several studies claimed that online discussions could enhance the academic participation of non-native speakers of English. However, there is little research around participation patterns in online discussions for non-native speakers of English. This descriptive pilot study considered the concept of communities of practice as it examined the online postings of three non-native and three native speakers of English who were enrolled in an online course on Teaching English to Speakers of Other Languages (TESOL). Content analysis was employed to study the 201 postings. The findings showed that the non-native speakers of English posted more messages in online discussions than their native peers did, and their postings showed more reflection on and accommodation of other students' perspectives than their native peers' postings. The pattern and frequency of these non-native English speakers' participation revealed that they gained a legitimate status engaging in academic socialization. In addition, an examination of the influence of the types of discussion questions posed for the non-native English speakers confirmed the significant role of the instructor in class participation.|online discussion; equal participation; academic discourse participation; non-native English speakers; communities of practice|DISCOURSE SOCIALIZATION; CLASSROOM; IDENTITY; COMMUNICATION; EDUCATION|Education \& Educational Research; Linguistics; Language \& Linguistics|5|0|11
Grounding the cognitive neuroscience of semantics in linguistic theory|2011|The mission of cognitive neuroscience is to represent the interaction of cognitive science and neuroscience: cognitive models of the mind guide a neuroscientific investigation of the brain bases of mental processes. In this endeavour, a cognitive model is crucial as without it, the cognitive neuroscientist does not know what to look for in the brain, what the nature of the relevant representations might be, or how the different components of a process might interact with each other. In the cognitive neuroscience of language, the interaction of theoretical models and brain research has, however, been far from ideal, especially when it comes to the study of meaning at the sentence level. Although theoretical semantics has a long history in linguistics and thus offers detailed and comprehensive models of the nature of semantic representations, these theories have had minimal impact on the brain investigation of semantic processing. In this article, we outline what a theoretically grounded cognitive neuroscience of semantics might look like and summarise our own findings regarding the neural bases of semantic composition, the basic combinatory operation that builds the complex meanings of natural language.|Formal semantics; Cognitive neuroscience; Magnetoencephalography; AMF|VENTROMEDIAL PREFRONTAL CORTEX; FUNCTIONAL NEUROANATOMY; DECISION-MAKING; ORBITOFRONTAL CORTEX; SYNTACTIC COMPREHENSION; SOCIAL COGNITION; BRAIN; PERCEPTION; KNOWLEDGE; EMOTION|Linguistics; Psychology, Experimental|17|0|11
Speech Emotion Analysis: Exploring the Role of Context|2010|Automated analysis of human affective behavior has attracted increasing attention in recent years. With the research shift toward spontaneous behavior, many challenges have come to surface ranging from database collection strategies to the use of new feature sets (e. g., lexical cues apart from prosodic features). Use of contextual information, however, is rarely addressed in the field of affect expression recognition, yet it is evident that affect recognition by human is largely influenced by the context information. Our contribution in this paper is threefold. First, we introduce a novel set of features based on cepstrum analysis of pitch and intensity contours. We evaluate the usefulness of these features on two different databases: Berlin Database of emotional speech (EMO-DB) and locally collected audiovisual database in car settings (CVRRCar-AVDB). The overall recognition accuracy achieved for seven emotions in the EMO-DB database is over 84\% and over 87\% for three emotion classes in CVRRCar-AVDB. This is based on tenfold stratified cross validation. Second, we introduce the collection of a new audiovisual database in an automobile setting (CVRRCar-AVDB). In this current study, we only use the audio channel of the database. Third, we systematically analyze the effects of different contexts on two different databases. We present context analysis of subject and text based on speaker/text-dependent/-independent analysis on EMO-DB. Furthermore, we perform context analysis based on gender information on EMO-DB and CVRRCar-AVDB. The results based on these analyses are promising.|Affect analysis; affective computing; context analysis; emotional speech; emotion intelligence; emotion recognition; vocal expression|ANNOTATION|Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications|34|1|11
Students' appraisal of emotional and relational experience whilst collaborating online using text based communication|2010|The impacts that the lack of physical cues and non-verbal cues of emotional expression has on the student learning experience in text based online environments were targeted separately in this study. A questionnaire was constructed with separate items for non-verbal cues of emotional expression and cues to physical identity. The survey also included questions about students' previous experience with technology and collaboration, and their motivations for undertaking the course. Views about their interactions with other students were also sought. The responses of 256 students who had undertaken a text based online course where collaboration was a mandatory requirement were collected and subsequently analysed using cluster analysis. Four distinct cohorts of students were identified. Using a conceptual approach borrowed from neuroscience, modularity, it has been possible to encapsulate the effects of three distinct aspects of collaborating in text based online contexts, lack of cues to physical identity, lack of cues to emotional expression and interaction experience. These aspects were analysed alongside the student profiles for each of the four cohorts. The findings indicate that the external factors that an individual student brings to a learning context can impact on the learning experience. Neuroscientifically based knowledge that is relevant for the findings of the survey are identified and considered in terms of the questions raised from an interdisciplinary perspective. (C) 2009 Elsevier Ltd. All rights reserved.|Emotion; Online interaction; Collaboration; Computer mediated communication; Neuroscience|COMPUTER-MEDIATED COMMUNICATION; FACIAL EXPRESSIONS; ANONYMITY; FACES; TERM|Computer Science, Interdisciplinary Applications; Education \& Educational Research|1|1|11
Developing a semantic-enable information retrieval mechanism|2010|The existing information retrieval systems are mostly keyword-based and retrieve relevant documents or information by matching keywords. Keyword-based search, in spite of its merits of expedient query for information and ease-of-use, has failed to represent the complete semantics contained in the content and has let to the retrieval failure. In a textual content, the author's intention is represented in a semantic format of various combinations of word-word relations that are comprehensible to human beings. Query constructed by descriptions in natural language best reflects querist's intention. This study developed a semantic-enable information retrieval mechanism that handles the processing, recognition, extraction, extensions and matching of content semantics to achieve the following objectives: (1) to analyze and determine the semantic features of content, to develop a semantic pattern that represents semantic features of the content, and to structuralize and materialize semantic features; (2) to analyze user's query and extend its implied semantics through semantic extension so as to identify more semantic features for matching: and (3) to generate contents with approximate semantics by matching against the extended query to provide correct contents to the querist. This mechanism is capable of improving the traditional problem of keyword search and enables the user to perform a semantic-based query and search for the required information, thereby improving the reusing and sharing of information. Crown Copyright (C) 2009 Published by Elsevier Ltd. All rights reserved.|Information retrieval; Semantic extraction; Query extension; Query matching|SUPPORT VECTOR MACHINES; SYSTEMS|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|21|0|11
Obligation and reader involvement in English and Korean science popularizations: a corpus-based cross-cultural text analysis|2010|Most research on English/Korean cross-cultural text analysis has focused on comparing the discourse organization of academic texts written by English native speakers and ESL learners. However, this provides a limited view of the textual differences between the two cultures. In the present If research, we analyze a genre with a mass readership-newspaper science popularization texts-from an interpersonal perspective. Using two corpora of 356 British and Korean newspaper articles, we investigated modal expressions of obligation. Analytical categories were devised based on two aspects: ``who is imposing the obligation?{''} ({''}the obligation-imposer{''}) and 11 on whom the obligation is imposed?{''} ({''}the obligation-imposed{''}). The analysis shows differences in the ways in which obligation is imposed on the reader in the two corpora. The English writers depend more on third-person scientific experts as ``the obligation-imposer,{''} and tend to specify ``the obligation-imposed{''} explicitly. In contrast, the Korean writers are more likely to impose obligation in their own persona, and to represent the ``obligation-imposed{''} implicitly. We explore in what ways these differences can be seen as reflecting cultural norms, focusing especially on the individualism and task-orientedness that are held to be characteristic of Western cultures as opposed to the collectivism and relation-orientedness of Korean culture.|reader involvement; science popularization; modality; obligation; cross-cultural text analysis|DISCOURSE; AMERICAN|Communication; Linguistics; Language \& Linguistics|4|0|11
A study of the role of relative clauses in the simplification of news texts for learners of English|2009|The aim of the current research is to investigate the effects of textual modification upon the distribution of specific linguistic features of news texts when authors adopt an intuitive approach to simplification. The research focuses on the distribution and use of relative clauses (RCs) across three levels of simplification. The analysis of news texts reveals that although many RCs are retained in unmodified form across the levels, RCs are also found to be unique to specific levels, highlighting their role as simplifying devices used to modify lower level texts. Additionally, non-restrictive RCs are systematically omitted from lower level texts, through a process of information reduction. A qualitative analysis provides insights into the intuitive approach to simplification highlighting the effects of information reduction, supply and elaboration upon the distribution and use or RCs in news texts. (C) 2009 Elsevier Ltd. All rights reserved.|Simplification; Relative clauses; News; Corpora; Simplified texts; Simplification methodology; Intuitive approach|READING-COMPREHENSION; LANGUAGE|Education \& Educational Research; Linguistics|10|0|11
The most frequent phrasal verbs in English language EU documents - A corpus-based analysis and its implications|2009|This study explores the use of phrasal verbs in English language documents of the European Union (EU) as part of a larger-scale project examining the use of English in EU texts from various aspects including lexical, lexico-grammatical and textual features. Phrasal verbs, known to represent one of the most difficult aspects of learning English, are highly productive and widely used by native speakers. The purpose of this study is to identify the most frequent phrasal verb combinations in EU documents. To this end, an EU English Corpus of approximately 200,000 running words was built using texts which are representative of the fields of activities of the EU. The analysis revealed that the top 25 phrasal verbs account for more than 60\% of all phrasal verb constructions in the corpus. The results also show that in terms of the frequency of phrasal verbs, EU documents show some similarity to written academic English. The paper also illustrates some instructional activities and the pedagogical relevance of the findings. (C) 2009 Elsevier Ltd. All rights reserved.|Phrasal verbs; Corpus analysis; EU documents; Course and materials design; English for Specific Purposes|LEARNERS|Education \& Educational Research; Linguistics|9|1|11
Automatic generation of textual summaries from neonatal intensive care data|2009|Effective presentation of data for decision support is a major issue when large volumes of data are generated as happens in the Intensive Care Unit (ICU). Although the most common approach is to present the data graphically, it has been shown that textual summarisation can lead to improved decision making. As part of the BabyTalk project, we present a prototype, called BT-45, which generates textual summaries of about 45 minutes of continuous physiological signals and discrete events (e.g.: equipment settings and drug administration). Its architecture brings together techniques from the different areas of signal processing, medical reasoning, knowledge engineering, and natural language generation. A clinical off-ward experiment in a Neonatal ICU (NICU) showed that human expert textual descriptions of NICU data lead to better decision making than classical graphical visualisation, whereas texts generated by BT-45 lead to similar quality decision-making as visualisations. Textual analysis showed that BT-45 texts were inferior to human expert texts in a number of ways, including not reporting temporal information as well and not producing good narratives. Despite these deficiencies, our work shows that it is possible for computer systems to generate effective textual Summaries of complex continuous and discrete temporal clinical data. (c) 2008 Elsevier B.V. All rights reserved.|Natural language generation; Intelligent data analysis; Intensive care unit; Decision support systems|ORIENTED CLINICAL-DATA; TEMPORAL-ABSTRACTION; WEATHER FORECASTS; TIME; INFORMATION; INTELLIGENT; SYSTEM; EXPLORATION; MODELS|Computer Science, Artificial Intelligence|66|1|11
`On MSN with buff boys': Self- and other-identity claims in the context of small stories|2008|This is a study of self- and other-identity claims such as ascriptions, assessments and categorizations in the classroom interactional data of female adolescent students of a London comprehensive school. The study follows an identities-in-interaction approach and attends to the occurrence of identity claims in stories of recent mediated interactions (e.g. on MSN, by text) between tellers and male suitors, which I collectively call small stories. In a narrative-interactional analysis of such claims in two small stories, I postulate a distinction between taleworld and telling identity claims that allows me to show how the sequential context of the claims has implications for their interactional uptake. I specifically focus on the relational organization of the identity claims in contrastive pairs of positive and negative attributes and on their contribution to the stories' tellership rights and tellability. My main aim is to show how identity claims can be intimately linked with and discursively invoke solidified roles (cf. known, habitual) that hold above and beyond the local context. I argue that the three interactional features of iterativity, narrativity and stylization hold the key to uncovering the links between identity claims with solidified roles.|Identity claims; taleworld-telling; small stories; breaking news; solidified roles|EXTREME CASE FORMULATIONS|Linguistics|23|1|11
Meeting in the margins: Effects of the teacher-student relationship on revision processes of EFL college students taking a composition course|2008|Using a case study approach, we explored the role of the teacher-student relationship in how a teacher made written comments on students' writing and in how students responded to these comments in revision. The focal participants were one non-native teacher of English and two of the students enrolled in her six-week composition course in a Korean university. Data sources included formal, informal, and text-based interviews, class observations, and writing samples with teacher written comments. Data analysis focused oil the comments the teacher made on the students' drafts and on how and why the students did or did not use her written comments. Findings showed that one student who had built a trusting relationship with his teacher faithfully used tier written feedback in revision, thereby improving his drafts, whereas the other student who had difficulty trusting her did not respond to her feedback positively. Consequently, his drafts did not improve as much as those of other students. We argue that establishing a trusting relationship between teacher and students may be fundamental to the effective use of feedback in revision. Results encourage a re-envisionment of the cognitive process model of revision to add the role of the relationship between teacher and student. (c) 2007 Elsevier Inc. All rights reserved.|teacher-student relationship; multiple draft approach; teacher written feedback; revision|STRATEGIES|Linguistics|14|0|11
Who tells which story and why? Micro and macro contexts in narrative|2008|This article focuses on the inter-relations between storytelling and micro and macro contexts. It explores how narrative activity is shaped by and shapes in unique ways the local context of interaction in a community of practice, an Italian American card-playing club, but also illustrates how the storytelling events that take place within this local community relate to wider social processes. The analysis centers on a number of topically linked narratives to argue that these texts have a variety of functions linked to the roles and relationships negotiated by individuals within the club and to the construction of a collective identity for the community. However, the narrative activities that occur within the club also articulate aspects of the wider social context. It is, argued that, in the case analyzed here, local meaning-making activities connect with macro social processes through the negotiation, within the constraints of local practices, of the position and roles of the ethnic group in the wider social space. In this sense, narrative activity can be seen as one of the many symbolic practices (Bourdieu 2002 {[}1977]) in which social groups engage to carry out struggles for legitimation and recognition in order to accumulate symbolic capital and greater social power.|narrative; identity; Italian Americans; stories; storytelling; migration|COMMUNITY|Communication; Linguistics; Language \& Linguistics|30|0|11
The consequences of talking to strangers: Evolutionary corollaries of socio-cultural influences on linguistic form|2007|We explore the proposal that the linguistic forms and structures employed by our earliest language-using ancestors might have been significantly different from those observed in the languages we are most familiar with today, not because of a biological difference between them and us, but because the communicative context in which they operated was fundamentally different from that of most modern humans. Languages that are used predominantly for esoteric (intra-group) communication tend to have features that are semantically and grammatically `complex', while those used also (or even exclusively) for exoteric (inter-group) communication become `simplified' towards rule-based regularity and semantic transparency. Drawing on a range of contemporary data, we propose a psycholinguistic explanation for why esotericity would promote such complexity, and argue that this is the natural default setting for human language. This being so, it should be taken into account when modelling the evolution of language, for some of the features that are normally viewed as fundamental - including the notion of fully developed underlying rule-based systematicity - may, in fact, be cultural add-ons. (c) 2005 Elsevier B.V. All rights reserved.|complexity; formulaic language; language evolution; literacy; esoteric; language processing|LANGUAGE; FACULTY|Linguistics; Language \& Linguistics|64|2|11
Analyzing and enacting academic criticism: The case of an L2 graduate learner of academic writing|2006|Academic criticism is defined in this paper as a statement which reflects a discrepancy between the stance of a researcher/author, on the one hand, and that of another researcher or the discourse community as a whole, on the other (Salager-Meyer \& Alcaraz Ariza, 2003). Despite researchers' awareness of the potential difficulty academic criticism poses for many L2 student writers, very few studies have explored learners' analysis of academic criticism in their reading, their enactment of it in their writing, or the factors influencing their analysis and enactment of this defining feature of academic writing. To address these issues, I analyzed the reading and writing tasks of an L2 graduate student in an English academic writing class. My analysis of the data indicates that, when analyzing discipline-specific samples of research articles, the learner noticed the irregular presence of criticism in his field, highlighted indirect criticism as a discipline-specific practice, and analyzed the linguistic formulations of academic criticism. In his writing, he recontextualized the indirect criticism practices he previously noticed, but, interestingly, also built direct criticisms into his texts. The learner's learning profile points to his rhetorical awareness, disciplinary engagement, and the instructional context as among the strong influences on his engagement with academic criticism. The analysis of the data suggests the need for a more nuanced view of the influences of national culture on students' academic literacy learning in general and their engagement with academic criticism in particular. (c) 2006 Elsevier Inc. All rights reserved.|academic criticism; academic writing; disciplinary culture; rhetorical awareness; learner characteristics|CULTURE|Linguistics|1|1|11
Characteristic functional networks in high- versus low-proficiency second language speakers detected also during native language processing: An explorative EEG coherence study in 6 frequency bands|2005|An EEG coherence study was performed with a twofold objective: first, to scrutinize the theoretical concept of ``cortical efficiency{''} in connection with second language (L2) acquisition and, second, to detect cooperations between cortical areas in specific frequency bands indicative for highly proficient L2 processing. Two groups differing only in their level of L2 proficiency were contrasted during presentation of natural language videos in English (L2) and German (native language, L1), with explorative coherence analysis in 6 frequency bands (0.5-31.5 Hz). The coherence brain maps revealed more pronounced and widespread increases in coherences in the alpha 1-band (8-10 Hz) in low-proficiency than in the high-proficiency L2 speakers. Surprisingly, this difference was obtained also during L1 processing and corroborated for both languages by multivariate permutation tests. These tests revealed additional differences between the low- and the high-proficiency group also for coherences within the beta 1- (13-18 Hz) and the beta 2-band (18.5-31.5 Hz), again during L2 and L1 processing. Since the same group differences were observed during L1 and L2 processing, our high-proficiency group might have profited from a more generic advantage in language or text processing strategy. This strategic advantage was most evident at alpha 1 frequencies, possibly related to a specific way of processing internal mental states (top-down processing). (c) 2005 Elsevier B.V. All rights reserved.|cortical efficiency; second language learning; bilingualism; language training; proficiency; EEG coherence; cortical network|BILINGUAL BRAIN; MEMORY PERFORMANCE; NEURAL EFFICIENCY; PARIETAL CORTEX; WORD GENERATION; VERBAL FLUENCY; BASAL GANGLIA; SPEECH; ALPHA; INTELLIGENCE|Computer Science, Artificial Intelligence; Neurosciences; Neuroimaging|22|2|11
Why promotion strategies based on market basket analysis do not work|2005|In text books as well as in the business literature, market basket analysis is often promoted as a means to obtain product associations to base a retailer's promotion strategy on. They argue that associated products with a high lift/interest can be promoted effectively by only discounting just one of the two products. Implicitly, they argue that market basket analysis automatically identifies complements. In this research, we show that this implicit assumption does not hold. Our empirical analysis reveals that market basket analysis identifies as many substitutes as complements. Therefore, market basket analysis cannot be used to build a promotion expert system for retailers. Instead, we advice to base the promotion strategy on cross-price elasticities. We conduct this research using scanner data of a large European retailer. Multivariate time-series techniques are used to identify both short-run as well as long-run (persistent) effects of promotions. (c) 2005 Elsevier Ltd. All rights reserved.|market basket analysis; cross-price elasticities; promotion strategy; multivariate time-series techniques; retailing|PRICE PROMOTIONS; ASSOCIATION RULES; DEMAND; SALES; DECISIONS; VARIETY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|10|0|11
Automatic discovery of similarity relationships through Web mining|2003|This work demonstrates how the World Wide Web can be mined in a fully automated manner for discovering the semantic similarity relationships among the concepts surfaced during an electronic brainstorming session, and thus improving the accuracy of automated clustering meeting messages. Our novel Context Sensitive Similarity Discovery (CSSD) method takes advantage of the meeting context when selecting a subset of Web pages for data mining, and then conducts regular concept co-occurrence analysis within that subset. Our results have implications on reducing information overload in applications of text technologies such as email filtering, document retrieval, text summarization, and knowledge management. (C) 2002 Elsevier Science B.V. All rights reserved.|data mining; context sensitive similarity discovery; empirical study; group decision support systems; Internet; machine learning; organizational concept space; text clustering; Web mining|SELF-ORGANIZING APPROACH; ELECTRONIC MEETINGS; COOCCURRENCE; RETRIEVAL; SYSTEMS; COMMUNICATION; CONSTRUCTION; SEARCH|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|39|1|11
L1 use in the L2 composing process: An exploratory study of 16 Chinese EFL writers|2002|This paper reports a study on how ESL/EFL writers use their L1 (first language) when composing in their L2 (second language) and how such L1 use is affected by L2 proficiency and writing tasks. Sixteen Chinese EFL learners were asked to compose aloud on two tasks, narration and argumentation. Analyses of their think-aloud protocols revealed that these student writers had both their L1 and L2 at their disposal when composing in their L2. They were more likely to rely on L1 when they were managing their writing processes, generating and organizing ideas, but more likely to rely on L2 when undertaking task-examining and text-generating activities. Additionally, more L1 use was found in the narrative writing task than in the argumentative writing. Finally, the think-aloud protocols reflected that L1 use decreased with the writer's L2 development, but the extent of the decline of L1 use in individual activities varied. Based on these findings, an L2 composing process model is proposed. (C) 2002 Elsevier Science Inc. All rights reserved.|Hayes-Flower model; think-aloud protocol; L2 composing process model|ESL STUDENTS; LANGUAGE; STRATEGIES; PROFICIENCY|Linguistics|70|0|11
Affect analysis of text using fuzzy semantic typing|2001|We propose a novel, convenient fusion of natural language processing and fuzzy logic techniques for analyzing the affect content in free text. Our main goals are fast analysis and visualization of affect content for decision making. The main linguistic resource for fuzzy semantic typing is the fuzzy-affect lexicon, from which other important resources-the fuzzy thesaurus and affect category groups-are generated. Free text is tagged with affect categories from the lexicon and the affect categories' centralities and intensities are combined using techniques from fuzzy logic to produce affect sets-fuzzy sets representing the affect quality of a document. We show different aspects of affect analysis using news content and movie reviews. Our experiments show a good correspondence between affect sets and human judgments of affect content. We ascribe this to the representation of ambiguity in our fuzzy affect lexicon and the ability of fuzzy logic to deal successfully with the ambiguity of words in a natural language. Planned extensions of the system include personalized profiles for Web-based content dissemination, fuzzy retrieval, clustering, and classification.|computing with words; fuzzy logic; knowledge engineering; text mining; World Wide Web|SIMILARITY|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic|107|1|11
Computer-supported content analysis - Trends, tools, and techniques|1996|This article reviews recent innovations in software for computer-supported content analysis, focusing on software designed to support quantitative analyses of texts and images. It also reviews recent developments in content analysis theory, recent research on the effectiveness of various coding protocols, and the proliferation of online databases.|content analysis; coding protocols; artificial intelligence; linguistics; mental maps|NATURAL-LANGUAGE; TEXTUAL ANALYSIS; EVENT DATA; CATEGORIZATION; RETRIEVAL; CULTURE|Computer Science, Interdisciplinary Applications; Information Science \& Library Science; Social Sciences, Interdisciplinary|18|1|11
A semi-automated approach for generating natural language requirements documents based on business process models|2018|Context: The analysis of requirements for business-related software systems is often supported by using business process models. However, the final requirements are typically still specified in natural language. This means that the knowledge captured in process models must be consistently transferred to the specified requirements. Possible inconsistencies between process models and requirements represent a serious threat for the successful development of the software system and may require the repetition of process analysis activities. Objective: The objective of this paper is to address the problem of inconsistency between process models and natural language requirements in the context of software development. Method: We define a semi-automated approach that consists of a process model-based procedure for capturing execution-related data in requirements models and an algorithm that takes these models as input for generating natural language requirements. We evaluated our approach in the context of a multiple case study with three organizations and a total of 13 software development projects. Results: We found that our approach can successfully generate well-readable requirements, which do not only positively contribute to consistency, but also to the completeness and maintainability of requirements. The practical use of our approach to identify a suitable subcontractor on the market in 11 of the 13 projects further highlights the practical value of our approach. Conclusion: Our approach provides a structured way to obtain high-quality requirements documents from process models and to maintain textual and visual representations of requirements in a consistent way. (c) 2017 Elsevier B.V. All rights reserved.|Requirements elicitation; Business process model; Natural language generation|REPRESENTATION; INFORMATION; SIZE|Computer Science, Information Systems; Computer Science, Software Engineering|0|10|10
Technology-function matrix based network analysis of cloud computing|2017|This study aims to employ technology-function based patent analysis to identify the important technologies of cloud computing. This study exploits the Stanford parser and association rule to extract and separate the information concerning technologies and functions from patent text. Based on the results of the technology-function matrix, this study employs technology network analysis to investigate technology change. Moreover, this study proposes a technology-function matrix analysis diagram (TFMAD) and applies the technique for order preference by similarity to ideal solution to identify the most important technologies of cloud computing. Among the three classes of cloud computing, infrastructure as a service has the largest number of patents and the connections between patents are close, but the platform as a service has the highest patent growth rate. Based on the analysis of TFMAD, this study shows that technological developments related to computing device and virtual machines are of particular importance to the cloud computing industry.|Cloud computing; Ontology; Technology-function matrix; Stanford parser; Association rule; Network analysis; TOPSIS; TFMAD|INTELLIGENCE SYSTEM; CLASSIFICATION; ONTOLOGY; PATENTS; SCIENCE; TRENDS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|10|10
Spreading semantic information by Word Sense Disambiguation|2017|This paper presents an unsupervised approach to solve semantic ambiguity based on the integration of the Personalized PageRank algorithm with word-sense frequency information. Natural Language tasks such as Machine Translation or Recommender Systems are likely to be enriched by our approach, which includes semantic information that obtains the appropriate word-sense via support from two sources: a multidimensional network that includes a set of different resources (i.e. WordNet, WordNet Domains, WordNet Affect, SUMO and Semantic Classes); and the information provided by word-sense frequencies and word-sense collocation from the SemCor Corpus. Our series of results were analyzed and compared against the results of several renowned studies using SensEval-2, SensEval-3 and SemEval-2013 datasets. After conducting several experiments, our procedure produced the best results in the unsupervised procedure category taking SensEval campaigns rankings as reference. (C) 2017 Elsevier B.V. All rights reserved.|Natural language processing; Graph-based; Knowledge-based; Word Sense Disambiguation; Pagerank|OF-THE-ART; KNOWLEDGE; CENTRALITY; FRAMEWORK; ALGORITHM; CONTEXT; ENGLISH|Computer Science, Artificial Intelligence|0|10|10
A multidimensional analysis of metadiscourse markers across spoken registers|2017|This study explores co-occurrence patterns and register variation of metadiscourse markers in spoken language. The few metadiscourse studies in spoken language have concentrated on specific metadiscourse markers or registers. This article conducts a more comprehensive analysis of metadiscourse in spoken discourse. Drawing on a modified reflexive model of metadiscourse, the study uses multidimensional analysis and a corpus of 126 spoken texts to extract spoken metadiscourse dimensions and investigate metadiscourse variation across nondiscussion broadcasts, discussion broadcasts, scripted speeches, unscripted speeches, public conversations and casual conversations. Three spoken metadiscourse dimensions emerged from a factor analysis and were labelled ``two-way communication{''}, ``united organization{''} and ``discourse presentation{''}. Quantitative and qualitative analyses of these dimensions revealed clear register variation, of metadiscourse across spoken registers. Dialogues more frequently than monologues and institutional discourse more frequently than mundane discourse adopt metadiscourse markers to emphasize interaction, seek cooperation and present discourse. The study contributes not only to a fuller understanding of metadiscourse in spoken language but also to computer-assisted research on metadiscourse. (C) 2017 Elsevier B.V. All rights reserved.|Metadiscourse marker; Spoken register; Multidimensional analysis; Spoken metadiscourse dimension; Register variation|DISCOURSE; CONVERSATION; WRITTEN; TALK|Linguistics; Language \& Linguistics|0|10|10
Understanding university students' peer feedback practices in EFL writing: Insights from a case study|2017|While research on peer feedback in the L2 writing classroom has proliferated over the past three decades, only limited attention has been paid to how students respond to their peers' writing in specific contexts and why they respond in the ways they do. As a result, much remains to be known about how individual differences and contextual influences shape L2 students' peer feedback practices. To bridge the research gap, this case study examines two Chinese EFL university students' peer feedback practices and the factors influencing their feedback practices. Analyses of multiple sources of data including interviews, video recordings of peer feedback sessions, stimulated recalls, and texts reveal that the students took markedly different approaches when responding to their peers' writing. The findings also indicate that their peer feedback practices were situated in their own distinct sociocultural context and mediated by a myriad of factors including beliefs and values, motives and goals, secondary school learning and feedback experience, teacher feedback practices, feedback training, feedback group dynamics, as well as learning and assessment culture.|Peer feedback; L2 writing; Sociocultural context; Assessment culture|ACTIVITY THEORY PERSPECTIVE; RESPONSE GROUPS; L2 WRITERS; TEACHER; 2ND-LANGUAGE; PARTICIPATION; STANCES; QUALITY|Education \& Educational Research; Linguistics|0|10|10
Counter-Discourse Activism on Social Media: The Case of Challenging ``Poverty Porn{''} Television|2017|In this paper we investigate how online counter-discourse is designed, deployed and orchestrated by activists to challenge dominant narratives around socio-political issues. We focus on activism related to the UK broadcast media's negative portrayal of welfare benefit claimants; portrayals characterised as ``poverty porn{''} by critics. Using critical discourse analysis, we explore two activist campaigns countering the TV programme Benefits Street. Through content analysis of social media, associated traditional media texts, and interviews with activists, our analysis highlights the way activists leverage the specific technological affordances of different social media and other online platforms in order to manage and configure counter-discourse activities. We reveal how activists use different platforms to carefully control and contest discursive spaces, and the ways in which they utilise both online and offline activities in combination with new and broadcast media to build an audience for their work. We discuss the challenges associated with measuring the success of counter-discourse, and how activists rely on combinations of social media analytics and anecdotal feedback in order to ascertain that their campaigns are successful. We also discuss the often hidden power-relationships in such campaigns, especially where there is ambiguity regarding the grassroots legitimacy of activism, and where effort is placed into controlling and owning the propagation of counter-discourse. We conclude by highlighting a number of areas for further work around the blurred distinctions between corporate advocacy, digilantism and grassroots activism.|Social media activism; Counter-discourse; Grassroots activism; Critical discourse analysis; socio-political issues|FACEBOOK; PROTEST; MOVEMENTS; YOUTUBE; MOBILIZATION; COMMUNITIES; INTERNET; ELECTION; POLITICS; TWITTER|Computer Science, Interdisciplinary Applications|0|5|10
Patterns of authors contribution in scientific manuscripts|2017|Science is becoming increasingly more interdisciplinary, giving rise to more diversity in the areas of expertise, In such a complex environment, the participation of authors became more specialized, hampering the task of evaluating authors according to their contributions. While some metrics were adapted to account for the order (or rank) of authors in a paper, many journals are now requiring a description of their specific roles in the publication. Surprisingly, the investigation of the relationships between credited contributions and author's rank has been limited to a few studies. Here we analyzed such a kind of data and show, quantitatively, that the regularity in the authorship contributions decreases with the number of authors in a paper. Furthermore, we found that the rank of authors and their roles in papers follow three general patterns according to the nature of their contributions: (i) the total contribution increases with author's rank; (ii) the total contribution decreases with author's rank; and (iii) the total contribution is symmetric, with most of contributions being performed by first and last authors. This was accomplished by collecting and analyzing the data retrieved from PLoS One and by devising a measurement of the effective number of authors in a paper. The analysis of such patterns confirms that some aspects of the author ranking are in accordance with the expected convention, such as the first and last authors being more likely to contribute more diversely in a scientific work. Conversely, such analysis also revealed that authors in the intermediary positions of the rank contribute more in specific roles, such as collecting data. This indicates that the an unbiased evaluation of researchers must take into account the distinct types of scientific contributions. (C) 2017 Elsevier Ltd. All rights reserved.|Authorship contributions; Science of science; Entropy; Text mining|CITATION IMPACT INDICATORS; H-INDEX; COMPLEX NETWORKS; KNOWLEDGE; SCIENCE; VISUALIZATION; TEAMS; NEED|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|6|10
Evaluating electronic health record data sources and algorithmic approaches to identify hypertensive individuals|2017|Objective: Phenotyping algorithms applied to electronic health record (EHR) data enable investigators to identify large cohorts for clinical and genomic research. Algorithm development is often iterative, depends on fallible investigator intuition, and is time-and labor-intensive. We developed and evaluated 4 types of phenotyping algorithms and categories of EHR information to identify hypertensive individuals and controls and provide a portable module for implementation at other sites. Materials and Methods: We reviewed the EHRs of 631 individuals followed at Vanderbilt for hypertension status. We developed features and phenotyping algorithms of increasing complexity. Input categories included International Classification of Diseases, Ninth Revision (ICD9) codes, medications, vital signs, narrative-text search results, and UnifiedMedical Language System (UMLS) concepts extracted using natural language processing (NLP). We developed a module and tested portability by replicating 10 of the best-performing algorithms at the Marshfield Clinic. Results: Random forests using billing codes, medications, vitals, and concepts had the best performance with a median area under the receiver operator characteristic curve (AUC) of 0.976. Normalized sums of all 4 categories also performed well (0.959 AUC). The best non-NLP algorithm combined normalized ICD9 codes, medications, and blood pressure readings with a median AUC of 0.948. Blood pressure cutoffs or ICD9 code counts alone had AUCs of 0.854 and 0.908, respectively. Marshfield Clinic results were similar. Conclusion: This work shows that billing codes or blood pressure readings alone yield good hypertension classification performance. However, even simple combinations of input categories improve performance. The most complex algorithms classified hypertension with excellent recall and precision.|phenotyping algorithms; machine learning; random forests; hypertension; natural language processing; electronic health records|PHENOME-WIDE ASSOCIATION; PERSONALIZED MEDICINE; BLOOD-PRESSURE; CLINICAL TEXT; VALIDATION; EXTRACTION; RESOURCE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|5|4|10
Investigating the use of appropriation in the writing of a child with autism: A case study|2017|This case study investigated how a 10 year old child with ASD (Autism Spectrum Disorder), Kameron (pseudonym), utilized appropriation as a writing strategy in the context of group therapy. Using the same questions as Lensmire and Beals (1994) in their study of a typically developing third-grader, written products were collected over the course of one semester and analyzed, along with video, audio, and participant observation data, to consider the following questions: 1) Where did the material come from? 2) What was taken? and 3) How was it used? Analysis of the process of Kameron's writing revealed utilization of appropriation as a strategy for 2 of the 4 written products. Material was appropriated from both adult authored texts performed via read alouds and from topics and values located in the local peer culture. Kameron's appropriation of shared experiences provided substance to initiate and engage in a shared peer culture. Increased engagement in the writing process and fewer off task behaviors were noted when appropriations were evidenced compared to the writing pieces where no appropriation occurred. The results demonstrate the powerful implications of both a process oriented and strength-based approach to writing and greater social awareness than expected in children with ASD. (C) 2016 Elsevier Inc. All rights reserved.|Autism spectrum disorders; Literacy; Meaning-based literacy; Writing|LEARNING-DISABILITIES; QUALITATIVE RESEARCH; SOCIAL CONSTRUCTION; COMMUNICATION; LANGUAGE; IMPAIRMENTS; INSTRUCTION; REPETITION; SPEECH|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|0|5|10
Integrating corpus linguistics into online language teacher education programs|2017|This study reports on a qualitative study which explored 32 pre-service teachers' evaluations of two online seven-week introductory courses in corpus linguistics (CL). Data were gathered through questionnaires, participants' written journals, post-course semi-structured email interviews, and discussion forum entries. The qualitative analysis of data revealed that for successful integration of CL into online language teacher education programs, several procedures should be employed. These include: providing the necessary technological infrastructure in educational settings; incorporating CL instruction in initial stages of language teacher education degree programs and extending it throughout the whole curriculum; focusing more on the practical aspects of CL with much emphasis placed on the necessary pedagogical knowledge and skills for successful exploitation of CL; introducing user-friendly tools and encouraging indirect use of corpora in the absence of necessary technological facilities; providing adequate and effective instructional materials (text-based reading materials, screen capture videos, hands-on activities, etc.) along with sufficient instructor support; and encouraging the participants to reflect on the approach critically. The findings may promise implications for language teacher educators to effectively introduce CL to student teachers in virtual learning environments.|ALL; teacher education; corpus linguistics; corpus-based tools|INSTRUCTION; COMPUTER; ENOUGH|Education \& Educational Research; Linguistics; Language \& Linguistics|1|2|10
A model of language learning with semantics and meaning-preserving corrections|2017|We present a computational model that takes into account semantics for language learning and allows us to model meaning-preserving corrections. The model is constructed with a learner and a teacher who interact in a sequence of shared situations by producing utterances intended to denote a unique object in each situation. We test our model with limited sublanguages of 10 natural languages exhibiting a variety of linguistic phenomena. The results show that learning to a high level of performance occurs after a reasonable number of interactions. Comparing the effect of a teacher who does no correction to that of a teacher who corrects whenever possible, we show that under certain conditions corrections can accelerate the rate of learning. We also define and analyze a simplified model of a probabilistic process of collecting corrections to help understand the possibilities and limitations of corrections in our setting. (C) 2016 Elsevier B.V. All rights reserved.|Semantics; Corrections; Language learning; Grammar learning|COMPUTATIONAL MODEL; NEGATIVE EVIDENCE; ACQUISITION; INFORMATION; EMERGENCE; CONTEXT; WORDS|Computer Science, Artificial Intelligence|0|1|10
The relationship between lexical sophistication and independent and source-based writing|2016|Lexical sophistication is an important component of writing proficiency. New lexical indices related to range, n-gram frequency, psycholinguistic word information, academic language, polysemy, and hypernymy have yielded new insights into the construct of lexical sophistication and its relationship with second language (L2) acquisition and writing. For example, recent studies have suggested that range and bigram indices are stronger indicators of lexical sophistication than frequency in the context of L2 acquisition and L2 writing and speaking proficiency. This study explores the relationship between these newly developed indices of lexical sophistication and holistic scores of writing proficiency in both independent and source-based writing tasks. The results suggest that range and bigrams are important predictors of essay quality in independent tasks, but that lexical sophistication indices are not strong predictors of essay quality in source-based tasks. The results also indicate that responses to source-based tasks tend to include more sophisticated lexical items than responses to independent tasks. Implications for second language writing assessment and pedagogy are discussed. (C) 2016 Elsevier Inc. All rights reserved.|Lexical sophistication; Independent writing tasks; Source-based writing tasks; Writing assessment; N-grams; Natural language processing|ENGLISH; PROFICIENCY; FREQUENCY; STUDENTS; LANGUAGE; RATINGS; ESSAYS; INSTRUCTION; VARIABILITY; ACQUISITION|Linguistics|2|1|10
PheKB: a catalog and workflow for creating electronic phenotype algorithms for transportability|2016|Objective Health care generated data have become an important source for clinical and genomic research. Often, investigators create and iteratively refine phenotype algorithms to achieve high positive predictive values (PPVs) or sensitivity, thereby identifying valid cases and controls. These algorithms achieve the greatest utility when validated and shared by multiple health care systems. Materials and Methods We report the current status and impact of the Phenotype KnowledgeBase (PheKB, http://phekb.org), an online environment supporting the workflow of building, sharing, and validating electronic phenotype algorithms. We analyze the most frequent components used in algorithms and their performance at authoring institutions and secondary implementation sites. Results As of June 2015, PheKB contained 30 finalized phenotype algorithms and 62 algorithms in development spanning a range of traits and diseases. Phenotypes have had over 3500 unique views in a 6-month period and have been reused by other institutions. International Classification of Disease codes were the most frequently used component, followed by medications and natural language processing. Among algorithms with published performance data, the median PPV was nearly identical when evaluated at the authoring institutions (n = 44; case 96.0\%, control 100\%) compared to implementation sites (n = 40; case 97.5\%, control 100\%). Discussion These results demonstrate that a broad range of algorithms to mine electronic health record data from different health systems can be developed with high PPV, and algorithms developed at one site are generally transportable to others. Conclusion By providing a central repository, PheKB enables improved development, transportability, and validity of algorithms for research-grade phenotypes using health care generated data.|electronic health records; electronic phenotyping; natural language processing; genomic research; clinical research|HEALTH RECORDS; MEDICAL-RECORDS; EMERGE NETWORK; PHENOME-WIDE; VALIDATION; SYSTEMS; CARE; DATABASE; SURVEILLANCE; INFECTION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|17|2|10
Quantifying Semantic Linguistic Maturity in Children|2016|We propose a method to quantify semantic linguistic maturity (SELMA) based on a high dimensional semantic representation of words created from the co-occurrence of words in a large text corpus. The method was applied to oral narratives from 108 children aged 4;0-12;10. By comparing the SELMA measure with maturity ratings made by human raters we found that SELMA predicted the rating of semantic maturity made by human raters over and above the prediction made using a child's age and number of words produced. We conclude that the semantic content of narratives changes in a predictable pattern with children's age and argue that SELMA is a measure quantifying semantic linguistic maturity. The study opens up the possibility of using quantitative measures for studying the development of semantic representation in children's narratives, and emphasizes the importance of word co-occurrences for understanding the development of meaning.|Semantic representation; Semantic development; Narratives; Child language; Semantic linguistic maturity|NARRATIVE SKILLS; LONGITUDINAL ANALYSIS; WRITTEN NARRATIVES; SWEDISH CHILDREN; ACQUISITION; IMPAIRMENT; COHESION; TEXT; REPRESENTATIONS; ADOLESCENTS|Linguistics; Psychology, Experimental|0|0|10
Moderating readers and reading online|2016|Despite the proliferation of online forums for the discussion of literary texts, very little has been written to date on the management of these spaces and how this helps frame the kinds of discussion and interpretative work that take place. This article draws on a series of interviews with moderators of online book-related sites, alongside close analysis of online interactions between moderators and users to consider issues of authority, hierarchy, power and control, asking how these act to structure or facilitate acts of interpretation taking place online. We begin by outlining the moderator's role before conducting a brief review of existing scholarship on offline reading groups and online communities, to identify how social infrastructures are established and negotiated. The main body of the article draws upon interviews with moderators of two online literary forums - The Republic of Pemberley and The Guardian's online Reading Group - to explore the ways in which each of the respective moderators frames his or her role. This is accompanied by an in-depth exploration of how the forms of interpretation we find on the two sites are shaped and directed by the moderators. The article concludes by reflecting upon some of the issues raised by this study and its methodology, particularly with regards to digital dualism and the blurring of the boundaries between the public and the private in online spaces.|Moderators; interpretation; interpretive communities; social reading; reading formations; digital dualism; internet studies|AUTHORITY|Linguistics; Language \& Linguistics|4|4|10
Languaging in story rewriting tasks by Chinese EFL students|2016|The present study examined the effects of languaging by asking four pairs of Chinese university English as a foreign language (EFL) students to rewrite a story from a different perspective through three stages (composing - comparing - revising). Multiple sources of data were collected, including pair discussions, co-constructed writings, individual revised texts, and interviews. Data analysis found that languaging, as an important meditational tool, helped the participants to co-construct meaning and solve problems (e.g. comprehending the original text, structuring their ideas, finding proper expressions) in the process of writing. Languaging was also observed to have immediate, delayed, and ongoing effects on joint writing and individual revision. This study suggests that an opportunity to engage in languaging with the support of source readings and models can facilitate the generation of students' ideas and expressions necessary for writing and allow them to reflect on their language knowledge in the process of writing and revising, resulting in the improvement of their L2 writing performance.|Story rewriting task; EFL learner; languaging; models|PROFICIENCY; UNIVERSITY; LEARNERS; PATTERNS; WRITERS; FRENCH; L1|Linguistics; Language \& Linguistics|1|6|10
The effects of L2 proficiency differences in pairs on idea units in a collaborative text reconstruction task|2016|Collaborative text reconstruction tasks such as dictogloss have been suggested as effective second language (L2) learning tasks that promote meaningful interaction between learners and their awareness of L2 target grammatical structures. However, it should be noted that the effect of pair interaction on the final product may differ depending on co-participant characteristics and particularly on proficiency disparities between partners. To date, most studies conducted on the effect of the different L2 proficiency of learners on paired performance have focused on the ways in which language learners interact, and the quantity and quality of language-related episodes (LREs) produced (Kim \& McDonough, 2008; Leeser, 2004), often sidelining learners' actual task performance. This study thus aims to investigate the extent to which partner L2 proficiency levels affect tangible language performance, particularly in terms of content accuracy in a dictogloss task. Results show large gains in idea units reproduced between first and second stages of the dictogloss across texts. However, while low-level students paired with high-level partners benefited most, this group also had the largest variation across the board and, overall, proficiency pairing did not systematically affect improvement in idea units. Idea unit analyses indicated that students tended to perform better on idea units from earlier parts of the text, and that some types of idea units were more discriminatory than others.|Collaborative writing; dictogloss; idea units; pair work; proficiency differences|FREE-RECALL; INTERLOCUTOR PROFICIENCY; COMPREHENSION; LEARNERS; WORK; FAMILIARITY; PATTERNS; DIALOGUE; CONTEXTS; MODEL|Education \& Educational Research; Linguistics|1|1|10
Factors Influencing Spanish Instructors' In-Class Feedback Decisions|2016|While oral corrective feedback is a principal focus in second language acquisition research, most studies examine feedback once it has been provided. Investigating how instructors make in-class feedback decisions has not been thoroughly explored, despite the fact that classroom feedback occurs at the discretion of the individual language instructor and evidence from case studies that feedback provision varies greatly between instructors (recently reviewed in Lyster, Saito, \& Sato, 2013). This study investigates how 32 instructors make their moment-to-moment feedback decisions in response to learner errors during natural, university-level Spanish foreign language lessons. Each instructor had a 50-minute grammar-focused lesson videotaped and participated in a stimulated recall. Results reveal instructor in-class feedback decision making to be a systematic and ordered cognitive process: Instructors who reflect on learner errors report that contextual (e.g., error type), learner (e.g., perceived student ability), and instructor factors (e.g., research background) influenced their decision whether or not to provide feedback, as well what type(s) to provide, and when. Others report having automatized their feedback practices and not reflecting on learner errors. All instructors report that their individual characteristics, specifically their native language, teaching experience, and training in second language acquisition, mediate the corrective feedback they provide.|teacher cognition; oral corrective feedback; foreign language classrooms; stimulated recall; instructor characteristics|LANGUAGE ANALYTIC ABILITY; WORKING-MEMORY CAPACITY; CORRECTIVE FEEDBACK; MODIFIED OUTPUT; IMPLICIT FEEDBACK; L2 DEVELOPMENT; TEACHERS USE; LEARNERS; EXPLICIT; SLA|Education \& Educational Research; Linguistics|0|1|10
Are single and extended metaphors processed differently? A test of two Relevance-Theoretic accounts|2016|Carston (2010) proposes that metaphors can be processed via two different routes. In line with the standard Relevance-Theoretic account of loose use, single metaphors are interpreted by a local pragmatic process of meaning adjustment, resulting in the construction of an ad hoc concept. In extended metaphorical passages, by contrast, the reader switches to a second processing mode because the various semantic associates in the passage are mutually reinforcing, which makes the literal meaning highly activated relative to possible meaning adjustments. In the second processing mode the literal meaning of the whole passage is metarepresented and entertained as an `imaginary world' and the intended figurative implications are derived later in processing. The results of three experiments comparing the interpretation of the same target expressions across literal, single-metaphorical and extended-metaphorical contexts, using self-paced reading (Experiment 1), eye-tracking during natural reading (Experiment 2) and cued recall (Experiment 3), offered initial support to Carston's distinction between the processing of single and extended metaphors. We end with a comparison between extended metaphors and allegories, and make a call for further theoretical and experimental work to increase our understanding of the similarities and differences between the interpretation and processing of different figurative uses, single and extended. (C) 2016 Elsevier B.V. All rights reserved.|Loose use; Meaning adjustment; Literal interpretation; Priming; Metarepresentation; Processing modes|CONCEPTUAL METAPHORS; COMPREHENSION; LANGUAGE|Linguistics; Language \& Linguistics|2|2|10
When cinema borrows from stage: theatrical artifice through indexical explicitness in The Cook, the Thief, His Wife and Her Lover and Dogville|2016|Framed within the debate on the different nature of theatrical and filmic communication, the study considers two avant-garde films by Greenaway, The Cook, the Thief, His Wife and Her Lover, and von Trier, Dogville, as examples of texts that travel from one medium to another and show closeness to the theatre. This is revealed not solely through the artificiality and the enclosure of the setting and the mise-en-scene, but also at the level of the discourse understood as the ensemble of images, music, gestures, and dialogue. The two films exhibit an unnaturalness unusual in cinema, a medium in which the editing realises a seemingly realistic representation of characters and events. The discussion focuses on how such a sensation of artificial non-realism is achieved in the films. It is argued that it derives from the marked explicit relation between the various levels of communication in the two films, the verbal and the visual, as well as between the dialogue contributions by the different participants in the narrative, characters, and narrator. The construct adopted for the analysis is indexicality, which is interpreted in a broad sense and that, as is discussed, contributes to the ``monstrative{''} dimension of the films in terms of the explicitness of the communication.|Indexicality; monstration; explicitness; verbal-visual; deixis|VERBAL IRONY|Humanities, Multidisciplinary; Communication; Linguistics|0|5|10
Developing teachers' critical language awareness: A case study of guided participation|2015|We explore the role of CLA in teacher development through a high school history teacher's understanding of disciplinary literacy (DL), and his classroom's discourse practices in DL lessons. A Critical Language Awareness (CLA) focus highlights how linguistic practices shape and are shaped by social relations of power. Disciplinary literacy, in this particular case of history, focuses on particular linguistic practices, which are valued in the field and help to understand the discipline as an interpretive community. In this paper, we investigate how CLA can be an effective tool in teacher development. We do this by tracking qualitative changes in the language he produces, we provide linguistic evidence of how a teacher develops a critical language awareness stance, which is ultimately used in classroom teacher talk. Our focus in this paper includes both what changed and how it changed, while the first part of our analysis highlights the qualitative changes in the way he conceptualized the lesson, the second part of the analysis focuses on the types of activities designed showing how his changing understanding translated into particular pedagogical actions; while the last part of the analysis focuses on the teacher's reflection of the designing and using DL lessons. (C) 2015 Elsevier Inc. All rights reserved.|Critical language awareness; Disciplinary literacy: Design experiment; Systemic functional linguistics; Socio-cultural activity|CONTEMPORARY-HISTORY; TEXTS|Education \& Educational Research; Linguistics; Language \& Linguistics|0|1|10
An empirical evaluation of supervised learning approaches in assigning diagnosis codes to electronic medical records|2015|Background: Diagnosis codes are assigned to medical records in healthcare facilities by trained coders by reviewing all physician authored documents associated with a patient's visit. This is a necessary and complex task involving coders adhering to coding guidelines and coding all assignable codes. With the popularity of electronic medical records (EMRs), computational approaches to code assignment have been proposed in the recent years. However, most efforts have focused on single and often short clinical narratives, while realistic scenarios warrant full EMR level analysis for code assignment. Objective: We evaluate supervised learning approaches to automatically assign international classification of diseases (ninth revision) - clinical modification (ICD-9-CM) codes to EMRs by experimenting with a large realistic EMR dataset. The overall goal is to identify methods that offer superior performance in this task when considering such datasets. Methods: We use a dataset of 71,463 EMRs corresponding to in-patient visits with discharge date falling in a two year period (2011-2012) from the University of Kentucky (UKY) Medical Center. We curate a smaller subset of this dataset and also use a third gold standard dataset of radiology reports. We conduct experiments using different problem transformation approaches with feature and data selection components and employing suitable label calibration and ranking methods with novel features involving code co-occurrence frequencies and latent code associations. Results: Over all codes with at least 50 training examples we obtain a micro F-score of 0.48. On the set of codes that occur at least in 1\% of the two year dataset, we achieve a micro F-score of 0.54. For the smaller radiology report dataset, the classifier chaining approach yields best results. For the smaller subset of the UKY dataset, feature selection, data selection, and label calibration offer best performance. Conclusions: We show that datasets at different scale (size of the EMRs, number of distinct codes) and with different characteristics warrant different learning approaches. For shorter narratives pertaining to a particular medical subdomain (e.g., radiology, pathology), classifier chaining is ideal given the codes are highly related with each other. For realistic in-patient full EMRs, feature and data selection methods offer high performance for smaller datasets. However, for large EMR datasets, we observe that the binary relevance approach with learning-to-rank based code reranking offers the best performance. Regardless of the training dataset size, for general EMRs, label calibration to select the optimal number of labels is an indispensable final step. (C) 2015 Elsevier B.V. All rights reserved.|Multi-label text classification; Learning to rank; Label calibration; Diagnosis code assignment|CLASSIFICATION; SEMANTICS; LIBRARY|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|5|2|10
Automatically finding relevant citations for clinical guideline development|2015|Objective: Literature database search is a crucial step in the development of clinical practice guidelines and systematic reviews. In the age of information technology, the process of literature search is still conducted manually, therefore it is costly, slow and subject to human errors. In this research, we sought to improve the traditional search approach using innovative query expansion and citation ranking approaches. Methods: We developed a citation retrieval system composed of query expansion and citation ranking methods. The methods are unsupervised and easily integrated over the PubMed search engine. To validate the system, we developed a gold standard consisting of citations that were systematically searched and screened to support the development of cardiovascular clinical practice guidelines. The expansion and ranking methods were evaluated separately and compared with baseline approaches. Results: Compared with the baseline PubMed expansion, the query expansion algorithm improved recall (80.2\% vs. 51.5\%) with small loss on precision (0.4\% vs. 0.6\%). The algorithm could find all citations used to support a larger number of guideline recommendations than the baseline approach (64.5\% vs. 37.2\%, p < 0.001). In addition, the citation ranking approach performed better than PubMed's ``most recent{''} ranking (average precision +6.5\%, recall@k +21.1\%, p < 0.001), PubMed's rank by ``relevance{''} (average precision +6.1\%, recall@k +14.8\%, p < 0.001), and the machine learning classifier that identifies scientifically sound studies from MEDLINE citations (average precision +4.9\%, recall@k +4.2\%, p < 0.001). Conclusions: Our unsupervised query expansion and ranking techniques are more flexible and effective than PubMed's default search engine behavior and the machine learning classifier. Automated citation finding is promising to augment the traditional literature search. (C) 2015 Elsevier Inc. All rights reserved.|Information retrieval; PubMed; Practice guideline; Medical subject headings; Natural language processing|ASSOCIATION TASK-FORCE; PERMANENT ATRIAL-FIBRILLATION; AMERICAN-STROKE-ASSOCIATION; VENTRICULAR RATE CONTROL; 2013 ACCF/AHA GUIDELINE; CARDIOVASCULAR-ANGIOGRAPHY; INTERVENTIONAL-RADIOLOGY; INTRAVENOUS DILTIAZEM; THORACIC SURGEONS; VASCULAR-MEDICINE|Computer Science, Interdisciplinary Applications; Medical Informatics|0|1|10
Keeping up with the times: Revising and refreshing a rating scale|2015|In performance-based writing assessment, regular monitoring and modification of the rating scale is essential to ensure reliable test scores and valid score inferences. However, the development and modification of rating scales (particularly writing scales) is rarely discussed in language assessment literature. The few studies documenting the scale development process have derived the rating scale from analyzing one or two data sources: expert intuition, rater discussion, and/or real performance. This study reports on the review and revision of a rating scale for the writing section of a large-scale, advanced-level English language proficiency examination. Specifically, this study first identified from literature, the features of written text that tend to reliably distinguish between essays across levels of proficiency. Next, using corpus-based tools, 796 essays were analyzed for text features that predict writing proficiency levels. Lastly, rater discussions were analyzed to identify components of the existing scale that raters found helpful for assigning scores. Based on these findings, a new rating scale has been prepared. The results of this work demonstrate the benefits of triangulating information from writing research, rater discussions, and real performances in rating scale design. (C) 2015 Elsevier Inc. All rights reserved.|Rating scale design; Scale validation; Corpora; Discriminant function analysis|WRITING DEVELOPMENT; PROFICIENCY; FEATURES|Education \& Educational Research; Linguistics|3|1|10
The role of `that' in managing averrals and attributions in post-graduate academic legal texts|2015|This study examines how post-graduate law students use the node `that' in managing attributions and averrals in academic legal writing. Studies in this field have tended to concentrate on either averral or attribution, but less on how student writers formulate the two when writing in a discipline. Understanding the roles students take when dealing with both aspects provides an important insight into the epistemology of writing at this academic level. The results showed it was possible to identify the generic categories of attributions and their frequencies. In addition, it was possible to describe the constructions favoured by students when making averrals, along with the rhetorical functions such constructions achieved. These features revealed varying degrees of critical stance, depending on which generic external source was being reported, or which language construction was being used for the students' own propositions. The students' use of syntax also followed distinct patterns, depending on whether an attribution or averral was being made. Awareness of such behaviours should help students, and in particular graduates of non-Common Law legal systems, to better understand how to manage the reporting of facts and opinions when writing in English. (C) 2015 Elsevier Ltd. All rights reserved.|That clauses; Averral; Attribution; Legal English; Corpus analysis|RESEARCH ARTICLES; STUDENTS; CITATION; CORPUS; CONSTRUCTION; LANGUAGE; CULTURES; ARGUMENT; WRITERS; THESES|Linguistics|0|1|10
Words on the screen: broadening analyses of interactions among fanfiction writers and reviewers|2015|Young fanfiction writers use the Internet to build networks of reading, writing and editing - literacy practices that are highly valued in schools, universities and workplaces. While prior research shows that online spaces frame multiple kinds of participation as legitimate, much of this work focuses on the extensive contributions of exceptional young authors. In this paper, we foreground the contributions of fanfiction reviewers and focus on their interactions with writers, exploring their communicative literacy practices and hypothesising about how we can make their reading and writing more visible and more effectively consider their learning practices. To do so, we conducted a linguistic analysis of fanfiction review comments on two sites, FanFiction. net and Figment.com. While fanfiction readers provide writers with an authentic audience for their creative work, our findings indicate that the review comments that they leave generally do not offer specific feedback regarding the craft of writing. For this reason, we argue that teachers' expertise is still needed in the difficult task of developing young adults' composition, peer review and critique skills.|fanfiction; writing; audience; digital media; writing pedagogy; peer review|MOTIVATION; REVISION; FEEDBACK; READ; TEXT|Education \& Educational Research; Linguistics; Language \& Linguistics|3|1|10
L2 multiple-documents comprehension: Exploring the contributions of L1 reading ability and strategic processing|2015|There is much prior L2 research estimating the contributions of strategic processing and L1 reading ability to L2 reading comprehension. This line of inquiry has, however, been mainly followed in relation to single-text reading. While multiple-documents comprehension constitutes the bulk of what EFL/ESL students do in their current academic environments, L2 research investigating the contributions of these two variables to this type of comprehension in essentially lacking. Against this background, the present paper reports on a study examining the relative contributions of strategic processing and L1 reading ability to L2 single-text vs. multiple-texts comprehension. To this end, 114 EFL students took measures of L1 reading ability, L2 single-text and multiple-texts reading comprehension, as well as self-reported strategic processing. Data were analyzed using regression analyses. The results indicated that while L1 reading ability and strategic processing contributed significantly to L2 single-text reading, only strategic processing was shown to contribute to L2 multiple-texts reading. Strategic processing was also shown to account for a much larger proportion of variance in L2 multiple-texts comprehension than L2 single-text comprehension. (C) 2015 Elsevier Ltd. All rights reserved.|Multiple-documents comprehension; L1 reading ability; Strategic processing; L2 readers|LINGUISTIC INTERDEPENDENCE; PERSONAL EPISTEMOLOGY; LANGUAGE PROFICIENCY; EXPOSITORY TEXTS; PRIOR KNOWLEDGE; STUDENTS; INSTRUCTION; PERFORMANCE; HYPOTHESIS; THRESHOLD|Education \& Educational Research; Linguistics|1|1|10
Monitoring polysemy: Word space models as a tool for large-scale lexical semantic analysis|2015|This paper demonstrates how token-level Word Space Models (a distributional semantic technique that was originally developed in statistical natural language processing) can be developed into a heuristic tool to support lexicological and lexicographical analyses of large amounts of corpus data. The paper provides a non-technical introduction to the statistical methods and illustrates with a case study analysis of the Dutch polysemous noun `monitor' how token-level Word Space Models in combination with visualisation techniques allow human analysts to identify semantic patterns in an unstructured set of attestations. Additionally, we show how the interactive features of the visualisation make it possible to explore the effect of different contextual factors on the distributional model. (C) 2014 Elsevier B.V. All rights reserved.|Distributional models; Lexical semantics; Statistical analysis; Visual analytics|COOCCURRENCE; INDUCTION; SENSES|Linguistics; Language \& Linguistics|5|0|10
Research on the mechanism for phonating stressed English syllables based on DIVA model|2015|Speech generation and acquisition is a complex cognitive process involving many brain regions. Simulating this process requires establishment of a proper neural network model according to the interaction between sensory organs and motor areas in the brain that occurs during phonation. Directions Into Velocities of Articulators (DIVA) is a neural network model of this type. In the process of speech generation and acquisition, this model can be used to control and simulate the trajectory of articulator and synthesize the desired speech. However, DIVA is flawed in terms of simulating natural language, because it cannot simulate the phonation of English stresses. A DIVA-based neural network computing model for analyzing stresses on English word's is proposed. The TD-POSAL (time-domain pitch synchronous overlap add) algorithm is used to tune DIVA's speech and rhythm parameters in order to simulate the generation and acquisition of stresses on English words. Simulation showed that the improved DIVA model can represent the features of stressed syllables. The model's pitch and duration compensation effect is tested in the increased pitch perturbation experiment. The experiment demonstrates that the improved DIVA model can correctly simulate the generation and acquisition of stresses on English words. (C) 2014 Elsevier B.V. All rights reserved.|DIVA model; Syllable stress; TD-POSAL; Disturbance compensation|SPEECH ACQUISITION; NEURAL THEORY; SCALE|Computer Science, Artificial Intelligence|2|1|10
The meanings of Hebrew: defining bilingual education in a dual-language charter school|2015|Using a discourse analytic framework that draws on theories of language ideologies, this paper analyzes the semiotics of a heritage language as it moves from the context of parochial education to the realm of public schooling. Specifically, it examines how Hebrew undergoes resemioticization when a Hebrew language charter school in the District of Columbia is established. I examine what Hebrew signifies through an analysis of two public texts: the Sela Public Charter School application and a community online forum. I identify how this new educational initiative redefines Hebrew teaching as a novel form of bilingual education that eschews discourses of identity, rights, and heritage. Next I show that the online forum participants attach diverse and contradictory meanings to Hebrew. This analysis examines the semiotic processes at work when a heritage language is untethered from its traditional communal context and transformed into a public language, and the ways in which bilingualism and bilingual education are reframed and contested in the process.|online forums; semiotics; charter schools; language ideologies; Hebrew|IDEOLOGIES; SEMIOTICS; POLICY|Education \& Educational Research; Linguistics; Language \& Linguistics|4|0|10
Completeness, accuracy, and computability of National Quality Forum-specified eMeasures|2015|Objective To analyze the completeness, computability, and accuracy of specifications for five National Quality Forum-specified (NQF) eMeasures spanning ambulatory, post-discharge, and emergency care within a comprehensive, integrated electronic health record (EHR) environment. Materials and methods To evaluate completeness, we assessed eMeasure logic, data elements, and value sets. To evaluate computability, we assessed the translation of eMeasure algorithms to programmable logic constructs and the availability of EHR data elements to implement specified data criteria, using a de-identified clinical data set from Kaiser Permanente Northwest. To assess accuracy, we compared eMeasure results with those obtained independently by existing audited chart abstraction methods used for external and internal reporting. Results One measure specification was incomplete; missing applicable LOINC codes rendered it non-computable. For three of four computable measures, data availability issues occurred; the literal specification guidance for a data element differed from the physical implementation of the data element in the EHR. In two cases, cross-referencing specified data elements to EHR equivalents allowed variably accurate measure computation. Substantial data availability issues occurred for one of the four computable measures, producing highly inaccurate results. Discussion Existing clinical workflows, documentation, and coding in the EHR were significant barriers to implementing eMeasures as specified. Implementation requires redesigning business or clinical practices and, for one measure, systemic EHR modifications, including clinical text search capabilities. Conclusions Five NQF eMeasures fell short of being machine-consumable specifications. Both clinical domain and technological expertise are required to implement manually intensive steps from data mapping to text mining to EHR-specific eMeasure implementation.|Electronic Health Record; Meaningful Use; Healthcare Quality Indicators/Methods; Process Assessment (Health Care)|ELECTRONIC HEALTH RECORDS; CORONARY-ARTERY-DISEASE; HITECH|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|9|3|10
Secondary use of electronic health records for building cohort studies through top-down information extraction|2015|Controlled clinical trials are usually supported with an in-front data aggregation system, which supports the storage of relevant information according to the trial context within a highly structured environment. In contrast to the documentation of clinical trials, daily routine documentation has many characteristics that influence data quality. One such characteristic is the use of non-standardized text, which is an indispensable part of information representation in clinical information systems. Based on a cohort study we highlight challenges for mining electronic health records targeting free text entry fields within semi-structured data sources. Our prototypical information extraction system achieved an F-measure of 0.91 (precision = 0.90, recall = 0.93) for the training set and an F-measure of 0.90 (precision = 0.89, recall = 0.92) for the test set. We analyze the obtained results in detail and highlight challenges and future directions for the secondary use of routine data in general. (C) 2014 Elsevier Inc. All rights reserved.|Information extraction; Secondary use; Clinical narrative|CLINICAL TEXT; BIOBANKS; SYSTEM; I2B2|Computer Science, Interdisciplinary Applications; Medical Informatics|7|0|10
Pedagogical stylistics in multiple foreign language and second language contexts: A synthesis of empirical research|2015|This article examines the efficacy of pedagogical stylistics as a learning tool for developing second or foreign language proficiency. Pedagogical stylistics - an instrument for investigating the linguistic, sociocultural and dialogic features inherent in literary and non-literary texts - has often been criticized for relying too heavily on intuition rather than empirical support to substantiate its employment in language learning classrooms. To better understand this criticism a coding framework adapted from previous research was employed to synthesize 13 studies across four, second or foreign languages in nine countries. Three themes emerged from this synthesis: (1) stylistics as a tool for improving L2 performance; (2) stylistics' contribution to building language awareness; (3) stylistics as a tool for building academic skills beyond L2 acquisition. This work explores these themes and discusses the research practices informing the claims made therein, highlighting a consistent underreporting or under collecting of data as a recurring problem in the literature. This shortcoming precludes a meta-analysis of the literature, and this article argues that this shortcoming contributes to a justifiably weak representation of stylistics in second or foreign language contexts. To rectify this issue suggestions are made for more thorough reporting of data and a more robust research agenda in second or foreign language-based, stylistic contexts.|Empirical studies; foreign-language; pedagogical stylistics; research synthesis; second-language; teaching and learning|METAANALYSIS; INSTRUCTION; TASK|Linguistics; Language \& Linguistics|3|0|10
Random Indexing and Modified Random Indexing based approach for extractive text summarization|2015|Random Indexing based extractive text summarization has already been proposed in literature. This paper looks at the above technique in detail, and proposes several improvements. The improvements are both in terms of formation of index (word) vectors of the document, and construction of context vectors by using convolution instead of addition operation on the index vectors. Experiments have been conducted using both angular and linear distances as metrics for proximity. As a consequence, three improved versions of the algorithm, viz. RISUM, RISUM+ and MRISUM were obtained. These algorithms have been applied on DUC 2002 documents, and their comparative performance has been studied. Different ROUGE metrics have been used for performance evaluation. While RISUM and RISUM+ perform almost at par, MRISUM is found to outperform both RISUM and RISUM+ significantly. MRISUM also outperforms LSA+TRM based summarization approach. The study reveals that all the three Random Indexing based techniques proposed in this study produce consistent results when linear distance is used for measuring proximity. (C) 2014 Elsevier Ltd. All rights reserved.|Word Space Model; Random Indexing; PageRank; Convolution; Modified Random Indexing|LATENT SEMANTIC ANALYSIS; INFORMATION|Computer Science, Artificial Intelligence|1|2|10
The variance of lexical diversity profiles and its relationship to learning style|2014|Studies in lexical diversity have shown an approximate relationship with learner instruction. Learners with more L2 instruction tend to display less repetition of words and so greater lexical diversity. However, at higher L2 levels of proficiency this relationship does not always occur. This study examines the lexical diversity scores in L2 texts. Lexical diversity scores are examined in relationship to a learning style framework of memory and analysis. The results show that variance in analytic ability scores can account for a proportion of variance in lexical diversity. It was also found that the type of writing task also affects lexical diversity. These results suggest that learners who are more grammatically able may be more likely to restructure their language. The findings illuminate Dynamic Systems Theory; in particular, how lexical diversity is shaped to some extent by differences within individuals and task conditions.|lexical diversity; learning style; variance|PERSPECTIVE; RICHNESS|Education \& Educational Research; Linguistics; Language \& Linguistics|1|0|10
Phonetic Detail and Dimensionality in Sound-shape Correspondences: Refining the Bouba-Kiki Paradigm|2014|Sound symbolism is the process by which speakers link phonetic features with meanings non-arbitrarily. For instance, speakers across languages associate non-words with rounded vowels, like bouba, with round shapes, and non-words without rounded vowels, like kiki, with spiky shapes. Researchers have posited that this link results from a cognitive association between sounds and visual or proprioceptive cues made in their production (e.g. sounds of rounded vowels cue the image of rounded lips, which is mapped to rounded shapes). However, non-words used in previous studies differ from one another along multiple phonetic dimensions, some showing no clear iconic mapping to shape. This study teases apart these features, finding that vowel backness, consonant voicing, and consonant place of articulation each elicit a sound symbolic effect, which is amplified when these dimensions are combined. This investigation also probes object properties that can be involved in sound symbolic association, bringing the ``bouba-kiki{''} paradigm, typically involving the use of abstract shapes, into the realm of real-world objects. To shed light on ways that sound symbolism may operate in natural language, this study suggests that future research in this paradigm would benefit from consideration of both more detailed phonetic correlates and more refined object properties.|Sound symbolism; phonetic symbolism; cross-modality; embodiment; dimensionality; bouba-kiki|CONSONANTS; SYMBOLISM; MALUMA|Audiology \& Speech-Language Pathology; Linguistics; Psychology, Experimental|11|5|10
Supporting Process Model Validation through Natural Language Generation|2014|The design and development of process-aware information systems is often supported by specifying requirements as business process models. Although this approach is generally accepted as an effective strategy, it remains a fundamental challenge to adequately validate these models given the diverging skill set of domain experts and system analysts. As domain experts often do not feel confident in judging the correctness and completeness of process models that system analysts create, the validation often has to regress to a discourse using natural language. In order to support such a discourse appropriately, so-called verbalization techniques have been defined for different types of conceptual models. However, there is currently no sophisticated technique available that is capable of generating natural-looking text from process models. In this paper, we address this research gap and propose a technique for generating natural language texts from business process models. A comparison with manually created process descriptions demonstrates that the generated texts are superior in terms of completeness, structure, and linguistic complexity. An evaluation with users further demonstrates that the texts are very understandable and effectively allow the reader to infer the process model semantics. Hence, the generated texts represent a useful input for process model validation.|Business process model validation; natural language text generation; verbalization|BUSINESS PROCESS MODELS; PETRI NETS; REQUIREMENTS; SPECIFICATIONS; VERIFICATION; MANAGEMENT; SEMANTICS; ERRORS; TEXT|Computer Science, Software Engineering; Engineering, Electrical \& Electronic|15|3|10
Assessing learners' writing skills in a SLA study: Validating the rating process across tasks, scales and languages|2014|There is still relatively little research on how well the CEFR and similar holistic scales work when they are used to rate L2 texts. Using both multifaceted Rasch analyses and qualitative data from rater comments and interviews, the ratings obtained by using a CEFR-based writing scale and the Finnish National Core Curriculum scale for L2 writing were examined to validate the rating process used in the study of the linguistic basis of the CEFR in L2 Finnish and English. More specifically, we explored the quality of the ratings and the rating scales across different tasks and across the two languages. As the task is an integral part of the data-gathering procedure, the relationship of task peformance across the scales and languages was also examined. We believe the kinds of analyses reported here are also relevant to other SLA studies that use rating scales in their data-gathering process.|CEFR scales; L2 learning; L2 writing; rating process; tasks; validation|CEFR|Linguistics; Language \& Linguistics|2|0|10
``What happened?{''} From talk to text in police interrogations|2014|Based on 11 interrogations and police records, I examine how stories are elicited, told and written up during the police interrogation. In the process of transforming a spoken story to a written story, we see several transformations. The written story is a more factual, detailed, precise and intentional story on paper constructed according to the institutional perspective of the officer. Whether the stories are told freely by the suspect, supervised or imposed by the officer, police officers adhere to their own structure and chronology of how they make events understandable. This is accomplished through further questioning, interrupting or by telling the story themselves. This process of institutionalization already begins in the interaction and continues when transforming talk to text. (C) 2014 Elsevier Ltd. All rights reserved.|Police interrogation; Police record; Conversation analysis; Storytelling; Talk; Text|ORGANIZATION; INTERVIEWS|Communication; Linguistics|7|0|10
Development and evaluation of RapTAT: A machine learning system for concept mapping of phrases from medical narratives|2014|Rapid, automated determination of the mapping of free text phrases to pre-defined concepts could assist in the annotation of clinical notes and increase the speed of natural language processing systems. The aim of this study was to design and evaluate a token-order-specific naive Bayes-based machine learning system (RapTAT) to predict associations between phrases and concepts. Performance was assessed using a reference standard generated from 2860 VA discharge summaries containing 567,520 phrases that had been mapped to 12,056 distinct Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT) concepts by the MCVS natural language processing system. It was also assessed on the manually annotated, 2010 i2b2 challenge data. Performance was established with regard to precision, recall, and F-measure for each of the concepts within the VA documents using bootstrapping. Within that corpus, concepts identified by MCVS were broadly distributed throughout SNOMED CT, and the token-order-specific language model achieved better performance based on precision, recall, and F-measure (0.95 +/- 0.15, 0.96 +/- 0.16, and 0.95 +/- 0.16, respectively; mean +/- SD) than the bag-of-words based, naive Bayes model (0.64 +/- 0.45, 0.61 +/- 0.46, and 0.60 +/- 0.45, respectively) that has previously been used for concept mapping. Precision, recall, and F-measure on the i2b2 test set were 92.9\%, 85.9\%, and 89.2\% respectively, using the token-order-specific model. RapTAT required just 7.2 ms to map all phrases within a single discharge summary, and mapping rate did not decrease as the number of processed documents increased. The high performance attained by the tool in terms of both accuracy and speed was encouraging, and the mapping rate should be sufficient to support near-real-time, interactive annotation of medical narratives. These results demonstrate the feasibility of rapidly and accurately mapping phrases to a wide range of medical concepts based on a token-order-specific naive Bayes model and machine learning. Published by Elsevier Inc.|Natural language processing; Bayesian prediction; Machine learning; Systematized nomenclature of medicine|INFORMATION EXTRACTION; CLINICAL TEXT; EMERGENCY-DEPARTMENT; CLASSIFICATION; CONCEPTUALIZATION; IDENTIFICATION; NORMALIZATION; RECORDS; TERMS; NEED|Computer Science, Interdisciplinary Applications; Medical Informatics|6|1|10
Reuse of termino-ontological resources and text corpora for building a multilingual domain ontology: An application to Alzheimer's disease|2014|Ontologies are useful tools for sharing and exchanging knowledge. However ontology construction is complex and often time consuming. In this paper, we present a method for building a bilingual domain ontology from textual and termino-ontological resources intended for semantic annotation and information retrieval of textual documents. This method combines two approaches: ontology learning from texts and the reuse of existing terminological resources. It consists of four steps: (i) term extraction from domain specific corpora (in French and English) using textual analysis tools, (ii) clustering of terms into concepts organized according to the UMLS Metathesaurus, (iii) ontology enrichment through the alignment of French and English terms using parallel corpora and the integration of new concepts, (iv) refinement and validation of results by domain experts. These validated results are formalized into a domain ontology dedicated to Alzheimer's disease and related syndromes which is available online (http://lesim.isped.u-bordeaux2.fr/SemBiP/ressources/ontoAD.owl). The latter currently includes 5765 concepts linked by 7499 taxonomic relationships and 10,889 non-taxonomic relationships. Among these results, 439 concepts absent from the UMLS were created and 608 new synonymous French terms were added. The proposed method is sufficiently flexible to be applied to other domains. (C) 2013 Elsevier Inc. All rights reserved.|Ontology development; Alzheimer's disease; Ontological resource reuse; Term alignment; Parallel corpus|INFORMATION-RETRIEVAL; SEMANTIC WEB; METHODOLOGY|Computer Science, Interdisciplinary Applications; Medical Informatics|3|1|10
EXPLORING HOW COLLABORATIVE DIALOGUES FACILITATE SYNCHRONOUS COLLABORATIVE WRITING|2014|Collaborative writing (CW) research has gained prevalence in recent years. However, the ways in which students interact socially to produce written texts through synchronous collaborative writing (SCW) is rarely studied. This study aims to investigate the effects of SCW on students' writing products and how collaborative dialogues facilitate SCW. Following an initial analysis, 54 students were divided into 18 groups; six groups with higher proportions of collaborative dialogue (HCD), six groups with median proportions of collaborative dialogue (MCD), and six groups with lower proportions of collaborative dialogue (LCD). The data collected includes the students' three reaction essays, their transcripts of text-based collaborative dialogues, and their writing process logs. The results showed that there were significant differences between the LCD, MCD, and HCD groups in terms of fluency and accuracy of their reaction essays. Through collaborative dialogues, students benefitted from text-based synchronous communications, such as clarifying their linguistic misconceptions, and receiving immediate feedback to help resolve their writing problems. The findings suggest that students could be provided with more opportunities for collaborative dialogues during the entire writing process, including the stages of generating ideas, writing reaction essays, and editing.|Collaborative Learning; Writing; Collaborative Dialogues|FOREIGN-LANGUAGE; INSTRUCTION; IMMERSION; ATTENTION; STUDENTS; FORM|Education \& Educational Research; Linguistics|4|0|10
The Discussion section in Microbiology research articles: genre, engagement and knowledge construction|2014|The aim of this paper is to identify common patterns in texts that function as Discussion of research articles in the area of Microbiology. With this purpose, a corpus of four texts was analyzed manually from the perspective of genre in Systemic Functional Linguistics. The schematic structure of the texts and the resources realizing it as configuration of meanings in the three metafunctions of language were explored. The analysis showed that the Discussion of research articles in this area realizes the genre warranty of the research, whose purpose is to legitimate the results found in the research in order to persuade the readers and to guarantee that they are pertinent to be incorporated to the body of disciplinary knowledge. The discourse-semantic resources found as relevant in the texts were the co-articulation of projection, a resource of the appraisal system, and comparison, a resource of the conjunction system. Concede plus counter pairings were found only when the writer rejects possible objections of the readers. The resources found suggest that the new knowledge in Microbiology is integrated in a hierarchical structure of vertical knowledge. Due to the number of texts analyzed in this article, the results obtained are considered preliminary.|scientific discourse; genre; Discussion section of research articles; appraissal; knowledge structures|DISCOURSE|Linguistics; Language \& Linguistics|1|1|10
Semiotic technology and practice: a multimodal social semiotic approach to PowerPoint|2014|The ubiquitous software PowerPoint has significant influence on evaluations of professional and academic success, and has attracted considerable attention from both social commentators and researchers in various fields. Existing research on PowerPoint considers the software, slideshows created with it, and PowerPoint-supported presentations in isolation from each other and is therefore unable to promote better understanding of the interaction between the software's design and its use. This article proposes a model for exploring this interaction. Specifically, it introduces a multimodal social semiotic approach to studying PowerPoint as a semiotic practice comprising three dimensions - the software's design, the multimodal composition of slideshows, and their presentation - and two semiotic artefacts, the software and the slideshow. It discusses the challenges each dimension presents for discourse analysis and social semiotic research, focusing especially on the need to step away from the notion of text and to develop a holistic, non-logocentric, and adaptive multimodal approach to researching semiotic technologies. Using PowerPoint as a case study, this article takes a step toward developing a social semiotic multimodal theory of the relation between semiotic technologies, or technologies for making meaning, and semiotic practices.|PowerPoint; semiotic technology; semiotic practice; software; slideshows; slideshow presentations|MULTIMEDIA|Communication; Linguistics; Language \& Linguistics|7|1|10
Towards a musical stylistics: Movement in Kate Bush's `Running Up That Hill'|2013|A very recent trend in stylistics proposes the extension of its field of enquiry to accommodate various forms of multimodal art. Reflecting as it does the growing semiotic complexity of contemporary aesthetics, multimodal stylistics' is a welcome development. So far, however, its proponents have concentrated on genres in which texts are complemented by, or realized through, the visual medium - films, stage plays, television series and illustrated books. In this article, a multimodal stylistic analysis is attempted on a genre which has attracted little critical attention in linguistics - modern pop-rock music. A 1985 song by singer-songwriter Kate Bush, Running Up That Hill', is studied linguistically and musically. Employing a blend of stylistic and musicological techniques, and some of the insights provided by newborn multimodal stylistics, the author explores the complex ways in which meaning is created in a pop-rock song.|Figure; foregrounding; ground; Kate Bush; multimodality; pop-rock music; stylistics|MULTIMODAL METAPHOR; DRAMA|Linguistics; Language \& Linguistics|3|2|10
Reading authentic texts: What counts as cognate?|2013|Most research on cognates has focused on words presented in isolation that are easily defined as cognate between L1 and L2. In contrast, this study investigates what counts as cognate in authentic texts and how such cognates are read. Participants with L1 Danish read news articles in their highly proficient L2, English, while their eye-movements were monitored. The experiment shows a cognate advantage for morphologically simple words, but only when cognateness is defined relative to translation equivalents that are appropriate in the context. For morphologically complex words, a cognate disadvantage is observed which may be due to problems of integrating cognate with non-cognate morphemes. The results show that fast non-selective access to the bilingual lexicon is conditioned by the communicative context. Importantly, a range of variables are statistically controlled in the regression analyses, including word predictability indexed by the conditional probability of each word.|bilingual mental lexicon; cognates; eye movements; reading|VISUAL WORD RECOGNITION; SENTENCE CONTEXT; LEXICAL ACCESS; AMBIGUOUS WORDS; TRANSLATION; ACTIVATION; BILINGUALS; MODEL; REPRESENTATION; PHONOLOGY|Linguistics; Psychology, Experimental|7|1|10
Form-focused social repertoires in an online language learning partnership|2013|This study explores how mutual language learning partners, a native speaker (NS) and learner of Italian as a foreign language, use conversational repair as an authentic resource for out-of-class social interaction and focus-on-form during online text chat sessions. Specifically, it analyses the sequential organization of prototypical form-focused exposed correction sequences where the NS both initiates and completes repair of the learner's non-target grammar in the same turn, also known as recast. Findings indicate that despite the face-threatening nature of exposed correction within an unequal speech exchange system, participants maintain social solidarity by orienting to expert-novice roles and integrating recasts into phatic action-accepting and appreciation routines to bring form-focused trajectories to a polite conclusion prior to returning to topical talk. The learner's role as interaction manager is evident in her regular transformation of NS-initiated pedagogical actions-in-progress into social ones. Comparison of these form-focused pedagogical-social trajectories with a prototypical teacher-fronted instructional repertoire, the Initiation-Response-Feedback (IRF) sequence, reveals previously unidentified differences in how participants manage their interactions, especially exposed correction, in a formal-pedagogical and an informal social-pedagogical environment. While IRF is only one of many instructional repertoires in which correction activity is nested, fundamental structural differences suggest that online dyadic chat within language learning partnerships provides a potentially empowering and spontaneous alternative to classroom-based instructional repertoires, in preparation for real-life interaction in the target language. (C) 2012 Elsevier B.V. All rights reserved.|Online chat; Conversation analysis; Second language acquisition; Foreign languages; Italian; Focus-on-form|COMPUTER-MEDIATED COMMUNICATION; TURN-TAKING; CONVERSATION; REPAIR; 2ND-LANGUAGE; ORGANIZATION; CLASSROOM; MANAGEMENT; STUDENTS; CHATS|Linguistics; Language \& Linguistics|8|0|10
An efficient concept-based retrieval model for enhancing text retrieval quality|2013|Most of the common techniques in text retrieval are based on the statistical analysis terms (words or phrases). Statistical analysis of term frequency captures the importance of the term within a document only. Thus, to achieve a more accurate analysis, the underlying model should indicate terms that capture the semantics of text. In this case, the model can capture terms that represent the concepts of the sentence, which leads to discovering the topic of the document. In this paper, a new concept-based retrieval model is introduced. The proposed concept-based retrieval model consists of conceptual ontological graph (COG) representation and concept-based weighting scheme. The COG representation captures the semantic structure of each term within a sentence. Then, all the terms are placed in the COG representation according to their contribution to the meaning of the sentence. The concept-based weighting analyzes terms at the sentence and document levels. This is different from the classical approach of analyzing terms at the document level only. The weighted terms are then ranked, and the top concepts are used to build a concept-based document index for text retrieval. The concept-based retrieval model can effectively discriminate between unimportant terms with respect to sentence semantics and terms which represent the concepts that capture the sentence meaning. Experiments using the proposed concept-based retrieval model on different data sets in text retrieval are conducted. The experiments provide comparison between traditional approaches and the concept-based retrieval model obtained by the combined approach of the conceptual ontological graph and the concept-based weighting scheme. The evaluation of results is performed using three quality measures, the preference measure (bpref), precision at 10 documents retrieved (P(10)) and the mean uninterpolated average precision (MAP). All of these quality measures are improved when the newly developed concept-based retrieval model is used, confirming that such model enhances the quality of text retrieval.|Text retrieval; Concept-based retrieval; Concept-based weighting; Concept index; Natural language processing|INFORMATION-RETRIEVAL|Computer Science, Artificial Intelligence; Computer Science, Information Systems|6|0|10
Can skilled readers perform a second task in parallel? A functional connectivity MRI study|2013|When asked to search for a target letter while reading, the patterns with which people miss the target letter reveal information about the process of reading itself. Questions remain as to whether this paradigm reflects normal reading processes however. We used a novel continuous-performance neuroimaging paradigm to address this question. In separate scanning runs, subjects either read alone, read while searching for a target letter, or searched non-words continuously. Functional connectivity analysis recovered the full extent of brain areas identified for reading in a localizer scan, with no differences between reading alone and the dual task condition. Differences were found, however, between both reading conditions and the nonword search condition. These results demonstrate that in skilled readers brain activation associated with reading is unaffected by a concurrent letter-search task. They further demonstrate the utility of a naturalistic, continuous-performance paradigm for studying the neural basis of language processing. (C) 2012 Elsevier Inc. All rights reserved.|Brain; Attention; fMRI; Missing letter effect; Letter search|INDEPENDENT COMPONENT ANALYSIS; DETECTING LETTERS; EYE-MOVEMENTS; VISUAL-SEARCH; BRAIN; FMRI; LANGUAGE; TEXT; COMPREHENSION; METAANALYSIS|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|6|1|10
A knowledge-engineering approach to the cognitive categorization of lexical meaning|2013|A key challenge in natural language processing is to develop intelligent agents which can retrieve and manage knowledge efficiently as well as simulate human-level reasoning. Undoubtedly, the knowledge base plays a crucial role in such a cognitive architecture. The problem lies in the fact that most approaches to the computational treatment of the meaning of words are restricted to systems of binary lexical relations. The goal of this article is to describe, from the view of linguistics and cognitive science, the theoretical foundation which underlies the construction of the deep semantic representations in FunGramKB, a multipurpose lexico-conceptual knowledge base to be implemented in natural language understanding systems. Thus, the conceptual schemata of thematic frames and meaning postulates may not only provide a full-fledged formalization of lexical semantics in natural language processing but can also facilitate the comprehension of linguistic realizations in artificial intelligence.|FunGramKB; meaning postulate; thematic frame; ontology; lexical semantics|REPRESENTATIONS; DECISIONS; MODEL|Linguistics; Language \& Linguistics|4|0|10
``Coded and uncoded error feedback: Effects on error frequencies in adult Colombian EFL learners' writing{''|2012|This paper reports on a small-scale study into the effects of uncoded correction (writing the correct forms above each error) and coded annotations (writing symbols that encourage learners to self-correct) on Colombian university-level EFL learners' written work. The study finds that while both coded annotations and uncoded correction appear to aid learners in a) recognising and correcting errors in their written work, and b) producing correct forms in subsequent pieces of work, coded feedback seems to be more effective at this, possibly as a result of the increased cognitive engagement and social interaction it affords. In both cases, however, the process of acquisition is non-linear, and may also be influenced by other factors, such as teaching input, natural orders of acquisition and individual differences. The findings also suggest that since certain error types, such as spelling, verb tense and word choice, are more persistent than others, correction codes may be usefully combined with written comments providing appropriate depth of feedback. Teachers may also adapt codes to individual groups of learners to reflect error types that cause particular difficulties, and annotate/correct selectively to avoid discouraging learners from taking risks and experimenting with more sophisticated language forms. (C) 2012 Elsevier Ltd. All rights reserved.|Feedback; Correction; SLA; Error; Writing; Codes|HONG-KONG; CONSCIOUSNESS; CLASSROOMS|Education \& Educational Research; Linguistics|8|1|10
Towards a conceptual framework of research on social signal processing|2012|Social Signal Processing (SSP) as an emerging research area can draw on material from many disciplines, but it needs effective ways to organise the material. We propose a framework that integrates concepts, drawn primarily from psychology, but with input from other disciplines, in a way that indicates how they relate to SSP. We identify seven core constructs: state; indicators that convey info about it; process by which indicators are generated; types of inference involved in identifying states from indicators; perceptual issues, including recovery of indicators from flux of activity and accuracy of impressions about the state; the role of macro-context; and the different levels at which analysis may be couched (the individual, the dyad, the group, the organisation). These may or may not be reflected in the structure of an SSP system, but the natural subtlety and context-sensitivity of human communication makes it important that people designing systems should consider how they relate to its task, and decide how best to take account of them. The analysis works from simple models which consider only states and indicators to models which embrace all seven constructs. At each stage it points to the literatures which discuss the relevant issues. It is fully acknowledged that attempting such a synthesis raises many problems (not least of terminology), and that alternative frameworks deal at least as well with subsets of the issues. It remains to be seen whether they could be extended to cover a comparable range.|Social signal processing; Psychology|SPONTANEOUS FACIAL EXPRESSIONS; EMOTION RECOGNITION; SELECTIVE ATTENTION; VOLUNTARY CONTROL; SMILES; PERCEPTION; PERSUASION; LANGUAGE; SELF; CREDIBILITY|Computer Science, Artificial Intelligence; Computer Science, Cybernetics|4|0|10
Benefits of supplementing use case narratives with activity diagrams-An exploratory study|2012|Use case narratives modeling the complex functionality of a given system often extend for several pages due to the need to include numerous alternative scenario specifications. In such situations, it is difficult to ensure the completeness and validity of the process logic embedded in such lengthy text narratives. This exploratory study investigates the benefits of supplementing each complex and lengthy use case narrative with an activity diagram for analysts and clients during requirements gathering and analysis. Our findings indicate that the process logic in corresponding activity diagrams is more complete and offers a greater degree of validity than that used in use case narratives. In addition, the quality of the process logic in these artifacts is not negatively affected by a use case narrative's length or complexity when they are used together to capture system requirements. Our research provides empirical evidence of beneficial improvements in the quality of these widely used artifacts that subsequently help eliminate or minimize inconsistencies among the requirements specified in different artifacts. (C) 2012 Elsevier Inc. All rights reserved.|Use case narratives; Activity diagrams; Process logic; Quality improvement; Unified Modeling Language|WORKING-MEMORY; UML; QUALITY; COMPLEXITY; MODELS|Computer Science, Software Engineering; Computer Science, Theory \& Methods|2|3|10
Cognitive adequacy in a dialogic Functional Discourse Grammar|2012|Functional Discourse Grammar (FDG), as a theory of the organization of natural languages, seeks to attain pragmatic, typological and cognitive adequacy. The attempt to achieve cognitive adequacy has been fraught with problems stemming from the vagueness of the concept and the difficulty of adapting to trends in psycholinguistics. Specifically, while FDG has seen every utterance as an entirely novel creation by an individual language user, developments in cognitive science have emphasized the extent to which aspects of utterances are primed by earlier occurrences in the context of dialogue involving two or more interlocutors. It is possible to develop a dialogic view of FDG in which the Contextual Component is re-interpreted as an implicit common ground and as a conduit for the interactive alignment of grammatical processes. In such a view, morphosyntactic alternations are defined by their potential for mutual priming. The analysis of dialogue data shows that authentic linguistic expressions, examined in their discourse context, can be described as being determined either by priming or by functional factors, with several instances of dys-functionality being attributed to the influence of priming. (C) 2012 Elsevier Ltd. All rights reserved.|Functional Discourse Grammar; Cognitive adequacy; Priming; Dialogue; Alternation; Interactive alignment|LANGUAGE PRODUCTION; COMPREHENSION; LINGUISTICS; PERSISTENCE; PSYCHOLOGY; MODEL|Linguistics; Language \& Linguistics|8|0|10
Constructing hegemonic masculinities in South Africa: The discourse and rhetoric of heteronormativity|2012|This paper considers how local and regional representations of hegemonic masculinity are (re)produced, and how men's gender identities are constituted through situated interaction in South Africa. It points toward the important role played by the discourse and rhetoric of heteronormativity among these men in hegemonic sense-making, and in particular, the underlying discursive practices of performative/intimate (hetero)sexuality and homosexual rejection/acceptance. An attempt is made to account for complexity and diversity in this sense-making across intersecting social categories such as ethnicity and social class. Focus group discussion among Afrikaans, English and Xhosa men was transcribed and back-translated where necessary. A technique of discourse analysis that considers the rhetorical aspects of text is developed through the introduction of norm-referencing rhetorical devices. Findings highlight the extent to which practices of both compliance and resistance contribute toward the (re)production of masculinities.|DISCOURSE; HEGEMONIC MASCULINITIES; HETERONORMATIVITY; RHETORIC; SOUTH AFRICA|DISCURSIVE PSYCHOLOGY; CONVERSATION ANALYSIS; MEN; REPRESENTATIONS; REPRODUCTION; IDENTITIES; SEXUALITY; VIOLENCE; GENDER; AIDS|Linguistics; Language \& Linguistics; Women's Studies|8|0|10
Argumentative use of reported speech in British newspaper discourse|2012|A reported utterance cannot be incorporated into the new discourse without undergoing certain transformations and losing some of its initial properties. Decision of representing or omitting information on certain aspects of the quoted utterance is not arbitrary, and this choice is subordinated to the writer's goals. In argumentative discourse the overall aim of convincing the addressee determines the way reported speech is presented to the readers. The present work analyzes those features of other discourses which are reproduced in argumentative discourse of the quality British press. Research revealed that of the six linguistic levels characterizing the initial utterance (phonetic, lexical, syntactic, semantic, pragmatic, and rhetorical), journalists choose only those relevant for the argumentative function the quotation performs. When reported speech is used as the thesis, the writer retains maximum control of the quotation by reproducing fewer levels, and focusing mainly on global semantics and pragmatics. When reported speech is used as an argument, the journalist, on the contrary, aims to show minimum control of the quoted utterance to increase its argumentative credibility. This is achieved by detailed reproduction of local semantics, lexica, and syntax of the quotation.|argumentation study; discourse analysis; reported speech; quotations; argumentative newspaper discourse; linguistic levels; argumentative functions|VOICES; LANGUAGE; TEXT|Communication; Linguistics; Language \& Linguistics|2|0|10
Different contexts, different ``stories{''}? A linguistic comparison of two development reports on climate change|2012|This paper describes some linguistic features related to the textual interaction taking place between different voices in two development reports focusing on climate change challenges, and discuss how these features function in an argumentative perspective. Given the different institutional contexts they are produced in (the UN Development Program and the World Bank), our hypothesis is that the reports tell different ``stories{''}. This is confirmed through a comparative analysis undertaken in an overarching polyphonic perspective, revealing a mix of different explicit and implicit voices, and different use of devices such as epistemic, deontic and axiological markers. (C) 2011 Elsevier Ltd. All rights reserved.|Discourse analysis/text linguistics; Semantics; Pragmatics; Polyphony; Modality|COMMUNICATION|Communication; Linguistics|17|0|10
Applying machine learning in accounting research|2011|Quite often, in order to derive meaningful insights, accounting researchers have to analyze large bodies of text. Usually, this is done manually by several human coders, which makes the process time consuming, expensive, and often neither replicable nor accurate. In an attempt to mitigate these problems, we perform a feasibility study investigating the applicability of computer-aided content analysis techniques onto the domain of accounting research. Krippendorff (1980) defines an algorithm's reliability as its stability, reproducibility and accuracy. Since in computer-aided text classification, which is inherently objective and repeatable, the first two requirements, stability and reproducibility, are not an issue, this paper focuses exclusively on the third requirement, the algorithm's accuracy. It is important to note that, although inaccurate classification results are completely worthless, it is surprising to see how few research papers actually mention the accuracy of the used classification methodology. After a survey of the available techniques, we perform an in depth analysis of the most promising one, LPU (Learning from Positive and Unlabelled), which turns out to have an F-value and accuracy of about 90\%, which means that, given a random text, it has a 90\% probability of classifying it correctly. (C) 2011 Elsevier Ltd. All rights reserved.|Data mining; Text classification; Accounting research; Artificial intelligence|ENVIRONMENTAL DISCLOSURES; REPUTATION|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|3|2|10
Quantitative analysis of Zamenhof's Esenco kaj estonteco|2011|The formation of a language community in a planned language is one of the most important steps in its development. Esperanto is the only fully functional language with relative success among more than one thousand planned language projects. Model texts have played a very significant role in the development of Esperanto. Esenco kaj estonteco de la ideo de lingvo internacia (Essence and future of the international language idea) by the founder of Esperanto, L. L. Zamenhof, is an important document on Esperanto. Taking the essay as the research object, this paper carries through lexical and syntactical analysis on Esperanto by adopting the research methods of quantitative linguistics and complex networks. The results show that the morpheme distribution of Esperanto follows a power law, word frequency distribution fits Zipf's Law, word length distribution is an exponential curve, and word class distribution obeys linear law. It is also clear that Esperanto is a language with SVO word order preference, the mean dependency distance of Esperanto is 3.85, and the distribution of the dependency distance tends to a minimum, making it typologically a head-middle language. A 43.6\% dependency relation appears in adjacent words. The complex syntactic networks of Esperanto display the characteristics of small-world, scale-free networks. All of these quantitative characteristics of Esperanto demonstrate that it is structurally a normal human language.|Esperanto; quantitative linguistics; complex network; word frequency distribution; linguistic typology; dependency syntax|COMPLEX NETWORKS; CHINESE; ESPERANTO; TREEBANK; DYNAMICS|Linguistics; Language \& Linguistics|5|0|10
Lexical Frequency Profiles and Zipf's Law|2011|<link rid={''}b10{''}>Laufer and Nation (1995) proposed that the Lexical Frequency Profile (LFP) can estimate the size of a second-language writer's productive vocabulary. Meara (2005) questioned the sensitivity and the reliability of LFPs for estimating vocabulary sizes, based on the results obtained from probabilistic simulations of LFPs. However, the underlying mathematical model for the simulations, based on Zipf's law, allows such an analysis to be done directly, without recourse to simulations. The direct analysis has the further advantage of demonstrating how variability estimates obtained from within the 1k band (the 1,000 most frequent words of English) portion of written texts may explain the simulation results. The findings confirm that the ability of LFPs to distinguish between groups diminishes as vocabulary size increases. However, for fairly homogeneous groups, LFPs are able to provide a coarse but reasonable tool for vocabulary size estimation. We also explore modifications to Zipf's law that may result in a more accurate model of word frequencies in natural language.|Zipf's law; L2 vocabulary learning; L2 vocabulary size; modeling vocabulary learning|POWER LAWS; VOCABULARY; PARETO|Education \& Educational Research; Linguistics|8|0|10
Your verbal zone: an intelligent computer-assisted language learning program in support of Turkish learners' vocabulary learning|2011|This study investigated the effectiveness of an intelligent computer-assisted language learning (ICALL) program on Turkish learners' vocabulary learning. Within the scope of this research, an ICALL application with a morphological analyser (Your Verbal Zone, YVZ) was developed and used in an English language preparatory class to measure its effects on students' achievement in vocabulary acquisition as well as their attitudes towards such an ICALL environment. The study employed a pre-test-post-test control group design. The sample consisted of 42 low intermediate learners who were assigned to experimental and control groups. The independent samples t test was used to study the differences in continuous variables between the experiment and the control groups. The improvement in the vocabulary knowledge of the participants was measured as to two different aspects, i.e. morphological knowledge and the knowledge of words' definitions and usage. The results indicate that reading activities with YVZ have proved to have positive effects on both learners' vocabulary learning and their attitudes towards the use of an intelligent computer-assisted language learning application in the classroom.|morphological analyser; vocabulary learning; quasi-experimental research design; natural language processing; ICALL|MODEL|Education \& Educational Research; Linguistics; Language \& Linguistics|8|0|10
Toward an Integrated Curriculum: Maximizing the Use of Target Language Literature|2010|This article presents an approach to literary texts that develops students' language proficiency, content knowledge, and analytical skills through the interweaving of three content areas-literary analysis, stylistics, and culture-at the beginning, intermediate, and advanced levels of the foreign language curriculum. Consistent with recommendations from the recent Modern Language Association (2007) report on foreign languages in higher education, this integrated approach develops students' translingual and transcultural competence by examining target language narratives from multiple perspectives. To ground this method, we review relevant research on literature in foreign language instruction and then present a sample lesson plan for teaching the Spanish-language text Apocalipsis {[}Apocalypse] (Denevi, 1974) at the intermediate instructional level. The article concludes with suggestions and strategies for modifying the lesson plan for beginning and advanced levels.|Spanish; culture; curriculum; literature; spiraling; stylistics|CRITICAL THINKING; TEXTS|Education \& Educational Research; Linguistics|10|1|10
Voice-over and self-narrative in film: A multimodal analysis of Antonioni's When Love Fails (Tentato Suicidio)|2010|Stylistic research on film discourse is growing; however, studies rarely take into consideration cinema's complex message resulting from the combination of the verbal and visual codes. This article proposes a multimodal analysis of Italian auteur Antonioni's When Love Fails to show how dialogue artfully interacts with elements of the mise-en-scene. The short film, part of a 1953 compilation, is an inquiry into the reality of suicide through the narratives of five women who at one point of their lives attempted suicide. Introducing and orchestrating the stories is a male voice-over and an invisible journalist/interviewer. The study analyses the women's recollections from a narrative approach and follows how, through their self-presentation strategies, the five survivors project their identity. Not all narratives and narrators are the same; some are interviewer-orchestrated, while two display a better control of their narratives and stronger authorship, which are interpreted here as signs of greater agency. The narrative styles of the more autonomous narrators are various: the creation of vectors and deictic centres through the use of deixis and gaze accompanied by camera movement, and the use of reported speech that construes a complex double plane narrative revolving around the switch from the verbal to the visual plane. In conclusion, the study demonstrates that a stylistic multimodal approach offers a viable tool for a richer understanding of cinema's semiotic by providing an interface between the levels of verbal and visual communication.|agency; Antonioni; deixis; eye-line; gaze; Love in the City; multimodality; narrative styles; (non) transactional; participants; vector; voice-over|DISCOURSE; REPRESENTATION; TEXT|Linguistics; Language \& Linguistics|4|3|10
An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation|2010|Word sense disambiguation (WSD), the task of identifying the intended meanings (senses) of words in context, has been a long-standing research objective for natural language processing. In this paper, we are concerned with graph-based algorithms for large-scale WSD. Under this framework, finding the right sense for a given word amounts to identifying the most ``important{''} node among the set of graph nodes representing its senses. We introduce a graph-based WSD algorithm which has few parameters and does not require sense-annotated data for training. Using this algorithm, we investigate several measures of graph connectivity with the aim of identifying those best suited for WSD. We also examine how the chosen lexicon and its connectivity influences WSD performance. We report results on standard data sets and show that our graph-based approach performs comparably to the state of the art.|Word sense disambiguation; graph connectivity; semantic networks; social network analysis|CENTRALITY; NETWORKS|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic|73|1|10
Exploring the Ability of Natural Language Processing to Extract Data From Nursing Narratives|2009|Natural Language Processing (NLP) offers an approach for capturing data from narratives and creating structured reports for further computer processing. We explored the ability of a NLP system, Medical Language Extraction and Encoding (MedLEE), on nursing narratives MedLEE extracted 490 concepts from narrative text in a sample of 553 oncology nursing process notes. The most frequently monitored and recorded signs and symptoms were related to chemotherapy care, such as adverse reactions shortness of breath, nausea, pain and bleeding. In terms of nursing interventions, chemotherapy blood culture, medication, and blood transfusion were commonly recorded in free text NLP may provide a feasible approach to extract data related to patient safety/quality measures and nursing outcomes by capturing nursing concepts that are not recorded through structured data entry. For better NLP performance in the domain of nursing additional nursing terms and abbreviations must be added to MedLEE lexicon.|Natural language processing; Nursing free text; Oncology nursing narratives; Patient safety measure; Quality measure|ADVERSE DRUG EVENTS|Computer Science, Interdisciplinary Applications; Medical Informatics; Nursing|16|3|10
Neural network processing of natural language: II. Towards a unified model of corticostriatal function in learning sentence comprehension and non-linguistic sequencing|2009|A central issue in cognitive neuroscience today concerns how distributed neural networks in the brain that are used in language learning and processing can be involved in non-linguistic cognitive sequence learning. This issue is informed by a wealth of functional neurophysiology studies of sentence comprehension, along with a number of recent studies that examined the brain processes involved in learning non-linguistic sequences, or artificial grammar learning (AGL). The current research attempts to reconcile these data with several current neurophysiologically based models of sentence processing, through the specification of a neural network model whose architecture is constrained by the known cortico-striato-thalamo-cortical (CSTC) neuroanatomy of the human language system. The challenge is to develop simulation models that take into account constraints both from neuranatomical connectivity, and from functional imaging data, and that can actually learn and perform the same kind of language and artificial syntax tasks. In our proposed model, structural cues encoded in a recurrent cortical network in BA47 activate a CSTC circuit to modulate the flow of lexical semantic information from BA45 to an integrated representation of meaning at the sentence level in BA44/6. During language acquisition, corticostriatal plasticity is employed to allow closed class structure to drive thematic role assignment. From the AGL perspective, repetitive internal structure in the AGL strings is encoded in BA47, and activates the CSTC circuit to predict the next element in the sequence. Simulation results from Caplan's {[}Caplan, D., Baker, C., \& Dehaut, F. (1985). Syntactic determinants of sentence comprehension in aphasia. Cognition, 21, 117-175] test of syntactic comprehension, and from Gomez and Schvaneveldts' {[}Gomez, R. L, \& Schvaneveldt, R. W. (1994). What is learned from artificial grammars?. Transfer tests of simple association. Journal of Experimental Psychology: Learning, Memory and Cognition, 20,396-410] artificial grammar learning experiments are presented. These results are discussed in the context of a brain architecture for learning grammatical structure for multiple natural languages, and non-linguistic sequences. (C) 2008 Elsevier Inc. All rights reserved.|Syntactic comprehension; Non-linguistic sequence; Basal ganglia; Cortico-striatal system; Neural network; Language acquisition|POSITRON-EMISSION-TOMOGRAPHY; BROCAS AREA; BASAL GANGLIA; GRAMMATICAL CONSTRUCTION; SYNTACTIC COMPREHENSION; PARALLEL ORGANIZATION; STRIATAL CONNECTIONS; ARTIFICIAL GRAMMARS; PARKINSONS-DISEASE; SEMANTIC PROCESSES|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|28|0|10
Lexical entrainment and lexical differentiation in reference phrase choice|2009|Speakers reuse prior references to objects when choosing reference phrases, a phenomenon known as lexical entrainment. One explanation is that speakers want to maintain a. set of previously established referential precedents. Speakers may also contrast any new referents against this previously established set, thereby avoiding applying the same reference phrase to refer to different referents, a complementary phenomenon I call lexical differentiation. This study provides evidence for lexical differentiation in the context of lexical entrainment. Both phenomena are present when speakers and addressees interact, when speakers imagine addressees, and when speakers simply name objects. This indicates that lexical entrainment and lexical differentiation may be products of speaker-centered processes. However, the magnitudes of these effects differ when speakers have different audience demands, indicating that audience-centered processes may also be involved. (C) 2009 Elsevier Inc. All rights reserved.|Conceptual pacts; Reference; Lexical entrainment; Lexical differentiation; Perspective-taking; Common ground; Contrast; Linguistic precedent|NATURAL CATEGORIES; CONCEPTUAL PACTS; CONVERSATION; LANGUAGE; COMPREHENSION; COORDINATION; PERSPECTIVE; PRECEDENTS; PRAGMATICS; CONTRAST|Linguistics; Psychology; Psychology, Experimental|24|0|10
Computer mediated communication and informalization of discourse: The influence of culture and subject matter|2009|This article compares the language used ill four online written asynchronous fora in English. Spanish and Catalan about football. We pay special attention to the use of informal, conversational language in these written texts. The results are then compared to a previous analysis of online fora in the three languages about a more serious topic, the Israeli-Palestinian conflict. Our initial hypotheses were that the linguistic behaviour in the English fora would show more informal, conversational characteristics than the Spanish and Catalan fora and that the fora about football Would be more conversational than those about the Israeli-Palestinian conflict. Our study largely confirms that, in the discussion groups studied, online asynchronous computer mediated communication in English displayed markedly more oral elements than in Catalan and Spanish. both in fora devoted to a serious topic and in fora devoted to sport. While the Catalan and Spanish showed more informal. conversational elements than the corresponding fora about politics, this topic related difference was not so clear in the case of the English fora. Another unforeseen finding was that the English asynchronous forum devoted to sport displayed a number of features associated with synchronous CMC. (C) 2008 Elsevier B.V. Ail rights reserved.|Discourse analysis; Computer mediated communication; Informalization|ENGLISH; SPEECH|Linguistics; Language \& Linguistics|16|0|10
Assessing source material difficulty for consecutive interpreting Quantifiable measures and holistic judgment|2009|Motivated by the need for better control of standards of a certification examination for interpreters in Taiwan, this exploratory study aimed at identifying indicators that may be used to predict source material difficulty for consecutive interpreting. A combination of quantifiable measures - readability level, information density and new concept density - was used to examine different aspects of three English source materials. Expert judgment was also used as a more holistic method of judging source material difficulty. The results of these analyses were compared with two groups of student interpreters' performance on consecutive interpreting of the source materials into Mandarin Chinese. The participants' assessment of speech difficulty after the interpreting task was also compared with the other measures and the expert judgment. The quantifiable measures all failed statistically in predicting source material difficulty, possibly due to the very small sample size of the materials or to the fact that the materials were very similar in the aspects assessed by these measures. A trend emerged to suggest that information density and sentence length may be potentially useful indicators for predicting source material difficulty. It was also shown that source material difficulty affected the performance of lower-skilled interpreters more than that of higher-skilled interpreters.|consecutive interpreting; difficulty; expert judgment; information density; readability; source material|COMPREHENSION; ACCURACY; ENGLISH; TEXT|Linguistics; Language \& Linguistics|7|1|10
Dealing with written language semantics by a connectionist model of cognitive reading|2009|Although machines perform much better than human beings in most of the tasks, it is not the case of natural language Processing. Computational linguistic systems usually rely on mathematical and statistical formalisms, which are efficient and useful but far from human procedures and therefore not so skilled. This paper proposes a computational model of natural language reading, called Cognitive Reading Indexing Model (CRIM), inspired by some aspects of human cognition, that tries to become as more psychologically plausible as possible. The model relies on a semantic neural network and it produces not vectors but nets of activated concepts as text representations. Based on these representations, measures of semantic similarity are also defined. Human comparison results show that the system is suitable to model human reading. Additional results also point out that the system could be used in real applications concerning natural language processing tasks. (C) 2008 Elsevier B.V. All rights reserved.|Computational models of reading; Language semantics representation; Text indexing; Connectionist semantics|COMPREHENSION|Computer Science, Artificial Intelligence|4|1|10
The influence of lexical familiarity on ERP responses during sentence comprehension in language learners|2009|Previous research on event-related potentials (ERPs) on second language processing has revealed a great degree of plasticity in brain mechanisms of adult language learners. Studies with natural and artificial languages show that the N400 as well as the P600 component appear in learners after sufficient training. The present experiment tests if and which ERP components in response to syntactic and thematic processes generalize to unfamiliar lexical material in adult language learners. Learners of a miniature version of Japanese were presented with correct and incorrect: sentences, half of which contained an unfamiliar word in the crucial sentence position. Incorrect sentences were either case-marking violations or word category violations. When all words were familiar, case-marking violations elicited a biphasic N400-P600 pattern and word category violations led to an early negativity that was followed by a P600. When the case violation occurred on an unfamiliar noun, only a P600 was seen. Word category violations that involved unknown verbs led to an early negativity and only to a reduced P600. The results suggest a high degree of nativelikeness for the learners during processing of familiar sentences. Unfamiliar words seem to entail additional processing costs and specifically lead to difficulties in the domain of case processing.|ERPs in SLA; N400-P600 patterns in SLA; L2 lexical processing; L2 sentence comprehension; micro-language learning|EVENT-RELATED POTENTIALS; BRAIN POTENTIALS; SYNTACTIC VIOLATIONS; SEMANTIC INCONGRUITY; NONNATIVE SPEAKERS; NATIVE SPEAKERS; WORLD KNOWLEDGE; 2ND-LANGUAGE; N400; AUTOMATICITY|Education \& Educational Research; Linguistics|3|1|10
Analyzing unstructured text data: Using latent categorization to identify intellectual communities in information systems|2008|The Information Systems field is structured by the research topics emphasized by communities of journals. The Latent Categorization Method categorized and automatically named IS research topics in 14,510 abstracts from 65 Information Systems journals. These topics were clustered into seven intellectual communities based on publication patterns. The technique develops categories from the data itself, it is replicable, is relatively insensitive to the size of the text units, and it avoids many of the problems that frequently accompany human categorization. As such LCM provides a new approach to analyzing a wide array of textual data. (C) 2008 Elsevier B.V. All rights reserved.|Latent Categorization Method; Unstructured data analysis; Organization of information systems; Research communities; Subfields; Research topics|KEYWORD CLASSIFICATION SCHEME; MANAGEMENT; ORGANIZATIONS; TECHNOLOGY; PREDICTORS; JOURNALS; SCIENCE; MIS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|25|1|10
EDITING AND GENRE CONFLICT: HOW NEWSPAPER JOURNALISTS CLARIFY AND NEUTRALIZE PRESS RELEASE COPY|2008|Although corporate press releases are `preformulated' to fit sonic of tire conventions of journalistic reports, their style at times seems quite different from the one favoured by journalists. That is, there appear to exist stylistic conflicts between the press release genre and the press report genre. This study investigates the nature of these conflicts by means of a corpus analysis of the reworking strategies employed by journalists that actually use press releases to compose press reports. Roughly, two orientations can be discerned behind the journalistic transformations of release copy: Readability and neutrality. In order to improve readability, journalists create shorter and less complex sentences, use everyday words, replace numbers and symbols by words, and insert short bits of background information. In order to preserve neutrality, they remove company and product names, tone down or remove positive statements, and introduce the company as source for statements they do not want to be responsible for. Sonic trans formations are more complex in that they are carried out in both directions: For instance, the company name may be removed as the subject in a press report sentence, but in other cases it may be introduced in the press report. These, two-way operations are shown to be sensitive to different orientations at the same time. For instance, removing company names from the subject position may help preserve neutrality, while introducing it may personalize the text and hence improve readability. In the discussion, the genre conflict between press releases and press reports is analyzed in terms of the incompatibility of tire stylistic constraints both genres need to satisfy. Some of the incompatibilities derive from differences in the communicative purposes characteristic of the two genres, while others probably have to do with the specific organizational context that co-determines the style of press releases.|Press report; Press release; Genre analysis; Genre conflict; Communicative purpose; Readability; Promotional language; Editing; Writing processes|SYNTAX|Linguistics; Language \& Linguistics|11|0|10
Engaging teachers in language analysis: A functional linguistics approach to reflective literacy|2007|Classrooms around the world are becoming more multilingual and teachers in all subject areas are faced with new challenges in enabling learners' academic language development without losing focus on content. These challenges require new ways of conceptualizing the relationship between language and content as well as new pedagogies that incorporate a dual focus on language and content in subject matter instruction. This article describes three professional development contexts in the U. S., where teachers have engaged in language analysis based on functional linguistics ( for example, Halliday \& Hasan, 1989; Christie, 1989) that has given them new insights into both content and learning processes. In these contexts, teachers in history classrooms with English Language Learners and teachers of languages other than English in classrooms with heritage speakers needed support to develop students' academic language development in a second language. The functional linguistics metalanguage and analysis skills they developed gave them new ways of approaching the texts read and written in their classrooms and enabled them to recognize how language constructs the content they are teaching, to critically assess how the content is presented in their teaching materials, and to engage students in richer conversation about content.|academic language; functional linguistics; L2 language development; reflective literacy|HISTORY; INSTRUCTION|Education \& Educational Research; Linguistics; Language \& Linguistics|36|1|10
Use of orthographic knowledge in reading by Chinese-English Bi-scriptal children|2007|We tested Chinese-English bi-scriptal fourth-graders on reading aloud and comprehension in Chinese and English and their understanding of some structural principles underlying Chinese orthography. These principles concern phonological and semantic representation in written Chinese. Regressions showed that knowledge about phonological representation predicted reading aloud in both Chinese and English. Understanding of semantic representation predicted reading comprehension only in Chinese. To explain these findings, we argue that although young readers find it natural to interpret orthography as representation of sound in either script, looking for broad meaning cues in orthography is more spontaneous in Chinese than English reading. The present findings support the notion that children generally attempt to extract as much phonological and semantic information as possible directly from print in reading, although in many situations, such information provides only very rough cuing on word pronunciation and meaning.|bi-scriptal reading; orthographic processing; reading Chinese; phonological representation; semantic representation; Chinese characters; reading comprehension; novel object labeling|PHONOLOGICAL AWARENESS; DEVELOPMENTAL DYSLEXIA; PHONEMIC AWARENESS; SKILLS; ACQUISITION; ABILITIES; CHARACTER; RADICALS; LANGUAGE; COMPREHENSION|Education \& Educational Research; Linguistics|24|0|10
Text classification: A least square support vector machine approach|2007|This paper presents a least square support vector machine ( LS-SVM) that performs text classification of noisy document titles according to different predetermined categories. The system's potential is demonstrated with a corpus of 91,229 words from University of Denver's Penrose Library catalogue. The classification accuracy of the proposed LS-SVM based system is found to be over 99.9\%. The final classifier is an LS-SVM array with Gaussian radial basis function ( GRBF) kernel, which uses the coefficients generated by the latent semantic indexing algorithm for classification of the text titles. These coefficients are also used to generate the confidence factors for the inference engine that present the final decision of the entire classifier. The system is also compared with a K-nearest neighbor ( KNN) and Naive Bayes ( NB) classifier and the comparison clearly claims that the proposed LS-SVM based architecture outperforms the KNN and NB based system. The comparison between the conventional linear SVM based classifiers and neural network based classifying agents shows that the LS-SVM with LSI based classifying agents improves text categorization performance significantly and holds a lot of potential for developing robust learning based agents for text classification. (c) 2006 Elsevier B. V. All rights reserved.|least square support vector machines; latent semantic indexing; text classification; kernel based learning algorithms|LATENT SEMANTIC ANALYSIS|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|51|3|10
Language contact and confidence in second language listening comprehension: A pilot study of advanced learners of German|2006|Over the past several decades, listening comprehension has not received a great deal of focus in foreign/second language acquisition (SLA) research compared to other skills and competencies. Although there is growing research on instructional techniques and strategies to enhance those skills in the earlier stages of second language (L2) learning, there is little investigation of text-related factors, as well as individual learner factors, that may contribute to advanced-level listening skills. This paper reports on a pilot study on both textual and individual factors for advanced-level listening comprehension. Twenty-seven advanced learners of L2 German served as participants, along with 10 native speaker controls, for multiple-choice listening items including both short and extended listening texts. In addition, a background survey assessed language-con tact factors to look for significant influence on advanced-level listening comprehension. T test and Analysis of Variance (ANOVA) tests show that the nonnative speakers do not differ significantly from the native speaker controls for these tasks, but that confidence in interpreting meaning was significant for certain item types. Correlational analyses point to several language contact factors that indicate both quantity and quality of L2 experience were significant for overall listening comprehension accuracy, as well as for confidence. Based on these preliminary findings, more research is recommended to explore experiential variables that may predict advanced attainment in listening.|adults; German as a second language; learner factors; listening; second language (L2) learning|TOPIC FAMILIARITY; STRATEGIES; FOREIGN; ACQUISITION; SPEECH; SEE|Education \& Educational Research; Linguistics|8|3|10
Impoliteness in Early Modern English courtroom discourse|2006|The paper investigates whether the notion of impoliteness worked out for synchronic pragmatics is also applicable in diachronic pragmatics. An analysis of two Early Modern English court trial records demonstrates that the answer is positive provided some new dimensions are added. My model of impoliteness cuts across the following axes: structural, semantic, and pragmatic. Structural impoliteness ranges from words and phrases to portions of texts, thus the syntactic dimension cuts across the complexity dimension. The semantic/pragmatic dimension includes numerous nonliteral meanings of impoliteness. An utterance can be judged as impolite on the basis of its surface representations ({''}overt impoliteness{''}), or the impoliteness of an expression has to be inferred and takes the form of an implicature ({''}covert impoliteness{''}). Thus, the final interpretation would depend both on the speaker's intention when producing an utterance, its (perlocutionary) effect(s) on the addressee, and the overall context. Finally, all these variables cut across the socio-historical dimension.|Early Modern English; courtroom discourse; (covert/overt) impoliteness; speech act network; discourse markers; questioning strategies; address forms|POLITENESS|Linguistics; Language \& Linguistics|10|0|10
Written discourse and acquired brain impairment: Evaluation of structural and semantic features of personal letters from a Systemic Functional Linguistic perspective|2005|This qualitative study investigated written discourse in the form of personal letters written by ten people with aphasia following stroke and ten people with cognitive-language disorder as a consequence of traumatic brain injury, and compared their performance with 15 non brain-damaged writers. Personal letters perform the dual function of providing information and maintaining social relationships. Using the Systemic Functional Linguistics framework for investigation, letters were examined in terms of their dual functions, and at two different strata of language-generic structure and semantic organisation. A small quantum of research suggests that the dissociation between different strata of language (i.e., macro and micro linguistic abilities), identified in the spoken discourse of people with aphasia and people with cognitive-language disorder is mirrored in written discourse. Aphasic writers largely maintain coherent text structure while writers with cognitive-language impairment demonstrate problems with global text coherence and the episodic structure of texts. Results of the generic structure analysis did not support the hypothesis. However, the semantic Move analysis revealed how diminished linguistic resources, most evident in the letters written by the subjects with aphasia, impacted upon the semantic diversity of the text, as well as the interpersonal function of the personal letter. Variable performance as a feature pathology and normality is highlighted and clinical implications discussed.|acquired brain impairment; aphasia; cognitive-language disorder; written discourse; sociolinguistics|APHASIA; INJURY|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|14|1|10
KDA - A KNOWLEDGE-BASED DATABASE ASSISTANT WITH A QUERY GUIDING FACILITY|1992|Advanced natural language query systems provide database retrieval facilities as an effective means for encouraging novice users to approach computer database systems. However, in these systems, facilities for guiding novice users in performing the database retrieval tasks, such as formulating valid database queries, refining incomplete database queries, and modifying database query misconstruction, have not yet been provided. In this paper, we provide a knowledge-based database assistant (KDA) which integrates a natural language query system with a skeleton-based query guiding facility. When a user works with the KDA natural language query system, the query guiding facility can supply several kinds of skeletons to guide users in performing database retrieval tasks. A semantic network model S-Net has been introduced to represent the knowledge for natural language query processing and skeleton generation. The methods for implementing the system are also discussed in this paper.|DATABASE QUERY SYSTEM; INTELLIGENT DATABASE FRONT END; KNOWLEDGE-BASED SYSTEM; NATURAL LANGUAGE QUERY SYSTEM; SEMANTIC NETWORK MODEL; USER INTERFACE|NATURAL-LANGUAGE; SYSTEM|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|2|0|10
Research patterns and trends in software effort estimation|2017|Context: Software effort estimation (SEE) is most crucial activity in the field of software engineering. Vast research has been conducted in SEE resulting into a tremendous increase in literature. Thus it is of utmost importance to identify the core research areas and trends in SEE which may lead the researchers to understand and discern the research patterns in large literature dataset. Objective: To identify unobserved research patterns through natural language processing from a large set of research articles on SEE published during the period 1996 to 2016. Method: A generative statistical method, called Latent Dirichlet Allocation (LDA), applied on a literature dataset of 1178 articles published on SEE. Results: As many as twelve core research areas and sixty research trends have been revealed; and the identified research trends have been semantically mapped to associate core research areas. Conclusions: This study summarises the research trends in SEE based upon a corpus of 1178 articles. The patterns and trends identified through this research can help in finding the potential research areas. (C) 2017 Elsevier B.V. All rights reserved.|Software effort estimation; Latent Dirichlet allocation; Research trends|DEVELOPMENT COST ESTIMATION; LATENT DIRICHLET ALLOCATION; MULTINOMIAL LOGISTIC-REGRESSION; DEVELOPMENT EFFORT PREDICTION; FUNCTIONAL SIZE MEASUREMENT; SUPPORT VECTOR REGRESSION; OBJECT-ORIENTED SYSTEMS; DEVELOPMENT WORK-EFFORT; LOGIC-BASED FRAMEWORK; ESTIMATION MODELS|Computer Science, Information Systems; Computer Science, Software Engineering|0|9|9
A natural language interface to a graph-based bibliographic information retrieval system|2017|With the ever-increasing volume of scientific literature, there is a need for a natural language interface to bibliographic information retrieval systems to retrieve relevant information effectively. In this paper, we propose one such interface, NLI-GIBIR, which allows users to search for a variety of bibliographic data through natural language. NLI-GIBIR makes use of a novel framework applicable to graph-based bibliographic information retrieval systems in general. This framework incorporates algorithms/heuristics for interpreting and analyzing natural language bibliographic queries via a series of text- and linguistic-based techniques, including tokenization, named entity recognition, and syntactic analysis. We find that our framework, as implemented in NLI-GIBIR, can effectively represent and address complex bibliographic information needs. Thus, the contributions of this paper are as follows: First, to our knowledge, it is the first attempt to propose a natural language interface for graph-based bibliographic information retrieval. Second, we propose a novel customized natural language processing framework that integrates a few original algorithms/heuristics for interpreting and analyzing bibliographic queries. Third, we show that the proposed framework and natural language interface provide a practical solution for building real-world bibliographic information retrieval systems. Our experimental results show that the presented system can correctly answer 39 out of 40 example natural language queries with varying lengths and complexities.|Information retrieval; Natural language interface; Graph database; Data and knowledge visualization; Digital libraries|NAMED ENTITY RECOGNITION; WEB-OF-SCIENCE; SEMANTIC WEB; KNOWLEDGE BASES; GOOGLE-SCHOLAR; DATABASES; SEARCH; SCOPUS; QUERY; MODEL|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|9|9
Joint attention and oromotor abilities in young children with and without autism spectrum disorder|2017|Purpose: This study examined the relationship between joint attention ability and oromotor imitation skill in three groups of young children with and without Autism Spectrum Disorder using both nonverbal oral and verbal motor imitation tasks. Research questions addressed a) differences among joint attention and oromotor imitation abilities; b) the relationship between independently measured joint attention and oromotor imitation, both nonverbal oral and verbal motor; c) the relationships between joint attention and verbal motor imitation during interpersonal interaction; and d) the relationship between the sensory input demands (auditory, visual, and tactile) and oromotor imitation, both nonverbal oral and verbal motor. Method: A descriptive, nonexperimental design was used to compare joint attention and oromotor skills of 10 preschool-aged children with ASD, with those of two control groups: 6 typically developing children (TD), and 6 children with suspected Childhood Apraxia of Speech (sCAS) or apraxic-like symptoms. All children had at least a 3.0 mean length utterance. Results: Children with ASD had poorer joint attention skills overall than children with sCAS or typically developing children. Typically developing children demonstrated higher verbal motor imitation skills overall compared to children with sCAS. Correlational analyses revealed that nonverbal oral imitation and verbal motor imitation were positively related to joint attention abilities only in the children with ASD. Strong positive relationships between joint attention in a naturalistic context (e.g., shared story experience) and oromotor imitation skills, both nonverbal oral and verbal motor, were found only for children with ASD. These data suggest there is a strong positive relationship between joint attention skills and the ability to sequence nonverbal oral and verbal motor movements in children with ASD. The combined sensory input approach involving auditory, visual, and tactile modalities contributed to significantly higher nonverbal oral and verbal motor imitation performance for all groups of children. Conclusions: Verbal children with ASD in this study had difficulties with both the social and cognitive demands of oromotor imitation within a natural environment that demanded cross modal processing of incoming stimuli within an interpersonal interaction. Further, joint attention and oral praxis may serve as components of an important coupling mechanism in the development of spoken communication and later developing socialcognitive skills.|Autism spectrum disorder; Childhood apraxia of speech; Oromotor imitation; Joint attention; Language development|NONVERBAL-COMMUNICATION; CHILDHOOD APRAXIA; FOLLOW-UP; SPEECH; IMITATION; PREDICTORS; PLAY; DIAGNOSIS; DEFICITS; MOTOR|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|0|9|9
What is technicality? A Technicality Analysis Model for EAP vocabulary|2017|The identification of technical words for teaching discipline-specific EAP courses remains a problem for materials designers and teachers alike. This study proposes a method that identifies technicality and measures the degree of technicality of a word. The Technicality Analysis Model (TAM) suggests five levels of technicality: least technical, slightly technical, moderately technical, very technical and most technical. In identifying technicality we take four factors into account: 1) both general and specialised senses of a word; (2) the banding of a word in reference word lists; (3) the polysemy of a word; (4) the literal meaning of a word. The set of categorisation criteria is stringent in the sense that even least technical words may have specialised senses in a specific discipline but those senses may be almost the same as the general sense. All words in more technical categories have specialised senses. We trialled the TAM with 837 financial-sector-specific words generated from a 6.7-million- word corpus of financial texts. Results show that with the categorisation criteria in the technicality analysis, every financial-sector-specific word could be categorised into one of the technical word categories. Future research may use the TAM to develop a repertoire of discipline-specific vocabulary for EAP teaching and learning. (C) 2017 Elsevier Ltd. All rights reserved.|Technicality Analysis Model; Specialised vocabulary; Technical vocabulary; Technicality; Terminology|ACADEMIC VOCABULARY; ENGINEERING ENGLISH; RESEARCH ARTICLES; WORD LIST; STUDENTS; SPECIFICITY; GO|Education \& Educational Research; Linguistics; Language \& Linguistics|2|8|9
Comparing student-selected and teacher-assigned pairs on collaborative writing|2017|Despite the preponderance of theoretical and empirical evidence that suggests the use of pair/group work to promote second language learning, it is still unclear who can best form high performance groups. Should students be allowed to choose their working partners, or should teachers themselves assign students to pairs? This study set out to compare the nature of student-selected and teacher-assigned pairs while they were engaged in collaborative writing. All learner talk was audio recorded, transcribed and analysed for the quantity, type and resolution of language related episodes (LREs) as well as the patterns of dyadic interaction. Furthermore, the study examined the texts produced using both quantitative and qualitative measures. Our findings suggest that the teacher-assigned pairs generated significantly more LREs than the student-selected pairs, while there was no significant difference in the patterns of interaction between the two pairing methods. Meanwhile, the qualitative analysis of learner talk revealed a considerable amount of off-task behavior among the members of student-selected pairs. Moreover, as far as the outcome of pair work (collaborative writing) was concerned, the teacher-assigned pairs noticeably outperformed the student-selected pairs on measures of fluency and accuracy. Also, they produced significantly better texts in terms of organization, grammar and vocabulary.|Language related episodes (LREs); outcome of pair work; patterns of dyadic interaction; student-selected pairing method; teacher-assigned pairing method|TASK-BASED INTERACTION; LEARNERS; ACQUISITION; PROFICIENCY; COMPLEXITY; BEHAVIOR; DIALOGUE; GENDER; WORK; L2|Education \& Educational Research; Linguistics|0|7|9
Task Effects on Linguistic Complexity and Accuracy: A Large-Scale Learner Corpus Analysis Employing Natural Language Processing Techniques|2017|Large-scale learner corpora collected from online language learning platforms, such as the EF-Cambridge Open Language Database (EFCAMDAT), provide opportunities to analyze learner data at an unprecedented scale. However, interpreting the learner language in such corpora requires a precise understanding of tasks: How does the prompt and input of a task and its functional requirements influence task-based linguistic performance? This question is vital for making large-scale task-based corpora fruitful for second language acquisition research. We explore the issue through an analysis of selected tasks in EFCAMDAT and the complexity and accuracy of the language they elicit.|learner corpus; task complexity; complexity; accuracy; fluency (CAF); NLP; TBLT|2ND-LANGUAGE WRITING RESEARCH; SYNTACTIC COMPLEXITY; FOREIGN-LANGUAGE; ACQUISITION; PERFORMANCE; FLUENCY; DISCOURSE; ENGLISH; FRENCH; TBLT|Education \& Educational Research; Linguistics|1|6|9
Strategy use in L2 Chinese reading: The effect of L1 background and L2 proficiency|2017|This study examined the interrelationship among L2 Chinese learners' use of reading strategies, L1 background, and L2 proficiency. Sixty-eight L2 Chinese learners of three different proficiency levels (i.e., elementary, intermediate and advanced) participated in the study. They were categorized further into two L1 groups: those within the Chinese cultural sphere (CCS) and those from the non-Chinese cultural sphere (NCCS). The results, based on analyses of think-aloud reports during reading, are as follows: (a) The use of L2 Chinese reading strategies was affected by L2 proficiency, since there was notable variation in reading strategy type frequency between the elementary level and the intermediate level, but no significant improvement from the intermediate level to the advanced level. (b) The application of decoding strategies remained for a long time regardless of readers' L2 proficiency level. (c) Readers of CCS background appeared to have an advantage in decoding compared to NCCS readers at the elementary level; yet, such an advantage vanished as readers' L2 proficiency level increased, as both CCS and NCCS readers adopted similar types of decoding strategies at the intermediate and advanced levels. Discussion is provided regarding the intricate relationships among L1 background, L2 proficiency, and reading strategy use in L2 Chinese. (C) 2017 Elsevier Ltd. All rights reserved.|Reading strategy; First language background; Second language proficiency; Chinese|COMPREHENSION; KNOWLEDGE; READERS; TEXT|Education \& Educational Research; Linguistics|0|3|9
eHealth patient-provider communication in the United States: interest, inequalities, and predictors|2017|Objective: Health-related Internet use and eHealth technologies, including online patient-provider communication (PPC), are continually being integrated into health care environments. This study aimed to describe sociodemographic and health-and Internet-related correlates that influence adult patients' interest in and electronic exchange of medical information with health care providers in the United States. Methods: Nationally representative cross-sectional data from the 2014 Health Information National Trends Survey (N = 3677) were analyzed. Descriptive statistics and multivariable regression analyses were performed to examine associations between patient-level characteristics and online PPC behavior and interests. Results: Most respondents were Internet users (82.8\%), and 61.5\% of information seekers designated the Internet as their first source for health information. Younger respondents (<50 years), Hispanics, those from higherincome households, and those perceiving access to personal health information as important were more likely to be interested in online PPC. Despite varying levels of patient interest, 68.5\% had no online PPC in the last year. However, Internet users (odds ratio, OR = 2.87, 95\% CI, 1.35-6.08), college graduates (OR = 2.92, 95\% CI, 1.42-5.99), and those with frequent provider visits (OR = 1.94, 95\% CI, 1.02-3.71) had a higher likelihood of online PPC via email or fax, while Hispanics and those from higher-income households were 2-3 times more likely to communicate via text messaging or phone/mobile apps. Conclusion: Patients' interest in and display of online PPC-related behaviors vary by age, race/ethnicity, education, income, Internet access/behaviors, and information type. These findings can inform efforts aimed at improving the use and adoption of eHealth technologies, which may contribute to a reduction in communication inequalities and health care disparities.|electronic patient-provider communication; eHealth; national health survey|NATIONAL TRENDS SURVEY; HEALTH-CARE PROVIDERS; E-MAIL; DIGITAL DIVIDE; MEDICAL-RECORD; TECHNOLOGY USE; INTERNET USE; INFORMATION; PHYSICIANS; ACCESS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|1|2|9
Automated essay evaluation with semantic analysis|2017|Essays are considered as the most useful tool to assess learning outcomes, guide students' learning process and to measure their progress. Manual grading of students' essays is a time-consuming process, but is nevertheless necessary. Automated essay evaluation represents a practical solution to this task, however, its main weakness is the predominant focus on vocabulary and text syntax, and limited consideration of text semantics. In this work, we propose an extension of existing automated essay evaluation systems by incorporating additional semantic coherence and consistency attributes. We design the novel coherence attributes by transforming sequential parts of an essay into the semantic space and measuring changes between them to estimate coherence of the text. The novel consistency attributes detect semantic errors using information extraction and logic reasoning. The resulting system (named SAGE - Semantic Automated Grader for Essays) provides semantic feedback for the writer and achieves significantly higher grading accuracy compared with 9 other state-of-the-art automated essay evaluation systems. (C) 2017 Elsevier B.V. All rights reserved.|Automated scoring; Essay evaluation; Natural language processing; Semantic attributes; Semantic feedback|LOCAL COHERENCE; REDUCTION; COMPUTER|Computer Science, Artificial Intelligence|2|7|9
Toward a more dialogic pedagogy: changing teachers' beliefs and practices through professional development in language arts classrooms|2017|In this paper, we report findings from the second year of a three-year research and professional development program designed to help elementary school teachers engage in dialogic teaching to support the development of students' argument literacy. We define argument literacy as the ability to comprehend and formulate arguments through speaking, listening, reading, and writing. The professional development program was focused on promoting teachers' use of a specific type of talk called `inquiry dialogue' to achieve the goal of developing students' argument literacy. We used a single-group pretest-posttest design to assess the impact of the professional development on teachers' epistemological beliefs and their enactment of inquiry dialogue in text-based discussions. Our analyses of videotaped discussions at the beginning and end of the year showed that there were substantial improvements in teachers' facilitation of inquiry dialogue and in the quality of students' argumentation during discussions. Contrary to expectations, however, there were no changes in teachers' epistemology; teachers' beliefs about knowledge and knowledge justification remained at a relativist stage throughout the course of the program, suggesting that teachers continued to view all opinions as equally valid and regard arguments and the use of reasons and evidence as idiosyncratic.|Classroom dialogue; dialogic; teacher development|PERSONAL EPISTEMOLOGY; INSTRUCTION; TEXT; CONSTRUCTIVISM; ARGUMENTATION; INTERVENTION; KNOWLEDGE; LITERACY; STUDENTS; MODEL|Education \& Educational Research; Linguistics; Language \& Linguistics|2|5|9
What Did You Say? How Did You Say It? Linguistics Choices in Online Discussions|2016|Following appraisal theory (Martin \& White, 2005), which examines the linguistic resources through which texts/speakers express, negotiate, and naturalize particular intersubjective or ideological positions (White, 2015), this study addresses (1) the extent to which second language (L2) learners express their attitudes toward their own and the L2 culture, and (2) the stance L2 learners take when addressing values and behaviors associated with both cultures. Analysis of the linguistic choices of L2 learners in a fourth-year Spanish language class's online discussions revealed that the learners' views and attitudes toward their own culture were somewhat negative, whereas their orientations in relation to the L2 culture were positively skewed. The analysis also illustrated how learners engage or disengage with their own statements and negotiate their ideological positions where the first and second cultures are concerned. Despite certain limitations and a need for further research, this study suggests that appraisal theory can provide insightful and exciting information about L2 learners' attitudes and ideological positioning with regard to first and second cultures, indicating, therefore, that appraisal theory presents itself as a different, complementary approach to research L2 learners' cultural discussions.|appraisal theory; attitudes; computer-mediated communication; discourse analysis|TELECOLLABORATION; PERSPECTIVE; ESSAYS|Education \& Educational Research; Linguistics|0|1|9
Investigating trainee translators' contrastive pragmalinguistic competence: a corpus-based analysis of interclausal linkage in learner translations|2016|This article aims to investigate trainee translators' contrastive pragmalinguistic competence, starting from the assumption that - although more elusively than knowledge about culture-specific references - it represents an important subcomponent of intercultural competence, which can determine the adequacy of translated texts. The study focuses in particular on the translation of interclausal linkage, as it is a form of cohesion which displays different preferences across languages. A multi-parallel corpus of English-to-Italian learner translations of the same source text is analysed to detect regularities and variation in the language behaviour of trainee translators. The frequency of connectives in target texts is compared to both the respective source texts and comparable non-translated Italian texts, in order to determine whether translations are mainly shaped by interference or normalisation. The results of the quantitative analysis confirm previous findings that interference is predominant, with students closely reproducing source text conjunctive patterns at the risk of making translations sound unnatural; more refined qualitative observations, however, reveal that there are also attempts at normalisation. A discussion of the relevance to translator training of the insights obtained is provided, together with suggestions for inclusion in training programmes.|Learner translation; translation competence; contrastive pragmalinguistics; interference; normalisation; multiple translation corpus|ENGLISH; GERMAN|Linguistics; Language \& Linguistics|0|4|9
Oral morphosyntactic competence as a predictor of reading comprehension in children with specific language impairment|2016|Background: Children with a diagnosis of specific language impairment (SLI) present impaired oral comprehension. According to the simple view of reading, general amodal linguistic capacity accounts for both oral and reading comprehension. Considering this, we should expect SLI children to display a reading comprehension deficit. However, previous research regarding the association between reading disorders and SLI has yielded inconsistent results. Aims: To study the influence of prior oral comprehension competence over reading comprehension during the first years of reading acquisition of bilingual Catalan-Spanish children with SLI (ages 7-8). Methods \& Procedures: We assessed groups of bilingual Catalan-Spanish SLI and matched control children at ages 7 and 8 with standardized reading comprehension tasks including grammatical structures, sentence and text comprehension. Early oral competence and prior non-verbal intelligence were also measured and introduced into regression analyses with the participants' reading results in order to state the relation between the comprehension of oral and written material. Outcomes \& Results: Although we found no significant differences between the scores of our two participant groups in the reading tasks, data regarding their early oral competence, but not non-verbal intelligence measures, significantly influence their reading outcome. Conclusions \& Implications: The results extend our knowledge regarding the course of literacy acquisition of children with SLI and provide evidence in support of the theories that assume common linguistic processes to be responsible for both oral and reading comprehension.|reading comprehension; specific language impairment; simple view of reading|ADOLESCENCE; DISORDERS; ABILITIES; OUTCOMES|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|2|5|9
Open-access writing: An investigation into the online drafting and revision of a research article in pure mathematics|2016|ESP research has provided an account of research articles (RAs) across disciplines using both text-analytical methods and ethnographically-oriented approaches. This study explores what additional insights are gained into the genre from the study of a collaboratively produced RA in pure mathematics, negotiated via an open-access research blog. The data consists of 659 thread comments posted by blog participants as they engage with the research and writing up process. Facets of research-based writing that preoccupy the blog participants are revealed, as well as how decisions pertaining to genre and dissemination outlets are made. In addition, blog posts point to how the RA is adjusted to cater for the more diverse readership that open-access knowledge dissemination may entail. The findings provide support for results of existing genre analyses of RAs in pure mathematics, and offer new insights into writing for publication practices in the discipline. Potential pedagogical applications of the findings are proposed. (C) 2016 Elsevier Ltd. All rights reserved.|Blogs; Disciplinary discourse; Pure mathematics; Writing for publication|APPLIED LINGUISTICS; ACADEMIC WEBLOGS; DISCOURSE; ARGUMENT|Linguistics|1|2|9
ERP correlates of prosody and syntax interaction in case of embedded sentences|2016|Understanding spoken language depends on processing the delicate combination of grammatical structure, meaning and prosody of utterances. Previous studies have established that prosody influences the processing of sentences when the grammatical structure is ambiguous, however it is unclear how closely prosody and Syntax are related when there is no ambiguity. In an event-related brain potential (ERP) study, we investigated the processing of embedded normal and pseudosentences in which all function and content words were replaced by meaningless words. Sentences could have either natural prosodic structure or incongruent prosodic structure, where the prosody deviated from the one expected based on the syntactic structure, but otherwise the sentences were unambiguous. The resulting ERP components (CPS) showed that the constructiOn of prosodic structure was similar in normal and pseudosentences, thus suggesting that prosody has an abstract, recursive representation, independent of other linguistic information. Moreover, we found evidence that the incongruent prosody was not only detected (shown by the RAN), but it induced neural reintegration processes (shown by the P600) in spite of the syntactic structure of sentences being intact. These results suggest that the prosodic structure is a mandatory constituent of sentence structure building whenever it is present. (C) 2015 Elsevier Ltd. All rights reserved.|Event related potentials; Closure positive shift; Intonation; Syntax; Embedded sentences|POSITIVE SHIFT; COMPREHENSION; BOUNDARIES; GERMAN; AMBIGUITY; COMPONENT; MARKER; COMMA; CUES|Linguistics; Neurosciences; Psychology, Experimental|3|1|9
Interjectional issues in translation A cross-cultural thematized approach|2016|This paper is trans-cultural approach to the analysis of interjectional and translational issues. `Interjection' is here intended as an umbrella term extended to a range of emotional utterances along a continuum of primary exclamatory remarks (oh, ah), expletives, greetings, and blessings Interjections, however, may feature either as culture-specific items or be universal and international. The present corpus includes a thematic-based selection including written literature, drama, film adaptation, cartoons and sacred texts. The framework of analysis is thematization within a cross-cultural interface.|interjection; translation; pragmatics; Creoles; contact languages|COMICS|Linguistics; Language \& Linguistics|0|4|9
Refining the understanding of novel metaphor in specialised language discourse|2016|Novel metaphorical expressions are understudied in traditional approaches to terminology because they behave as sporadic units incapable of structuring whole discourse events. To show that this assumption is wrong, this paper presents a case study of novel bioeconomics metaphors in an academic marine biology research article (Landa 1998). They were analysed following the Career of Metaphor Theory (Bowdle and Gentner 2005), a framework for the description of novel metaphor in usage, and the text-linguistics approach to term description (Collet 2004), which suggests criteria for term definition that challenge the tenets of monolithic terminology models. The analysis of unexpected metaphors identified in the text suggests that these units should be considered proto-terms experienced as deliberate rhetorical and conceptual devices. Pragmatically speaking, the metaphors are part and parcel of the writer's discursive strategy to communicate specialised knowledge to her peers. Conceptually speaking, the metaphors are essential building blocks of the article's mental model.|novel metaphor and simile; conceptual and rhetorical facets; text-linguistics approach to LSP; career of metaphor theory; marine biology|SCIENTIFIC METAPHORS; FISH|Linguistics; Language \& Linguistics|0|0|9
Prefrontal Cortical Activity During Discourse Processing An Observational fNIRS Study|2016|Discourse is a commonly occurring and cognitively demanding form of naturalistic communication (e.g., conversation, event narration, personal and fictional narratives, text reading/generation). Because of the prevalence of these communication acts in daily routines (e.g., educational, vocational, and social), disrupted discourse is an important target for treatment of persons with cognitive-communication (CC) disorders (American Speech-Language Hearing Association, 2005). However, there is a paucity of information with regard to the underlying cognitive architecture and processing demands associated with the various forms of discourse in non-brain-injured adults. This is, in part, due to a number of methodological constraints of functional neuroimaging technologies such as functional magnetic resonance imaging that severely limit ecologically typical communication acts such as listening and speaking during scanning. To circumvent these issues, this pilot investigation used functional near infrared spectroscopy (fNIRS) to monitor hemodynamic activity in the prefrontal cortex (PFC) during natural discourse-processing tasks in 13 neurologically healthy adult participants. Task demands were manipulated across a variety of discourse types to elucidate the associated neural and cognitive resources. Results indicate that the comprehension of well-organized discourse text is minimally demanding on the PFC. However, discourse production places a significant burden on the PFC and these processing demands generally reflect the relative complexity of the discourse task. These findings are discussed in terms of potential clinically relevant implications with regard to the elicitation, assessment, and remediation of CC impairments in clinical populations.|brain injury; cognitive-communicative disorders; cortical activity; discourse; functional near infrared spectroscopy; speech-language pathology|TRAUMATIC BRAIN-INJURY; TEXT COMPREHENSION; ELICITATION TASK; NARRATIVE SPEECH; LANGUAGE; IMPAIRMENT; COHERENCE; ADULTS; FMRI; CHILDREN|Linguistics; Rehabilitation|3|0|9
Discriminative subprofile-specific representations for author profiling in social media|2015|The Author Profiling (AP) task aims to reveal as much as possible information from a given author's document (e.g., age, gender, etc.). AP is crucial for several applications, ranging from customized advertising to computer forensics, psychology, and entertainment. Nonetheless, the AP task is far from being solved, particularly in social media domains, where the nature of documents hinder the applicability of state-of-the-art text mining tools (e.g., because of spelling-grammar errors, huge vocabularies, and the presence of many out-of-vocabulary terms). Currently, most of the work in AP for social media has been devoted to the development of descriptive features, which are used under standard representations, such as the Bag-of-Words (BoW). Nevertheless, BoW-like representations have some well known shortcomings, namely: (i) the sparsity and high dimensionality of the representation, and (ii) the failure to capture relationships, other than mere occurrence, among terms. This paper focuses on the study of alternative document representations that can deal with such issues. We propose a representation for documents that capture discriminative and subprofile-specific information of terms. Under the proposed representation, terms are represented in a vector space that captures discriminative information. Then, term representations are aggregated to represent the content of a document. In this manner, documents are represented in a low-dimensional (and discriminative) space which is non-sparse. We evaluate the effectiveness of the proposed representation on several corpora from the social media domain. The proposed representation is compared to the standard BoW representation and a wide variety of state-of-the-art AP approaches. Experimental results reveal that the proposed representation outperforms most of the reference methodologies. Furthermore, we show that the proposed representation is in agreement with previous studies on handcrafted attributes for AP. (C) 2015 Elsevier B.V. All rights reserved.|Author profiling; Web mining; Text classification; Social media|SEMANTIC ANALYSIS; LANGUAGE USE; PATTERNS|Computer Science, Artificial Intelligence|8|3|9
``I AM WHAT I AM{''}: MULTILINGUAL IDENTITY AND DIGITAL TRANSLANGUAGING|2015|This paper presents a case study of the multilingual writing practices of a Serbian university student on Facebook, examining how he uses multiple varieties of English and Serbian, images, and video to shape his online identity and establish membership in local and global communities. Drawing on data from stimulated-recall interviews, online participant observation, and rhetorical analysis, this study shows how Aleksandar, a hip-hop artist, appropriates hip-hop codes and employs the ``gate-keeping{''} function of posting links (Baek, Holton, Harp, \& Yaschur, 2011) by embedding links to music videos in his own highly personal code-mixed text in order to establish himself as a distinctly Serbian member of the global hip-hop community. The findings suggest that Aleksandar's language practices and attitudes might be better understood as translingual (Canagarajah, 2011), as the student integrates diverse linguistic and semiotic resources into a unified expression of identity, relying on the multimodal affordances of digital writing to accomplish his communicative goals. However, these sophisticated textual practices go undervalued in his EFL writing courses, where formal, monolingual, non-digital literacy remains primary (Saxena, 2011). These findings suggest a need to re-evaluate what it means to have a second language-mediated identity, and to expand the focus of EFL writing pedagogy.|ICT Literacies; Identity; Multimodal Texts; Social Networking; Technology-Mediated Communication|SOCIAL NETWORKING; GLOBAL ENGLISHES; LITERACY; FACEBOOK|Education \& Educational Research; Linguistics|5|2|9
Singing for the dead, on and off line: Diversity, migration, and scale in Mexican Muertos music|2015|This article examines the recent emergence of online debates about Day of the Dead music, one of countless sites worldwide where conversations about diversity take place in the shadow of state policies. There, people engage diversity not through the state-centric ``managerial discourse{''} of ``diversity talk{''} but through localized interpretations of sameness and difference. I discuss the social effects of semiotic processes through which people consider sameness and difference: the emergence of a regional venue for debating contentious issues and the consolidation of an implicit consensus of linguistic practice. Attending to local understandings of difference can reduce the risk of taking state-sponsored views of (linguistic) diversity as natural kinds while recovering diversity and surrounding ideologies as ethnographic objects. (C) 2014 Elsevier Ltd. All rights reserved.|Ideologies of difference; Indigeneity; Online communication; Music; Scale; Mexico|LANGUAGE; POLITICS|Communication; Linguistics|4|2|9
A CORPUS APPROACH FOR AUTONOMOUS TEACHERS AND LEARNERS: IMPLEMENTING AN ON-LINE CONCORDANCER ON TEACHERS' LAPTOPS|2015|The present article deals with the issue of how to create and operate a customizable on-line concordancer from viewpoints of language teachers and with their own laptops. It aims to introduce how to use and manage this application without relying on computer engineers for various pedagogical purposes, focusing on the four beneficial dimensions of its interface and technical features: accessibility, simplicity, functionality, and manageability. In addition, the carefully written directions illustrate how to implement this open-source application on laptops using pre-established or customized corpora. For those in the field of language teaching and learning, this application is designed to allow teachers to operate different types or levels of corpora in separate spaces on one server and to enable multiple simultaneous connections in classroom contexts. Ultimately, the authors believe that this application will not only allow students to actively experience data-driven learning anywhere and anytime, but also will help teachers manage their own version of this on-line concordancer by autonomously uploading any kinds of source texts for corpus analysis at their pedagogical discretion.|Autonomy; (on-line) Concordancer; Corpus Analysis; Data-Driven Learning|LANGUAGE|Education \& Educational Research; Linguistics|4|1|9
Balloons and bavoons versus spikes and shikes: ERPs reveal shared neural processes for shape-sound-meaning congruence in words, and shape-sound congruence in pseudowords|2015|There is something about the sound of a pseudoword like takete that goes better with a spiky, than a curvy shape (Kohler, 1929:1947). Yet despite decades of research into sound symbolism, the role of this effect on real words in the lexicons of natural languages remains controversial. We report one behavioural and one ERP study investigating whether sound symbolism is active during normal language processing for real words in a speaker's native language, in the same way as for novel word forms. The results indicate that sound-symbolic congruence has a number of influences on natural language processing: Written forms presented in a congruent visual context generate more errors during lexical access, as well as a chain of differences in the ERP. These effects have a very early onset (40-80 ms, 100-160 ms, 280-320 ms) and are later overshadowed by familiar types of semantic processing, indicating that sound symbolism represents an early sensory-co-activation effect. (C) 2015 Elsevier Inc. All rights reserved.|Sound symbolism; Event related potentials; Lexical decision; Implicit interference; Language processing|AUTISM SPECTRUM DISORDERS; TAKETE-MALUMA PHENOMENON; LEXICAL ACCESS; CASCADE MODEL; SYMBOLISM; CORRESPONDENCES; SYNAESTHESIA; RECOGNITION; PERCEPTION; VOCABULARY|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|8|1|9
Production and comprehension show divergent constituent order preferences: Evidence from elicited pantomime|2015|All natural languages develop devices to communicate who did what to whom. Elicited pantomime provides one model for studying this process, by providing a window into how humans (hearing non-signers) behave in a natural communicative modality (silent gesture) without established conventions from a grammar. Most studies in this paradigm focus on production, although they sometimes make assumptions about how comprehenders would likely behave. Here, we directly assess how naive speakers of English (Experiments 1 \& 2). Korean (Experiment 1), and Turkish (Experiment 2) comprehend pantomimed descriptions of transitive events, which are either semantically reversible (Experiments 1 \& 2) or not (Experiment 2). Contrary to previous assumptions, we find no evidence that PERSON-PERSON-ACTION sequences are ambiguous to comprehenders, who simply adopt an agent-first parsing heuristic for all constituent orders. We do find that PERSON-ACTION-PERSON sequences yield the most consistent interpretations, even in native speakers of SOV languages. The full range of behavior in both production and comprehension provides counter-evidence to the notion that producers' utterances are motivated by the needs of comprehenders. Instead, we argue that production and comprehension are subject to different sets of cognitive pressures, and that the dynamic interaction between these competing pressures can help explain synchronic and diachronic constituent order phenomena in natural human languages, both signed and spoken. (C) 2014 Elsevier Inc. All rights reserved.|Word order; Production; Comprehension; Pantomime; Gesture; Sign language|WORD-ORDER; COMMUNICATION-SYSTEM; EVOLUTION; LANGUAGE|Linguistics; Psychology; Psychology, Experimental|3|1|9
Stancetaking and the joint construction ofzine producer identities in a researchinterview|2015|This article examines the construction of zine producer identities (self and other) during a research interview. Zines are self-published texts that circulate in mainly underground communities. In this study, I draw on dialogic understandings of the notion of stance' to show how a zine producer accomplishes a situated identity performance in the interview that also functions as an interdiscursive move in a larger conversation about the role Do-It-Yourself (DIY) ethics should play in zine communities. Specifically, Ishow how this speaker displays stances in relation to recognizable social types within zine communities but also the canonical stances associated with these social types. I unpack the features that work in support of this stancetaking, including discourse markers, constructed dialogue, referring terms, and prosodic cues. The analysis also foregrounds how the interviewer's turns contributed to these emergent stance displays, which furthers our understanding of the dynamic social context of the research interview.|Stance; identity; discourse analysis; zines; research interviews|DISCOURSE; ZINES|Linguistics|1|1|9
Language Learner Investment and Identity Negotiation in the Korean EFL Context|2015|Most research on language and identity has been conducted in contexts in which English is an official language. As a result, the Western-derived framework guiding identity research may not be representative for L2 learners/speakers in localized settings. To address this potential disparity, this qualitative study examines L2 identity construction and negotiation in the local context of Korea and investigates how English shapes self and social identity through actual use of English in day-to-day interaction. Using purposive homogenous sampling techniques, open-ended questionnaires and in-depth interviews were conducted with 10 adult bilingual Korean-English speakers who have lived abroad for over 4 years, a criterion which assumes the formation of self and social identity aside from their native L1. Analysis of the interview and questionnaire data reveals the challenges and opportunities to reconstruct and renegotiate L1/L2 identities locally. Findings show (1) challenges in using English in the local context, (2) strategic use or non-use of language to blend in or distinguish themselves from the local population, and (3) ``natural{''} L2 expression and identity occurring mainly in private or professional circumstances. Findings suggest that L2 identity negotiation in local contexts is a complex process raising the question of L2 identity options and (dis)empowerment. Pedagogical implications relating to L2 language instruction follow.|identity; Korea; English; foreign language learning|SOUTH-KOREA; SELF|Education \& Educational Research; Linguistics; Language \& Linguistics|1|1|9
Combining automatic table classification and relationship extraction in extracting anticancer drug-side effect pairs from full-text articles|2015|Anticancer drug-associated side effect knowledge often exists in multiple heterogeneous and complementary data sources. A comprehensive anticancer drug-side effect (drug-SE) relationship knowledge base is important for computation-based drug target discovery, drug toxicity predication and drug repositioning. In this study, we present a two-step approach by combining table classification and relationship extraction to extract drug-SE pairs from a large number of high-profile oncological full-text articles. The data consists of 31,255 tables downloaded from the Journal of Oncology (JCO). We first trained a statistical classifier to classify tables into SE-related and -unrelated categories. We then extracted drug-SE pairs from SE-related tables. We compared drug side effect knowledge extracted from JCO tables to that derived from FDA drug labels. Finally, we systematically analyzed relationships between anti-cancer drug-associated side effects and drug-associated gene targets, metabolism genes, and disease indications. The statistical table classifier is effective in classifying tables into SE-related and -unrelated (precision: 0.711; recall: 0.941; F1: 0.810). We extracted a total of 26,918 drug-SE pairs from SE-related tables with a precision of 0.605, a recall of 0.460, and a Fl of 0.520. Drug-SE pairs extracted from JCO tables is largely complementary to those derived from FDA drug labels; as many as 84.7\% of the pairs extracted from JCO tables have not been included a side effect database constructed from FDA drug labels. Side effects associated with anticancer drugs positively correlate with drug target genes, drug metabolism genes, and disease indications. (C) 2014 Elsevier Inc. All rights reserved.|Text mining; Information extraction; Cancer drug side effect; Drug discovery; Drug repositioning; Drug toxicity prediction|LARGE-SCALE; BIOMEDICAL LITERATURE; SIGNAL-DETECTION; SAFETY; PREDICTION; DISCOVERY; KNOWLEDGE; PROFILES; NETWORK; EVENTS|Computer Science, Interdisciplinary Applications; Medical Informatics|3|1|9
Modeling workflow to design machine translation applications for public health practice|2015|Objective: Provide a detailed understanding of the information workflow processes related to translating health promotion materials for limited English proficiency individuals in order to inform the design of context-driven machine translation (MT) tools for public health (PH). Materials and methods: We applied a cognitive work analysis framework to investigate the translation information workflow processes of two large health departments in Washington State. Researchers conducted interviews, performed a task analysis, and validated results with PH professionals to model translation workflow and identify functional requirements for a translation system for PH. Results: The study resulted in a detailed description of work related to translation of PH materials, an information workflow diagram, and a description of attitudes towards MT technology. We identified a number of themes that hold design implications for incorporating MT in PH translation practice. A PH translation tool prototype was designed based on these findings. Discussion: This study underscores the importance of understanding the work context and information workflow for which systems will be designed. Based on themes and translation information workflow processes, we identified key design guidelines for incorporating MT into PH translation work. Primary amongst these is that MT should be followed by human review for translations to be of high quality and for the technology to be adopted into practice. Conclusion: The time and costs of creating multilingual health promotion materials are barriers to translation. PH personnel were interested in MT's potential to improve access to low-cost translated PH materials, but expressed concerns about ensuring quality. We outline design considerations and a potential machine translation tool to best fit MT systems into PH practice. (C) 2014 Elsevier Inc. All rights reserved.|Public health informatics; Workflow; Public health practice; Natural language processing; Human centered design|ECOLOGICAL INTERFACE DESIGN; PROVIDER ORDER ENTRY; TASK-ANALYSIS; INFORMATION; CARE; DISPARITIES; BARRIERS; QUALITY; SYSTEMS; COSTS|Computer Science, Interdisciplinary Applications; Medical Informatics|1|1|9
(Im)politeness strategies in social networks: A comparative analysis of Facebook and Twitter|2015|The aim of this paper is to analyze the (im)politeness present in two popular social networks in Spain, namely Facebook and Twitter, using both quantitative and qualitative comparative studies. To do this, comments made to a publication that contains exactly the same text that was written by the same journalist are analyzed, firstly, on his Facebook profile, and, secondly, on his Twitter profile. In conclusion, a wide use of impoliteness in both social networks has been observed; more specifically, the discursive categories of impoliteness reach 70.66\% of the corpus on Facebook, and 60.66\% on Twitter, and the discourse on Facebook is generally found to be rather more offensive.|pragmatics; (im) politeness; social networks; Facebook; Twitter|IMPOLITENESS|Linguistics; Language \& Linguistics|0|0|9
Engagement and graduation resources as markers of translator/interpreter positioning|2015|This article examines the application of appraisal theory (Martin and White 2005) to the analysis of translation. It develops the findings in Munday (2012), which focused on attitudinal meanings, and explores the potential for the use of engagement resources and graduation as a means of determining translator/interpreter positioning. Using a range of examples from texts of international organizations, it discusses the translation of reporting verbs and intensification as a signal of the translator's/interpreter's degree of `investment' in a proposition and control over the text receiver's response. This is framed within the concept of `discourse space theory' (Chilton 2004) to provide a reference for future work in this field.|discourse analysis; translation; evaluation; appraisal theory; reporting verbs; translator positioning|VERBS|Linguistics; Language \& Linguistics|1|2|9
Grammaticalization or pragmaticalization of discourse markers? More than a terminological issue|2015|Discourse markers are a crucial component of natural language, which is why a description and account of their diachronic evolution must be part of our linguistic models. However, researchers have different views on whether this evolution should be accounted for in terms of grammaticalization and/or pragmaticalization. In this paper, we provide a structured overview of the accounts given for the diachronic evolution of DMs. It is shown that the different positions encountered in the literature can be brought back to diverging views on the conceptualization of grammar, the categorization of discourse markers, and the weight that is put on specific processes involved in the diachronic change. We provide case studies for each of the positions that we present and discuss.|discourse markers; grammaticalization; pragmaticalization|FRENCH CAUSAL CONNECTIVES; PARCE-QUE; ENGLISH; CONSTRUCTIONS; SUBJECTIVITY; UTTERANCE; PARTICLE; DUTCH; CAR|Linguistics; Language \& Linguistics|8|1|9
Towards a dialogic syntax|2014|This paper argues for the need to recognize a new order of syntactic phenomena, and for a theory of syntax capable of addressing it. Dialogic syntax encompasses the linguistic, cognitive, and interactional processes involved when speakers selectively reproduce aspects of prior utterances, and when recipients recognize the resulting parallelisms and draw inferences from them. Its most visible reflex occurs when one speaker constructs an utterance based on the immediately co-present utterance of a dialogic partner. Words, structures, and other linguistic resources invoked by the first speaker are selectively reproduced by the second. The alignment of utterances yields a pairing of patterns at varying levels of abstraction, ranging from identity of words and affixes, to parallelism of syntactic structures, to equivalence of grammatical categories and abstract features of form, meaning, and function. This mapping generates dialogic resonance, defined as the catalytic activation of affinities across utterances. The key unit of analysis is the diagraph, recognized as a higher-order, supra-sentential syntactic structure that emerges from the structural coupling of two or more utterances. Dialogic syntax goes beyond traditional linear syntax to recognize as integral to the task of syntactic analysis a new kind of structural relation that arises between otherwise independent sentences.|dialogic syntax; resonance; parallelism; structure-mapping; structure-coupling; priming; analogy; diagraph; dialogicality; prior text|DISCOURSE ANALYSIS; COGNITIVE GRAMMAR; STANCE; CONVERSATION; LANGUAGE; RESONANCE; FRAMEWORK; ORGANIZATION; SIMILARITY; REPETITION|Linguistics; Language \& Linguistics|43|3|9
Voiceless ends: Melville's Benito Cereno and the translator in narrative discourse|2014|The first part of this article confronts the ways in which translation scholars have drawn on insights from narratology to make sense of the translator's involvement in narrative texts. It first considers competing metaphors for conceptualizing the translator's involvement, arguing for a clearer differentiation between modes of framing and telling. Next, it evaluates the ways in which translation scholars have attempted to integrate the translator as a separate textual agent in governing models of narrative communication, concluding that the conceptual gains to be reaped from positing the translator as a separate enunciator or agent in narrative transactions are limited. The second part of the article analyzes two Dutch translations of Herman Melville's novella Benito Cereno, by Johan Palm (1950) and Jean Schalekamp (1977) respectively. Rather than striving to isolate the translators as separate tellers or co-producers of narrative structure, the analysis reveals that their agency shows foremost in the ways the `voiceless' narrative of New World slavery is perspectivized in view of changing readerly expectations.|(Double) focalization; double negation; implied author/translator; narrative voice; narratology; (re-)translation|IMPLIED-AUTHOR|Linguistics; Language \& Linguistics|1|0|9
Faceted navigation through keyword interaction|2014|A text usually contains multiple semantic units corresponding to various reading requests from users. One semantic unit represents a topic that people are interested in reading. A meaningful combination of semantic units can represent a certain aspect of the text. This paper proposes a mechanism that can extract the semantic units from text according to the keywords representing users' interests and can organise semantic units into facets reflecting certain aspects of a text. The mechanism can display facets of a text with a set of operations. The proposed mechanism considers human reading process. With this mechanism, readers can quickly obtain the interested content from a large text. Experiments show its effectiveness and robustness.|faceted navigation; human factor; text analysis; web search|DIGITAL LIBRARIES; RETRIEVAL; MODEL|Computer Science, Information Systems; Computer Science, Software Engineering|3|0|9
Generation of a phonetic transcription for modern standard Arabic: A knowledge-based model|2014|This paper outlines a comprehensive system for automatically generating a phonetic transcription of a given Arabic text which closely matches the pronunciation of the speakers. The presented system is based on a set of (language-dependent) pronunciation rules that works on converting fully diacriticised Arabic text into the actual sounds, along with a lexicon for exceptional words. This is a two-phase process: one-to-one grapheme to phoneme conversion and then phoneme-to-allophone conversion using a set of ``phonological rules{''}. Phonological rules operate on the phonemes and convert them to the actual sounds considering the neighbouring phones or the containing syllable or word. This system is developed for the purpose of delivering a robust Automatic Arabic Speech Recognition (AASR) system which is able to handle speech variation resulting from the mismatch between the text and the pronunciation. We anticipate that it could also be used for producing natural sounding speech from an Arabic text-to-speech (ATTS) system as well, but we have not extensively tested it in this application. (C) 2014 Elsevier Ltd. All rights reserved.|Phonological rules; Phonetic transcription; Speech processing; Modern standard Arabic; Sound-spelling correspondences|EMPHASIS SPREAD; STRESS|Computer Science, Artificial Intelligence|2|0|9
Evaluation of the Mining Techniques in Constructing a Traditional Chinese-Language Nursing Recording System|2014|In 2009, the Department of Health, part of Taiwan's Executive Yuan, announced the advent of electronic medical records to reduce medical expenses and facilitate the international exchange of medical record information. An information technology platform for nursing records in medical institutions was then quickly established, which improved nursing information systems and electronic databases. The purpose of the present study was to explore the usability of the data mining techniques to enhance completeness and ensure consistency of nursing records in the database system. First, the study used a Chinese word-segmenting system on common and special terms often used by the nursing staff. We also used text-mining techniques to collect keywords and create a keyword lexicon. We then used an association rule and artificial neural network to measure the correlation and forecasting capability for keywords. Finally, nursing staff members were provided with an on-screen pop-up menu to use when establishing nursing records. Our study found that by using mining techniques we were able to create a powerful keyword lexicon and establish a forecasting model for nursing diagnoses, ensuring the consistency of nursing terminology and improving the nursing staff's work efficiency and productivity.|Chinese nursing records system; Data mining; Text mining|INFORMATION-SYSTEMS|Computer Science, Interdisciplinary Applications; Medical Informatics; Nursing|0|0|9
Appraisal Theory applied to the wine tasting sheet in English and Spanish|2014|The main goal of this study is the application of Appraisal Theory (Martin \& White, 2005) developed in the framework of Systemic Functional Linguistics to wine tasting sheets. Firstly, whether this text type meets the defining requirements specified by Swales (1990) for the discursive genre will be verified. 110 tasting sheets in Spanish and English extracted from the Internet have been grouped into four corpora corresponding to the country of origin of the wine: Spain, Australia, California and New Zealand. An analysis undertaken with Word Smith Tools has demonstrated the positive polarization of all the texts and the existence of cultural differences reflected in the use of fruit-related terms, adjectives oenological terms and ``oenological culturemes{''} (Wislocka Breit, 2012). An unforeseen result of the study was the strong contrast observed between the free and literary manner of the English and the concise style of Spanish tasting sheets.|genre; tasting sheet; Appraisal Theory; winespeak; cultureme|WINESPEAK|Linguistics; Language \& Linguistics|3|1|9
Syntactic parsing of clinical text: guideline and corpus development with handling ill-formed sentences|2013|Objective To develop, evaluate, and share: (1) syntactic parsing guidelines for clinical text, with a new approach to handling ill-formed sentences; and (2) a clinical Treebank annotated according to the guidelines. To document the process and findings for readers with similar interest. Methods Using random samples from a shared natural language processing challenge dataset, we developed a handbook of domain-customized syntactic parsing guidelines based on iterative annotation and adjudication between two institutions. Special considerations were incorporated into the guidelines for handling ill-formed sentences, which are common in clinical text. Intra- and inter-annotator agreement rates were used to evaluate consistency in following the guidelines. Quantitative and qualitative properties of the annotated Treebank, as well as its use to retrain a statistical parser, were reported. Results A supplement to the Penn Treebank II guidelines was developed for annotating clinical sentences. After three iterations of annotation and adjudication on 450 sentences, the annotators reached an F-measure agreement rate of 0.930 (while intra-annotator rate was 0.948) on a final independent set. A total of 1100 sentences from progress notes were annotated that demonstrated domain-specific linguistic features. A statistical parser retrained with combined general English (mainly news text) annotations and our annotations achieved an accuracy of 0.811 (higher than models trained purely with either general or clinical sentences alone). Both the guidelines and syntactic annotations are made available at https://sourceforge.net/projects/medicaltreebank. Conclusions We developed guidelines for parsing clinical text and annotated a corpus accordingly. The high intra- and inter-annotator agreement rates showed decent consistency in following the guidelines. The corpus was shown to be useful in retraining a statistical parser that achieved moderate accuracy.|natural language processing; syntactic parsing; annotation guidelines; corpus development|RADIOLOGY REPORTS; INFORMATION; EXTRACTION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|3|0|9
Toward a situation model in a cognitive architecture|2013|The ability to coherently represent information that is situationally relevant is vitally important to perform any complex task, especially when that task involves coordinating with team members. This paper introduces an approach to dynamically represent situation information within the ACT-R cognitive architecture in the context of a synthetic teammate project. The situation model represents the synthetic teammate's mental model of the objects, events, actions, and relationships encountered in a complex task simulation. The situation model grounds textual information from the language analysis component into knowledge usable by the agent-environment interaction component. The situation model is a key component of the synthetic teammate as it provides the primary interface between arguably distinct cognitive processes modeled within the synthetic teammate (e.g., language processing and interactions with the task environment). This work has provided some evidence that reasoning about complex situations requires more than simple mental representations and requires mental processes involving multiple steps. Additionally, the work has revealed an initial method for reasoning across the various dimensions of situations. One purpose of the research is to demonstrate that this approach to implementing a situation model provides a robust capability to handle tasks in which an agent must construct a mental model from textual information, reason about complex relationships between objects, events, and actions in its environment, and appropriately communicate with task participants using natural language. In this paper we describe an approach for modeling situationally relevant information, provide a detailed example, discuss challenges faced, and present research plans for the situation model.|Synthetic teammate; Situation model; Mental model; Language comprehension; Language generation; Knowledge representation; Computational cognitive model|LANGUAGE COMPREHENSION; WORKING-MEMORY|Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods|2|0|9
Evaluation of Health Alerts From an Early Illness Warning System in Independent Living|2013|Passive sensor networks were deployed in independent living apartments to monitor older adults in their home environments to detect signs of impending illness and alert clinicians so they can intervene and prevent or delay significant changes in health or functional status. A retrospective qualitative deductive content analysis was undertaken to refine health alerts to improve clinical relevance to clinicians as they use alerts in their normal workflow of routine care delivery to older adults. Clinicians completed written free-text boxes to describe actions taken (or not) as a result of each alert; they also rated the clinical significance (relevance) of each health alert on a scale of 1 to 5. Two samples of the clinician's written responses to the health alerts were analyzed after alert algorithms had been adjusted based on results of a pilot study using health alerts to enhance clinical decision-making. In the first sample, a total of 663 comments were generated by seven clinicians in response to 385 unique alerts; there are more comments than alerts because more than one clinician rated the same alert. The second sample had a total of 142 comments produced by three clinicians in response to 88 distinct alerts. The overall clinical relevance of the alerts, as judged by the content of the qualitative comments by clinicians for each alert, improved from 33.3\% of the alerts in the first sample classified as clinically relevant to 43.2\% in the second. The goal is to produce clinically relevant alerts that clinicians find useful in daily practice. The evaluation methods used are described to assist others as they consider building and iteratively refining health alerts to enhance clinical decision making.|Aging in place; Independent living; Long-term care; Technology|NURSE CARE COORDINATION; OLDER-ADULTS; RECOGNITION; TECHNOLOGY|Computer Science, Interdisciplinary Applications; Medical Informatics; Nursing|10|0|9
Written production in primary education: narrative analysis of students in Chilean public schools|2013|The study is aimed at understanding and describing the production of written narratives according to the criteria of coherence, cohesion, textual organization, development of ideas, and adequacy to the stimulus instruction. It is intended to describe the most common difficulties and errors in a sample of 414 texts produced by 3rd, 5th, 6th, and 7th grade children studying at public (state) schools in low socioeconomic status districts. The texts were evaluated through rubrics developed and validated during the study. Results suggest that students can produce a global meaning in their narratives but have a small repertoire of connectors and co-referential devices for their schooling level. They also reveal that students have internalized a basic narrative structure, although their resolutions are mostly inadequate. The development of detailed ideas with a precise lexicon improves when the total number of words written increases, with females performing better than males in this aspect.|written production; assessment of writing; writing difficulties; writing instruction|GRADE STUDENTS; INSTRUCTION; PERFORMANCE; KNOWLEDGE|Linguistics; Language \& Linguistics|2|0|9
The Voice of Leadership: Models and Performances of Automatic Analysis in Online Speeches|2012|We introduce the automatic determination of leadership emergence by acoustic and linguistic features in online speeches. Full realism is provided by the varying and challenging acoustic conditions of the presented YouTube corpus of online available speeches labeled by 10 raters and by processing that includes Long Short-Term Memory-based robust voice activity detection (VAD) and automatic speech recognition (ASR) prior to feature extraction. We discuss cluster-preserving scaling of 10 original dimensions for discrete and continuous task modeling, ground truth establishment, and appropriate feature extraction for this novel speaker trait analysis paradigm. In extensive classification and regression runs, different temporal chunkings and optimal late fusion strategies (LFSs) of feature streams are presented. In the result, achievers, charismatic speakers, and teamplayers can be recognized significantly above chance level, reaching up to 72.5 percent accuracy on unseen test data.|Personality analysis; dimensional analysis; acoustic/linguistic fusion|TRANSACTIONAL LEADERSHIP; PERSONALITY; TESTS; CLASSIFICATION; METAANALYSIS; RECOGNITION; TEXT|Computer Science, Artificial Intelligence; Computer Science, Cybernetics|9|1|9
SMOOTHING THE ROUGH EDGES: TOWARDS A TYPOLOGY OF DISCLAIMERS IN RESEARCH ARTICLES|2012|Disclaimers are generally defined as devices employed to ward off and defeat doubts and negative typifications which may result from intended conduct (Hewitt \& Stokes 1975). In academic prose, writers also take advantage of disclaimers to remove any probable infelicities that could occur as a result of their research or language choices in an attempt to promote the precision and persuasive power of their text. In order to develop a clearer understanding of disclaiming in research articles (RAs), a sample of 120 RAs was selected to identify and discuss different types of disclaimers. The qualitative analysis of the corpus led to introduce six disjunctive types of disclaimers employed by writers of RAs: overt vs. covert, excluder vs. includer, internal vs. external, antecedent vs. subsequent, warning vs. clarification, and local vs. global. Each has been discussed with reference to authentic examples from various journals. Furthermore, a list of formal varieties is developed along with an opinion of what they typically target and where they tend to occur. The paper concludes with a definition of disclaimers in RAs.|Academic writing; Disclaimers; Metadiscourse; Propositions; Quality|ACADEMIC DISCOURSE; METADISCOURSE; LINGUISTICS; ENGLISH; STANCE|Linguistics; Language \& Linguistics|0|1|9
An ontology for clinical questions about the contents of patient notes|2012|Objective: Many studies have been completed on question classification in the open domain, however only limited work focuses on the medical domain. As well, to the best of our knowledge, most of these medical question classifications were designed for literature based question and answering systems. This paper focuses on a new direction, which is to design a novel question processing and classification model for answering clinical questions applied to electronic patient notes. Methods: There are four main steps in the work. Firstly, a relatively large set of clinical questions was collected from staff in an Intensive Care Unit. Then, a clinical question taxonomy was designed for question and answering purposes. Subsequently an annotation guideline was created and used to annotate the question set. Finally, a multilayer classification model was built to classify the clinical questions. Results: Through the initial classification experiments, we realized that the general features cannot contribute to high performance of a minimum classifier (a small data set with multiple classes). Thus, an automatic knowledge discovery and knowledge reuse process was designed to boost the performance by extracting and expanding the specific features of the questions. In the evaluation, the results show around 90\% accuracy can be achieved in the answerable subclass classification and generic question templates classification. On the other hand, the machine learning method does not perform well at identifying the category of unanswerable questions, due to the asymmetric distribution. Conclusions: In this paper, a comprehensive study on clinical questions has been completed. A major outcome of this work is the multilayer classification model. It serves as a major component of a patient records based clinical question and answering system as our studies continue. As well, the question collections can be reused by the research community to improve the efficiency of their own question and answering systems. (C) 2011 Elsevier Inc. All rights reserved.|Classification; Electronic health records; Natural language processing|INFORMATION; CARE; PHYSICIANS; CLASSIFICATION; OBSTACLES; AGREEMENT; RETRIEVAL; KNOWLEDGE; DATABASE; DOCTORS|Computer Science, Interdisciplinary Applications; Medical Informatics|8|0|9
Hesitation and monitoring phenomena in bilingual speech: A consequence of code-switching or a strategy to facilitate its incorporation?|2011|Hesitation and monitoring phenomena (hereafter HMP) are forms that occur in speech such as filled or unfilled pauses, paralinguistic markers such as (nervous) laughter or coughing, or signals which pre-empt or justify other forms in utterances. The functions of these forms have commonly been associated with planning or accessing difficulties. However, HMP can also have a function of signalling clause boundaries, changes of mood or topic, aiding intelligibility for listeners. This paper draws on a large sample of bilingual speech and examines the overall incidence of HMP from two contributing languages, Croatian and English, and their incidence in speech containing code-switching. Analysis of results seeks to establish whether there is disproportionately high frequency of HMP surrounding code-switches, and whether such HMP are indicative of accessing/production difficulties concomitant to the appearance of code-switches, or appear to perform a function that facilitates the intelligibility of code-switches. HMP co-occur disproportionately with code-switches. However, analysis of code-switching examples shows that different types of code-switches attract higher or lower frequencies of HMP, depending on their phonological and/or morphological form. Although not identical to discourse markers, HMP perform a congruent function, that of integrating or facilitating the incorporation of `other language' text. (C) 2011 Elsevier B.V. All rights reserved.|Hesitation phenomena; Metalinguistic awareness; Discourse markers; Code-switching; Bilingual speech|DISCOURSE MARKERS; ENGLISH SPEECH; FILLED PAUSES; SPEAKERS; DISFLUENCIES; LISTENERS; PROSODY; REPAIR; ERRORS; UM|Linguistics; Language \& Linguistics|6|1|9
Intended and unintended effects of language planning: insights from an orthography debate in Cyprus|2011|This paper presents key insights from the analysis of a language debate in Cyprus, triggered when a number of individuals and groups refused to endorse the standardisation of the orthography of place names and the argumentation through which it was supported. The paper is based on a collection of newspaper texts and related documents and is informed by interviews with participants on either side of the debate. Drawing from work on language ideologies and orthography debates (e.g. Blommaert 1999; Kroskrity 2000; Schieffelin et al. 1998; Johnson 2005; Sebba 2007), this paper aims to make three key arguments. Firstly, language planning in this case did not measure up against changing sociolinguistic realities, as the standardisation committee disregarded or rejected changes in current practices and pluralist language ideologies that had been gaining ground, both in the academia and in lay perceptions. Secondly, the argumentation the committee developed so as to support its decisions, together with its negative connotations for the local dialect, played a major role in the way the standardisation project was perceived and responded to. Thirdly, the scepticism and scorn the standardisation was greeted with during its implementation stage can be attributed, partially, to specific linguistic choices by policy makers carrying negative indexicalities, which were then projected onto their users and the project (Irvine and Gal 2000). The paper concludes with some implications for language policy and planning practice and research.|Standardisation; Orthography; Debate; Language ideologies; Indexicalities; Dialect; Greek; Cyprus|IDEOLOGY; ISSUES|Education \& Educational Research; Linguistics; Language \& Linguistics|0|0|9
Between irony and humor A pragmatic model|2011|The goal of this paper is to propose a model that distinguishes between irony and humor in the context of literary texts. The comparative model was constructed based on existing models, and elaborated on them, substantiating the model through textual analysis focusing on cues for irony (Clark and Gerrig 1984; Grice 1975, 1978; Haverkate 1990; Sperber and Wilson 1981; Wilson and Sperber 1992;) and cues for humor (Alexander 1997; Jeffers 1995; Oring 1989; Raskin and Attardo 1994). The research was based on four conceptual paradigms: pragmatic studies of irony, pragmatic studies of humor, a pragmatic approach to the study of literary texts, and theories of text interpretation. The textual analysis was based on an existing model for the interpretation of indirect speaker's meanings (Dascal and Weizman 1987; Weizman and Dascal 1991; 2005), and on the concepts ``cues{''} and ``clues{''} as employed in that model.|clue; cue; humor; irony; pragmatics; textual analysis|VERBAL IRONY; PRETENSE THEORY; TEXT|Linguistics; Language \& Linguistics|11|2|9
Multimodal representations of identity in the English-as-an-additional-language classroom in South Africa|2011|This paper explores the multimodal engagement of English-as-an-additional-language (EAL) students in a classroom in Johannesburg. Within a social semiotic framework, and using constructions of design and identity to understand the students' multimodal engagement, the paper argues that multimodal representations offer EAL students from under-resourced contexts opportunities for creativity and agency to redesign meaning. It demonstrates how they use the opportunities provided to reconstruct their identities as black South Africans and to communicate a sense of their own social world. The analysis focuses on two texts produced by the students - a digital narrative text and a poetry performance - to illustrate their multimodal engagement with literacy. The paper concludes with an examination of the broader implications for teaching and learning EAL.|multimodality; English as an additional language; South Africa; identity; social semiotics; teaching implications|MULTILITERACIES|Education \& Educational Research; Linguistics; Language \& Linguistics|4|0|9
Quantifiers more or less quantify on-line: ERP evidence for partial incremental interpretation|2010|Event-related brain potentials were recorded during RSVP reading to test the hypothesis that quantifier expressions are incrementally interpreted fully and immediately. In sentences tapping general knowledge (Farmers grow crops/worms as their primary source of income), Experiment 1 found larger N400s for atypical (worms) than typical objects (crops). Experiment 2 crossed object typicality with non-logical subject noun phrase quantifiers (most, few). Offline plausibility ratings exhibited the crossover interaction predicted by full quantifier interpretation: Most farmers grow crops and Few farmers grow worms were rated more plausible than Most farmers grow worms and Few farmers grow crops. Object N400s, although modulated in the expected direction, did not reverse. Experiment 3 replicated these findings with adverbial quantifiers (Farmers often/rarely grow crops/worms). Interpretation of quantifier expressions thus is neither fully immediate nor fully delayed. Furthermore, object atypicality was associated with a frontal slow positivity in few-type/rarely quantifier contexts, suggesting systematic processing differences among quantifier types. (C) 2010 Elsevier Inc. All rights reserved.|Quantifier; Incremental interpretation; Brain potential; ERP; N400; Language comprehension|GOOD-ENOUGH REPRESENTATIONS; EYE-MOVEMENTS; LANGUAGE COMPREHENSION; BRAIN POTENTIALS; COUNTERFACTUAL WORLDS; SCOPE AMBIGUITIES; LINGUISTIC FOCUS; NATURAL-LANGUAGE; SENTENCE; VERIFICATION|Linguistics; Psychology; Psychology, Experimental|23|0|9
Contextual information in terminological knowledge bases: A multimodal approach|2010|In Lexicology and Terminology, the notion of context often refers to a textual excerpt selected according to syntactic criteria, leaving aside any semantic and pragmatic analysis. For the creation of terminological knowledge bases (TKBs), this notion is too simplistic Contexts must be studied from an integrated approach, such as Frame Semantics and Frame-Based Terminology These theoretical and methodological frameworks do not separate the semantic and pragmatic components of language Meaning is acquired in context, more specifically. within a frame including a semantic and pragmatic background Within the domain of the environment, we select and manipulate multimodal information to offer two kinds of contexts to the end-user (1) FrameNet-like contexts, more specifically, sentences showing the different syntactic constructions of the frame elements and the target predicate, (2) combined contexts, including knowledge-rich linguistic contexts coupled with knowledge-rich visual contexts, which provide a comprehensive view of related processes and specialized lexical units In the TKB EcoLexicon, the resulting multimodal contexts are structured in terms of specific frames and general events Thus, the end-users have the possibility to find both cognitive and communicative information, which is selected according to the user's level of expertise (c) 2009 Elsevier B.V. All rights reserved|Frame-Based Terminology; FrameNet; Terminology; Context; Multimodal contexts|PHOTOGRAPHS; FRAMENET; IMAGES; TEXT|Linguistics; Language \& Linguistics|14|2|9
Stuttering after right cerebellar infarction: A case study|2010|We report a male patient with neurogenic stuttering after cerebellar infarction. He had suffered from frontal and thalamus damage and he had exhibited aphasia, but his speech had been fluent until onset of the cerebellar infarction. Results of analysis of speech samples included the following: (1) the patient showed very frequent syllable repetition and part-word repetition. (2) The stuttering occurrence rate at the second test was much higher than at the first test. (3) Almost all stuttering occurred on initial word sounds: stuttering on the medial and final word was less frequent. (4) Adaptation effect was absent. (5) Secondary behaviors such as closing of the eyes and grimacing were observed. The internal model related to cerebellar functions can be modified using feedback-error information. Results suggest that internal model dysfunction caused this patient's stuttering. Educational objectives: After reading this text, the reader will be able to: (1) provide characteristics of neurogenic stuttering after the cerebellum infarction: (2) discuss the relationship between neurogenic stuttering and functions of the cerebellum. (C) 2010 Elsevier Inc. All rights reserved.|Neurogenic stuttering; Cerebellum; Internal model|ADULTS|Audiology \& Speech-Language Pathology; Education, Special; Linguistics; Rehabilitation|6|0|9
Collaborative scaffolding in online task-based voice interactions between advanced learners|2010|This paper reports some of the findings of a distinctive innovative use of audio-conferencing involving a population (campus-based advanced learners) and a type of application (task-based language learning) that have received little attention to date: the use of Wimba Voice Tools to provide additional opportunities for spoken interactions between advanced learners of French. The experiment had a dual aim: (a) to examine the suitability of Wimba Voice Tools as an environment for sustained interactive talk, and (b) to study the nature of interactions between advanced learners, with particular reference to the processes supporting collaborative activity. After a brief summary of the rationale and main characteristics of the experiment, the paper focuses on the strategies used by three non-native speaker (NNS) dyads to resolve language problems as they worked on a set of four tasks. Extending the classical model of negotiation for meaning to cover other instances of language-related episodes identified through discourse analysis of the empirical data, the study offers a detailed account of the incidence and nature of negotiated interaction and collaboration between partners. This leads to a discussion covering the impact of functionalities, scaffolding and task effects. The paper ends with some suggestions for future research.|Voice chat; negotiation for meaning; learner collaboration; scaffolding; task effects; advanced learners|MEDIATED NEGOTIATED INTERACTION; LANGUAGE; CONVERSATIONS; PATTERNS; MODEL; CHAT; TEXT|Education \& Educational Research; Linguistics; Language \& Linguistics|9|0|9
Reflective Random Indexing and indirect inference: A scalable method for discovery of implicit connections|2010|The discovery of implicit connections between terms that do not occur together in any scientific document underlies the model of literature-based knowledge discovery first proposed by Swanson. Corpus-derived statistical models of semantic distance such as Latent Semantic Analysis (LSA) have been evaluated previously as methods for the discovery of such implicit connections. However, LSA in particular is dependent on a computationally demanding method of dimension reduction as a means to obtain meaningful indirect inference, limiting its ability to scale to large text corpora. In this paper, we evaluate the ability of Random Indexing (RI), a scalable distributional model of word associations, to draw meaningful implicit relationships between terms in general and biomedical language. Proponents of this method have achieved comparable performance to LSA on several cognitive tasks while using a simpler and less computationally demanding method of dimension reduction than LSA employs. In this paper, we demonstrate that the original implementation of RI is ineffective at inferring meaningful indirect connections, and evaluate Reflective Random Indexing (RRI), an iterative variant of the method that is better able to perform indirect inference. RRI is shown to lead to more clearly related indirect connections and to outperform existing RI implementations in the prediction of future direct co-occurrence in the MEDLINE corpus. (C) 2009 Elsevier Inc. All rights reserved.|Distributional semantics; Literature-based discovery; Implicit associations; Indirect inference|LATENT SEMANTIC ANALYSIS; GENERATING HYPOTHESES; FISH-OIL; KNOWLEDGE; REPRESENTATION; RAYNAUDS; SYSTEMS; SPACE|Computer Science, Interdisciplinary Applications; Medical Informatics|44|1|9
Generic title labeling for clustered documents|2010|Document clustering is a powerful technique to detect topics and their relations for information browsing, analysis, and organization. However, clustered documents require post-assignment of descriptive titles to help users interpret the results. Existing techniques often assign labels to clusters based only on the terms that the clustered documents contain, which may not be sufficient for some applications. To solve this problem, a cluster labeling algorithm for creating generic titles, based on external resources Such as WordNet, is proposed. Our method first extracts category-specific terms as cluster descriptors. These descriptors are then mapped to generic terms based on a hypernyrn search algorithm. The proposed method has been evaluated on a patent document collection and a subset of the Reuters-21578 collection. Experimental results revealed that our method performs as anticipated. Real-case applications of these generic terms show promising in assisting humans in interpreting the clustered topics. Our method is general enough such that it can be easily extended to use other hierarchical resources for adaptable label generation. (C) 2009 Elsevier Ltd. All rights reserved.|Hypernym search; Clustering labeling; WordNet; Correlation coefficient; Topic identification|TEXT|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|19|1|9
Automatic summarization of MEDLINE citations for evidence-based medical treatment: A topic-oriented evaluation|2009|As the number of electronic biomedical textual resources increases, it becomes harder for physicians to find useful answers at the point of care. Information retrieval applications provide access to databases; however, little research has been done on using automatic summarization to help navigate the documents returned by these systems. After presenting a semantic abstraction automatic summarization system for MEDLINE citations, we concentrate on evaluating its ability to identify useful drug interventions for 53 diseases. The evaluation methodology uses existing sources of evidence-based medicine as surrogates for a physician-annotated reference standard. Mean average precision (MAP) and a clinical usefulness score developed for this study were computed as performance metrics. The automatic summarization system significantly outperformed the baseline in both metrics. The MAP gain was 0.17 (p < 0.01) and the increase in the overall score of clinical usefulness was 0.39 (p < 0.05). Published by Elsevier Inc.|Natural language processing; Semantic processing; Automatic summarization; Evidence-based medicine; Knowledge representation; Artificial intelligence; Evaluation|CLINICAL QUESTIONS; BIOMEDICAL TEXT; RETRIEVAL; KNOWLEDGE; FRAMEWORK; QUALITY; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|24|1|9
Computational assessment of lexical differences in L1 and L2 writing|2009|The purpose of this paper is to provide a detailed analysis of how lexical differences related to cohesion and connectionist models can distinguish first language (L1) writers of English from second language (L2) writers of English. Key to this analysis is the use of the computational tool Coh-Metrix, which measures cohesion and text difficulty at various levels of language, discourse, and conceptual analysis, and a statistical method known as discriminant function analysis. Results show that L1 and L2 written texts vary in several dimensions related to the writer's use of lexical choices. These dimensions correlate to lexical depth of knowledge, variation, and sophistication. These findings, together with the relevance of the new computational tools for the text analysis used in the study, are discussed. (C) 2009 Elsevier Inc. All rights reserved.|Second language writing; Lexical proficiency; Corpus linguistics; Computational linguistics; Cohesion; Lexical networks|LATENT SEMANTIC ANALYSIS; TEXT COMPREHENSION; WORD MEANINGS; ACQUISITION; LANGUAGE; VOCABULARY; IMAGERY; MODEL|Linguistics|46|1|9
Psychiatric document retrieval using a discourse-aware model|2009|With the increased incidence of depression-related disorders, many psychiatric websites have been developed to provide huge amounts of educational documents along with rich self-help information. Psychiatric document retrieval aims to assist individuals to locate documents relevant to their depressive problems efficiently and effectively. By referring to relevant documents, individuals can understand how to alleviate their depression-related symptoms according to recommendations from health professionals. This work proposes the use of high-level discourse information extracted from queries and documents to improve the precision of retrieval results. The discourse information adopted herein includes negative life events, depressive symptoms and semantic relations between symptoms, which are beneficial for better understanding of users' queries. Experimental results show that the discourse-aware retrieval model achieves higher precision than the word-based retrieval models, namely the vector space model (VSM) and Okapi model, adopting word-level information alone. (c) 2008 Elsevier B.V. All rights reserved.|Natural language processing; Information retrieval; Discourse structure; Discourse-aware model; Sequence kerne function; Discounted cumulative gain|STRESSFUL LIFE EVENTS; TEXT RETRIEVAL; WEB RESOURCES; ONTOLOGY; ARTICLES; IDENTIFICATION; ARGUMENTATION; BIBLIOTHERAPY; EXTRACTION; RELEVANCE|Computer Science, Artificial Intelligence|14|0|9
Syntactic complexity and ambiguity resolution in a free word order language: Behavioral and electrophysiological evidences from Basque|2009|In natural languages some syntactic structures are simpler than others. Syntactically complex structures require further computation that is not required by syntactically simple structures. In particular, canonical, basic word order represents the simplest sentence-structure. Natural languages have different canonical word orders, and they vary in the degree of word order freedom they allow. In the case of free word order, whether canonical word order plays any role in processing is still unclear. In this paper, we present behavioral and electrophysiological evidence that simpler, canonical word order preference is found even in a free word order language. Canonical and derived structures were compared in two self-paced reading and one ERPs experiment. Non-canonical sentences required further syntactic computation in Basque, they showed longer reading times and a modulation of anterior negativities; and P600 components providing evidence that even in free word order, case-marking grammars, underlying canonical word order can play a relevant role in sentence processing. These findings could signal universal processing mechanisms because similar processing patterns are found in typologically very distant grammars. We also provide evidence from syntactically fully ambiguous Sequences. Our results on ambiguity resolution showed that fully ambiguous sequences were processed as canonical sentences. Moreover, when fully ambiguous Sequences were forced to complex interpretation by means of the world knowledge of the participants, a frontal negativity distinguished simple and complex ambiguous sequences. Thus the preference of simple structures is presumably a universal design property for language processing, despite differences on parametric variation of a given grammar. (C) 2009 Elsevier Inc. All rights reserved.|Linguistic complexity; Word order processing; Syntactic processing; ERPs; Canonicity; Basque; Ergativity|BRAIN POTENTIALS; RELATIVE CLAUSES; WORKING-MEMORY; PSYCHOLINGUISTIC STATISTICS; SENTENCE COMPREHENSION; ERP; FREQUENCY; INTEGRATION; VIOLATIONS; DEPENDENCIES|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|32|1|9
When is it appropriate to talk? Managing overlapping talk in multi-participant voice-based chat rooms|2009|There has been extensive reporting on the interactional characteristics of multi-participant text-based chat rooms. In these chat rooms there are several students typing at the same time, often on more than one topic. As a result, it is not uncommon to see multiple overlapping utterances. Despite these communicative challenges, research suggests that multi-participant text-based chat rooms are beneficial for language teaching and learning. It is my objective to investigate whether the same can be said for multi-participant voice-based chat rooms. As there is little empirical work on the interaction that results from communicating in voice-based chat rooms, a necessary first step in discussing pedagogical benefits is to investigate its interactional structure. This study will therefore focus on how overlapping talk is dealt with in a medium in which multiple voices are heard in the absence of nonverbal cues. The findings show how pauses act in connection to overlapping talk, both as a source and an interactional resource. These findings will then be used to discuss the pedagogical implications of communicating in multi-participant voice-based chat rooms.|computer-mediated communication; conversation analysis; turn-taking; overlapping talk|TEXT|Education \& Educational Research; Linguistics; Language \& Linguistics|17|1|9
Identities on paper Constructing lives for people with intellectual disabilities in life story books|2009|This paper examines how life story books were used in two care settings in the UK for people with complex support needs. The context of the research was the transition of six people from a long stay hospital to a community home. Discourse analysis was used to analyse talk and texts in the care settings including staff interviews, meetings and the written text in the life story books. Three uses of the books are highlighted in the analysis. They were used as a resource for: getting to know the person; defining the person; and displaying personality and uniqueness. Mutual identities of the various participants were constantly changing with reference to the life story books. It is suggested that the books encourage acceptance in the care relationships. The analysis demonstrated that despite the different uses of the life story books, highlighted by the care staff, there is an underlying assumption that what is written in the books is a direct representation of the person. It appears that once this type of information is committed to paper the identity of the person becomes reified.|life story; identities; intellectual disabilities; discourse analysis|LEARNING-DIFFICULTIES; CARE; HISTORY; ADULTS; STAFF; WORK|Communication; Linguistics; Language \& Linguistics|2|0|9
AGE, GENDER AND SOCIOECONOMIC STATUS INFLUENCES ON PHONOLOGICAL DEVELOPMENT IN CHILDREN FROM 3 TO 6 YEARS OF AGE|2009|This study approaches phonological development in children from the natural phonology theory, focusing on the possible impact of age, socioeconomic status (SES), and gender. The sample total consisted of 360 children (176 female subjects and 184 male subjects) exhibiting normal language development and ranging from 3 to 6 years of age. The sample was split in four different groups of 90 subjects each considering a between-groups age factor (3.0-3.11; 4.0-4.11, 5.0-5.11 and 6.0-6.11) and within group SES factor (30 lower-middle class children, 30 middle class children and 30 upper-middle class children). The phonological simplification processes was scored using the TEPROSIF-R. The analysis showed that a) as children move from age 3 to age 6 they display a significant tendency to suppress phonological simplification processes in their productions, b) SES generates a significant distinction between children, especially when comparing lower-middle class children with upper-middle class children, and c) gender does not impact in the observed frequency of phonological simplification processes.|Phonological development; natural phonology theory; socioeconomic status; gender|ENGLISH BILINGUAL-CHILDREN; RISK-FACTORS; SPANISH-SPEAKING; LANGUAGE; SPEECH; REPRESENTATIONS; IMPAIRMENT; PATTERNS; HISTORY; SKILLS|Linguistics; Language \& Linguistics|6|1|9
Inferencing and cultural reproduction: a corpus-based critical discourse analysis|2009|On 1 May 2004, the European Union (EU) expanded to twenty-five countries, eight of the ten new countries being from Eastern Europe. Around six weeks prior to this date, the popular British tabloid, The Sun, began to conduct a quasi-campaign which highlighted the detrimental effects of probable immigration from Eastern European countries to the United Kingdom. This article investigates a 26,000-word corpus of quasi-campaign texts from The Sun. I employ Wordsmith Tools 5.0, and a British National Corpus reference corpus, BNC-baby (four million words), to help locate regular ``strategies{''} in The Sun corpus which promote this quasi-campaign, and which position regular target readers into acceptance of them. In turn, I show how cultural reproduction of ideas about projected Eastern European immigration to the United Kingdom call take place in reading a text from The Sun on May 1 which announces the F. U expansion. The main focus of this paper is at the ``interpretation{''} stage of CDA (Fairclough 2001). In other words, I make air interpretation of how cultural reproduction call take place over the six weeks indicated. Finally, I use corpus evidence to enhance a CDA ``explanation{''} of the May 1 text in highlighting it as a barometer of social change.|corpus-based CDA; keywords; cultural reproduction; contrastive inferences; deductive inferences|METAPHOR|Communication; Linguistics; Language \& Linguistics|6|0|9
Veridical and false memory for text: A multiprocess analysis|2008|People report recognizing discourse inferences at rates that approach target acceptance. Brainerd et al. {[}Brainerd, C. J., Wright, R., Reyna, V. F., \& Mojardin, A. H. (2001). Conjoint recognition and phantom recollection. Journal of Experimental Psychology: Learning, Memory, and Cognition, 27, 307-329] proposed that memory retrieval in contexts associated with very high levels of false memory involve a process of illusory recollection which complements the impact of recollection and familiarity {[}Jacoby, L. L. (1991). A process dissociation framework: Separating automatic from intentional uses of memory. Journal of Memory and Language, 30, 513-541]. Experiments were conducted to compare three multiprocess models of text retrieval: A three-process ``phantom recollection{''} model; and two dual-process models, respectively lacking mechanisms of veridical recollection and phantom recollection. Participants read lists of brief texts and then evaluated explicit, implicit, and foil memory probes. Different participant groups were instructed to use verbatim, verbatim plus gist, or gist-only memory-criteria. Multinomial processing tree analysis indicated that both immediate and delayed testing require the involvement of phantom recollection (Experiments 1 and 2, respectively). When the participant's extraction of text meaning is impaired, a dual-process model is adequate to fit the data (Experiment 3). (c) 2008 Elsevier Inc. All rights reserved.|text; memory; recognition; inference; representation; process dissociation; false memory; dual-process|PROCESS DISSOCIATION PROCEDURE; PROCESSING TREE MODELS; RECOLLECTION REJECTION; CONJOINT RECOGNITION; ELABORATIVE INFERENCES; UNCONSCIOUS INFLUENCES; PRAGMATIC INFERENCES; BRIDGING INFERENCES; DIVIDED ATTENTION; BRIEF PASSAGES|Linguistics; Psychology; Psychology, Experimental|11|1|9
Hemispheric asymmetries in semantic processing: Evidence from false memories for ambiguous words|2008|Previous research suggests that the left hemisphere (LH) focuses on strongly related word meanings; the right hemisphere (RH) may contribute uniquely to the processing of lexical ambiguity by activating and maintaining a wide range of meanings, including subordinate meanings. The present study used the word-lists false memory paradigm {[}Roediger, H. L. Ill., \& McDermott, K. B. (1995). Creating false memories: Remembering words not presented in lists. Journal of Experimental Psychology: Learning, Memory, and Cognition, 21, 803-814.] to examine whether these differences between the two cerebral hemispheres in semantic processing also affect memory representations for different meanings of ambiguous words. Specifically, we tested the differences between the LH and RH in recollecting unpresented. semantically related, ambiguous words following the presentation of lists of words all related to either the dominant or the subordinate meanings of these ambiguous words. Findings showed that for the unpresented ambiguous words, the LH made more false alarms than the RH for the dominant lists, whereas the opposite pattern emerged for subordinate lists. Moreover, d' analyses showed that, whereas the LH was more sensitive to subordinate than dominant meanings, the RH showed no differences in sensitivity for the two types of word-lists. Taken as a whole, these results support the RH coarse semantic coding theory {[}Beeman, M. (1998). Coarse semantic coding and discourse comprehension. In Beeman \& M., Chiarello, C. (Eds.), Right hemisphere language comprehension: Perspectives from cognitive neuroscience (pp. 255-284). Mahwah, NJ: Erlbaum; Jung-Beeman, M. (2005). Bilateral brain processes for comprehending natural language. Trends in Cognitive Sciences, 9, 512-518.] indicating that during word recognition, the RH activates and maintains a broader and less differentiated range of related meanings than the LH, including both dominant and subordinate meanings of ambiguous words. Furthermore, the findings suggest that hemispheric differences in ambiguity resolution during language processing extend also to verbal memory. (C) 2007 Elsevier Inc. All rights reserved.|visual fields; hemispheres; false memory; semantic processing; lexical ambiguity|VENTROLATERAL PREFRONTAL CORTEX; ILLUSORY RECOGNITION MEMORY; CEREBRAL HEMISPHERES; MCDERMOTT PARADIGM; LEXICAL AMBIGUITY; REMEMBERING WORDS; SENSORY SIGNATURE; BRAIN POTENTIALS; RECALL; TRUE|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|16|0|9
Manner-of-motion verbs in wine description|2007|Manner-of-motion verbs are frequently used in English narratives to portray motion events in vivid terms. This use of motion verbs contrasts with their use in non-narrative texts where the verbs are used to qualify static entities, and often instantiate figurative phenomena. The present paper explores the use of motion verbs in the descriptive-plus-evaluative genre of the wine tasting note. The discussion draws upon the results of an ongoing research project dealing with figurative language in wine discourse, and is theoretically anchored in research done in cognitive linguistics. My goals in this paper are two: on the one hand, I describe the way the expressions are used in the genre and the reasons underlying this use; on the other, I discuss the figurative motivation of the motion verbs in the genre under analysis, particularly their reliance on synesthetic metaphor and metonymy, respectively. (C) 2007 Elsevier B.V. All rights reserved.|manner-of-motion verbs; winespeak; genre; fictive motion; synesthesia; metonymy|LANGUAGE|Linguistics; Language \& Linguistics|26|0|9
Generating and evaluating evaluative arguments|2006|Evaluative arguments are pervasive in natural human communication. In countless situations people attempt to advise or persuade their interlocutors that something is desirable (vs. undesirable) or right (vs. wrong). With the proliferation of on-line systems serving as personal advisors and assistants, there is a pressing need to develop general and testable computational models for generating and presenting evaluative arguments. Previous research on generating evaluative arguments has been characterized by two major limitations. First, researchers have tended to focus only on specific aspects of the generation process. Second, the proposed approaches were not empirically tested. The research presented in this paper addresses both limitations. We have designed and implemented a complete computational model for generating evaluative arguments. For content selection and organization, we devised an argumentation strategy based on guidelines from argumentation theory. For expressing the content in natural language, we extended and integrated previous work in computational linguistics on generating evaluative arguments. The key knowledge source for both tasks is a quantitative model of user preferences. To empirically test critical aspects of our generation model, we have devised and implemented an evaluation framework in which the effectiveness of evaluative arguments can be measured with real users. Within the framework, we have performed an experiment to test two basic hypotheses on which the design of the computational model is based; namely, that our proposal for tailoring an evaluative argument to the addressee's preferences increases its effectiveness, and that differences in conciseness significantly influence argument effectiveness. The second hypothesis was confirmed in the experiment. In contrast, the first hypothesis was only marginally confirmed. However, independent testing by other researchers has recently provided further support for this hypothesis. (C) 2006 Elsevier B.V. All rights reserved.|natural language generation; user tailoring; preferences; empirical evaluation|MODEL; TEXT; EXPLANATION; PREFERENCES; DISCOURSE; COHERENCE; COGNITION; DIALOGUE; SYSTEM; NEED|Computer Science, Artificial Intelligence|46|1|9
Fast mapping of words and story recall by individuals with down syndrome|2004|This study compared adolescents with Down syndrome to nonverbal mental-age matched controls in their ability to fast map new noun vocabulary in spoken story contexts. Context for novel words varied within subjects in the distance between mentions (close-distant) and the ease of inferring a real word for the referent (specificity). The 23 participants with Down syndrome (DS) were aged 12.8-20.3 years. The 24 typically developing (TD) children, matched on visual nonverbal mental age (MA), were 4.1 to 6.1 years old. Participants listened to 4 tape-recorded stories, each containing 3 mentions of 2 novel words in close or distant proximity and with clear or uncertain reference, and recalled each story after presentation. Fast-mapping production was measured by the occurrence of the novel word in story recall. Fast-mapping comprehension was measured by asking children to define the novel words. The DS group did not differ from the TD group in novel word production but seemed to have more difficulty with novel word definition. For both groups, novel word production was higher in the nonspecific than the specific referent condition, suggesting that availability of a real word label interfered with fast mapping. Recall of story propositions was poorer for the DS group. For both groups, story recall was better for text units not directly associated with novel words than for text units containing novel words, suggesting a trade-off effect in processing. Regression analyses indicated that syntax comprehension, rather than mean length of utterance, predicted novel word production in both groups; MA additionally contributed to predict DS story recall.|fast mapping; memory; narratives; Down syndrome; language disorders|SHORT-TERM-MEMORY; LANGUAGE PRODUCTION; YOUNG-CHILDREN; ADOLESCENTS; COMPREHENSION; ACQUISITION; SKILLS|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|19|1|9
Electrophysiological correlates of prosody and punctuation|2003|Psycholinguistic models of sentence parsing are primarily based on reading rather than auditory processing data. Moreover, both prosodic information and its potential orthographic equivalent, i.e., punctuation, have been largely ignored until recently. The unavailability of experimental online methods is one likely reason for this neglect. Here I give an overview of six event-related brain potential (ERP) studies demonstrating that the processing of both prosodic boundaries in natural speech and commas during silent reading can determine syntax parsing immediately. In ERPs, speech boundaries and commas reliably elicit a similar online brain response, termed the Closure Positive Shift (CPS). This finding points to a common mechanism, suggesting that commas serve as visual triggers for covert phonological phrasing. Alternative CPS accounts are tested and the relationship between the CPS and other ERP components, including the P600/SPS, is addressed. (C) 2003 Elsevier Science (USA). All rights reserved.|event-related potentials; language; prosody; punctuation; syntax; commas; P600; Closure Positive Shift; CPS; garden path sentences|BRAIN POTENTIALS; SPOKEN SENTENCES; WORKING-MEMORY; POSITIVE SHIFT; LANGUAGE; INFORMATION; COMPREHENSION; HYPOTHESIS; AMBIGUITY; RESPONSES|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|82|2|9
An ERP study of continuous speech processing I. Segmentation, semantics, and syntax in native speakers|2003|Speech segmentation, breaking continuous streams of sound into units that can be recognized, is a necessary step in auditory language processing. To date, most studies of speech segmentation have been limited to behavioral measures that may not index online segmentation as it occurs when listening to natural speech. In, the present study, we measured event-related potentials (ERPs) evoked by word-initial and word-medial syllables equated for loudness, length, and phonemic content. This comparison provided an online measure of natural speech segmentation. Word-initial sounds elicited a larger early sensory component (N100). In addition, we measured the effects of semantic and syntactic information on speech segmentation by comparing ERPs to word-initial and word-medial syllables in sentences with varying amounts of semantic and syntactic content. The results indicated that neither semantic nor syntactic information is necessary for the word-onset segmentation effect to be observed. We also identified additional ERP components that index more general semantic and syntactic aspects of natural speech processing. (C) 2002 Elsevier Science B.V. All rights reserved.|speech segmentation; temporal parsing; speech perception; auditory; language; lexical|EVENT-RELATED POTENTIALS; BRAIN POTENTIALS; WORD SEGMENTATION; SPOKEN SENTENCES; TIME-COURSE; LANGUAGE; CUES; INFANTS; VIOLATIONS; COMPONENTS|Computer Science, Artificial Intelligence; Neurosciences; Neuroimaging|51|1|9
Friend or foe: the defamation or legitimate and necessary criticism? Reflections on recent political discourse in Austria|2002|This paper illustrates the necessity of very differentiated approaches to context when analyzing political discourses. Specifically, the case of antisemitic rhetoric will be regarded because antisemitic beliefs were tabooed in official domains, in postwar Austria. Nevertheless, politicians continued to use such prejudices for political purposes. Certain linguistic devices, like presuppositions and insinuations can only be understood and interpreted when enough co-text and context knowledge is assumed. The paper argues for an interdisciplinary approach in the Social Sciences, because such complex problems, like populism, racism or antisemitism cannot be grasped by one traditional discipline. It also argues for an intertextual approach which regards historical developments and socio-political factors while analyzing discourses. (C) 2002 Elsevier Science Ltd. All rights reserved.|critical discourse analysis; allusion; antisemitic discourse; rightwing populist rhetoric; theories of context; postwar Austria|RACISM|Communication; Linguistics|10|3|9
Prosody-based automatic segmentation of speech into sentences and topics|2000|A crucial step in processing speech audio data for information extraction, topic detection, or browsing/playback is to segment the input into sentence and topic units. Speech segmentation is challenging, since the cues typically present for segmenting text (headers, paragraphs, punctuation) are absent in spoken language. We investigate the use of prosody (information gleaned from the timing and melody of speech) for these tasks. Using decision tree and hidden Markov modeling techniques, we combine prosodic cues with word-based approaches, and evaluate performance on two speech corpora, Broadcast News and Switchboard. Results show that the prosodic model alone performs on par with, or better than, word-based statistical language models - for both true and automatically recognized words in news speech. The prosodic model achieves comparable performance with significantly less training data, and requires no hand-labeling of prosodic events. Across tasks and corpora, we obtain a significant improvement over word-only models using a probabilistic combination of prosodic and lexical information. Inspection reveals that the prosodic models capture language-independent boundary indicators described in the literature. Finally, cue usage is task and corpus dependent. For example, pause and pitch features are highly informative for segmenting news speech, whereas pause, duration and word-based cues dominate for natural conversation. (C) 2000 Elsevier Science B.V. All rights reserved.|sentence segmentation; topic segmentation; prosody; information extraction; automatic speech recognition; broadcast news; switchboard|LANGUAGE MODEL; DISCOURSE; TEXT|Acoustics; Computer Science, Interdisciplinary Applications|172|1|9
An empirical study of algorithms for point-feature label placement|1995|A major factor affecting the clarity of graphical displays that include text labels is the degree to which labels obscure display features (including other labels) as a result of spatial overlap. Point-feature label placement (PFLP) is the problem of placing text labels adjacent to point features on a map or diagram so as to maximize legibility. This problem occurs frequently in the production of many types of informational graphics, though it arises most often in automated cartography. In this paper we present a comprehensive treatment of the PFLP problem, viewed as a type of combinatorial optimization problem. Complexity analysis reveals that the basic PFLP problem and most interesting variants of it are NP-hard. These negative results help inform a survey of previously reported algorithms for PFLP; not surprisingly, all such algorithms either have exponential time complexity or are incomplete. To solve the PFLP problem in practice, then, we must rely on good heuristic methods. We propose two new methods, one based on a discrete form of gradient descent, the other on simulated annealing, and report on a series of empirical tests comparing these and the other known algorithms for the problem. Based on this study, the first to be conducted, we identify the best approaches as a function of available computation time.|automated cartography; heuristic search; label placement; simulated annealing; stochastic methods|INTEGER PROGRAMMING-PROBLEMS; OPTIMIZATION|Computer Science, Software Engineering|127|1|9
POLITICAL-SCIENCE - ARTIFICIAL-INTELLIGENCE APPLICATIONS|1995|Scholars who apply artificial intelligence to political questions seek, most generally, to expand the scope and relevance of political model analysis. By incorporating the effects of variable human notions, traditions, and meanings, they seek to humanize political models. Most early applications of artificial intelligence in political science research address substantive issues pertaining to political decision making. Most of these works apply production-system technology to construct choice models in foreign-policy decision contexts. In recent years, political applications have begun to diversify. Today, lively research efforts flourish in widely varied application areas, such as computational text analysis, logic programming, computer learning, and conflict simulation. The works reviewed here constitute the early steps of a nascent program of study. Much remains to be accomplished. Nevertheless, the efforts conducted thus far suggest many potentially fruitful research avenues.|ARTIFICIAL INTELLIGENCE; PRODUCTION SYSTEMS; LOGIC PROGRAMMING; COMPUTATIONAL HERMENEUTICS; BELIEF MODELS; POLITICAL SIMULATION; POLITICAL SCIENCE|CUBAN MISSILE CRISIS; MODEL|Computer Science, Interdisciplinary Applications; Information Science \& Library Science; Social Sciences, Interdisciplinary|5|6|9
Leveraging deep learning with LDA-based text analytics to detect automobile insurance fraud|2018|Automobile insurance fraud represents a pivotal percentage of property insurance companies' costs and affects the companies' pricing strategies and social economic benefits in the long term. Automobile insurance fraud detection has become critically important for reducing the costs of insurance companies. Previous studies on automobile insurance fraud detection examined various numeric factors, such as the time of the claim and the brand of the insured car. However, the textual information in the claims has rarely been studied to analyze insurance fraud. This paper proposes a novel deep learning model for automobile insurance fraud detection that uses Latent Dirichlet Allocation (LDA)-based text analytics. In our proposed method, LDA is first used to extract the text features hiding in the text descriptions of the accidents appearing in the claims, and deep neural networks then are trained on the data, which include the text features and traditional numeric features for detecting fraudulent claims. Based on the real-world insurance fraud dataset, our experimental results reveal that the proposed text analytics-based framework outperforms a traditional one. Furthermore, the experimental results show that the deep neural networks outperform widely used machine learning models, such as random forests and support vector machine. Therefore, our proposed framework that combines deep neural networks and LDA is a suitable potential tool for automobile insurance fraud detection. (C) 2017 Elsevier B.V. All rights reserved.|Insurance fraud; Fraud detection; Text analytics; Topic modeling; Deep leaming|NEURAL-NETWORKS; CLASSIFICATION; CLAIMS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|0|8|8
QAPD: an ontology-based question answering system in the physics domain|2018|The tremendous development in information technology led to an explosion of data and motivated the need for powerful yet efficient strategies for knowledge discovery. Question answering (QA) systems made it possible to ask questions and retrieve answers using natural language queries. In ontology-based QA system, the knowledge-based data, where the answers are sought, have a structured organization. The question-answer retrieval of ontology knowledge base provides a convenient way to obtain knowledge for use. In this paper, QAPD, an ontology-based QA system applied to the physics domain, which integrates natural language processing, ontologies and information retrieval technologies to provide informative information for users, is presented. This system allows users to retrieve information from formal ontologies using input queries formulated in natural language. We proposed inferring schema mapping method, which uses the combination of semantic and syntactic information, and attribute-based inference to transform users' questions into ontological knowledge base query. In addition, a novel domain ontology for physics domain, called EAEONT, is presented. Relevant standards and regulations have been utilized extensively during the ontology building process. The original characteristic of system is the strategy used to fill the gap between users' expressiveness and formal knowledge representation. This system has been developed and tested on the English language and using an ontology modeling the physics domain. The performance level achieved enables the use of the system in real environments.|Question answering; Ontology modeling; Natural language interface; Information retrieval|INFORMATION; KNOWLEDGE|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|0|8|8
Emergent arguments: A functional approach to analyzing student challenges with the argument genre|2017|University students across disciplines are often expected to write argumentative texts. However, many students, particularly L2 writers, struggle writing arguments and teachers may not be prepared to effectively scaffold argument writing. Despite its importance, argumentative writing is still an underresearched area in second language writing. In this paper, we use a Systemic Functional Linguistics conceptualization of argumentation to examine emergent arguments, texts that meet some of the expectations for argumentative writing but not others. We adapt Humphrey et al. (2010) 3 x 3 professional learning toolkit to analyze student writing from a first-year university history class. The 3 x 3 allows us to highlight these texts' mixed effectiveness in meeting genre expectations, based on how they control the resources of each of SFL's three metafunctions (ideational, interpersonal, and textual) at the levels of whole-text, paragraph, and sentence/clause. Our analysis of three emergent arguments shows how each exhibits challenges controlling the resources of a particular metafunction. Our application of the 3 x 3 provides a theoretical conceptualization of argumentative writing that can help teachers uncover subtle ways that student writing does and does not meet genre expectations.|Argument writing; History writing; Academic writing; SFL|LANGUAGE INSTRUCTION; HISTORY; ENGLISH; TEXT|Linguistics|0|8|8
The use and analysis of anti-plagiarism software: Turnitin tool for formative assessment and feedback|2017|This analysis investigates the efficiency of the Turnitin software as a formative writing tool. The inquiry is especially looking into undergraduate and postgraduate students' experiences while using Turnitin. The perceptions and experiences of students will be prioritized in the study with the purpose of determining ways to improve Turnitin from students' point of view. Turnitin obtains text matches or similarity index values of 3,173 assignments submitted on subjects uploaded between 2012 and 2014 by university students. We statistically analyzed the similarity index values or levels of plagiarism percentage between the first and the last assignments, using the two-sample Kolmogorov-Smirnov test, and we found that there was a significant improvement (p=0.002). Hence, our results demonstrated that using Turnitin as a formative writing tool, allows students to prepare an assignment in an academically acceptable way, during the second half of the semester, with less plagiarism. The results found in this study suggests an insignificant difference between the draft version and final version of the same assignment (p=0.192). Similarity index values are also different for different courses, such as writing based project subject and mathematics based engineering subject have different values (p<0.0001). We also observed that students seem to be able to fool Turnitin tool by uploading images of the assignments instead of the text. Nevertheless, the nature of the subject, individual talent, learning approach, time contribution, and the exclusion of consecutive word count may affect the plagiarism percentage. Our results also indicate that there is a substantial benefit in using Turnitin as an educational writing tool rather than a punitive tool, as the use of Turnitin, promotes student learning outcomes with significantly improved academic skills. Thus, this paper provides an insight into avoiding high levels of plagiarism by using Turnitin as a preemptive tool.|assessment; formative assessment; formative writing tool; Turnitin; plagiarism|ATTAINMENT; STUDENTS|Computer Science, Interdisciplinary Applications; Education, Scientific Disciplines; Engineering, Multidisciplinary|0|8|8
Long-term knowledge evolution modeling for empirical engineering knowledge|2017|In this era of knowledge economy, appropriate management of the rapidly evolving knowledge is a real and urgent issue for factories and enterprises, in order to maintain the competitive edges. However, facing the onerous analysis required for understanding the long-term knowledge evolution, especially the evolving of empirical knowledge in the engineering field, effective and comprehensive modeling methods for knowledge evolution are absent. In this paper, a novel knowledge evolution modeling method is pro-posed for portraying the long-term evolution of empirical engineering knowledge (EEK) and assisting engineers in comprehending the evolving history. Three phases, EEK elicitation and formalization, EEK networks foundation, and family-tree evolution model construction, are included in the modeling method. This method is developed using natural language processing, semantic similarity calculation, fuzzy neural network prediction, clustering algorithm, and latent topic extraction techniques. To evaluate the performance of the proposed modeling method, an evolution model of empirical knowledge in computer-aided design (CAD) is constructed and then verified. Experimental results show that the pro-posed method outperforms the former approaches in feasibility and effectiveness, and hence opens up a better way of further understanding the long-term evolution course of EEK. (C) 2017 Published by Elsevier Ltd.|Knowledge evolution; Empirical engineering knowledge (EEK); Evolution model; Knowledge representation; Data visualization|FUZZY NEURAL-NETWORK; 1ST 10 YEARS; BIBLIOMETRIC ANALYSIS; EXPERIENCE FEEDBACK; T-S; CITATION; REPRESENTATION; PERSPECTIVE; TECHNOLOGY; PATTERNS|Computer Science, Artificial Intelligence; Engineering, Multidisciplinary|0|8|8
Science-specific technical vocabulary in science fiction-fantasy texts: A case for `language through literature'|2017|This study investigated the lexical coverage and frequency of occurrence of 318 common science-specific technical word families in a corpus of science fiction-fantasy texts in order to determine the potential for science fiction-fantasy literature to be a resource for incidental technical vocabulary acquisition. Coverage of the word list in the science fiction fantasy corpus was found to be 0.50\%, which was 46\% higher than coverage of the same list in a corpus of fiction texts (0.27\%), and 70\% lower than coverage of the same list in a corpus of academic science journals (1.68\%). These findings suggest that, in terms of exposure to technical vocabulary, science fiction-fantasy could serve as a bridge resource for second-language learners studying or prespecializing in the Sciences. A frequency analysis revealed that the highest potential for lexical learning occurs at the 500,000-word reading level, at which 21\% of science words occurred 10+ times and 83\% occurred 1+ times. Potential lexical gains, as well as both practical and theoretical implications, are discussed. (C) 2017 Elsevier Ltd. All rights reserved.|English for Specific Purposes; Academic English; Extensive reading; Incidental learning; Technical vocabulary; Language through literature|ACADEMIC WORD LIST; RESEARCH ARTICLES; 2ND-LANGUAGE VOCABULARY; FOREIGN-LANGUAGE; ACQUISITION; FREQUENCY; ESL; LEARNERS; DEMANDS; ENGLISH|Linguistics|0|8|8
Children's interaction and lexical acquisition in text-based online chat|2017|This is an empirical study in which we explore child foreign language learners' interactional strategy use, uptake, and lexical acquisition in synchronous computer-mediated communication (SCMC). The study was carried out with 16 10-year-old Spanish English as a foreign language learners paired with age-and proficiency-matched English native speaker peers who worked together over a 5-week period on three communicative jigsaw tasks. Results show that during text-based SCMC, the children negotiated for meaning in ways that coincided with and differed from studies of young learners' face-to-face communication. Successful uptake of target lexis occurred infrequently despite high rates of negotiation, although the children's lexical knowledge improved significantly over time. Analyses of the chat scripts revealed that the learners noticed and retained additional lexical items embedded in the task and used during the interaction. They had not been the focus of negotiation, but were useful for task completion. Participation in SCMC also raised the children's awareness of gaps in their lexical knowledge and stimulated their attempts to fill those gaps outside the classroom. The results are discussed and implications suggested for implementing SCMC in instructional settings.|Computer-Mediated Communication; Vocabulary; Task-Based Learning and Teaching|COMPUTER-MEDIATED COMMUNICATION; NEGOTIATED INTERACTION; TASK; ROOMS; WIKI|Education \& Educational Research; Linguistics|0|7|8
Survey: Finite-state technology in natural language processing|2017|In this survey, we will discuss current uses of finite-state information in several statistical natural language processing tasks. To this end, we will review standard approaches in tokenization, part-of-speech tagging, and parsing, and illustrate the utility of finite-state information and technology in these areas. The particular problems were chosen to allow a natural progression from simple prediction to structured prediction. We aim for a sufficiently formal presentation suitable for readers with a background in automata theory that allows to appreciate the contribution of finite-state approaches, but we will not discuss practical issues outside the core ideas. We provide instructive examples and pointers into the relevant literature for all constructions. We close with an outlook on finite-state technology in statistical machine translation. (C) 2016 Elsevier B.V. All rights reserved.|Finite-state automaton; Tree automaton; Context-free grammar; Natural language processing; Tokenization; Part-of-speech tagging; Parsing; Machine translation|MAXIMUM-LIKELIHOOD; PROBABILISTIC FUNCTIONS; MARKOV CHAINS; ALGORITHM; GRAMMARS|Computer Science, Theory \& Methods|1|5|8
Literature and readers' empathy: A qualitative text manipulation study|2017|The alleged crisis of the humanities is currently fueling renewed interest in the affective benefits of literary reading. Several quantitative studies have shown a positive correlation between literary reading and empathy. However, the literary nature of the stimuli used in these studies has not been defined at a more detailed, stylistic level. In order to explore the stylistic underpinnings of the hypothesized link between literariness and empathy, we conducted a qualitative experiment in which the degree of stylistic foregrounding was manipulated. Subjects (N = 37) read versions of Katherine Mansfield's The Fly, a short story rich in foregrounding, while marking striking and evocative passages of their choosing. Afterwards, they were asked to select three markings and elaborate on their experiences in writing. One group read the original story, while the other read a non-literary' version, produced by an established author of suspense fiction for young adults, where stylistic foregrounding was reduced. We found that the non-literary version elicited significantly more (p < 0.01) explicitly empathic responses than the original story. This finding stands in contradiction to widely accepted assumptions in recent research, but can be assimilated in alternative models of literariness and affect in literary reading. We present an analysis of the data with a view to offering more than one interpretation of the observed effects of stylistic foregrounding.|Reader response; empathy; literary fiction; foregrounding; qualitative methods|EXPOSURE; FICTION; MIND; EXPERIENCE; STORIES; PRINT|Linguistics; Language \& Linguistics|1|3|8
Nested self-citation: the citation of a paper's least divisible unit|2017|Try to imagine that a figure, a table or an explanatory box in your main manuscript gets cited, in addition to citations to the main paper. Some scientists would no doubt be ecstatic at this unrealistic opportunity of gathering additional citations. This paper highlights a case in which a text box (Unger and Couzin in Science 312(5770): 40-41, 2006. doi:10.1126/science.312.5770.40) within a larger paper (Couzin and Unger in Science 312(5770): 38-43, 2006. doi:10.1126/science.312.5770.38), as well as the paper itself, are both cited, 33 and 8 times, respectively, according to Clarivate Analytics' (formerly Thomson Reuters) Web of Science. Both papers were published in AAAS' Science. This paper explores details of these citations and shows how four papers between 2007 and 2015 have cited both papers, including the text box. The argument is put forward that citation of least divisible units of a paper, in this case, a text box, are unfair citation practices, and since they refer to the citation of a part of the same paper, the term ``nested self-citation{''} has been coined. Given the attention given in recent times to citation manipulation, citation rings and inappropriate citations, the risks of nested self-citations, including the skewing of citation counts, and of not correcting potentially misleading information, need to be explored.|AAAS; Box; figure or table; Ethics; Science; Scopus; Unique self-citation; Web of Science|CONDUCT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|4|8
Exploring the relationship of organization and connection with scores in integrated writing assessment|2017|Traditionally, second language writing assessment has employed writing tasks that require only a single skill; however, in many academic contexts, writing requires the integration of several abilities, including reading and listening. To improve authenticity, integrated tasks are increasingly used in the research and assessment of second language writing. Scholars have proposed discourse synthesis as an underlying construct for these tasks. This study investigated performances on integrated reading-listening-writing tasks to consider how organization and connection, subprocesses in discourse synthesis, are reflected in scores. Four hundred eighty responses to an integrated writing prompt were analyzed for organizational patterns, coherence, and cohesion in relation to test scores. Raters coded essays for type and appropriateness of organization and coherence quality, while computational analysis was used to look at cohesion features. The results indicate that organization and coherence were related to writing score, with quality improving as score increased. However, the cohesion markers analyzed in this study yielded no statistical differences across the score levels. (C) 2016 Elsevier Inc. All rights reserved.|Second language writing; Discourse organization; Integrated writing; Assessment|PROFICIENCY; TEXTS; COHESION; STUDENTS; FEATURES; TASKS|Education \& Educational Research; Linguistics|1|2|8
Narrative and expository genre effects on students, raters, and performance criteria|2017|The effects of genre play an important role in the assessment of student writing. This study examines the effects of narrative and expository genres on student language proficiency, raters, and performance criteria. For this study, EFL students (n = 180) from three proficiency levels (novice, intermediate, and advanced) wrote a narrative and an expository essay that were assessed by raters using four performance criteria: paragraph structure, content, form, and vocabulary. A multi-faceted Rasch measurement (MFRM) analysis showed that differences in the students' scores were not statistically significant between genres, but showed a significant difference depending on the writing proficiency level. Novice students received significantly higher scores on narratives, while advanced students received significantly higher scores on expository essays, but there was no score difference for intermediate students. Raters showed greater variance when rating for narratives compared to expository texts. Narrative essays covered a wider range of student writing ability, while expository essays showed more centralization in writing scores. For the four performance Criteria, vocabulary showed interactions with narrative and expository genres. Expository essays were given significantly higher scores for vocabulary than for narrative texts. The results of this study have implications for the use of narrative and expository genres for writing assessment. (C) 2016 Elsevier Inc. All rights reserved.|Genre effect; Rater effect; Multi-faceted rasch analysis; Writing assessment; Narrative; Expository|SYNTACTIC COMPLEXITY; WRITING PERFORMANCE; SELF-ASSESSMENT; EFL LEARNERS; DISCOURSE; LANGUAGE; DIFFERENTIATION; PERSPECTIVE; QUALITY|Education \& Educational Research; Linguistics|0|1|8
Analysing voice in language policy: plurality and conflict in Slovene government documents|2016|Contemporary analyses of language policy often tend to presume ideological uniformity, rather than focus on the contrasts between various positions, and the power struggles that those differences bring about. In this paper, I present an approach that implements the notion of voice in language policy analysis to denote the ideological positions and interests of different social actors, in this case as reflected in government documents. I propose a method of analysis based on the discourse-historical approach in critical discourse analysis and demonstrate how this exposes different social actors behind policy documents by focussing on the traces of their participation in policymaking. I analyse two different texts produced by the Slovene government and intended to specify its language policy strategy for the 2007-2011 and 2012-2016 periods. I show that there are two hegemonic voices of linguists behind both texts, one based on values of national unity, and a second based on human rights and broad inclusion. Alongside these, there are various voices from other domains of Slovene society and EU policy, all recontextualised through the prisms of the two dominant voices.|Language policy; Critical discourse analysis; Polyphony; Discourse historical approach; Policy documents|POWER|Education \& Educational Research; Linguistics; Language \& Linguistics|2|2|8
Use of ``off-the-shelf{''} information extraction algorithms in clinical informatics: A feasibility study of MetaMap annotation of Italian medical notes|2016|Information extraction from narrative clinical notes is useful for patient care, as well as for secondary use of medical data, for research or clinical purposes. Many studies focused on information extraction from English clinical texts, but less dealt with clinical notes in languages other than English. This study tested the feasibility of using ``off the shelf{''} information extraction algorithms to identify medical concepts from Italian clinical notes. Among all the available and well-established information extraction algorithms, we used MetaMap to map medical concepts to the Unified Medical Language System (UMLS). The study addressed two questions: (Q1) to understand if it would be possible to properly map medical terms found in clinical notes and related to the semantic group of ``Disorders{''} to the Italian UMLS resources; (Q2) to investigate if it would be feasible to use MetaMap as it is to extract these medical concepts from Italian clinical notes. We performed three experiments: in EXP1, we investigated how many medical concepts of the ``Disorders{''} semantic group found in a set of clinical notes written in Italian could be mapped to the UMLS Italian medical sources; in EXP2 we assessed how the different processing steps used by MetaMap, which are English dependent, could be used in Italian texts to map the original clinical notes on the Italian UMLS sources; in EXP3 we automatically translated the clinical notes from Italian to English using Google Translator, and then we used MetaMap to map the translated texts. Results in EXP1 showed that the Italian UMLS Metathesaurus sources covered 91\% of the medical terms of the ``Disorders{''} semantic group, as found in the studied dataset. We observed that even if MetaMap was built to analyze texts written in English, most of its processing steps worked properly also with texts written in Italian. MetaMap identified correctly about half of the concepts in the Italian clinical notes. Using MetaMap's annotation on Italian clinical notes instead of a simple text search improved our results of about 15 percentage points. MetaMap's annotation of Italian clinical notes showed recall, precision and F-measure equal to 0.53, 0.98 and 0.69, respectively. Most of the failures were due to the impossibility for MetaMap to generate meaningful variants for the Italian language, suggesting that modifying MetaMap to allow generating Italian variants could improve the performance. MetaMap's performance in annotating automatically translated English clinical notes was in line with findings in the literature, with similar recall (0.75), F-measure (0.83) and even higher precision (0.95). Most of the failures were due to a bad Italian to English translation of medical terms, suggesting that using an automatic translation tool specialized in translating medical concepts might be useful to obtain better performances. In conclusion, performances obtained using MetaMap on the fully automatic translation of the Italian text are good enough to allow to use MetaMap ``as it is{''} in clinical practice. (C) 2016 Elsevier Inc. All rights reserved.|Information extraction; Unstructured clinical notes; Italian language; MetaMap; Failure analysis; EHR data reuse|ELECTRONIC HEALTH RECORDS; TRANSFER MMTX; UMLS; TEXT; SYSTEM; NORMALIZATION; RECOGNITION; RETRIEVAL; DOCUMENTS|Computer Science, Interdisciplinary Applications; Medical Informatics|3|1|8
Dystemo: Distant Supervision Method for Multi-Category Emotion Recognition in Tweets|2016|Emotion recognition in text has become an important research objective. It involves building classifiers capable of detecting human emotions for a specific application, for example, analyzing reactions to product launches, monitoring emotions at sports events, or discerning opinions in political debates. Most successful approaches rely heavily on costly manual annotation. To alleviate this burden, we propose a distant supervision method-Dystemo-for automatically producing emotion classifiers from tweets labeled using existing or easy-to-produce emotion lexicons. The goal is to obtain emotion classifiers that work more accurately for specific applications than available emotion lexicons. The success of this method depends mainly on a novel classifier-Balanced Weighted Voting (BWV)-designed to overcome the imbalance in emotion distribution in the initial dataset, and on novel heuristics for detecting neutral tweets. We demonstrate how Dystemo works using Twitter data about sports events, a fine-grained 20-category emotion model, and three different initial emotion lexicons. Through a series of carefully designed experiments, we confirm that Dystemo is effective both in extending initial emotion lexicons of small coverage to find correctly more emotional tweets and in correcting emotion lexicons of low accuracy to perform more accurately.|Distant supervision; emotion recognition; natural language processing; semi-supervised learning; text mining; twitter|LIBRARY; TEXT|Computer Science, Artificial Intelligence; Computer Science, Information Systems|2|1|8
Supporting Semantic Annotation of Educational Content by Automatic Extraction of Hierarchical Domain Relationships|2016|The domain model is an essential part of an adaptive learning system. For each educational course, it involves educational content and semantics, which is also viewed as a form of conceptual metadata about educational content. Due to the size of a domain model, manual domain model creation is a challenging and demanding task for teachers or content (and metadata) authors. We propose a method for the automated acquisition of hierarchical relationships between relevant domain terms from educational content, which constitutes a fundamental step in the semantic composition of an educational course. The method is based on existing text mining methods and applied to educational content. We evaluate our approach by performing several experiments. The evaluation shows that the method's performance is very promising. A study in a real-user scenario reveals that despite the fact that utilization of our method does not necessarily improve the speed of the domain model creation nor does it reduce the overall difficulty of the task, a significant improvement in the quality of resulting domain models has been observed. Our work is a promising contribution to the growing field of automated domain model acquisition.|Authoring tools; ontologies; text analysis; semantic networks|TEXT|Computer Science, Interdisciplinary Applications; Education \& Educational Research|2|1|8
Automated identification of molecular effects of drugs (AIMED)|2016|Introduction Genomic profiling information is frequently available to oncologists, enabling targeted cancer therapy. Because clinically relevant information is rapidly emerging in the literature and elsewhere, there is a need for informatics technologies to support targeted therapies. To this end, we have developed a system for Automated Identification of Molecular Effects of Drugs, to help biomedical scientists curate this literature to facilitate decision support. Objectives To create an automated system to identify assertions in the literature concerning drugs targeting genes with therapeutic implications and characterize the challenges inherent in automating this process in rapidly evolving domains. Methods We used subject-predicate-object triples (semantic predications) and co-occurrence relations generated by applying the SemRep Natural Language Processing system to MEDLINE abstracts and ClinicalTrials.gov descriptions. We applied customized semantic queries to find drugs targeting genes of interest. The results were manually reviewed by a team of experts. Results Compared to a manually curated set of relationships, recall, precision, and F2 were 0.39, 0.21, and 0.33, respectively, which represents a 3- to 4-fold improvement over a publically available set of predications (SemMedDB) alone. Upon review of ostensibly false positive results, 26\% were considered relevant additions to the reference set, and an additional 61\% were considered to be relevant for review. Adding co-occurrence data improved results for drugs in early development, but not their better-established counterparts. Conclusions Precision medicine poses unique challenges for biomedical informatics systems that help domain experts find answers to their research questions. Further research is required to improve the performance of such systems, particularly for drugs in development.|precision oncology; targeted therapy; molecular; SemRep; biomedical question answering; pharmacogenomics|ANSWER CLINICAL QUESTIONS; PRECISION ONCOLOGY; BIOMEDICAL TEXT; MEDLINE; DOMAIN; SYSTEM; KNOWLEDGE; PATIENT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|5|1|8
Multimodular Text Normalization of Dutch User-Generated Content|2016|As social media constitutes a valuable source for data analysis for a wide range of applications, the need for handling such data arises. However, the nonstandard language used on social media poses problems for natural language processing (NLP) tools, as these are typically trained on standard language material. We propose a text normalization approach to tackle this problem. More specifically, we investigate the usefulness of a multimodular approach to account for the diversity of normalization issues encountered in user-generated content (UGC). We consider three different types of UGC written in Dutch (SNS, SMS, and tweets) and provide a detailed analysis of the performance of the different modules and the overall system. We also apply an extrinsic evaluation by evaluating the performance of a part-of-speech tagger, lemmatizer, and named-entity recognizer before and after normalization.|Social media; text normalization; user-generated content|LANGUAGE|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|3|8
EFFECTS OF TEXT SEGMENTATION ON SILENT READING OF CHINESE REGULATED POEMS: EVIDENCE FROM EYE MOVEMENTS|2016|Interword spaces have been reported to play an important role in silent reading of alphabetic languages. However, it has not yet been clear whether text spacing/segmentation facilitates the cognitive process in silent reading of Chinese, a logographic language, especially in reading Chinese regulated poems which have predefined rhythmic structures. An eye-tracking experiment was conducted to monitor eye movements of native participants in reading Chinese regulated poems in four segmenting conditions: normal text, character segmentation, rhythmic segmentation, and syntactic segmentation. By comparing a set of measures of eye movements, both global and local analyses showed that syntactic segmentation boosted reading efficiency, while rhythmic segmentation did not. The findings demonstrate that not rhythmic but syntactic structure plays major roles in the cognitive process in reading Chinese regulated poems, suggesting an intrinsic difference in the information structure between spoken and written languages.|Text segmentation; Reading; Chinese regulated poem; Rhythmic structure; Syntactic structure; Eye movement|SPACE INFORMATION; READERS; 2ND-LANGUAGE; REANALYSIS; DISPLAY; ENGLISH; WORDS; TIME|Asian Studies; Linguistics; Language \& Linguistics|0|1|8
SIMILAR AND DIFFERENT: COGNITIVE RHYTHM AND EFFORT IN TRANSLATION AND PARAPHRASING|2016|Although Jakobson's (1959) seminal classification of translation into three kinds: interlingual, intralingual and intersemiotic has been widely accepted in Translation Studies, so far most research interest has focused on interlingual translation, defined as ``translation proper{''}. Intralingual translation, more often understood as rewording, paraphrasing or reformulation within the same language, is a less prototypical kind of translation, yet we believe that the underlying mental operations needed to perform both tasks include similar processing stages. Bearing in mind the lack of research comparing inter-and intralingual translation we designed the ParaTrans project in which we investigate how translators make decisions in both tasks. In this article we present the results of a comparative analysis of processing effort and cognitive rhythm demonstrated by professional translators who were asked to translate and paraphrase similar texts. Having collected three streams of translation process data with such tools as key-logging, eye-tracking and screen-capture software, we are able to draw some tentative conclusions concerning the similarities and differences between language processing for interlingual translation and intralingual paraphrasing. The results confirm a higher processing effort in interlingual translation most likely due to the need to switch between languages.|Paraphrasing; processing effort; intralingual translation; cognitive rhythm; key-logging and eye-tracking|INTRALINGUAL TRANSLATION; LANGUAGE; COMPREHENSION; PATTERNS; TASKS; KEY|Linguistics; Language \& Linguistics|0|4|8
Personality-aware followee recommendation algorithms: An empirical analysis|2016|As the popularity of micro-blogging sites, expressed as the number of active users and volume of online activities, increases, the difficulty of deciding who to follow also increases. Such decision might not depend on a unique factor as users usually have several reasons for choosing whom to follow. However, most recommendation systems almost exclusively rely on only two traditional factors: graph topology and user-generated content, disregarding the effect of psychological and behavioural characteristics, such as personality, over the followee selection process. Due to its effect over people's reactions and interactions with other individuals, personality is considered as one of the primary factors that influence human behaviour. This study aims at assessing the impact of personality in the accurate prediction of followees, beyond simple topological and content-based factors. It analyses whether user personality could condition followee selection by combining personality traits with the most commonly used followee predictive factors. Results showed that an accurate appreciation of such predictive factors tied to a quantitative analysis of personality is crucial for guiding the search of potential followees, and thus, enhance recommendations. (C) 2016 Elsevier Ltd. All rights reserved.|Followee recommendation; Twitter; Human aspects recommendation; Personality traits|5-FACTOR MODEL; BEHAVIOR; SIMILARITY; NETWORKS; RATINGS; TEXT|Automation \& Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical \& Electronic|2|3|8
Classification of radiology reports for falls in an HIV study cohort|2016|Methods We used the Veterans Aging Cohort Study Virtual Cohort (VACS-VC), an electronic health record-based cohort of 146 530 veterans for whom radiology reports were available (N =2 977 739). We created a reference standard of radiology reports, represented each report by a feature set of words and Unified Medical Language System concepts, and then developed several support vector machine (SVM) classifiers for falls. We compared mutual information (MI) ranking and embedded feature selection approaches. The SVM classifier with MI feature selection was chosen to classify all radiology reports in VACS-VC. Results Our SVM classifier with MI feature selection achieved an area under the curve score of 97.04 on the test set. When applied to all the radiology reports in VACS-VC, 80 416 of these reports were classified as positive for a fall. Of these, 11 484 were associated with a fall-related external cause of injury code (E-code) and 68 932 were not, corresponding to 29 280 patients with potential fall-related injuries who could not have been found using E-codes. Discussion Feature selection was crucial to improving the classifier's performance. Feature selection with MI allowed us to select the number of discriminative features to use for classification, in contrast to the embedded feature selection method, in which the number of features is chosen automatically. Conclusion Machine learning is an effective method of identifying patients who have suffered a fall. The development of this classifier supplements the clinical researcher's toolkit and reduces dependence on under-coded structured electronic health record data.|information retrieval; text mining; falls; aging; HIV|ARCHITECTURE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|3|2|8
Literacy discussions in low-income families: The effect of parent questions on fourth graders' retellings|2016|This study examines the effects of four types of reading comprehension questions - immediate, non-immediate, summary, and unanswerable questions - that linguistically diverse and predominantly low-income parents asked their fourth graders on children's text retellings. One-hundred-twenty (N = 120) parent and child dyads participated in a home visit study in which they talked about narrative and informational texts. Moderation analyses indicated that immediate questions and non-immediate questions had a more positive effect on student retellings of an informational text and a narrative text, respectively, for less proficient than more proficient readers. These findings suggest that parents may be able to help their children, particularly less proficient readers, with text memory and text comprehension by asking specific types of questions.|Family literacy; middle childhood; parent-child literacy interactions; parent questions; retelling|INFORMATIONAL TEXTS; READING-COMPREHENSION; CHILDRENS VOCABULARY; PRESCHOOL-CHILDREN; BOOK READINGS; INSTRUCTION; STRATEGIES; STORYBOOK; QUALITY; MOTHERS|Psychology, Developmental; Linguistics; Language \& Linguistics|0|5|8
Verb Argument Structure in Narrative Speech: Mining AphasiaBank|2016|Previous research has found that verb argument structure characteristics (such as the number of participant roles in the situation described by the verb) can facilitate or hinder aphasic language production and comprehension in constrained laboratory tasks. This research needs to be complemented by studies of narrative or unrestricted speech, which can capture the spontaneous selection of verbs and grammatical structures by people with aphasia and may be particularly sensitive to the relative cost of access to different verb types in more natural conditions. Focusing on the number of subcategorization options, we investigated verb argument structure effects in a large sample of narratives from AphasiaBank, by speakers with aphasia, as well as control speakers without brain damage. Verb argument structure complexity did not negatively affect verb selection in any type of aphasia. However, people with aphasia, particularly with Broca's aphasia, used verbs in less complex and diverse ways, with fewer arguments and less diverse subcategorization options. In line with previous research, this suggests that deficits in verb use in aphasia are likely due to difficulties with the online application of or partial damage to verb argument structure knowledge.|Verb argument structure; aphasia; subcategorization options; spontaneous speech in aphasia; verb processing in aphasia|AGRAMMATIC APHASIA; CORTICAL REPRESENTATION; SENTENCE COMPREHENSION; NAMING ERRORS; SPEAKERS; NOUNS; RECOGNITION; COMPLEMENTS; COMPLEXITY; RETRIEVAL|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|0|1|8
In the pursuit of a semantic similarity metric based on UMLS annotations for articles in PubMed Central Open Access|2015|Motivation: Although full-text articles are provided by the publishers in electronic formats, it remains a challenge to find related work beyond the title and abstract context. Identifying related articles based on their abstract is indeed a good starting point; this process is straightforward and does not consume as many resources as full-text based similarity would require. However, further analyses may require in-depth understanding of the full content. Two articles with highly related abstracts can be substantially different regarding the full content. How similarity differs when considering title-and-abstract versus full-text and which semantic similarity metric provides better results when dealing with full-text articles are the main issues addressed in this manuscript. Methods: We have benchmarked three similarity metrics - BM25, PMRA, and Cosine, in order to determine which one performs best when using concept-based annotations on full-text documents. We also evaluated variations in similarity values based on title-and-abstract against those relying on full-text. Our test dataset comprises the Genomics track article collection from the 2005 Text Retrieval Conference. Initially, we used an entity recognition software to semantically annotate titles and abstracts as well as full-text with concepts defined in the Unified Medical Language System (UMLS). For each article, we created a document profile, i.e., a set of identified concepts, term frequency, and inverse document frequency; we then applied various similarity metrics to those document profiles. We considered correlation, precision, recall, and F1 in order to determine which similarity metric performs best with concept-based annotations. For those full-text articles available in PubMed Central Open Access (PMC-OA), we also performed dispersion analyses in order to understand how similarity varies when considering full-text articles. Results: We have found that the PubMed Related Articles similarity metric is the most suitable for full-text articles annotated with UMLS concepts. For similarity values above 0.8, all metrics exhibited an F1 around 0.2 and a recall around 0.1; BM25 showed the highest precision close to 1; in all cases the concept-based metrics performed better than the word-stem-based one. Our experiments show that similarity values vary when considering only title-and-abstract versus full-text similarity. Therefore, analyses based on full-text become useful when a given research requires going beyond title and abstract, particularly regarding connectivity across articles. Availability: Visualization available at ljgarcia.github.io/semsim.benchmark/, data available at http://dx.doi.org/10.5281/zenodo.13323. (C) 2015 Elsevier Inc. All rights reserved.|Semantic similarity; Scientific publications; Similarity metrics; Semantic annotations; Related articles|TEXT CLASSIFICATION; ONTOLOGY; SEARCH; DOMAIN; MODEL|Computer Science, Interdisciplinary Applications; Medical Informatics|2|0|8
The good, the bad and the implicit: a comprehensive approach to annotating explicit and implicit sentiment|2015|We present a fine-grained scheme for the annotation of polar sentiment in text, that accounts for explicit sentiment (so-called private states), as well as implicit expressions of sentiment (polar facts). Polar expressions are annotated below sentence level and classified according to their subjectivity status. Additionally, they are linked to one or more targets with a specific polar orientation and intensity. Other components of the annotation scheme include source attribution and the identification and classification of expressions that modify polarity. In previous research, little attention has been given to implicit sentiment, which represents a substantial amount of the polar expressions encountered in our data. An English and Dutch corpus of financial newswire text, consisting of over 45,000 words each, was annotated using our scheme. A subset of this corpus was used to conduct an inter-annotator agreement study, which demonstrated that the proposed scheme can be used to reliably annotate explicit and implicit sentiment in real-world textual data, making the created corpora a useful resource for sentiment analysis.|Corpus annotation; Polarity; Sentiment analysis; Natural language processing|AGREEMENT; EMOTIONS|Computer Science, Interdisciplinary Applications|1|1|8
Comparing image search behaviour in the ARRS GoldMiner search engine and a clinical PACS/RIS|2015|Information search has changed the way we manage knowledge and the ubiquity of information access has made search a frequent activity, whether via Internet search engines or increasingly via mobile devices. Medical information search is in this respect no different and much research has been devoted to analyzing the way in which physicians aim to access information. Medical image search is a much smaller domain but has gained much attention as it has different characteristics than search for text documents. While web search log files have been analysed many times to better understand user behaviour, the log files of hospital internal systems for search in a PACS/RIS (Picture Archival and Communication System, Radiology Information System) have rarely been analysed. Such a comparison between a hospital PACS/RIS search and a web system for searching images of the biomedical literature is the goal of this paper. Objectives are to identify similarities and differences in search behaviour of the two systems, which could then be used to optimize existing systems and build new search engines. Log files of the ARRS GoldMiner medical image search engine (freely accessible on the Internet) containing 222,005 queries, and log files of Stanford's internal PACS/RIS search called radTF containing 18,068 queries were analysed. Each query was preprocessed and all query terms were mapped to the RadLex (Radiology Lexicon) terminology, a comprehensive lexicon of radiology terms created and maintained by the Radiological Society of North America, so the semantic content in the queries and the links between terms could be analysed, and synonyms for the same concept could be detected. RadLex was mainly created for the use in radiology reports, to aid structured reporting and the preparation of educational material (Lanlotz, 2006) {[}1]. In standard medical vocabularies such as MeSH (Medical Subject Headings) and UMLS (Unified Medical Language System) specific terms of radiology are often underrepresented, therefore RadLex was considered to be the best option for this task. The results show a surprising similarity between the usage behaviour in the two systems, but several subtle differences can also be noted. The average number of terms per query is 2.21 for GoldMiner and 2.07 for radTF, the used axes of RadLex (anatomy, pathology, findings,...) have almost the same distribution with clinical findings being the most frequent and the anatomical entity the second; also, combinations of RadLex axes are extremely similar between the two systems. Differences include a longer length of the sessions in radTF than in GoldMiner (3.4 and 1.9 queries per session on average). Several frequent search terms overlap but some strong differences exist in the details. In radTF the term ``normal{''} is frequent, whereas in GoldMiner it is not. This makes intuitive sense, as in the literature normal cases are rarely described whereas in clinical work the comparison with normal cases is often a first step. The general similarity in many points is likely due to the fact that users of the two systems are influenced by their daily behaviour in using standard web search engines and follow this behaviour in their professional search. This means that many results and insights gained from standard web search can likely be transferred to more specialized search systems. Still, specialized log files can be used to find out more on reformulations and detailed strategies of users to find the right content. (C) 2015 Elsevier Inc. All rights reserved.|Medical image search; Log file analysis; User behaviour; Information retrieval|RADIOLOGISTS; WEB|Computer Science, Interdisciplinary Applications; Medical Informatics|1|1|8
Therapist-Centered Design of a Robot's Dialogue Behavior|2014|Significant research effort has already been invested in the field of robot-assisted therapy for children with developmental disorders, and the researchers generally agree that therapists should be involved in the development of assistive robotic tools. However, relatively little attention has been devoted to robots' capacity to autonomously engage in a natural language dialogue in the context of robot-assisted therapy. This paper focuses on this desideratum. It introduces a programming platform that enables the therapist to design a robot's dialogue behavior. To the extent that the platform is domain-independent, it enables the therapist to flexibly model (1) the interaction domain and the lexicon, (2) the interaction context, and (3) the robot's dialogue strategy. To the extent that the platform is therapist-centered, it is motivated by real-life difficulties that therapists encounter while trying to specify a robot's dialogue behavior and can be used by nontechnical therapists in a user-friendly and intuitive manner. In addition, the platform (4) enables the therapist to test dialogue strategies independently of therapeutic settings, and (5) provides estimated cognitive load placed on the child while trying to process the therapist's dialogue acts.|Robot-assisted therapy; Human-machine interaction; Therapist-centered design; Context modeling; Dialogue behavior modeling; Focus tree|LANGUAGE COMPREHENSION; WORKING-MEMORY; ASSISTED THERAPY; CEREBRAL-PALSY; INFORMATION; ATTENTION; STROKE; REAL; LIFE|Computer Science, Artificial Intelligence; Neurosciences|7|1|8
Preparing an annotated gold standard corpus to share with extramural investigators for de-identification research|2014|Objective: The current study aims to fill the gap in available healthcare de-identification resources by creating a new sharable dataset with realistic Protected Health Information (PHI) without reducing the value of the data for de-identification research. By releasing the annotated gold standard corpus with Data Use Agreement we would like to encourage other Computational Linguists to experiment with our data and develop new machine learning models for de-identification. This paper describes: (1) the modifications required by the Institutional Review Board before sharing the de-identification gold standard corpus; (2) our efforts to keep the PHI as realistic as possible; (3) and the tests to show the effectiveness of these efforts in preserving the value of the modified data set for machine learning model development. Materials and methods: In a previous study we built an original de-identification gold standard corpus annotated with true Protected Health Information (PHI) from 3503 randomly selected clinical notes for the 22 most frequent clinical note types of our institution. In the current study we modified the original gold standard corpus to make it suitable for external sharing by replacing HIPAA-specified PHI with newly generated realistic PHI. Finally, we evaluated the research value of this new dataset by comparing the performance of an existing published in-house de-identification system, when trained on the new de-identification gold standard corpus, with the performance of the same system, when trained on the original corpus. We assessed the potential benefits of using the new de-identification gold standard corpus to identify PHI in the i2b2 and PhysioNet datasets that were released by other groups for de-identification research. We also measured the effectiveness of the i2b2 and PhysioNet de-identification gold standard corpora in identifying PHI in our original clinical notes. Results: Performance of the de-identification system using the new gold standard corpus as a training set was very close to training on the original corpus (92.56 vs. 93.48 overall F-measures). Best i2b2/PhysioNet/CCHMC cross-training performances were obtained when training on the new shared CCHMC gold standard corpus, although performances were still lower than corpus-specific trainings. Discussion and conclusion: We successfully modified a de-identification dataset for external sharing while preserving the de-identification research value of the modified gold standard corpus with limited drop in machine learning de-identification performance. (C) 2014 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license|Natural Language Processing; Privacy of patient data; Health insurance portability and accountability act; Automated de-identification; De-identification gold standard; Protected Health Information|SYSTEM; TEXT; DOCUMENTS; RECORD|Computer Science, Interdisciplinary Applications; Medical Informatics|5|2|8
The interdiscursive construction of irresponsibility as a defence strategy in the Belgian Assize Court|2014|Research on intertextuality in criminal trials postulates a dynamic view of legal text and demonstrates how discourse takes on different meanings at various stages in the legal process. This article examines how these intertextual dynamics affect the negotiation of issues relating to the moral responsibility of defendants in the Belgian Assize Court. Linguistic-ethnographic analysis of the defence counsel's argumentation in a strangling trial demonstrates how the ambiguity in Belgian criminal law of legal concepts related to moral responsibility opens up enormous potential for negotiation and multiple interpretations of these concepts. This article considers the implications of local constructions of irresponsibility for the assessment of criminal culpability and reflects on the relation between lay and professional input in the adjudication process. (C) 2014 Elsevier Ltd. All rights reserved.|Legal discourse analysis; Interdiscursivity; Textual travel; Criminal culpability; Insanity defence; Assize Court procedure|INSANITY DEFENSE; TRIAL; QUESTIONS; TESTIMONY; LAW|Communication; Linguistics|1|0|8
Two modes of referring to the case file in the courtroom: The use of indirect reported text and text-as-addressed speech in case summaries|2014|This paper analyzes summaries of the written case file which judges produce at the onset of pre-parole pluridisciplanary hearings for assessing the future dangerousness of an inmate. Such summaries of the case file are a highly reflexive discursive practice, as the inmate who appears before the committee is simultaneously the object of the written expert assessments that are re-enacted by the judge and the recipient of these reenactments. Both the production of the summary as an extended turn-at-talk and the procedures for referring to the file are sensitive to this ``participative dilemma{''}. Two different modes for referring to the file are identified: ``indirect reported text{''} and ``text-as-addressed speech.{''} Each has different sequential implications and invokes different epistemic domains and asymmetries. (C) 2013 Elsevier Ltd. All rights reserved.|Conversation analysis; Courtroom interaction; Turn taking; Reported speech; Video communication|TALK; MEETINGS|Communication; Linguistics|3|0|8
Narrative, text and time: Telling the same story twice in the oral narrative reporting of 7/7|2014|The question of whether it is possible to `tell the same story twice' has been explored in work on conversational narratives, which has set out to understand the existence of some kind of `underlying semantic structure' and `script' (Polanyi, 1981). In conversational narratives, `local occasioning' and `recipient design' (Sacks et al., 1974) are factors that determine the form and function of the story. Here, ongoing talk frames the narrative while other participants provide a ready made audience, all of which, form part of the storytelling process. What happens, however, when a survivor of 7/7 (the date in 2005 of the co-ordinated terrorist bomb attacks on the London transport system in the morning rush hour, which killed 52 and injured hundreds of people), whose personal narrative was reported globally on the day of the event, is again interviewed two and a half years later for their experience of that morning? Is the `same story' retold? Specifically, how far does the latest story replicate the experience and events of the first and which of the prototypical features of a personal narrative - at the level of both the macrostructure and microstructure - remain constant? By comparing both interviews and using Labov and Waletzky's (1967) narrative framework as the central model for analysis, it is possible to see whether events within the complicating action or features of evaluation remain the most memorable, that is, they are recalled in the second telling as important aspects of the experience, and may be seen to be core narrative categories. While findings show that both narratives are comparable in form, a closer investigation finds compelling differences as well as unexpected linguistic choices. Not only has the second narrative become informed by other, external narratives to become part of a broader, mediated narrative but various discourse strategies of `dissociation' in both interviews have resulted in a retelling of a traumatic experience that appears to have features of an eye witness report rather than a personal narrative. Moreover, this blurring of two distinct genres of storytelling provides a true insight of how the narrator positions himself inside this terrible experience.|7; 7 bombings; dissociation; oral narrative; story template; tellability; trauma|ORGANIZATION|Linguistics; Language \& Linguistics|0|0|8
A mathematical model for academic genre awareness Writer's metalinguistic knowledge in English L2 writing|2014|Spanish undergraduates of English Studies are required to submit their essays in academic English, a genre which most of them are not acquainted with. This paper aims to explore the extralinguistic side of L2 academic writing, more specifically, the combination of metalinguistic items (e.g. transition and frame markers, among others) with writers' awareness of academic genre features. The research sample conveys a group of 200 Spanish undergraduates of English Studies; they are in their fourth year, so they are expected to be proficient in English academic writing but their written production quality varies considerably. Results are analysed following a mixed methodology by which metalinguistic items are statistically measured, and then contrasted with semi-structured interview results; SPSS (R) and NVivo (R) provide quantitative and qualitative outcomes, respectively. The analyses reveal that undergraduate students who produce complex sentences and more coherent texts show greater awareness of academic genre features, being able to (un) consciously employ academic language in their written expression. These high-scoring students make more proficient use of complex transition markers for coherence and frame markers for textual cohesion.|writing; academic; English; L2; awareness; metalinguistic|LANGUAGE; IDENTITY|Linguistics; Language \& Linguistics|0|1|8
Interrelations of representations of academic writing and professors' written feedback|2014|This paper shows some interrelations of representations of academic writing and its teaching, and the discourse strategies (Menendez, 2000) adopted by lecturers and professors when giving written feedback. On the basis of a corpus of 30 interviews to professors and 184 samples of written feedback by the same professors, we have identified four representations about writing and a set of eight discourse strategies, which are first outlined here. Second, on the basis of two cases, two of the representations are described in detail, using discourse analysis tools based on Systemic Functional Linguistics. Additionally, the same two cases allow us to examine the strategies adopted by professors when assessing the texts produced by their students. The results show that those professors who represent writing as a tool used in material processes and who assign their students and themselves the role of Actors use strategies to feedback written production, under the form of instructions and questions. In contrast, when the prevailing representation is that in which writing is associated with a phenomenon in which the professor is a mere observer, feedback is mainly provided by using strategies whose purpose is expressing an evaluation about the correctness or incorrectness of an answer.|academic literacy; representations of academic writing; discourse strategies; written feedback|GENRE|Linguistics; Language \& Linguistics|0|3|8
Computer Aided Error Analysis of a Computer based on Learner Corpus for Spanish as a Foreign Language|2014|This paper presents a Computer Aided Error Analysis ( CEA) study based on Spanish as a Foreign Language Learners' Corpus. The corpus is made up of 84 summary texts: 40 of them are of expository modality, 22 narrative and 22 argumentative. These were written in Spanish by 22 international students from diverse university study programs with a B1 language proficiency level, enrolled in a b-learning Spanish as a foreign language course at Universidad de Concepcion, Chile (ele.udec.cl). The writing computerized tasks involved the production of 250-word-summaries based on scientific, historical and cultural topics that learners were asked to read. The methodology included Computer Aided Error Analysis and Computer Learner Corpora proceedings for the corpus construction, linguistic annotation and data processing using the NVIVO software tools. The aim is to determine error types, with the highest frequency of occurrence, committed by learners of Spanish as a foreign language. The corpus processing results suggest errors with the highest frequency correspond to orthographical stress-marking errors, followed by grammatical errors; such as, prepositions, grammatical agreement, verbs and articles. These findings will have implications in the delimitation, identification and treatment of errors with the use of an intelligent tutorial system for Spanish as a foreign language.|Computer-aided-error-analysis (CEA); Computer Learner Corpora (CLC); Intelligent Tutorial Systems for Foreign Languages (ITS for FL); Spanish as a Foreign Language|TUTOR|Linguistics; Language \& Linguistics|0|1|8
A cross-cultural study of metaphoric imagery in Shakespeare's Macbeth|2014|Metaphor is an important literary device, and its translation poses the challenge of switching between different cultural, conceptual, and linguistic frames of reference. This study uses cross-cultural comparison to investigate the metaphoric imagery used in six translations of Shakespeare's Macbeth into three languages: French, Italian, and Persian. To accomplish the aims of the study, metaphoric images in this play were identified in the source and target texts and then subjected to comparative analysis using Newmark's categorization of strategies for translating metaphors. After analyzing the translations in the above-mentioned languages, it became apparent that all the translators, including the two Persian translators, tended to retain the same metaphoric images as in the source text. This is somewhat surprising given the greater linguistic and cultural distance between English and Persian. The findings suggest that the literal treatment of metaphors - and not their explicitation - may be a translation universal, at least in regard to canonical texts.|imagery; metaphor; translation strategies; translation of metaphor; Macbeth|TRANSLATING METAPHOR|Linguistics; Language \& Linguistics|0|0|8
Examination of Nursing Data Elements From Evidence-Based Recommendations for Clinical Decision Support|2013|The purpose of this descriptive, exploratory study was to examine the current use, metadata, and availability of delirium data elements in an electronic health record and clinical data repository. The investigation explored risk for ICU delirium by comparing the delirium data elements representing nursing practice at one clinical agency with a Synthesis of evidence-based practice recommendations developed for the Knowledge-Based Nursing Initiative. The analysis provided a description of the representation of data elements and issues related to the availability of data for use in the future development of clinical decision support system that was intended to prevent ICU delirium. Content analysis and descriptive statistics were used to categorize and analyze the instance-level data from the convenience sample of 1714 patients. Forty-one data element categories were derived from the synthesis based on nursing process components and were matched to 160 data elements identified in the clinical agency's electronic health record. The matched data elements were primarily text based, entered by RNs using flow sheets and care planning documentation. Even though there was a high number of potential data element matches, there was considerable variable data availability related to clinical, conceptual, and technical factors. The further development of valid and reliable data that accurately capture the interaction between nurse, patient, and family is necessary before embarking on electronic clinical decision support.|Clinical data elements; Clinical decision support systems; Evidence-based practice; Informatics; Information systems; Nursing|MECHANICALLY VENTILATED PATIENTS; ELECTRONIC HEALTH RECORD; INTENSIVE-CARE-UNIT; DELIRIUM; SYSTEMS|Computer Science, Interdisciplinary Applications; Medical Informatics; Nursing|2|2|8
Interactional resources in the letters of young writers in Swedish and English|2013|This study examines the use of interactional resources in letters to a penfriend of Swedish 11-year-olds in Swedish (L1) and English (FL) from a multi-competence perspective. The objectives of the study are to ascertain whether the language in which the letters were written and the gender of the writers influenced the extent to which interactional meanings were expressed, and also to examine the textual resources that the young novice writers employed to convey interactional meanings in FL. The texts are analysed in terms of both content and discourse-semantic expression, with the discourse-semantic analysis drawing on a Systemic Functional Linguistic framework known as Appraisal. The quantitative results show that, when the amount of text produced is taken into account, there are few significant differences in the frequency of expression of interactional meanings in L1 and FL, but slightly more for gender. The qualitative description identifies a number of language-specific and non-language specific resources used by the writers to enable them to express interactional meanings in FL. In the discussion, these findings are linked to the notion of multi-competence. (C) 2013 Elsevier Inc. All rights reserved.|Young writers; Interactional resources; Multi-competency; Swedish (L1); English (FL); Gender|LANGUAGE; METADISCOURSE; DISCOURSE; WRITTEN; FL|Linguistics|5|2|8
Of babies and bath water: Is there any place for Austin and Grice in interpersonal pragmatics?|2013|This paper discusses a particular strand of interpersonal pragmatics that may be known as `discursive' pragmatics and attempts to delineate what is entailed in such an approach. Some scholars may characterise it as placing emphasis on participant evaluations, others may foreground the analysis of contextualised and sequential texts, while still others consider it to include both of these. In general, though, discursive pragmatics often seems to involve a reaction to, and a contrast with, so-called Gricean intention-based approaches. In this paper I argue that, far from discarding the insights of Grice, Austin and others, a discursive approach to interpersonal pragmatics should embrace those aspects of non-discursive pragmatics that provide us with a `tool-kit' and a vocabulary for examining talk-in-interaction. At the same time, I will argue that the shortcomings of the speaker-based, intention-focused pragmatics can be compensated for, not by privileging hearer evaluations of meaning, but by taking an ethnographic and, to some extent, ethnomethodological approach to the analysis of naturally-occurring discourse data. By providing a critique of Locher and Watts' (2005) paradigmatic example of a discursive approach to politeness and then a sample analysis of interactional data, I demonstrate how a combination of insights from Gricean pragmatics and from ethnomethodology allows the analyst to comment on the construction and negotiation of meaning in discourse, without having recourse to notions of either intention or evaluation. (C) 2013 Elsevier B.V. All rights reserved.|Discursive politeness; Discursive pragmatics; Grice; Austin; Post-modern|POLITENESS THEORY; FACE|Linguistics; Language \& Linguistics|6|0|8
Riddle Appreciation and Reading Comprehension in Cantonese-Speaking Children|2013|Purpose: Inference-making skills are necessary for reading comprehension. Training in riddle appreciation is an effective way to improve reading comprehension among English-speaking children. However, it is not clear whether these methods generalize to other writing systems. The goal of the present study was to investigate the relationship between inference-making skills, as measured by riddle appreciation ability, and reading comprehension performance in typically developing Cantonese-speaking children in the 4th grade. Method: Forty Cantonese-speaking children between the ages of 9;1 (years; months) and 11;0 were given tests of riddle appreciation ability and reading comprehension. Chinese character reading and auditory comprehension abilities were also assessed using tests that had been standardized in Hong Kong. Results: Regression analyses revealed that riddle appreciation ability explained a significant amount of variance in reading comprehension after variance due to character reading skills and auditory comprehension skills were first considered. Orthographic, lexical, morphological, and syntactic riddles were also significantly correlated with reading comprehension. Conclusion: Riddle appreciation ability predicts reading comprehension in Cantonese-speaking 4th-grade children. Therefore, training Cantonese speakers in riddle appreciation should improve their reading comprehension.|reading comprehension; riddles; inference; decoding; Chinese|TEXT COMPREHENSION; COMPONENT SKILLS; WORKING-MEMORY; METALINGUISTIC AWARENESS; DEVELOPMENTAL DYSLEXIA; CHINESE CHILDREN; SIMPLE VIEW; INSTRUCTION; ORTHOGRAPHY; PHONOLOGY|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|0|1|8
Large, huge or gigantic? Identifying and encoding intensity relations among adjectives in WordNet|2013|We propose a new semantic relation for gradable adjectives in WordNet, which enriches the present, vague, similar relation with information on the degree or intensity with which different adjectives express a shared attribute. Using lexical-semantic patterns, we mine the Web for evidence of the relative strength of adjectives like ``large{''}, ``huge{''} and ``gigantic{''} with respect to their attribute ({''}size{''}). The pairwise orderings we derive allow us to construct scales on which the adjectives are located. To represent the intensity relation among gradable adjectives in WordNet, we combine ordered scales with the current WordNet dumbbells based on the relation between a pair of central adjectives and a group of undifferentiated semantically similar adjectives. A new intensity relation links the adjectives in the dumbbells and their concurrent representation on scales. Besides capturing the semantics of gradable adjectives in a way that is both intuitively clear as well as consistent with corpus data, the introduction of an intensity relation would potentially result in several specific benefits for NLP.|Gradable adjectives; Scales; Intensity relation; WordNet|RETRIEVAL; ENGLISH|Computer Science, Interdisciplinary Applications|2|0|8
Qur'anic school sermons as a site for sacred and second language socialisation|2013|Research on Islamic education in Africa has focused on the core curriculum of elementary Qur'anic school - that is, the memorisation, recitation, reading, and writing of the Qur'an without explanation of the literal meaning of the sacred text. Taking a language socialisation perspective, I examine the Qur'anic school sermon as practiced by Fulbe in northern Cameroon. I situate the practice by providing an overview of the Qur'anic school tradition in this community and of the sociolinguistic context in which Fulbe children are being schooled. I then present discourse analysis of a sermon, showing how the activity provides children with instruction in proper Muslim conduct and feeling, as well as Qur'anic Arabic text that is glossed in Fulfulde and connected to their daily lives. I conclude by discussing Qur'anic school sermons as routine activities in which children learn to engage with the Qur'an and other Arabic texts as language that they can comprehend and use in ways that are socially and culturally appropriate in their community.|language socialisation; communicative competence; discourse analysis; second language; Islamic education; codeswitching|LANGUAGE SOCIALIZATION; REPRODUCTION|Linguistics; Language \& Linguistics|4|1|8
It is ... quite common for theoretical predictions to go untested (BNC\_CMH). A register-specific analysis of the English go un-V-en construction|2013|This paper reports on an empirical investigation into the English go un-V-en construction from a usage-based construction-grammar perspective. The starting point is a quantitative analysis of the respective usage data extracted from the complete British National Corpus (BNC), the results of which are correlated with those gained from an analysis of the more general go adjective pattern. In a second step, the data set is reduced to those instances occurring in the four registers academic prose, newspaper texts, fiction and conversation. These are then submitted to a distinctive collexeme analysis to identify the register-specific behaviour of the patterns at issue. The results of this analysis make it plain that register has an impact on whether and how exactly the patterns are used in authentic communication. This finding is seen as an argument in favour of the requirement for a usage-based approach (to constructions) to incorporate extralinguistic factors. (C) 2013 Elsevier B.V. All rights reserved.|Usage-based approach; Construction grammar; Quantitative corpus analysis; go un-V-en construction; Register|LANGUAGE|Linguistics; Language \& Linguistics|4|1|8
Grammatical metaphor in Social Sciences textbooks in Spanish|2013|This paper addresses the study of grammatical metaphor in Spanish, specifically in Social Science textbooks in use in Colombian secondary schools. Our main interest is to analyze, from a Systemic Functional Grammar perspective (Halliday, 1994, 2004b), the particular characteristics of ideational grammatical metaphors in Spanish and their implications for citizenship education and for learning processes. The corpus is made up of chapters about the Industrial Revolution from three eighth-grade texts. Our analysis has identified the presence of grammatical metaphors in Hallidayan terms: nominalizations of processes and qualities and the use of causal verbs in place of conjunctions. We have also identified other types of metaphor: non-ergative clauses, historical present tense, and inanimate participants. The paper also stresses the importance of unpacking metaphors during the process of analysis and also during teaching and learning processes, since unpacking sheds light on information hidden in the metaphor.|grammatical metaphor; nominalization; ideology; learning|CRITICAL DISCOURSE ANALYSIS; LANGUAGE|Linguistics; Language \& Linguistics|1|0|8
Temporality and Textual Engagement in a Middle School English Language Arts Classroom|2012|Using Gadamer's concept of tarrying, this paper explores the impact of classroom temporality on students' engagement with text in an 8th grade English Language Arts classroom. Through an analysis of interactional data collected during two years of an ethnographic study of classroom activities, I show how reading strategies helped constitute and were constituted by a linear, dimensional temporality, within which text and reader were individuated and textual meaning objectified, characterized by an ``ontology of static substance{''} (Ross 2006). In such cases, the act of reading was defined as a processual movement through or consumption of text, which could break down requiring strategies to restore the smooth flow. At other moments, however, interaction around text took on a tarrying temporality. These less frequent moments resonate with Gadamer's claims for the state of understanding associated with the experience of art, a ``being moved{''} (2001: 76), an ``uninterrupted pure gazing{''} (2006: 72) associated with the ``absolute presentness{''} of art (2006: 60). In classroom moments I call tarrying, students were more often engaged in an open-ended, exploratory co-construction of meaning with other participants, rather than producing items at someone else's request. Text was not possessed but, on the contrary, became something that took hold of participants and was jointly occupied or shared. Within such moments, reading strategies, usually decontextualized tools to be applied by an individual subject to a text, receded instead into the tarrying or ``playing{''}-a ``movement backwards and forwards{''} (Gadamer 1975: 93)-of the immediate interactional context.|classroom interaction; phenomenology of reading; temporality; teaching|INSTRUCTION; STRATEGIES; COMPREHENSION|Anthropology; Linguistics; Language \& Linguistics|0|0|8
Leda and the stylisticians|2012|This article presents an analysis of WB Yeats' `Leda and the Swan' for the 21st century, adopting a Text World Theory perspective (Gavins, 2007; Hidalgo Downing, 2000; Werth, 1999) on this iconic poem. In so doing, I also trace the evolution of the discipline of stylistics - from its roots in formalist linguistics, through functionalist and contextualised stylistics, to the development of cognitive poetics - by examining a series of shifting analyses of the text. I argue that the varying treatments of Yeats' poem to be found in Halliday (1966), Widdowson (1975) and Burke (2000) can be seen to mirror the development of stylistics over the last half century. I also argue for the positive contribution cognitive poetics can make towards a fuller contemporary understanding of the complex discoursal configuration of `Leda and the Swan', examining both its textual and conceptual structures and its significant political and historical context.|Cognitive poetics; deixis; Leda and the Swan; political context; split discourse-worlds; stylistics; text-worlds; Text World Theory; WB Yeats|ATTENTION; EKPHRASIS; READERS|Linguistics; Language \& Linguistics|4|0|8
Using EmotiBlog to annotate and analyse subjectivity in the new textual genres|2012|Thanks to the increasing amount of subjective data on the Web 2.0, tools to manage and exploit such data become essential. Our research is focused on the creation of EmotiBlog, a fine-grained annotation scheme for labelling subjectivity in non-traditional textual genres. We also present the EmotiBlog corpus; a collection of blog posts composed by 270,000 tokens about 3 topics and in 3 languages: Spanish, English and Italian. Additionally, we carry out a series of experiments focused on checking the robustness of the model and its applicability to Natural Language Processing tasks with regards to the 3 languages. The experiments for the inter-annotator agreement, as well as for feature selection, provided satisfactory results, which have given an impetus to continue working with the model and extend the annotated corpus. In order to check its applicability, we tested different Machine Learning models created using the annotation in EmotiBlog on other corpora in order to see if the obtained annotation is domain and genre independent, obtaining positive results. Finally, we also applied EmotiBlog to Opinion Mining, proving that our resource allows an improvement the performance of systems built for this task.|Sentiment analysis; Annotation model; Feature selection; Opinion Mining; New textual genres|AGREEMENT|Computer Science, Artificial Intelligence; Computer Science, Information Systems|9|0|8
Rapid modeling and analyzing networks extracted from pre-structured news articles|2012|In the face of uprisings and revolutions happening in several countries within short period of time (Arab Spring 2011), the need for fast network assessments is compelling. In this article we present a rapid network assessment approach which uses a vast amount of pre-indexed news data to provide up-to-date overview and orientation in emerging and ongoing incidents. We describe the fully automated process of preparing the data and creating the dynamic meta-networks. We also describe the network analytical measures that we are using to identify important topics, persons, organizations, and locations in these networks. With our rapid network modeling and analysis approach first results can be provided within hours. In the explorative study of this article we use 108,000+ articles from 600+ English written news sources discussing Egypt, Libya, and Sudan within a time period of 18 months to show an application scenario of our approach. In particular we are looking at the involvement of other countries and their politicians during time periods of major incidents.|Rapid network analysis; Rapid assessment; Network text analysis; Dynamic networks; Two mode networks; Weighted networks|CENTRALITY; BETWEENNESS|Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods|8|0|8
Language and ageing - exploring propositional density in written language - stability over time|2012|This study investigated the stability of propositional density (PD) in written texts, as this aspect of language shows promise as an indicator and as a predictor of language decline with ageing. This descriptive longitudinal study analysed written texts obtained from the Australian Longitudinal Study of Women's Health in which participants were invited to respond to an open-ended question about their health. The 635 texts used for this study were taken from 127 middle-aged women who responded to this question on each of the five surveys conducted at 3-year intervals over a 16-year period. The study made use of an automated PD rater (CPIDR-3) for the analysis. PD was found to be a stable measure over time when comparing the grouped data, but there was between-and within-subject variation over time. Further research is needed to explore the valid use of this measure in research into language and ageing.|propositional density; language; ageing; computerised language analysis|LIFE-SPAN; COGNITIVE FUNCTION; ADULTS; NUN|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|5|0|8
Common data model for natural language processing based on two existing standard information models: CDA+GrAF|2012|An increasing need for collaboration and resources sharing in the Natural Language Processing (NLP) research and development community motivates efforts to create and share a common data model and a common terminology for all information annotated and extracted from clinical text. We have combined two existing standards: the HL7 Clinical Document Architecture (CDA), and the ISO Graph Annotation Format (GrAF; in development), to develop such a data model entitled ``CDA+GrAF{''}. We experimented with several methods to combine these existing standards, and eventually selected a method wrapping separate CDA and GrAF parts in a common standoff annotation (i.e., separate from the annotated text) XML document. Two use cases, clinical document sections, and the 2010 i2b2/VA NLP Challenge (i.e., problems, tests, and treatments, with their assertions and relations), were used to create examples of such standoff annotation documents, and were successfully validated with the XML schemata provided with both standards. We developed a tool to automatically translate annotation documents from the 2010 i2b2/VA NLP Challenge format to GrAF, and automatically generated 50 annotation documents using this tool, all successfully validated. Finally, we adapted the XSL stylesheet provided with HL7 CDA to allow viewing annotation XML documents in a web browser, and plan to adapt existing tools for translating annotation documents between CDA+GrAF and the UIMA and GATE frameworks. This common data model may ease directly comparing NLP tools and applications, combining their output, transforming and ``translating{''} annotations between different NLP applications, and eventually ``plug-and-play{''} of different modules in NLP applications. (c) 2011 Elsevier Inc. All rights reserved.|Natural language processing (MeSH L01.224.065.580); Medical informatics (L01.700); Data model; Information model; HL7 Clinical Document Architecture; ISO Graph Annotation Format|ANNOTATION|Computer Science, Interdisciplinary Applications; Medical Informatics|2|1|8
Using an ensemble system to improve concept extraction from clinical records|2012|Recognition of medical concepts is a basic step in information extraction from clinical records. We wished to improve on the performance of a variety of concept recognition systems by combining their individual results. We selected two dictionary-based systems and five statistical-based systems that were trained to annotate medical problems, tests, and treatments in clinical records. Manually annotated clinical records for training and testing were made available through the 2010 i2b2/VA (Informatics for Integrating Biology and the Bedside) challenge. Results of individual systems were combined by a simple voting scheme. The statistical systems were trained on a set of 349 records. Performance (precision, recall, F-score) was assessed on a test set of 477 records, using varying voting thresholds. The combined annotation system achieved a best F-score of 82.2\% (recall 81.2\%, precision 83.3\%) on the test set, a score that ranks third among 22 participants in the i2b2/VA concept annotation task. The ensemble system had better precision and recall than any of the individual systems, yielding an F-score that is 4.6\% point higher than the best single system. Changing the voting threshold offered a simple way to obtain a system with high precision (and moderate recall) or one with high recall (and moderate precision). The ensemble-based approach is straightforward and allows the balancing of precision versus recall of the combined system. The ensemble system is freely available and can easily be extended, integrated in other systems, and retrained. (C) 2012 Elsevier Inc. All rights reserved.|Clinical record analysis; Natural language processing; Voting scheme; Ensemble system|INFORMATION EXTRACTION; BIOMEDICAL TEXT; CLASSIFIER ENSEMBLES; RECOGNITION; ASSERTIONS; FUSION; IDENTIFICATION; ARCHITECTURE; DOCUMENTS; UMLS|Computer Science, Interdisciplinary Applications; Medical Informatics|12|0|8
Teaching Students With Reading Difficulties to be Close Readers: A Feasibility Study|2009|Purpose: This article describes a program that was designed to help upper elementary students read and understand words as they read texts independently. As a first step in helping middle-to-upper elementary children with mild-to-moderate language and/or reading difficulties engage in textual analysis during reading, the Close Reading program combines instruction in morphological-analysis and context-analysis strategies with guided experiences applying these strategies during reading. Method: To carry out an initial feasibility study of the program, we conducted 3 case studies using standardized pretest and posttest measures of language and reading skills and experimental progress monitoring measures administered before, during, and after instruction. Three fourth-grade girls participated in the 12-week program. Results: All 3 students showed improved word reading and comprehension with small to large effect sizes on standardized and experimental measures. Patterns of improvement reflected the initial strengths and weaknesses of the students' reading and language skills. Conclusion: The results suggest that further experimental investigation of this program is warranted. Instruction in morphological-analysis strategies with guided practice during reading holds promise as a way to improve word reading and comprehension for struggling readers in the middle-to-upper elementary years.|written comprehension disorders; morphology; literacy; intervention|CHILD LANGUAGE INTERVENTION; CLINICAL-OUTCOME RESEARCH; WORD MEANINGS; CONTEXT; INSTRUCTION; DISABILITIES; MODEL; ACQUISITION; DISORDERS; PROGRAM|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|18|3|8
Cognitive archaeology: Uses, methods, and results|2009|The earliest stages of cognitive decline in cases of slowly progressive dementia are difficult to pinpoint, yet detection of the preclinical period of the illness is likely to be of significant importance to understanding Alzheimer's disease and other slowly progressive dementias at both clinical and biological levels. A number of authors have used retrospective analysis to describe preclinical linguistic decline in written texts and spoken language samples. This paper reviews the methods available for classifying and comparing such samples, and presents some exploratory analyses of historical texts derived from verbatim records of preclinical spoken activity. Change in the nature of the language used by Harold Wilson (Prime Minister of the United Kingdom 1964-1970 and 1974-1976) is quantified in the light of a later diagnosis of probable Alzheimer's disease and historical uncertainties about his final months in office. (C) 2008 Elsevier Ltd. All rights reserved.|Alzheimer's disease; Mild cognitive impairment (MCI); Textual analysis; Digital stylometry|EARLY ALZHEIMERS-DISEASE; NEUROFIBRILLARY CHANGES; SENTENCE COMPREHENSION; LANGUAGE; DEMENTIA; IMPAIRMENT; PREVALENCE; COMMUNITY; AUTHOR; CORPUS|Linguistics; Neurosciences; Psychology, Experimental|7|0|8
The effectiveness of implicit and explicit error correction on learners' performance|2009|The study looked at the effects of correction of learners' errors on learning of grammatical features. In particular, the manner of correction (explicit vs. implicit correction) was investigated. The study also focussed on the effectiveness of explicit and implicit correction of developmental early vs. developmental late features. Fifty-six intermediate level Iranian learners of English were asked to read and retell a written text during an interview. The participants were corrected on their grammatical errors implicitly (using recasts) or explicitly during or following the interview. Based on the corrected errors made by learners, individualised tests were constructed and administered. The scores the learners received on these tests were statistically analysed. Results revealed higher scores for explicitly corrected learners than implicitly corrected ones. The findings lend support to the argument concerning the role of metalinguistic awareness in language learning. Further analysis of the scores showed that developmental early features are learned better with explicit correction and developmental late features with implicit correction. I (C) 2008 Elsevier Ltd. All rights reserved.|Second language learning; Error correction; Explicit; Implicit feedback|TEACHING STRATEGIES; INSTRUCTION; FEEDBACK; FORM|Education \& Educational Research; Linguistics|16|1|8
Neurolinguistic approach to natural language processing with applications to medical text analysis|2008|Understanding written or spoken language presumably involves spreading neural activation in the brain. This process may be approximated by spreading activation in semantic networks, providing enhanced representations that involve concepts not found directly in the text. The approximation of this process is of great practical and theoretical interest. Although activations of neural circuits involved in representation of words rapidly change in time snapshots of these activations spreading through associative networks may be captured in a vector model. Concepts of similar type activate larger clusters of neurons, priming areas in the left and right hemisphere. Analysis of recent brain imaging experiments shows the importance of the right hemisphere non-verbal clusterization. Medical ontologies enable development of a large-scale practical algorithm to re-create pathways of spreading neural activations. First concepts of specific semantic type are identified in the text, and then all related concepts of the same type are added to the text, providing expanded representations. To avoid rapid growth of the extended feature space after each step only the most useful features that increase document clusterization are retained. Short hospital discharge summaries are used to illustrate how this process works on a real, very noisy data. Expanded texts show significantly improved clustering and may be classified with much higher accuracy. Although better approximations to the spreading of neural activations may be devised a practical approach presented in this paper helps to discover pathways used by the brain to process specific concepts, and may be used in large-scale applications. (C) 2008 Elsevier Ltd. All rights reserved.|Natural language processing; Semantic networks; Spreading activation networks; Medical ontologies; Vector models in NLP|SPREADING ACTIVATION; INSIGHT; PEOPLE; WORDS|Computer Science, Artificial Intelligence; Neurosciences|19|0|8
How science students can learn about unobservable phenomena using computer-based analogies|2008|A novel instructional computer simulation that incorporates a dynamic analogy to represent Le Chatelier's Principle was designed to investigate the contribution of this feature to students' understanding. Two groups of 12th grade Chemistry students (n = 15) interacted with the computer simulation during the study. Both groups did the same pre-instructional and simulation activities except one of the groups interacted with the analogical example in the simulation and the other group was asked to recall an analogy that was presented in the form of text and pictures. A statistical analysis of the tests administered at the end of the study suggested that analogies that are dynamic, interactive, and integrated in a computer simulation may have a stronger effect on learning outcomes than analogies which are presented in the form of text and static pictures. The implication of this study for science educators is that dynamic computer-based analogies can enhance student learning of unobservable phenomena in science. (C) 2007 Elsevier Ltd. All rights reserved.|simulations; multimedia/hypermedia systems; interactive learning environments; teaching strategies/learning strategies|CHEMICAL-EQUILIBRIUM; REPRESENTATIONS; VISUALIZATIONS; INTEGRATION|Computer Science, Interdisciplinary Applications; Education \& Educational Research|33|0|8
Alienation: A laughing matter|2008|A previously ignored method of assessing relative levels of alienation is the content analysis of work jokes exchanged in different venues. This study uses quantitative content analysis to code 1,085 joke-texts collected from ten job-sites and from the Internet. Using past measurements of powerlessness, meaninglessness, social isolation, and self-estrangement, the author develops a content protocol that is consistent with popular alienation indexes. Past methods for assessing both the functions of humor and the concept of alienation are criticized as tautologies, and null-categories for the social-psychological aspects of alienation (empowerment, understanding, social integration, and self-actualization) are introduced and critically examined. Research expectations are developed, and evaluations of predictions are made by comparing the proportion of jokes between the data sets within each of the conceptual categories. Jokes posted to the Internet are found to have more expressions of alienation it? each of the social-psychological aspects except meaninglessness, which was slightly higher for entry-level service workers. The study concludes that the content analysis of jokes may prove to be a more direct way of accessing group sentiment than the study of either individual sentiment or the social structure of work.|Alienation; humor; jokes; meaninglessness; methodology; workers|JOB-SATISFACTION; WORK; HUMOR; JOKING; POWER; ORGANIZATIONS; COMMUNITY; BEHAVIOR; ALCOHOL|Language \& Linguistics; Psychology, Multidisciplinary|2|0|8
``It's not necessarily the words you say... it's your presentation{''}: Teaching the interactional text of the job interview|2007|This article explores one institution's efforts to teach strategies for succeeding in a customer service job interview. The study takes place at Possibilities Inn, a work-training program aimed at preparing underemployed and unemployed African American adults for jobs in the hospitality industry. In this article, I explore the ways the teachers work not only to build students' competency in the interactional practices believed to be valued by interviewers, but also to change their perception of these practices. Using an analytic approach grounded in Contemporary Linguistic Anthropology, I examine multiple levels of text production in the teachers' interviewing lessons. Looking at long stretches of classroom discourse, I explore the ways the teachers work to socialize the students into valued interviewing behaviors without devaluing the students' means of self-expression. Mock interviews play an important role in the socialization efforts of the teachers. As the teachers and students participate in the event, they explore the various social positions, interactional texts and ideologies associated with the roles of interviewer and interviewee. Through the mock interviews, teachers (a) implicitly construct the interview as a hostile environment, and (b) coach students on how to present themselves as the ``professional{''} person the interviewers will want to hire. The mock interview events also contribute to the teachers' positions as mentors on whom the students can rely for emotional and educational support in their efforts to succeed in their upcoming high stakes gatekeeping events. (c) 2007 Elsevier B.V. All rights reserved.|lnterview(ing) discourse analysis; communities of practice; linguistic anthropology; language ideologies; classroom discourse; adult education|LANGUAGE; PERSPECTIVES; STANDARD|Linguistics; Language \& Linguistics|4|1|8
A Preliminary study of speech discrimination in youth with Down syndrome|2007|Few studies have examined the ability of individuals with learning disabilities, in general, or with Down syndrome, specifically, to discriminate speech. The purpose of this study was compare the speech discrimination abilities of eight children with Down syndrome ( aged 5.7 to 12.8 years) to seven nonverbal mental-age matched controls (aged 4.0 to 5.3 years). A computer program presented the speech discrimination task using a two-cued alternative forced choice procedure. On each trial, the participants heard four successive synthesized speech syllables, with the first and last stimuli being the same and serving as the cue. The results indicated children with Down syndrome differed from their nonverbal mental-age matched peers in their ability to discriminate two of the five pairs, but not in the manner predicted. The relationship between speech discrimination, phonological memory, and speech-language development is also discussed.|speech discrimination; Down syndrome; phonological memory; speech-language development|VERBAL-MOTOR INTEGRATION; LANGUAGE IMPAIRMENT; CEREBRAL SPECIALIZATION; EXPRESSIVE LANGUAGE; GRAMMATICAL MORPHOLOGY; PROCESSING DEFICITS; PHONOLOGICAL MEMORY; NONWORD REPETITION; NATURAL SPEECH; CHILDREN|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|4|0|8
Reversing spoken items - mind twisting not tongue twisting|2005|Using 12 participants we conducted an fMRI study involving two tasks, word reversal and rhyme judgment, based on pairs of natural speech stimuli, to study the neural correlates of manipulating auditory imagery under taxing conditions. Both tasks engaged the left anterior superior temporal gyrus, reflecting previously established perceptual mechanisms. Engagement of the left inferior frontal gyrus in both tasks relative to baseline could only be revealed by applying small volume corrections to the region of interest, suggesting that phonological segmentation played only a minor role and providing further support for factorial dissociation of rhyming and segmentation in phonological awareness. Most importantly, subtraction of rhyme judgment from word reversal revealed activation of the parietal lobes bilaterally and the right inferior frontal cortex, suggesting that the dynamic manipulation of auditory imagery involved in mental reversal of words seems to engage mechanisms similar to those involved in visuospatial working memory and mental rotation. This suggests that reversing spoken items is a matter of mind twisting rather than tongue twisting and provides support for a link between language processing and manipulation of mental imagery. (C) 2004 Elsevier Inc. All rights reserved.|speech; auditory imagery; word reversal; parietal lobes; spatial processing; rhyme judgment; fMRI|WORKING-MEMORY; MENTAL ROTATION; PREFRONTAL CORTEX; RIGHT-HEMISPHERE; TEMPORAL-LOBE; PERCEPTION; SPEECH; BRAIN; FMRI; ACTIVATION|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|7|0|8
Designing talk in social networks: What Facebook teaches about conversation|2017|The easy accessibility, ubiquity, and plurilingualism of popular SNSs such as Facebook have inspired many scholars and practitioners of second language teaching and learning to integrate networked forms of communication into educational contexts such as language classrooms and study abroad programs (e.g., Blattner \& Fiori, 2011; Lamy \& Zourou, 2013; Mills, 2011; Reinhardt \& Ryu, 2013; Reinhardt \& Zander, 2011). At the same time, the complex and dynamic patterns of interaction that emerge in these spaces quickly push back upon standard ways of describing conversational genres and communicative competence (Kern, 2014; Lotherington \& Ronda, 2014). Drawing from an ecological interactional analysis (Goffman, 1964, 1981a, 1981b, 1986; Kramsch \& Whiteside, 2008) of the Facebook communications of three German-speaking academics whose social and professional lives are largely led in English, the authors consider the kinds of symbolic maneuvers required to participate in the translingual conversational flows of SNS-mediated communication. Based on this analysis, this article argues that texts generated through SNS-mediated communication can provide classroom opportunities for critical, stylistically sensitive reflection on the nature of talk in line with multiliteracies approaches.|Discourse Analysis; Social Networking; Technology-Mediated Communication; Literacy|LANGUAGE; INTERNET; SITES|Education \& Educational Research; Linguistics|1|2|7
Feature extraction and selection for Arabic tweets authorship authentication|2017|In tweet authentication, we are concerned with correctly attributing a tweet to its true author based on its textual content. The more general problem of authenticating long documents has been studied before and the most common approach relies on the intuitive idea that each author has a unique style that can be captured using stylometric features (SF). Inspired by the success of modern automatic document classification problem, some researchers followed the Bag-Of-Words (BOW) approach for authenticating long documents. In this work, we consider both approaches and their application on authenticating tweets, which represent additional challenges due to the limitation in their sizes. We focus on the Arabic language due to its importance and the scarcity of works related on it. We create different sets of features from both approaches and compare the performance of different classifiers using them. We experiment with various feature selection techniques in order to extract the most discriminating features. To the best of our knowledge, this is the first study of its kind to combine these different sets of features for authorship analysis of Arabic tweets. The results show that combining all the feature sets we compute yields the best results.|Online social networks; Authorship authentication; Computational intelligence; Stylometric features; BOW features; SVM; NB; Decision tree; Correlation-based feature selection; Relief; PCA; Information gain|E-MAIL; IDENTIFICATION; ATTRIBUTION; TEXT; MESSAGES|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications|0|5|7
Improving a full-text search engine: the importance of negation detection and family history context to identify cases in a biomedical data warehouse|2017|Objective: The repurposing of electronic health records (EHRs) can improve clinical and genetic research for rare diseases. However, significant information in rare disease EHRs is embedded in the narrative reports, which contain many negated clinical signs and family medical history. This paper presents a method to detect family history and negation in narrative reports and evaluates its impact on selecting populations from a clinical data warehouse (CDW). Materials and Methods: We developed a pipeline to process 1.6 million reports from multiple sources. This pipeline is part of the load process of the Necker Hospital CDW. Results: We identified patients with ``Lupus and diarrhea,{''} ``Crohn's and diabetes,{''} and ``NPHP1{''} from the CDW. The overall precision, recall, specificity, and F-measure were 0.85, 0.98, 0.93, and 0.91, respectively. Conclusion: The proposed method generates a highly accurate identification of cases from a CDW of rare disease EHRs.|data warehouse; search engine; natural language processing; rare diseases; electronic health records|SYSTEMIC-LUPUS-ERYTHEMATOSUS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|1|7|7
How do speech-and-language therapists address the psychosocial well-being of people with aphasia? Results of a UK online survey|2017|Background: The psychosocial impact of stroke and aphasia is considerable. Aims: To explore UK speech-and-language therapists' (SLTs) clinical practice in addressing the psychological and social needs of people with aphasia, including their experiences of working with mental health professionals. Methods \& Procedures: A 22-item online survey was distributed to UK SLTs via the British Aphasiology Society mailing list and Clinical Excellence Networks. Results were analysed using descriptive statistics and qualitative content analysis. Outcomes \& Results: UK SLTs (n = 124) overwhelmingly considered that addressing psychological well-being (93\%) and social participation (99\%) was part of their role. To achieve this, they frequently/very frequently used supportive listening (100\%) and selected holistic goals collaboratively with clients (87\%), including social goals (83\%). However, only 42\% felt confident in addressing the psychological needs of clients. The main barriers to addressing psychosocial well-being were time/caseload pressures (72\%); feeling under-skilled/lack of training (64\%), and lack of ongoing support (61\%). The main barriers to referring on to mental health professionals were that mental health professionals were perceived as under-skilled when working with people with aphasia (44\%); were difficult to access (41\%); and provided only a limited service (37\%). Amain theme fromthe free-text responses was a concern that those with aphasia, particularly more severe aphasia, received inadequate psychological support due to the stretched nature of many mental health services; mental health professionals lacking skills working with aphasia; and SLTs lacking the necessary time, training and support. The main enablers to addressing psychosocial well-being were collaborative working between SLTs and stroke-specialist clinical psychologists; SLTs with training in providing psychological and social therapy; and ongoing support provided by the voluntary sector. Conclusions \& Implications: The vast majority of SLTs consider the psychosocial well-being of their clients, and work collaboratively with people with aphasia in selecting holistic goals. It is, however, of concern that most respondents felt they lacked confidence and received insufficient training to address psychological well-being. In order to improve psychological services for this client group, there is a strong case that stroke-specialist mental health professionals should strive to make their service truly accessible to people with even severe aphasia, which may involve working more closely with SLTs. Further, improving the skills and confidence of SLTs may be an effective way of addressing psychological distress in people with aphasia.|psychological well-being; social well-being; aphasia; clinical practice|ISCHEMIC-STROKE; REHABILITATION; DEPRESSION|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|0|6|7
The Experiential Meaning in Saudi Postgraduate Business Students' Multimodal Accounting Texts: A Multidimensional Exploration|2017|The multimodal experiential meanings of accounting play a vital role in maximizing the learning experiences of accounting students. This paper aims to explore the literacy and numeracy practices of six Saudi postgraduate students enrolled in the Master of Commerce accounting foundation module Accounting Concepts and Methods. Responding to repeated calls regarding the lack of research on the literacy and numeracy practices that construe disciplinary subjects, we employed a multidimensional approach proposed by Alyousef to describe the epistemologies of the module and the actual practices the participants engaged with to complete their assignment, in addition to conducting a Systemic Functional Multimodal Discourse Analysis (SF-MDA) of the experiential meanings in accounting texts. The SF-MDA enabled us to capture the patterns of such complicated interrelationships between numbers and texts. The findings of the analysis of the multimodal accounting financial statements demonstrated that systemic functional linguistics provides tools that structure interpretation of the functioning of multimodal texts.|ESL; EFL; Literacy and Numeracy Practices; Experiential Meaning; Business Discourse; Accounting Literacies|THEME|Linguistics; Language \& Linguistics|0|1|7
A passage retrieval method based on probabilistic information retrieval model and UMLS concepts in biomedical question answering|2017|Background and Objective: Passage retrieval, the identification of top-ranked passages that may contain the answer for a given biomedical question, is a crucial component for any biomedical question answering(QA) system. Passage retrieval in open-domain QA is a longstanding challenge widely studied over the last decades. However, it still requires further efforts in biomedical QA. In this paper, we present a new biomedical passage retrieval method based on Stanford CoreNLP sentence/passage length, probabilistic information retrieval (IR) model and UMLS concepts. Methods: In the proposed method, we first use our document retrieval system based on PubMed search engine and UMLS similarity to retrieve relevant documents to a given biomedical question. We then take the abstracts from the retrieved documents and use Stanford CoreNLP for sentence splitter to make a set of sentences, i.e., candidate passages. Using stemmed words and UMLS concepts as features for the BM25 model, we finally compute the similarity scores between the biomedical question and each of the candidate passages and keep the N top-ranked ones. Results: Experimental evaluations performed on large standard datasets, provided by the BioASQ challenge, show that the proposed method achieves good performances compared with the current stateof-the-art methods. The proposed method significantly outperforms the current state-of-the-art methods by an average of 6.84\% in terms of mean average precision (MAP). Conclusion: We have proposed an efficient passage retrieval method which can be used to retrieve relevant passages in biomedical QA systems with high mean average precision. (C) 2017 Elsevier Inc. All rights reserved.|Biomedical question answering system; Biomedical passage retieval; Probabilistic information retrieval model; Unified medical language system; Natural language processing; Biomedical informatics|COMPLEX CLINICAL QUESTIONS; QUERY EXPANSION; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|2|6|7
Semi-supervised Learning for Affective Common-Sense Reasoning|2017|Big social data analysis is the area of research focusing on collecting, examining, and processing large multi-modal and multi-source datasets in order to discover patterns/correlations and extract information from the Social Web. This is usually accomplished through the use of supervised and unsupervised machine learning algorithms that learn from the available data. However, these are usually highly computationally expensive, either in the training or in the prediction phase, as they are often not able to handle current data volumes. Parallel approaches have been proposed in order to boost processing speeds, but this clearly requires technologies that support distributed computations. Extreme learning machines (ELMs) are an emerging learning paradigm, presenting an efficient unified solution to generalized feed-forward neural networks. ELM offers significant advantages such as fast learning speed, ease of implementation, and minimal human intervention. However, ELM cannot be easily parallelized, due to the presence of a pseudo-inverse calculation. Therefore, this paper aims to find a reliable method to realize a parallel implementation of ELM that can be applied to large datasets typical of Big Data problems with the employment of the most recent technology for parallel in-memory computation, i.e., Spark, designed to efficiently deal with iterative procedures that recursively perform operations over the same data. Moreover, this paper shows how to take advantage of the most recent advances in statistical learning theory (SLT) in order to address the issue of selecting ELM hyperparameters that give the best generalization performance. This involves assessing the performance of such algorithms (i.e., resampling methods and in-sample methods) by exploiting the most recent results in SLT and adapting them to the Big Data framework. The proposed approach has been tested on two affective analogical reasoning datasets. Affective analogical reasoning can be defined as the intrinsically human capacity to interpret the cognitive and affective information associated with natural language. In particular, we employed two benchmarks, each one composed by 21,743 common-sense concepts; each concept is represented according to two models of a semantic network in which common-sense concepts are linked to a hierarchy of affective domain labels. The labeled data have been split into two sets: The first 20,000 samples have been used for building the model with the ELM with the different SLT strategies, while the rest of the labeled samples, numbering 1743, have been kept apart as reference set in order to test the performance of the learned model. The splitting process has been repeated 30 times in order to obtain statistically relevant results. We ran the experiments through the use of the Google Cloud Platform, in particular, the Google Compute Engine. We employed the Google Compute Engine Platform with NM = 4 machines with two cores and 1.8 GB of RAM (machine type n1-highcpu-2) and an HDD of 30 GB equipped with Spark. Results on the affective dataset both show the effectiveness of the proposed parallel approach and underline the most suitable SLT strategies for the specific Big Data problem. In this paper we showed how to build an ELM model with a novel scalable approach and to carefully assess the performance, with the use of the most recent results from SLT, for a sentiment analysis problem. Thanks to recent technologies and methods, the computational requirements of these methods have been improved to allow for the scaling to large datasets, which are typical of Big Data applications.|Analogical reasoning; Sentiment analysis; Semi-supervised learning; Classification; Model selection; Extreme learning machines; Vapnik-Chervonenkis theory; Rademacher complexity; Algorithmic stability|STRUCTURAL RISK MINIMIZATION; SENTIMENT ANALYSIS; MODEL SELECTION; SOCIAL MEDIA; PROBABILITY-INEQUALITIES; RADEMACHER COMPLEXITY; ERROR ESTIMATION; BOUNDS; MACHINES; STABILITY|Computer Science, Artificial Intelligence; Neurosciences|1|3|7
Legitimating Multilingual Teacher Identities in the Mainstream Classroom|2017|This article explores the identities of a group of elementary teachers who participated in a professional development (PD) project on multilingual language learners.1 We study how the participating teachers drew on different aspects of their identities to respond to encouragement to increase their attention to students' diverse multilingual repertoires in classroom practices. Drawing onresearch that has sought to open up more spaces for multilingualism in North American, English-medium schooling, the teachers were invited to create multilingual print environments (Lotherington, ), use group work to increase oral participation among multilingual learners, invite students to take on the role of language teacher' (Cary, ), and encourage students to author multilingual identity texts (Cummins \& Early, ). As the teachers grappled with these ideas, we collected data in the form of classroom observation notes, interviews, assignments, and WebCT posts. Using Gee's (2001) framework for identity, our analysis sheds light on how the teachers enacted their professional identities as they worked to put the PD concepts and recommendations into practice. Our analysis reveals how the teachers' own linguistic histories strongly shaped their views about multilingualism in schools, but it also demonstrates that a formally sanctioned opportunity to experiment with multilingual pedagogies opened up new spaces for critical self-reflection about the links among languages, teachers' identities, and academic engagement for multilingual learners.|teacher identities; multilingual language learners; professional development; mainstream classrooms|PEDAGOGY|Education \& Educational Research; Linguistics|0|3|7
Conducting Sparse Feature Selection on Arbitrarily Long Phrases in Text Corpora with a Focus on Interpretability|2016|We propose a general framework for topic-specific summarization of large text corpora, and illustrate how it can be used for analysis in two quite different contexts: an Occupational Safety and Health Administration (OSHA) database of fatality and catastrophe reports (to facilitate surveillance for patterns in circumstances leading to injury or death), and legal decisions on workers' compensation claims (to explore relevant case law). Our summarization framework, built on sparse classification methods, is a compromise between simple word frequency-based methods currently in wide use, and more heavyweight, model-intensive methods such as latent Dirichlet allocation (LDA). For a particular topic of interest (e.g., mental health disability, or carbon monoxide exposure), we regress a labeling of documents onto the high-dimensional counts of all the other words and phrases in the documents. The resulting small set of phrases found as predictive are then harvested as the summary. Using a branch-and-bound approach, this method can incorporate phrases of arbitrary length, which allows for potentially rich summarization. We discuss how focus on the purpose of the summaries can inform choices of tuning parameters and model constraints. We evaluate this tool by comparing the computational time and summary statistics of the resulting word lists to three other methods in the literature. We also present a new R package, textreg. Overall, we argue that sparse methods have much to offer in text analysis and is a branch of research that should be considered further in this context. (C) 2016 Wiley Periodicals, Inc.|concise comparative summarization; sparse classification; regularized regression; Lasso; text summarization; text mining; key-phrase extraction; text classification; high-dimensional analysis; L2 normalization|COORDINATE DESCENT; CATEGORIZATION; REGRESSION; REGULARIZATION; MODEL|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Statistics \& Probability|0|2|7
NASARI: Integrating explicit knowledge and corpus statistics for a multilingual representation of concepts and entities|2016|Owing to the need for a deep understanding of linguistic items, semantic representation is considered to be one of the fundamental components of several applications in Natural Language Processing and Artificial Intelligence. As a result, semantic representation has been one of the prominent research areas in lexical semantics over the past decades. However, due mainly to the lack of large sense-annotated corpora, most existing representation techniques are limited to the lexical level and thus cannot be effectively applied to individual word senses. In this paper we put forward a novel multilingual vector representation, called NASARI, which not only enables accurate representation of word senses in different languages, but it also provides two main advantages over existing approaches: (1) high coverage, including both concepts and named entities, (2) comparability across languages and linguistic levels (i.e., words, senses and concepts), thanks to the representation of linguistic items in a single unified semantic space and in a joint embedded space, respectively. Moreover, our representations are flexible, can be applied to multiple applications and are freely available at http://1cl.uniroma1.it/nasari/. As evaluation benchmark, we opted for four different tasks, namely, word similarity, sense clustering, domain labeling, and Word Sense Disambiguation, for each of which we report state-of-the-art performance on several standard datasets across different languages. (C) 2016 Elsevier B.V. All rights reserved.|Semantic representation; Lexical semantics; Word Sense Disambiguation; Semantic similarity; Sense clustering; Domain labeling|LATENT SEMANTIC ANALYSIS; SIMILARITY; RELATEDNESS; CONTEXT; WIKIPEDIA; INDUCTION; SEARCH|Computer Science, Artificial Intelligence|3|1|7
A computational framework for converting textual clinical diagnostic criteria into the quality data model|2016|Background: Constructing standard and computable clinical diagnostic criteria is an important but challenging research field in the clinical informatics community. The Quality Data Model (QDM) is emerging as a promising information model for standardizing clinical diagnostic criteria. Objective: To develop and evaluate automated methods for converting textual clinical diagnostic criteria in a structured format using QDM. Methods: We used a clinical Natural Language Processing (NLP) tool known as cTAKES to detect sentences and annotate events in diagnostic criteria. We developed a rule-based approach for assigning the QDM datatype(s) to an individual criterion, whereas we invoked a machine learning algorithm based on the Conditional Random Fields (CRFs) for annotating attributes belonging to each particular QDM datatype. We manually developed an annotated corpus as the gold standard and used standard measures (precision, recall and f-measure) for the performance evaluation. Results: We harvested 267 individual criteria with the datatypes of Symptom and Laboratory Test from 63 textual diagnostic criteria. We manually annotated attributes and values in 142 individual Laboratory Test criteria. The average performance of our rule-based approach was 0.84 of precision, 0.86 of recall, and 0.85 off-measure; the performance of CRFs-based classification was 0.95 of precision, 0.88 of recall and 0.91 of f-measure. We also implemented a web-based tool that automatically translates textual Laboratory Test criteria into the QDM XML template format. The results indicated that our approaches leveraging cTAKES and CRFs are effective in facilitating diagnostic criteria annotation and classification. Conclusion: Our NLP-based computational framework is a feasible and useful solution in developing diagnostic criteria representation and computerization. (C) 2016 Elsevier Inc. All rights reserved.|Diagnostic criteria; Quality data model; Natural language processing; cTAKES; Conditional random fields|INFORMATION EXTRACTION; DISCHARGE SUMMARIES; GUIDELINES; DOCUMENTS; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|1|1|7
Assessing Comprehension in Kindergarten Through Third Grade|2016|Traditional measures of reading ability designed for younger students typically focus on componential skills (e.g., decoding, vocabulary), and the items are often presented in a discrete and decontextualized format. The current study was designed to explore whether it was feasible to develop a more integrated, scenario-based assessment of comprehension for younger students. A secondary goal was to examine developmental differences in item performance when administration was in listening versus reading modalities. Cross-sectional differences were examined across kindergarten to third grade on a scenario-based assessment comprising literal comprehension, inference, vocabulary, and background knowledge items. The assessment, originally targeted for third grade, was administered one-on-one to 141 third-grade and 485 second-grade students. It was adapted for and administered to kindergarten (n = 390) and first-grade (n = 419) students by reducing the number of items and switching to a listening comprehension method of administration. Each grade was significantly more accurate than the previous grade on overall performance and background knowledge. A regression analysis showed significant variance associated with background knowledge in predicting comprehension, even after controlling for grade. A deeper analysis of item performance across grades was conducted to examine what elements worked well and where improvements should be made in adapting comprehension assessments for use with young children.|assessment; early literacy; listening comprehension; reading comprehension; scenario-based assessment|READING-COMPREHENSION; PRIOR KNOWLEDGE; INDIVIDUAL-DIFFERENCES; SIMPLE VIEW; READERS; MEMORY; TEXTS; LANGUAGE; MODEL; ASSESSMENTS|Linguistics; Rehabilitation|2|4|7
A method for modeling co-occurrence propensity of clinical codes with application to ICD-10-PCS auto-coding|2016|Objective Natural language processing methods for medical auto-coding, or automatic generation of medical billing codes from electronic health records, generally assign each code independently of the others. They may thus assign codes for closely related procedures or diagnoses to the same document, even when they do not tend to occur together in practice, simply because the right choice can be difficult to infer from the clinical narrative. Methods We propose a method that injects awareness of the propensities for code co-occurrence into this process. First, a model is trained to estimate the conditional probability that one code is assigned by a human coder, given than another code is known to have been assigned to the same document. Then, at runtime, an iterative algorithm is used to apply this model to the output of an existing statistical auto-coder to modify the confidence scores of the codes. Results We tested this method in combination with a primary auto-coder for International Statistical Classification of Diseases-10 procedure codes, achieving a 12\% relative improvement in F-score over the primary auto-coder baseline. The proposed method can be used, with appropriate features, in combination with any auto-coder that generates codes with different levels of confidence. Conclusions The promising results obtained for International Statistical Classification of Diseases-10 procedure codes suggest that the proposed method may have wider applications in auto-coding.|Clinical Coding; ICD-10; Probability Learning; Logistic Regression|CLASSIFICATION; ASSIGNMENT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|0|7
Automated identification and predictive tools to help identify high-risk heart failure patients: pilot evaluation|2016|Objective Develop and evaluate an automated identification and predictive risk report for hospitalized heart failure (HF) patients. Methods Dictated free-text reports from the previous 24 h were analyzed each day with natural language processing (NLP), to help improve the early identification of hospitalized patients with HF. A second application that uses an Intermountain Healthcare-developed predictive score to determine each HF patient's risk for 30-day hospital readmission and 30-day mortality was also developed. That information was included in an identification and predictive risk report, which was evaluated at a 354-bed hospital that treats high-risk HF patients. Results The addition of NLP-identified HF patients increased the identification score's sensitivity from 82.6\% to 95.3\% and its specificity from 82.7\% to 97.5\%, and the model's positive predictive value is 97.45\%. Daily multidisciplinary discharge planning meetings are now based on the information provided by the HF identification and predictive report, and clinician's review of potential HF admissions takes less time compared to the previously used manual methodology (10 vs 40 min). An evaluation of the use of the HF predictive report identified a significant reduction in 30-day mortality and a significant increase in patient discharges to home care instead of to a specialized nursing facility. Conclusions Using clinical decision support to help identify HF patients and automatically calculating their 30-day all-cause readmission and 30-day mortality risks, coupled with a multidisciplinary care process pathway, was found to be an effective process to improve HF patient identification, significantly reduce 30-day mortality, and significantly increase patient discharges to home care.|clinical decision support; heart failure; risk stratification|END-POINTS; SCORE; HOSPITALIZATION; MORTALITY; SURVIVAL; TRENDS; STRATIFICATION; IMPACT; DEATH; TRIAL|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|9|1|7
A new algorithmic approach for the extraction of temporal associations from clinical narratives with an application to medical product safety surveillance reports|2016|The sheer volume of textual information that needs to be reviewed and analyzed in many clinical settings requires the automated retrieval of key clinical and temporal information. The existing natural language processing systems are often challenged by the low quality of clinical texts and do not demonstrate the required performance. In this study, we focus on medical product safety report narratives and investigate the association of the clinical events with appropriate time information. We developed a novel algorithm for tagging and extracting temporal information from the narratives, and associating it with related events. The proposed algorithm minimizes the performance dependency on text quality by relying only on shallow syntactic information and primitive properties of the extracted event and time entities. We demonstrated the effectiveness of the proposed algorithm by evaluating its tagging and time assignment capabilities on 140 randomly selected reports from the US Vaccine Adverse Event Reporting System (VAERS) and the FDA (Food and Drug Administration) Adverse Event Reporting System (FAERS). We compared the performance of our tagger with the SUTime and HeidelTime taggers, and our algorithm's event time associations with the Temporal Awareness and Reasoning Systems for Question Interpretation (TARSQI). We further evaluated the ability of our algorithm to correctly identify the time information for the events in the 2012 Informatics for Integrating Biology and the Bedside (i2b2) Challenge corpus. For the time tagging task, our algorithm performed better than the SUTime and the HeidelTime taggers (F-measure in VAERS and FAERS: Our algorithm: 0.86 and 0.88, SUTime: 0.77 and 0.74, and HeidelTime 0.75 and 0.42, respectively). In the event-time association task, our algorithm assigned an inappropriate timestamp for 25\% of the events, while the TARSQI toolkit demonstrated a considerably lower performance, assigning inappropriate timestamps in 61.5\% of the same events. Our algorithm also supported the correct calculation of 69\% of the event relations to the section time in the i2b2 testing set. Published by Elsevier Inc.|Natural language processing; Post-marketing surveillance; Temporal information|INFORMATION EXTRACTION; TEXT; SYSTEM; EVENTS|Computer Science, Interdisciplinary Applications; Medical Informatics|4|1|7
Mining Privacy Goals from Privacy Policies Using Hybridized Task Recomposition|2016|Privacy policies describe high-level goals for corporate data practices; regulators require industries to make available conspicuous, accurate privacy policies to their customers. Consequently, software requirements must conform to those privacy policies. To help stakeholders extract privacy goals from policies, we introduce a semiautomated framework that combines crowdworker annotations, natural language typed dependency parses, and a reusable lexicon to improve goal-extraction coverage, precision, and recall. The framework evaluation consists of a five-policy corpus governing web and mobile information systems, yielding an average precision of 0.73 and recall of 0.83. The results show that no single framework element alone is sufficient to extract goals; however, the overall framework compensates for elemental limitations. Human annotators are highly adaptive at discovering annotations in new texts, but those annotations can be inconsistent and incomplete; dependency parsers lack sophisticated, tacit knowledge, but they can perform exhaustive text search for prospective requirements indicators; and while the lexicon may never completely saturate, the lexicon terms can be reliably used to improve recall. Lexical reuse reduces false negatives by 41\%, increasing the average recall to 0.85. Last, crowd workers were able to identify and remove false positives by around 80\%, which improves average precision to 0.93.|Design; Languages; Requirements extraction; crowdsourcing; natural language processing; privacy|REQUIREMENTS SPECIFICATIONS; CATEGORIZATION; ELICITATION; LANGUAGE; NOVICES; EXPERTS|Computer Science, Software Engineering|3|2|7
Electronic medical record phenotyping using the anchor and learn framework|2016|Background Electronic medical records (EMRs) hold a tremendous amount of information about patients that is relevant to determining the optimal approach to patient care. As medicine becomes increasingly precise, a patient's electronic medical record phenotype will play an important role in triggering clinical decision support systems that can deliver personalized recommendations in real time. Learning with anchors presents a method of efficiently learning statistically driven phenotypes with minimal manual intervention. Materials and Methods We developed a phenotype library that uses both structured and unstructured data from the EMR to represent patients for real-time clinical decision support. Eight of the phenotypes were evaluated using retrospective EMR data on emergency department patients using a set of prospectively gathered gold standard labels. Results We built a phenotype library with 42 publicly available phenotype definitions. Using information from triage time, the phenotype classifiers have an area under the ROC curve (AUC) of infection 0.89, cancer 0.88, immunosuppressed 0.85, septic shock 0.93, nursing home 0.87, anticoagulated 0.83, cardiac etiology 0.89, and pneumonia 0.90. Using information available at the time of disposition from the emergency department, the AUC values are infection 0.91, cancer 0.95, immunosuppressed 0.90, septic shock 0.97, nursing home 0.91, anticoagulated 0.94, cardiac etiology 0.92, and pneumonia 0.97. \textbackslash{} Discussion The resulting phenotypes are interpretable and fast to build, and perform comparably to statistically learned phenotypes developed with 5000 manually labeled patients. Conclusion Learning with anchors is an attractive option for building a large public repository of phenotype definitions that can be used for a range of health IT applications, including real-time decision support.|machine learning; knowledge representation; natural language processing; clinical decision support systems; electronic health records|HEALTH RECORDS; EMERGE NETWORK; VARIANTS; GENOME; CARE; SYSTEMS; WIDE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|8|0|7
The relationship between the Nasality Severity Index 2.0 and perceptual judgments of hypernasality|2016|Purpose: The Nasality Severity Index 2.0 (NSI 2.0) forms a new, multiparametric approach in the identification of hypernasality. The present study aimed to investigate the correlation between the NSI 2.0 scores and the perceptual assessment of hypernasality. Method: Speech samples of 35 patients, representing a range of nasality from normal to severely hypernasal, were rated by four expert speech-language pathologists using visual analogue scaling (VAS) judging the degree of hypernasality, audible nasal airflow (ANA) and speech intelligibility. Inter- and intra-listener reliability was verified using intraclass correlation coefficients. Correlations between NSI 2.0 scores and its parameters (i.e. nasalance score of an oral text and vowel /u/, voice low tone to high tone ratio of the vowel /i/) and the degree of hypernasality were determined using Pearson correlation coefficients. Multiple linear regression analysis was used to investigate the possible influence of ANA and speech intelligibility on the NSI 2.0 scores. Results: Overall good to excellent inter- and intra-listener reliability was found for the perceptual ratings. A moderate, but significant negative correlation between NSI 2.0 scores and perceived hypernasality (r = -0.64) was found, in which a more negative NSI 2.0 score indicates the presence of more severe hypernasality. No significant influence of ANA or intelligibility on the NSI 2.0 was observed based on the regression analysis. Conclusion: Because the NSI 2.0 correlates significantly with perceived hypernasality, it provides an easy-to-interpret severity score of hypernasality which will facilitate the evaluation of therapy outcomes, communication to the patient and other clinicians, and decisions for treatment planning, based on a multiparametric approach. However, research is still necessary to further explore the instrumental correlates of perceived hypernasality. Learning outcomes: The reader will be able to (1) describe and discuss current issues and influencing variables regarding perceptual ratings of hypernasality; (2) describe and discuss the relationship between the Nasality Severity Index 2.0, a new multiparametric approach to hypernasality, and perceptual judgments of hypernasality based on visual analogue scale ratings; (3) compare these results with the correlations based on a single parameter approach and (4) describe and discuss the possible influence of audible nasal airflow and speech intelligibility on the NSI 2.0 scores. (C) 2016 Elsevier Inc. All rights reserved.|Nasality Severity Index 2.0; Hypernasality; Perceptual judgment; Visual analogue scale|DIRECT MAGNITUDE ESTIMATION; HIGH TONE RATIO; VOICE LOW TONE; AND/OR VELOPHARYNGEAL DYSFUNCTION; EQUAL-APPEARING INTERVAL; PHARYNGEAL FLAP SURGERY; CLEFT-PALATE; NASALANCE SCORES; LISTENER JUDGMENTS; DUTCH PATIENTS|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|2|0|7
``In the mind's eye': A cognitive linguistic re-construction of WD Snodgrass' ``Matisse: The Red Studio'|2016|Although ekphrastic poetry has always been a popular poetic genre, the twentieth century saw a profusion in the production of literary texts that describe art objects. Ekphrastic criticism is abundant with critical discussions raising questions concerning aesthetics, the value of artistic creations, and the nature of representation. However, these discussions rarely consider the experience of reading an ekphrastic poem or account for readers' responses to ekphrastic texts. The present paper uses the tools and methodology of cognitive poetics to examine how WD Snodgrass' ekphrastic poem Matisse: The Red Studio' may be mentally reconstructed. The analysis focuses on figure-ground relations and the psychological notion of attention to explore how textual cues are brought together to create a representation of the painting described in the poem. It examines the use of particular lexical items that denote colors, forms, and textures as they become available for processing into objects. While addressing Snodgrass' questions concerning the ownership of art objects and the notion of still movement', it also illustrates the ability of cognitive poetics to account for reader responses to ekphrastic poems in a way that complements and expands on trends in linguistics and literary criticism.|Attention; cognitive poetics; ekphrasis; figure-ground organization; immediate scope; kinesis; present participle; stasis; still movement; WD Snodgrass|EKPHRASIS|Linguistics; Language \& Linguistics|0|0|7
Teacher expectations and student literacy engagement and achievement|2016|Notwithstanding the complex and dynamic nature of teaching and learning in schools, over four decades of research findings have consistently revealed a correlation between teacher expectations and student achievement. Focusing on teacher expectations for the narrative structures created by young children, this article features a discussion of data gathered during a multifaceted study with 7- and 8-year-old students. The overall purpose of the case study research was to explore the development of student understanding of elements of visual art and design and diverse narrative structures in picturebooks. For the culminating activity of the research, the students had opportunities to apply and transform their knowledge of the instructional foci when they composed their own multimodal print texts. Analysis of the students' narrative structures revealed the multiple forms of metalepsis, the purposeful breaking of storyworld/narrative boundaries, evident in their writing and artwork. In addition to a discussion about the socially situated nature of the children's multimodal text-making, the article includes a consideration of the importance of teacher expectations with respect to student literacy engagement and achievement.|picturebooks; early years; multimodality; writing; narrative; pedagogy|CLASSROOM; INSTRUCTION; AGE|Education \& Educational Research; Linguistics; Language \& Linguistics|0|1|7
``I'm an artist and a scholar who is trying to find a middle point{''}: A textographic analysis of a Colombian art historian's thesis writing|2014|As the number of periphery scholars who pursue graduate studies in the U.S. increases, there is an urgent need to understand how these multilingual writers build knowledge on academic writing in their second language (L2) and join the academic dialogs of their disciplinary communities. Drawing on theories of translingualism (e.g., Homer, Lu, Royster, \& Trimbur, 2011) and cultural-historical activity (e.g., Prior, 1998), this textographic study reports on a multilingual graduate student's knowledge construction during the process of thesis writing. The central research questions of this study include: (i) What are some of the rhetorical enactments and literacy practices this multilingual writer developed around his thesis writing? (ii) What writerly identities are constructed in art oriented, new humanities thesis/dissertation writing? As results illustrate, navigation of academic writing with multiple modalities and languages during thesis writing help multilingual writers carve a creative space for theory construction which eventually contributes to the writer's scholarly identity growth. Examining some of the key translingual academic practices in their engagement with multiple texts around thesis writing, this paper reveals how an experienced multilingual writer utilized his cultural and symbolic capital as he constructed his identity both as an art historian and an emerging scholar. (C) 2014 Elsevier Inc. All rights reserved.|Textography; Thesis writing; Multilingual writers; Translingual academic literacy; Culturalhistoric activity theory (CHAT)|PERFORMING-ARTS; SOCIALIZATION; STUDENTS|Linguistics|4|0|7
Recent official policy and concepts of reading comprehension and inference: the case of England's primary curriculum|2014|This article engages with recent policy on reading comprehension. It argues that the construct of inference has been treated as a single entity despite research and literature to the contrary, and this is perpetuated in the National Curriculum for 2014. It explores the limitations of conceptualising inference as a unitary construct and demonstrates that official policy has confused progression in inference with the process of a reader building a mental representation of a text. It argues that criterion-referenced statements for progression in inference are flawed. The article proposes a means of conceptualising inference so it can be operationalised for the purpose of teaching and learning in the classroom. This is exemplified and applied to an example of a standardised test.|comprehension; inference; reading; primary; policy analysis; literacy; policy; curriculum; assessment|TEXT COMPREHENSION|Education \& Educational Research; Linguistics; Language \& Linguistics|3|0|7
Just what is narrative urgency?|2014|This article takes as its main point of departure a body of empirical research on reading and text processing, and makes particular reference to the type of experiments conducted in Egidi and Gerrig (2006) and Rapp and Gerrig (2006). Broadly put, these experiments (i) explore the psychology of readers' preferences for narrative outcomes, (ii) examine the way readers react to characters' goals and actions, and (iii) investigate how readers tend to identify with characters' goals the more `urgently' those goals are narrated. The present article signals how stylistics can productively enrich such experimental work. Stylistics, it is argued, is well equipped to deal with subtle and nuanced variations in textual patterns without losing sight of the broader cognitive and discoursal positioning of readers in relation to these patterns. Making particular reference to what might constitute narrative `urgency', the article develops a model which amalgamates different strands of contemporary research in narrative stylistics. This model advances and elaborates three key components: a Stylistic Profile, a Burlesque Block and a Kuleshov Monitor. Developing analyses of, and informal informant tests on, examples of both fiction and film, the article calls for a more rounded and sophisticated understanding of style in empirical research on subjects' responses to patterns in narrative.|Burlesque (in style); film narrative; Kuleshov (effect); narrative style; Pyscho; text processing; ``urgency'|IMPACT|Linguistics; Language \& Linguistics|3|0|7
Knowledge engineering in the legal domain: The construction of a FunGramKB Satellite Ontology|2014|One of the most time-consuming tasks in the daily work of legal professions is the search for information in the field of law. To implement advanced computer-based applications of natural language processing in this regard, we have developed a model of specialized knowledge representation driven by the deep semantics of FunGramKB, a multilingual general-purpose lexico-conceptual knowledge base. In particular, our research results in a terminological ontology on criminal law in the domain of transnational terrorism and organized crime to be implemented in intelligent systems which aim to understand legal discourse automatically. The objective of this paper is to describe the methodology used in the development of that ontology, focusing on the computerised tool to assist linguists in the process of terminological acquisition and conceptualization.|Knowledge engineering; ontology; FunGramKB; terminology; law|SEMANTIC SIMILARITY; INFORMATION-CONTENT; CONSCIOUSNESS; FRAMEWORK|Linguistics; Language \& Linguistics|5|2|7
QUALITATIVE ASSESSMENT DYNAMICS - COMPLEMENTING TRUST METHODS FOR DECISION MAKING|2014|Trust is not only one key ingredient of prosperous organizations and societies, but also an essential factor in decision-making processes. And when it comes to trust, the latest advances in computing sciences area are increasingly supporting the related processes by deployment of so-called trust management systems. These systems are slowly advancing from their early stages of evolution toward more sophisticated and already operationally deployable solutions. As there seems to be no ``Swiss-army knife{''} like methodology for trust management, it is reasonable to assume that not only one, but a few of them will be deployed in the future, depending on their basic principles of functioning, purposes and contexts of use. Therefore there still exists a gap in this area with unaddressed issues where humans (or humans-like agents) would be in focus. Quality Assessment Dynamics, QAD, which is presented in this paper, is taking these issues into account. It is based on operands and operators that model human ways of reasoning as described in many natural languages. Further, it is a formal system and therefore enabled for deployment in computing environments. This way QAD complements existing trust management methods and provides additional means for decision making through deployment in simulations and in trust management engines, while being understandable to ordinary users without requiring sophisticated expert knowledge.|Decision making; trust management; user modeling; multi-agent systems; simulation|MANAGEMENT; EMOTION; DESIGN; MODEL|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Operations Research \& Management Science|0|1|7
eTACTS: A method for dynamically filtering clinical trial search results|2013|Objective: Information overload is a significant problem facing online clinical trial searchers. We present eTACTS, a novel interactive retrieval framework using common eligibility tags to dynamically filter clinical trial search results. Materials and methods: eTACTS mines frequent eligibility tags from free-text clinical trial eligibility criteria and uses these tags for trial indexing. After an initial search, eTACTS presents to the user a tag cloud representing the current results. When the user selects a tag, eTACTS retains only those trials containing that tag in their eligibility criteria and generates a new cloud based on tag frequency and co-occurrences in the remaining trials. The user can then select a new tag or unselect a previous tag. The process iterates until a manageable number of trials is returned. We evaluated eTACTS in terms of filtering efficiency, diversity of the search results, and user eligibility to the filtered trials using both qualitative and quantitative methods. Results: eTACTS (I) rapidly reduced search results from over a thousand trials to ten; (2) highlighted trials that are generally not top-ranked by conventional search engines; and (3) retrieved a greater number of suitable trials than existing search engines. Discussion: eTACTS enables intuitive clinical trial searches by indexing eligibility criteria with effective tags. User evaluation was limited to one case study and a small group of evaluators due to the long duration of the experiment. Although a larger-scale evaluation could be conducted, this feasibility study demonstrated significant advantages of eTACTS over existing clinical trial search engines. Conclusion: A dynamic eligibility tag cloud can potentially enhance state-of-the-art clinical trial search engines by allowing intuitive and efficient filtering of the search result space. (C) 2013 The Authors. Published by Elsevier Inc. All rights reserved.|Information storage and retrieval; Clinical trials; Dynamic information filtering; Interactive information retrieval; Tag cloud; Association rules|ELIGIBILITY CRITERIA; INFORMATION-RETRIEVAL; TAG CLOUDS; TEXT; REPRESENTATION; RECRUITMENT; INTERNET; DESIGN; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|8|0|7
Multilingualism, Multimodality and Identity Construction on French-Based Amazigh (Berber) Websites|2013|This article investigates the vital processes of identity construction (i.e. interactive semiotic processes) on multilingual French-based Amazigh websites. It examines how the Internet as an instrument of globalisation allows people to perform the functions afforded by linguistic resources trans-locally and, accordingly, how it repositions these functions in the interactive (substantive and cognitive) space. The article also discusses the particular relationship between linguistic diversity, language representations and ethnic identity on minority websites through the analysis of the interactants' online discourses (edited and user texts).|Multilingualism; Multimodality; Identity; French-based Amazigh Websites|LANGUAGE|Linguistics; Language \& Linguistics|1|2|7
Detecting implicit expressions of affect in text using EmotiNet and its extensions|2013|In the past years, an important volume of research in Natural Language Processing has concentrated on the development of automatic systems to deal with affect in text. The different approaches considered dealt mostly with explicit expressions of emotion, at word level. Nevertheless, expressions of emotion are often implicit, inferrable from situations that have an affective meaning. Dealing with this phenomenon requires automatic systems to have ``knowledge{''} on the situation, and the concepts it describes and their interaction, to be able to ``judge{''} it, in the same manner as a person would. This necessity motivated us to develop the EmotiNet knowledge base - a resource for the detection of emotion from text based on commonsense knowledge on concepts, their interaction and their affective consequence. In this article, we briefly present the process undergone to build EmotiNet and subsequently propose methods to extend the knowledge it contains. We further on analyse the performance of implicit affect detection using this resource. We compare the results obtained with EmotiNet to the use of alternative methods for affect detection. Following the evaluations, we conclude that the structure and content of EmotiNet are appropriate to address the automatic treatment of implicitly expressed affect, that the knowledge it contains can be easily extended and that overall, methods employing EmotiNet obtain better results than traditional emotion detection approaches. (C) 2013 Elsevier B.V. All rights reserved.|EmotiNet; Emotion detection; Emotion ontology; Knowledge base; Appraisal Theories; Self-reported affect|KNOWLEDGE|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|1|7
The Role of Affect Analysis in Dialogue Act Identification|2013|We present a qualitative analysis of the lexicon of dialogue acts: we explore the relationship between the communicative goal of an utterance and its affective lexicon as well as the salience of specific word classes for each speech act. Thought not constituting any deep understanding of the dialogue, automatic dialogue act labeling is a task that may be relevant for a wide range of applications in both human-computer and human-human interaction. The experiments described in this paper fit in the scope of a research study whose long-term goal is to build an unsupervised classifier that simply exploits the lexical semantics of utterances to automatically annotate dialogues with the proper speech acts.|Affective lexicon; dialogue acts recognition; empirical methods; latent semantic analysis; lexical semantics|LATENT SEMANTIC ANALYSIS; ORGANIZATION; EMOTIONS; LANGUAGE; SPEECH; TEXT|Computer Science, Artificial Intelligence; Computer Science, Cybernetics|2|1|7
Synesketch: An Open Source Library for Sentence-Based Emotion Recognition|2013|Online human textual interaction often carries important emotional meanings inaccessible to computers. We propose an approach to textual emotion recognition in the context of computer-mediated communication. The proposed recognition approach works at the sentence level and uses the standard Ekman emotion classification. It is grounded in a refined keyword-spotting method that employs: a WordNet-based word lexicon, a lexicon of emoticons, common abbreviations and colloquialisms, and a set of heuristic rules. The approach is implemented through the Synesketch software system. Synesketch is published as a free, open source software library. Several Synesketch-based applications presented in the paper, such as the the emotional visual chat, stress the practical value of the approach. Finally, the evaluation of the proposed emotion recognition algorithm shows high accuracy and promising results for future research and applications.|Natural language processing; text analysis; sentiment analysis; emotion in human-computer interaction|TEXT|Computer Science, Artificial Intelligence; Computer Science, Cybernetics|16|0|7
Event-related brain potential evidence that local nouns affect subject-verb agreement processing|2013|The conditions under which speakers make syntactic errors, and the manner in which listeners respond to them, provide insight into how complex computational problems related to the rules of language are solved. One of the important syntactic rules of English is that a subject and its corresponding verb must agree in number. However, the presence of a number-bearing element between the subject and verb results in frequent production errors and has also been shown to complicate comprehension. When asked to press a button in response to anomalies in several narrated short stories, participants in the current study were better able to detect subjectverb agreement violations when there were no intervening words. In a separate event-related potential (ERP) experiment in which participants listened to the same stories for comprehension, simple subjectverb agreement violations elicited the predicted anterior negativity and later posterior positivity (P600). In contrast, when a singular noun phrase appeared between a singular subject and the corresponding verb, agreement violations elicited an early negativity with a distinctly posterior distribution. When a singular subject was followed by a plural noun phrase, there were no differences evident in ERPs elicited by singular and plural verbs. These results indicate that during comprehension of natural speech, the computation of subjectverb agreement is affected by the presence of number-bearing elements other than the subject itself.|Sentence processing; ERP; LAN; P600; Syntactic violation|SYNTACTIC POSITIVE SHIFT; ELECTROPHYSIOLOGICAL EVIDENCE; SENTENCE COMPREHENSION; EYE-MOVEMENTS; ERP; ENGLISH; NUMBER; WORD; SPEECH; ERRORS|Linguistics; Psychology, Experimental|9|0|7
Generic structure and promotional elements in best-selling online book blurbs: a cross-cultural study|2013|This study investigates the generic structure and promotional elements of the online fiction blurbs accompanying the 95 best-selling books from Amazon United Kingdom and Okuoku Turkey (1999-2011), a company that sells books online that are written in Turkish or translated into Turkish, and adds to the growing number of investigations into this genre (Kathpalia, 1997; Bhatia, 2004; Cacchiani, 2007; Gea-Valor, 2007; Gesuato, 2007; Basturkmen, 2009). Based on the findings, a two-level schematic structure (moves and steps) is proposed for the blurbs following Swales (1990). The findings suggest that Amazon UK book blurbs have a six-move schematic structure: complimenting the author, book description, justifying the book by establishing a niche, book promotion, author's background and author's website/blog being the second, fourth and fifth obligatory moves. However, Okuoku book blurbs feature a five-move schematic structure with complimenting the author, book description, involving the reader in the text, book promotion and author's background, the second and fourth being obligatory. Analysis of promotional elements in the corpora reveals that online fiction book blurbs employ the art of advertising through the use of favorable expressions (Bhatia, 2005) and innovative uses of rhetorical strategies to persuade the reader to read the book.|blurbs; online books; genre analysis; promotional element; evaluative language|RESEARCH ARTICLES; GENRE|Linguistics; Language \& Linguistics|0|0|7
Detection of semantic errors in Arabic texts|2013|Detecting semantic errors in a text is still a challenging area of investigation. A lot of research has been done on lexical and syntactic errors while fewer studies have tackled semantic errors, as they are more difficult to treat. Compared to other languages, Arabic appears to be a special challenge for this problem. Because words are graphically very similar to each other, the risk of getting semantic errors in Arabic texts is bigger. Moreover, there are special cases and unique complexities for this language. This paper deals with the detection of semantic errors in Arabic texts but the approach we have adopted can also be applied for texts in other languages. It combines four contextual methods (using statistics and linguistic information) in order to decide about the semantic validity of a word in a sentence. We chose to implement our approach on a distributed architecture, namely, a Multi Agent System (MAS). The implemented system achieved a precision rate of about 90\% and a recall rate of about 83\%. (C) 2012 Elsevier B.V. All rights reserved.|Semantic error; Detection; Statistical method; Linguistic method; Combining methods; Co-occurrence; Collocation; Latent Semantic Analysis (LSA); Multi-Agent System (MAS); Arabic|SPELLING CORRECTION|Computer Science, Artificial Intelligence|0|0|7
Exceptions to rules: a qualitative analysis of backward causal connectives in Dutch naturalistic discourse|2013|Language users systematically prefer one lexical item (because) over another (even highly similar) one (since) to express a causal relationship in discourse. Such choices provide a window on speakers' cognitive categorizations, and have been modeled in previous work in terms of subjectivity. This paper analyzes the Dutch connectives omdat ('because') and want ('since/for') in written text, conversation, and chat interactions. These can be considered a case in point for linguistic categorization since related European languages show similar distinctions. We sketch a profile for the interpretation of omdat and want based on corpus analyses of large numbers of occurrences in different media and genres. However, we focus on the deviations from the prototypical use of the connectives. We analyze instances of those deviations, in order to be able to understand the deviating use. We conclude that deviations should be interpreted in terms of core elements of the prototypical use. Therefore, the semantic-pragmatic profile of want and omdat should not be considered as hard-wired all-or-nothing rules, but rather as a prototype structure with a core meaning/use and more peripheral uses. The non-prototypical, peripheral uses are motivated deviations: we need the elements in the core profile to understand the deviations.|causality; connectives; subjectivity; Dutch; discourse; prototype structure; coherence|COHERENCE RELATIONS; GRAMMAR|Communication; Linguistics; Language \& Linguistics|2|0|7
Papers, documents, and the opening of an academic supervision encounter|2013|Despite a growing interest in the interaction in academic pedagogical settings, the role of texts in the actual interaction has not been systematically addressed. This article examines the practices and orientations through which written documents have a significant role in the openings of supervision encounters. We use videotaped recordings of supervision encounters and adopt conversation-analytical methodology to analyze the data. The analysis consists of two main foci: (i) the initial moments of the encounter prior to the actual supervisory activity, and (ii) the launching of the supervisory activity and the negotiation of what that activity will entail. We analyze the orientations toward the document as the necessary object of the joint activity and the prominent bodily orientation toward the papers during the initial moments of the encounter. Furthermore, when the participants move from the initial moments of the encounter toward the main activity, the paper document plays a major role in that interaction. In our conclusions, we summarize our observations as shared, implicit orientations related to the role of the document. These assumptions constitute the ``implicit pedagogy{''} of the supervisory encounter. We will discuss some of the consequences of this type of pedagogy.|academic supervision; opening; document; conversation analysis; ethnomethodology; university pedagogy|ADVICE; TASK|Communication; Linguistics; Language \& Linguistics|19|1|7
Effects of text length on lexical diversity measures: Using short texts with less than 200 tokens|2012|Despite the importance of lexical diversity (LD) in L2 speaking and writing performance, LD assessment measures are known to be affected by the number of words analyzed in the text. This study aims to identify LD measures that are least affected by text length and can be used for the analysis of short L2 texts (50-200 tokens). We compared the type token ratio, Guiraud index, Maas, measure of textual lexical diversity (MTLD), D, and HD D to assess their robustness in relation to text length variation. Spoken texts of 200 tokens from 38 L2 English learners at the lower-intermediate-level were divided into segments of 50-200 tokens and the text length impact was examined. We found that MTLD was least affected by text length across most ranges, but was somewhat affected across 50-150 and 50-200 tokens. We further observed low correlations between equal-sized texts for up to 100 tokens. These results suggest that MTLD can be used with texts of more than 100 tokens and MTLD values can be compared between texts across 100 and 200 tokens. We also showed that D and HD D produced similar results for texts; this indicates that D and HD D are comparable. (C) 2012 Elsevier Ltd. All rights reserved.|Type-token ratio; Guiraud index; Maas; D; Measure of textual lexical diversity|ORAL LANGUAGE; CHILDREN; RATIOS|Education \& Educational Research; Linguistics|12|2|7
Lexicalisation and de-lexicalisation processes in sign languages: Comparing depicting constructions and viewpoint gestures|2012|In this paper, we compare so-called ``classifier{''} constructions in signed languages (which we refer to as ``depicting constructions{''}) with comparable iconic gestures produced by non-signers. We show clear correspondences between entity constructions and observer viewpoint gestures on the one hand, and handling constructions and character viewpoint gestures on the other. Such correspondences help account for both lexicalisation and de-lexicalisation processes in signed languages and how these processes are influenced by viewpoint. Understanding these processes is crucial when coding and annotating natural sign language data. (C) 2012 Elsevier Ltd. All rights reserved.|Classifier; Sign language; Gesture; Point of view; Iconicity|AMERICAN; SPEECH|Communication; Linguistics|18|0|7
The discourse marker odnosno at the ICTY: A case of disputed translation in war crime trials|2012|What discourse markers mean depends not only on the local context (co-text), but also, and more widely, on global contexts such as political, ideological and institutional. This conclusion was derived from our cognitive and sociopragmatic analysis of the translation of the Bosnian/Croatian/Serbian (BCS)(3) discourse marker odnosno ('that is', `in other words'), which generally has two dominant functions: distributive and reformulative. We introduce a novel insight into this problem by applying the relevance-theoretic framework of ad hoc concept construction as our analytical apparatus. The selection of interpretation is analysed on the data from a trial at the International Criminal Tribunal for the Former Yugoslavia (ICTY) in which the defence legal team disputed the way odnosno was translated by court translators/interpreters in several instances. We find the cognitive options that were taken as resources for the evasion of translator's responsibility towards a ``disagreeable{''} meaning. By choosing the most neutral translation, however, the translator often steps aside from the court-required direct translation type. (C) 2012 Elsevier B.V. All rights reserved.|Ad hoc concept construction; Discourse marker; Interpretive use; Procedural meaning; Reformulation; Translation; Bosnian/Croatian/Serbian|IDEOLOGY|Linguistics; Language \& Linguistics|4|0|7
Generation 1.5 written error patterns: A comparative study|2012|In an attempt to contribute to existing research on Generation 1.5 students, the current study uses quantitative and qualitative methods to compare error patterns in a corpus of Generation 1.5, L1, and L2 community college student writing. This error analysis provides one important way to determine if error patterns in Generation 1.5 student writing are distinct from L1 and L2 student writing, thereby supporting or refuting claims made in prior research about writing error frequency and type (e.g., Ferris, 2009; Frodesen, 2009; Frodesen \& Starna, 1999; Reid, 1997), as well as addressing the role of errors as a defining criterion of Generation 1.5 writing in post-secondary contexts. Results reported in this study reveal significantly more errors were made by Generation 1.5 writers versus L1 writers within the error types of verb errors, prepositional phrase errors, word form errors, and total identified errors. A qualitative analysis also identified specific patterns of difference between Generation 1.5, L1, and L2 verb error production. Differences found in both the quantitative and the qualitative analyses suggest that the category of Generation 1.5 writing may indeed be characterized in part by an increased likelihood of difficulty in controlling the accuracy of various language forms. Findings are discussed in relation to claims made in prior research about Generation 1.5 writing error frequency and type, as well as the role of errors as a defining characteristic of Generation 1.5 writing in post-secondary contexts. (C) 2011 Elsevier Inc. All rights reserved.|Generation 1.5; Developmental writing; L2 writing; Error analysis; Text analysis; Quantitative research methods|STUDENTS|Linguistics|10|0|7
Descriptive study on narrative competence development in Chilean Sign Language|2012|The purpose of this study was to evaluate the narrative competence development of a group of deaf children who use sign language as their natural language. Children in this study were in the elementary grades, 1st to 4th. This three-year case study obtained narratives from each child three times, at one-year intervals. These narratives were analyzed focusing on two main aspects: the formal organization of the narrative text, its superstructure, and content organization dealing with the use of linguistic resources that serve to textual cohesion. This study focused on the various forms employed by the children to establish reference and co-reference, when introducing, maintaining or re-introducing the focus of the characters involved in the story they were narrating. Even though the children used all the cohesive elements from the first telling, they modified the functions these elements serve. The study demonstrates how the children gradually develop a capacity to construct narratives, being aware of the information needed by the audience. This is especially important within bilingual education, where it is assumed the ability to develop literacy has an important role in the consolidation process related to the development of competence in the natural language of deaf people of our country, the Chilean Sign Language.|narrative development; cohesion; sign language|CHILDRENS NARRATIVES|Linguistics; Language \& Linguistics|1|0|7
Assessments and the social construction of expertise in political TV interviews|2012|This paper investigates how rights to knowledge and opinion are negotiated through assessments embedded in questioning sequences in political news interviews. The focus is on describing how assessments index epistemic positions and evaluative stances embedded in the turns through which the institutional goals of the interview are achieved. The analysis shows how assessments combine with other turn-constructional resources to build a critical or opposing position toward the interviewee's actions, deeds, status, views, or attitudes. It also sheds light on the strategies through which interviewees (IE) engage with and resist the positions displayed by interviewers (IR). Findings show that in the data corpus interviewers often challenge the IE through unmitigated assertions of ``facts,{''} while matters of opinion and assessment of the IE involve footing shifts in the form of citations and quoting written texts. The paper adds to existing research on the tensions in news interview talk; the need to present newsworthy information and hold public figures to account while adhering to the norm of factual, neutral reporting.|broadcast talk; news interviews; conversation analysis; adversarial questioning; assessments; epistemic stance|SPECIAL-ISSUE; INTERROGATIVES; CONFERENCES; QUESTION|Communication; Linguistics; Language \& Linguistics|2|0|7
Lexico-grammatical portraits of vulnerable women in war The 1641 Depositions|2012|The 1641 Depositions are testimonies collected from (mainly Protestant) witnesses documenting their experiences of the Irish uprising that began in October 1641. As news spread across Europe of the events unfolding in Ireland, reports of violence against women became central to the ideological construction of the barbarism of the Catholic rebels. Against a backdrop of women's subordination and firmly defined gender roles, this article investigates the representation of women in the Depositions, creating what we have termed ``lexico-grammatical portraits{''} of particular categories of woman. In line with other research dealing with discursive constructions in seventeenth-century texts, a corpus-assisted discourse analytical approach is taken. Adopting the assumptions of Critical Discourse Analysis, the discussion is extended to what the findings reveal about representations of the roles of women, both in the reported events and in relation to the dehumanisation of the enemy in atrocity propaganda more generally.|1641 Depositions; women; representation; Critical Discourse Analysis; corpus; lexico-grammatical portraits|DISCOURSE|Linguistics; Language \& Linguistics|1|0|7
`Oh, I've known a lot of Irish people': Reading groups and the negotiation of literary interpretation|2011|Reading groups are an increasingly popular phenomenon in contemporary life, offering a space for readers to share literary and personal experiences. Although there is a growing body of research into reading groups, few studies have considered in detail the language used by readers as they debate the meaning of texts. This article offers a close analysis of interaction in reading groups, focusing on a meeting held by a book club in 2009. Employing a mixed-methodology approach, combining conversation analysis and communities of practice, this study analyses the reading group's interaction in fine detail while also accounting for elements of group dynamics that influence the talk in this specific community of readers. I consider how members go about articulating their interpretations of the stories in the context of the reading group, focusing on the way that members present these interpretations as reasonable and valid. Three features of interaction are found to be important to this: category entitlement, the `oh'-preface and X then Y structures. I conclude that the interpretations offered in the reading group are necessarily socially situated and are inextricable from the interactive context in which they are produced.|communities of practice; conversation analysis; literary interpretation; reading groups|CONVERSATION ANALYSIS; GENDER RESEARCH; DISCOURSE; LANGUAGE; POWER; COMMUNITIES; TERMS; TEXT|Linguistics; Language \& Linguistics|14|0|7
The Use of Glossing in Modern Original Scientific Writing in Arabic An Influence of Translation?|2011|This study investigates the use of glossing in translated and original scientific texts in Arabic and the factors that motivate this use, given existing knowledge and linguistic gaps between Arabic and English. The form of glossing investigated is the insertion of foreign terms next to their target text counterparts. The study draws on a corpus of 10 translated and 15 original research articles taken from three publications. Statistical analysis of the occurrence of glossing was conducted, taking into consideration variables such as the types of glossed expressions, the ratios of glossed expressions to the total number of words in each text and the recurrence of the same gloss in each text. Results show that glosses of source language scientific terms are used frequently in translated and original texts in the corpus, although the ratios are smaller in original texts than in translated texts. Historical, educational, linguistic and practical factors that could explain such usage in original writings are discussed.|Arabic; Arabization; Glossing; Glossaries; Scientific writing; Terminology|JAMAHIRIYA; DIAGNOSIS|Communication; Linguistics; Language \& Linguistics|0|0|7
Improving MeSH classification of biomedical articles using citation contexts|2011|Medical Subject Headings (MeSH) are used to index the majority of databases generated by the National Library of Medicine. Essentially, MeSH terms are designed to make information, such as scientific articles, more retrievable and assessable to users of systems such as PubMed. This paper proposes a novel method for automating the assignment of biomedical publications with MeSH terms that takes advantage of citation references to these publications. Our findings show that analysing the citation references that point to a document can provide a useful source of terms that are not present in the document. The use of these citation contexts, as they are known, can thus help to provide a richer document feature representation, which in turn can help improve text mining and information retrieval applications, in our case MeSH term classification. In this paper, we also explore new methods of selecting and utilising citation contexts. In particular, we assess the effect of weighting the importance of citation terms (found in the citation contexts) according to two aspects: (i) the section of the paper they appear in and (ii) their distance to the citation marker. We conduct intrinsic and extrinsic evaluations of citation term quality. For the intrinsic evaluation, we rely on the UMLS Metathesaurus conceptual database to explore the semantic characteristics of the mined citation terms. We also analyse the ``informativeness{''} of these terms using a class-entropy measure. For the extrinsic evaluation, we run a series of automatic document classification experiments over MeSH terms. Our experimental evaluation shows that citation contexts contain terms that are related to the original document, and that the integration of this knowledge results in better classification performance compared to two state-of-the-art MeSH classification systems: MeSHUP and MTI. Our experiments also demonstrate that the consideration of Section and Distance factors can lead to statistically significant improvements in citation feature quality, thus opening the way for better document feature representation in other biomedical text processing applications. (C) 2011 Elsevier Inc. All rights reserved.|Citation contexts; Document expansion; Biomedical text classification; MeSH terms|TEXT; CATEGORIZATION|Computer Science, Interdisciplinary Applications; Medical Informatics|10|0|7
Mining association language patterns using a distributional semantic model for negative life event classification|2011|Purpose: Negative life events, such as the death of a family member, an argument with a spouse or the loss of a job, play an important role in triggering depressive episodes. Therefore, it is worthwhile to develop psychiatric services that can automatically identify such events. This study describes the use of association language patterns, i.e., meaningful combinations of words (e.g., < loss, job >), as features to classify sentences with negative life events into predefined categories (e.g., Family, Love, Work). Methods: This study proposes a framework that combines a supervised data mining algorithm and an unsupervised distributional semantic model to discover association language patterns. The data mining algorithm, called association rule mining, was used to generate a set of seed patterns by incrementally associating frequently co-occurring words from a small corpus of sentences labeled with negative life events. The distributional semantic model was then used to discover more patterns similar to the seed patterns from a large, unlabeled web corpus. Results: The experimental results showed that association language patterns were significant features for negative life event classification. Additionally, the unsupervised distributional semantic model was not only able to improve the level of performance but also to reduce the reliance of the classification process on the availability of a large, labeled corpus. (C) 2011 Elsevier Inc. All rights reserved.|Text mining; Natural language processing; Association language pattern; Distributional semantic model; Mental health; Negative life event|TEXT CATEGORIZATION; RECOGNITION; INFORMATION; DISORDERS; DOCUMENTS; ONTOLOGY|Computer Science, Interdisciplinary Applications; Medical Informatics|6|0|7
The influence of the post-apartheid context on APPRAISAL choices in Clem Sunter's transformational leadership discourse|2011|Transformational leadership was first identified as a distinct leadership style in the fields of business and organizational research in the 1970s. Transformational leaders motivate followers by appealing to their higher-order needs, offering incentives for compliance such as feelings of personal empowerment, a sense of moral self-actualization, and an emphasis on the individual's contribution to the community at large (Harvey 2004). They have been observed to emerge and thrive within contexts fraught with sociopolitical and economic turbulence, where they maximize the uncertainty of the environment to instigate change. They are also seen to be especially adept at using discourse to foster strong, persuasive interpersonal relations with their followers. This-article reports on the interpersonal dimension of Clem Sunter's discourse in three of his texts written in 1996, a time conducive to the rise of a transformational leader like Sunter. The text analyses are grounded in appraisal theory (Halliday 2004 {[}1994], 2005; Martin 2000a, 2000b), with special focus on the Affect and Judgment choices. Analysis of the Judgment choices reveals that Sunter evokes high l-evels of Tenacity (typical in transformational leadership discourse), whereas the high frequency of Disquiet revealed in the analysis of Affect choices is completely inconsistent with this leadership paradigm. We suggest that the unique sociopolitical context of South Africa in 1996 enabled Sunter to maximize this Disquiet/Tenacity configuration in order to instigate change in his ideal reader, making Sunter a decidedly different kind transformational leader.|APPRAISAL; Affect; Judgment; transformational leadership; discourse; post-apartheid South Africa|CHARISMATIC LEADERSHIP|Communication; Linguistics; Language \& Linguistics|1|0|7
MyMediHealth - Designing a next generation system for child-centered medication management|2010|Background: The last mile of the medication use system requires tools to help patients comply with medication administration rules and monitor for side effects. Personal health records (PHR) and emerging user-adopted communication tools promise to change the landscape of medication management; however, no research has been done to demonstrate how these tools might be constructed to support children with special healthcare needs. The overarching goal of the MyMediHealth project was to investigate ways in which PHRs and supported applications can improve the safety and quality of medication delivery in this population. Design approach: This project employed user-centered design to identify requirements for a child-centered medication management system. We collected information through site visits, facilitated group discussions, and iterative design sessions with adult caregivers. Once design requirements were articulated and validated, we constructed an initial prototype medication scheduler, which was evaluated by 202 parents using scripted activities completed using an online interactive prototype. The results of this analysis informed the development of a working prototype. Status: We have completed a working prototype of a scheduling system, a text-message-based alert and reminder system, and a medication administration record based on web-entered patient data. Implications: Pilot testing of the working prototype by stakeholders yielded strong endorsement and helpful feedback for future modifications, which are now underway as a part of an expanded project to test this system in a real-world environment. (C) 2010 Elsevier Inc. All rights reserved.|Medication management; User-centered design; User interface evaluation|PERSONAL HEALTH RECORDS; CHALLENGES|Computer Science, Interdisciplinary Applications; Medical Informatics|12|0|7
The enregisterment of Putonghua in practice|2010|Drawing on ethnographic research, this article explores how a once alien and unsophisticated language has enregistered as a national linguistic standard through the mediation of metadiscursive practices in everyday social life, and how its indexical values associated with speaker attributes and social personae are reproduced in mass circulation of metadiscursive standard. It shows that the standardization of Putonghua has been a deliberate institutional effort closely related to the making of the nation: it is however, part of a more general and more tacit ideological process - enregisterment - through which the symbolic dominance of Putonghua is accepted as natural and normative. (C) 2010 Elsevier Ltd. All rights reserved.|Enregisterment; Putonghua; Symbolic power; Indexicality; Language Standardization; China|MIGRANT IDENTITY; LIFE|Communication; Linguistics|16|1|7
Potential of rhetorical relations for differentiation among specialized texts from different domains in Basque and Spanish|2010|This study presents our research on the potential of using rhetorical relations and superficial marks evidencing them to discriminate among specialized texts of different domains but with a high specialization level, in two very different languages as Basque and Spanish. For our analysis, we employ of the Rhetorical Structure Theory (RST). We compiled a parallel corpus of Spanish-Basque specialized texts that contains two subcorpora of medical and terminological texts. We marked these texts with RST rhetorical relations and we detected the discourse markers that evidence them. Finally, we noted that certain types of rhetorical relations and the amount of used discourse markers allow us to differentiate among specialized texts of different domains in both Spanish and Basque.|Rhetorical Structure Theory; rhetorical relations; discourse markers; annotation; specialized text; contrastive study; Spanish; Basque|STRATEGIES|Linguistics; Language \& Linguistics|0|0|7
An interactive and user-centered computer system to predict physician's disease judgments in discharge summaries|2010|Purpose: This article describes a formative natural language processing (NLP) system that is grounded in user-centered design, simplification, and transparency of function. Methods: The NLP system was tasked to classify diseases within patient discharge summaries and is evaluated against clinician judgment during the 2008 i2b2 Shared Task competition. Text classification is performed by interactive, fully supervised learning using rule-based processes and support vector machines (SVMs). Results: The macro-averaged F-score for textual (t) and intuitive (i) classification were 0.614(t) and 0.629(i), while micro-averaged F-scores were recorded at 0.966(t) and 0.954(i) for the competition. These results were comparable to the top 10 performing systems. Discussion: The results of this study indicate that an interactive training method, de novo knowledge base with no external data sources, and simplified text mining processes can achieve a comparably high performance in classifying health-related texts. Further research is needed to determine if the user-centered advantages of a NLP system translate into real world benefits. (C) 2009 Elsevier Inc. All rights reserved.|Natural language processing; Patient discharge; Medical records; Medical records systems; Computerized; Obesity|INFORMATION|Computer Science, Interdisciplinary Applications; Medical Informatics|4|0|7
The use of narrative analysis as a research and evaluation method of atypical language: the case of deaf writing|2010|The present paper argues the use of narratives as the most appropriate evaluation method in cases of atypical language production. Narrative as a genre has an ecological validity that other genres used in language research and evaluation do not have. Narratives develop naturally from very early, they are independent of education and academic skills, and they are meaningful because of their direct contact to experience. As a result the paper argues that narrative analysis is the most appropriate evaluation and research method for atypical language, one instance of which is deaf writing. The paper will present an example of narrative analysis application on a story written by a deaf writer. Via the illustrative example it will be shown that narrative analysis captures deeper levels of the language production by exploring the content of information, and the structure of text.|narrative analysis; methodology; writing; atypical language; deafness|WRITTEN LANGUAGE; CHILDREN; LITERACY; STUDENTS; SKILLS|Education \& Educational Research; Linguistics; Language \& Linguistics|6|0|7
Relevance-theoretical versus pragmatic and cognitive approaches to coherence A survey|2010|Discourse coherence can be approached as one of the variables that allow both the writer and the reader to cope with the meaning of texts. It will be hypothesised that this is possible because coherence integrates both cognitive and textual aspects. In fact, most of contemporary linguistic and pragmatic theories have laid emphasis on the need to go beyond the sentence and enter into the realms of text and discourse so as to grasp meaning. Hence, meaning results from an ongoing process of negotiation among language users. An important consequence of this is the need to approach discourse formation and comprehension as a cognitive process, which in turn entails that the notion of coherence, as the key defining trait of discourse and of texture, must also be cognitively grounded. It is for this reason that a cognitive approach to interpersonal communication, like the one supplied by relevance theory, appears to be in a position to provide suitable proposals for the explanation of the production, processing and interpretation of discourse. This paper will therefore aim to examine critically the proposals on coherence contributed in the framework of relevance theory and assess them in relation with other discourse and cognitive approaches. Its main underlying contention is that these proposals are best understood as complementary rather than mutually excluding.|discourse analysis; discourse and language; discourse coherence; relevance theory; negotiation of meaning in discourse|DISCOURSE COHERENCE; TEXT COHERENCE|Linguistics; Language \& Linguistics|0|0|7
Sociology of literature, sociology of translation The reception of Irene Nemirovsky's Suite francaise in France and Britain|2010|This article uses Irene Nemirovsky's posthumously published novel Suite francaise (2004 {[}in French] and 2006 {[}in English]) as a case study to investigate the ways in which the market for translated literature functions in Britain today. The article raises methodological questions relating to the analysis of the function of the translated literary text in the target culture, proposing that work in the sociology of translation should be brought into dialogue with research into contemporary publishing, and that questions raised by polysystems theory remain relevant to such a dialogue. It suggests that an analysis of the reception of the translated text in the target culture should pay attention to paratextual elements and to modern marketing strategies in order to assess how translated fiction is currently presented to the British reading public. The example of Suite francaise demonstrates that, under certain commercial and cultural conditions, translated fiction in English can become a bestseller.|Irene Nemirovsky; Suite francaise; Pierre Bourdieu; sociology of literature; polysystems theory|POLYSYSTEM; CULTURE|Linguistics; Language \& Linguistics|6|0|7
Making the instructional curriculum as an interactive, contextualized process: case studies of seven ESOL teachers|2009|This article reports on data from interpretive case studies of seven well-qualified, experienced teachers of adult ESOL, collected through weekly interviews and analysis of documents and materials produced over the duration of a whole course for each teacher. Teachers' knowledge and experience was apparent in their ability to conceptualize and plan globally in the pre-course phase, to establish rapport and diagnose learners' developmental priorities as soon as teaching began, and to weave a coherent instructional curriculum(1) from a variety of components and dimensions of conceptual content according to the developmental needs, wishes and responses of learners, syllabus pre-specifications, constraints of the teaching context and their own personal theories of best practice. The study draws attention to a number of differences between the curriculum making practices of experienced teachers and the content of language teacher education texts with regard to pre-course planning procedures and the separation of syllabus and methodology. Dissonances were also apparent between conventional descriptions of process-product orientations and strong-weak versions of communicative language teaching on the one hand, and the blended, non-standard approaches apparent in the courses in this study. The article identifies curriculum making principles and practices that were common to a number of teachers as a contribution to practice-based disciplinary knowledge and second language teacher education literature.|curriculum implementation; curriculum planning; process and product approaches; teacher cognition|EDUCATION; KNOWLEDGE|Education \& Educational Research; Linguistics|5|0|7
Evaluation and audience acceptance in biotech news texts|2009|It is well known that news texts are not value neutral and that in these texts even genuinely tactual statements can function as evaluations. Hence, only an analysis of the hypes of evaluation used will reveal the true picture of the attitudinal import of reporting texts. The paper explores these features by analysing the coverage of the biotechnology debate in one of the largest Danish newspapers, Politiken, during the first 9 months of 2004. The aim of this analysis is to uncover how seemingly objective and `neutral' accounts of events and state of affairs can be used by journalists to significantly influence the attitudes of the readership. In the analysis, it is shown that the feature Judgement (of people) is virtually absent, whereas Appreciation (of things) is quite frequent, reflecting the fact that the perceived risk factor associated with biotechnology was paramount in the said period. Furthermore, the metaphorical construction of the audience is discussed through the combination of conceptual and rhetorical theories. This combination allows for the assessment of metaphor's role in constructing a conceptual common ground between the writer and his audience with the aim of convincing the audience of a particular viewpoint. Moreover, it is shown that the newspaper caters to a readership which sees risk as a societal and ethical issue rather than a scientific one. Along these lines, the imagined reader is constructed as a less change oriented person than the reader of the newspaper's opinion articles. (c) 2008 Elsevier B.V. All rights reserved.|Newspaper language; Appraisal; Metaphor; Rhetoric; Ideal reader|DISCOURSE; EXPERT; FOOD|Linguistics; Language \& Linguistics|10|1|7
Prosodic realizations of global and local structure and rhetorical relations in read aloud news reports|2009|The aim of this research is to Study effects of global and local structure of texts and of rhetorical relations between sentences on the prosodic realization of sentences in read aloud text. Twenty texts were analyzed using Rhetorical Structure Theory. Based oil these analyses, the global structure in terms of hierarchical level, the local structure in terms of the relative importance of text segments and the rhetorical relations between text segments were identified. The texts were read aloud. Pause durations preceding segments, F0-maxima and articulation rates of the segments were measured. It was found that speakers give prosodic indications about hierarchical level by means of variations in pause duration and pitch range: the higher the segments are connected in the text structure, the longer the preceding pauses and the higher the F0-maxima are realized. Also, it was found that speakers articulate important segments more slowly than unimportant segments, and that they read aloud causally related segments with shorter in-between pauses and at faster rate than non-causally related segments. We conclude that variation in pause duration and F0-maximum is a robust means for speakers to express the global structure of texts, although this does not apply to all speakers. Speakers also vary pause duration and articulation rate to indicate importance of sentences and meaning relations between sentences. (C) 2008 Elsevier B.V. All rights reserved.|Discourse; Text structure; Prosody; Global structure; Local structure; Rhetorical relations|COHERENCE RELATIONS; DISCOURSE|Acoustics; Computer Science, Interdisciplinary Applications|17|0|7
Selecting texts for English Language Arts classrooms: When assessment is not enough|2008|This exploratory analysis examines the text selection practices of four pairs of pre-service and in-service teachers during a course on content area reading instruction in English language arts. Each pair independently negotiated responsibilities for selecting the texts used in a series of four lessons. Results of this analysis identify several factors in the process of text selection that may influence the kinds of texts teachers choose for their classrooms, including teacher knowledge of texts, access to texts, and institutional constraints on text selection. The reasoning participants provided for the selections they made also points to the influence of the current emphasis on high-stakes assessment on teacher decision-making. Text selection is explored as a potential site for teacher agency and differentiation of instruction.|Assessment; content area reading; cultural capital; differentiated instruction; English language arts; Bourdieu; text selection; youth literature; young adult literature|NONFICTION TRADE BOOKS; SCHOOL; TEACHERS; INSTRUCTION; READABILITY; GRADES; READ|Education \& Educational Research; Linguistics; Language \& Linguistics|4|0|7
Getting a picture that is both accurate and stable: Situation models and epistemic validation|2008|Text comprehension entails the construction of a situation model that prepares individuals for situated action. In order to meet this function, situation model representations are required to be both accurate and stable. We propose a framework according to which comprehenders rely on epistemic validation to prevent inaccurate information from entering the situation model. Once information has been integrated in the current situation model, it serves as part of the epistemic background for validating new information, leading to a stable representation. We present evidence for this view from an experiment in which participants responded to paraphrase and inference items after reading expository texts. Multinomial model analyses of the responses and multilevel analyses of the response latencies revealed that plausible information is more likely to be integrated into the situation model while information that is part of the situation model is more likely to be judged as plausible. This pattern of results suggests a close bi-directional relationship between situation models and epistemic validation. (C) 2008 Elsevier Inc. All rights reserved.|Situation model; Text comprehension; Validation; Verification|CAUSAL BRIDGING INFERENCES; PROCESSING TREE MODELS; TEXT COMPREHENSION; MEMORY; INFORMATION; PERSEVERANCE; PROGRAM|Linguistics; Psychology; Psychology, Experimental|37|0|7
The effects of hedges in persuasive arguments - A nuanced analysis of language|2008|Drawing together research on persuasion and text comprehension, two experiments test the effects of hedge placement (Experiment 1) and hedge type (Experiment 2) on attitudes, source evaluations, and perceptions of argument strength. Participants read an editorial in support of implementing comprehensive exams at their university. Experiment 1 shows that hedges placed on data statements (and not interpretation statements) lead to negative perceptions of the policy, source, and argument. This is especially pronounced on source evaluations among individuals with more scientific training. Experiment 2 reveals that colloquial, but not professional, hedges placed on interpretation statements lead to more negative evaluations relative to no hedges. Data related to perceptions of the source are moderated by individual differences in scientific reasoning. This research suggests that hedges describing data statements and/or that use colloquial language can, but do not always, undermine persuasive attempts.|persuasion; attitudes; hedges; qualifiers|COGNITIVE RESPONSES; CONSEQUENCES; INVOLVEMENT; POWERFUL|Communication; Linguistics; Psychology, Social|10|0|7
Attention to form and meaning revisited|2008|The present study revisited the issue of simultaneous attention to form and meaning from a methodological perspective that addressed several potential methodological issues of previous research in this strand of inquiry. Seventy-two second-semester-level participants were randomly assigned to one of five experimental groups, including a control, and requested to read a Spanish text and also circle one of four targeted forms (10 occurrences each) in the input. To measure comprehension, a 10-item multiple-choice test was administered immediately after the reading. Both qualitative (think-aloud protocols) and quantitative analyses were conducted to address the following research question: Does type of attentional condition have a differential effect on adult second language reading comprehension? The quantitative analysis revealed no significant difference in comprehension among all five groups. To explicate the findings, the quantitative and qualitative data and analyses are discussed with regard to the issues of modality, depth or level of processing, and research methodology.|simultaneous attention; levels of processing; form vs. meaning; hybrid design; input processing; The Primacy of Meaning Principle; think-aloud protocols|FOREIGN-LANGUAGE BEHAVIOR; SLA RESEARCH METHODOLOGY; REACTIVITY; AWARENESS; SEQUENCE; L2; MEMORY; INPUT; TASK|Education \& Educational Research; Linguistics|15|1|7
Assessing the microstructure of written language using a retelling paradigm|2008|Purpose: The primary goal of this study was to document the progression of the microstructural elements of written language in children at 4 grade levels. The secondary purpose was to ascertain whether the variables selected for examination. could be classified into valid categories that reflect the multidimensional nature of writing. Method: Written language samples were collected and transcribed from 120 children in Grades 3 through 6 using an expository text-retelling paradigm. Nine variables at various levels of language were analyzed. Results: Using a text-retelling paradigm, measures of productivity (e.g., total number of words and ideas) improved steadily with age, whereas measures of complexity (e.g., mean length of T-unit) did not. Results for measures of accuracy (e.g., spelling and writing conventions) were mixed, with some showing improvement across grades. Grade 3 students showed consistently. poorer performance than students in Grades 4, 5, and 6. Grade 4 students showed poorer performance than students in Grades 5 and 6. Exploratory factor analysis suggests that writing can be represented by 3 factors: Productivity, Complexity, and Accuracy. Conclusions: Clinicians can use this multidimensional scheme for examining writing skills using text-retelling formats with children from Grades 3 through 6. This empirically based framework for measuring microstructural variables of writing provides clinicians with a 3-prong. conceptual framework for determining children's strengths and weaknesses within the translational stage of writing.|expository writing; microstructural elements of writing; school-age language; writing; writing assessment; writing development|LEARNING-DISABLED STUDENTS; SCHOOL-AGE-CHILDREN; STORY COMPOSITION SKILLS; READING-COMPREHENSION; DEVELOPMENTAL SKILLS; WORKING-MEMORY; EFFECT SIZE; DISABILITIES; INTERVENTION; ADOLESCENTS|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|45|0|7
The other C in CMC: What alternative data sources can tell us about text-based synchronous computer mediated communication and language learning|2008|Most research on text-based synchronous computer-mediated communication (SCMC) in language learning has used output logs as the sole data source. I review interactionist and sociocultural SCMC research, focusing in particular on the question of technological determinism, and conclude that, from whichever perspective, reliance on output logs leads to an impoverished picture of the experience of SCMC users and of phenomena relevant to learning. The assumption that output logs are an adequate data source fails to give due weight to the specificities of this form of communication, in particular the constraints and affordances of the computer interface. I examine the potential contribution of other data sources, providing by way of illustration an analysis of sample eye-tracker data from a tandem SCMC session.|synchronous computer-mediated communication; CALL research methodology; HCI; eye-tracking; tandem language learning; MOO|FACE-TO-FACE; NATIVE SPEAKERS; CHAT; NEGOTIATION|Education \& Educational Research; Linguistics; Language \& Linguistics|20|0|7
Construction grammar in ICALL|2008|The choice of grammatical framework in ICALL - the branch of CALL that applies artificial intelligence techniques - has important implications for both research and development. Matthews (1993) argued for one `that potentially meshes with SLA (second language acquisition)' (p. 5) and sketches three criteria that facilitate the crucial decision of selecting a grammatical framework for an ICALL system: computational effectiveness, linguistic perspicuity and acquisitional perspicuity. We will use Matthews' three adequacy criteria to review recent research in construction grammar and propose its application in ICALL, particularly in projects which involve the building of a student model. Such a student modeling project - Mocha - will be sketched briefly to provide a concrete context for the conceptualisation and implementation of construction grammar. This grammatical framework has the potential to help overcome some challenges in ICALL and to facilitate a more thorough analysis of learner language in context and thus improve our knowledge about language learning processes.|intelligent CALL (ICALL); natural language processing (NLP); construction grammar|2ND-LANGUAGE ACQUISITION; EMERGENCE; SYSTEMS|Education \& Educational Research; Linguistics; Language \& Linguistics|4|0|7
Metatalk in a Pair Work Activity: Level of Engagement and Implications for Language Development|2008|This classroom-based study investigated the metatalk of learners working in pairs on a text reconstruction task. Specifically, the study investigated the learners' level of engagement with linguistic choices, and whether the level of engagement affected subsequent language development. Data were collected over a 2-week period. In the first week, students completed one version of a text reconstruction task in pairs and all pair talk was audio recorded. In the second week, students completed another version of the task individually. Analysis of the pair talk data showed that pairs attended to a range of grammatical and lexical items, but that the nature of their engagement ranged from elaborate to limited. Elaborate engagement was operationalised as instances where learners deliberated and discussed language items and limited engagement where one learner made a suggestion and the other repeated, acknowledged or did not respond to the suggestion. Analysis of learner performance on a set of items that were common to the two versions of the text reconstruction task suggests that elaborate engagement was more facilitative of learning/consolidation for both members of the dyad than limited engagement. The findings also suggest that repetitions, common in language classes, need further investigation.|language development; learner-learner interaction; metatalk; repetitions; text reconstruction|NEGOTIATION; CONVERSATION; REPETITION; DISCOURSE; ATTENTION; PATTERNS; GRAMMAR|Linguistics; Language \& Linguistics|55|1|7
International and local curricula: The question of ideology|2008|This article examines the ideological import of (a) a selection of internationally distributed ELT textbooks to find out whether a recurrent ideological pattern could be observed and (b) the ELT books used in Iranian high schools to see if the ideological import of these books was different from that of the internationally distributed ELT textbooks. To this end, the theory and procedures of critical discourse analysis (CDA), as expounded by Fairclough (1989), were applied to conversations in these textbooks and three dimensions of meaning - the social relations of textbook characters, their subject positions, and the content of the texts were categorized and statistically analyzed. The analysis revealed that the internationally distributed ELT textbooks tend to represent a particular discourse type - the discourse of western economy and consumer society. Moreover, in the locally produced ELT materials, owing to the absence of certain topics and features, the preparation of the high school books appears to have been influenced by post-revolution norms and standards.|critical discourse analysis; ideology; textbooks|ENGLISH|Education \& Educational Research; Linguistics|8|2|7
An approach for automatic generation of adaptive hypermedia in education with multilingual knowledge discovery techniques|2007|This work describes a framework that combines techniques from Adaptive Hypermedia and Natural Language processing in order to create, in a fully automated way, on-line information systems from linear texts in electronic format, such as textbooks. The process is divided into two steps: an off-line processing step, which analyses the source text, and an on-line step, which executes when a user connects to the system with a web browser, moment at which the contents and hyperlinks are generated. The framework has been implemented as the WELKIN system, which has been used to build three adaptive on-line information sites in a quick and easy way. Some controlled experiments have been performed with real users aimed to provide positive feedback on the implementation of the system. (C) 2005 Elsevier Ltd. All rights reserved.|architectures for educational technology system; authoring tools and methods; multimedia/hypermedia systems|ENGLISH|Computer Science, Interdisciplinary Applications; Education \& Educational Research|10|0|7
Graphical and text-based design interfaces for parameter design of an I-beam, desk lamp, aircraft wing, and job shop manufacturing system|2007|In this paper we describe four design optimization problems and corresponding design interfaces that have been developed to help assess the impact of fast, graphical interfaces for design space visualization and optimization. The design problems involve the design of an I-beam, desk lamp, aircraft wing, and job shop manufacturing system. The problems vary in size from 2 to 6 inputs and 2 to 7 outputs, where the outputs are formulated as either a multiobjective optimization problem or a constrained, single objective optimization problem. Graphical and text-based design interfaces have been developed for the I-beam and desk lamp problems, and two sets of graphical design interfaces have been developed for the aircraft wing and job shop design problems that vary in the number of input variables and analytical complexity, respectively. Response delays ranging from 0.0 to 1.5 s have been imposed in the interfaces to mimic computationally expensive analyses typical of complex engineering design problems, allowing us to study the impact of delay on user performance. In addition to describing each problem, we discuss the experimental methods that we use, including the experimental factors, performance measures, and protocol. The focus in this paper is to publicize and share our design interfaces as well as our insights with other researchers who are developing tools to support design space visualization and exploration.|visualization; design optimization; metamodels; simulation; graphical user interface|MULTIOBJECTIVE OPTIMIZATION; PROXIMITY COMPATIBILITY; ENGINEERING DESIGN; MULTIDISCIPLINARY; VISUALIZATION; SIMULATION; METAMODEL; COGNITION; QUALITY; HOUSE|Computer Science, Interdisciplinary Applications; Engineering, Mechanical|3|0|7
Monitoring knowledge - A text-based approach|2007|The diffusion and transfer of knowledge is central to the process of innovation and is of importance to both academics and industrialists. In this paper, we propose that academic articles and patent documents referring to a set of well-researched concepts may be used as a measure of this diffusion and transfer. Concepts are typically articulated as terms, and shared terms in specialist research papers and patent documents are proposed as a monitoring index for the transfer of academic knowledge to patented technology. The identification and statistical monitoring of changes in the use of terms, through the medium of texts, may provide innovative opportunities and reduce the extensive lead-time from invention to innovation. A text-based approach has been taken to research the changes in terminology that occurred in the development of Artificial Intelligence since 1936. Biological models of growth have been applied to model the diachronic changes, and the results show that the growth of term usage may be modelled by using logistic growth techniques.|diffusion modelling; knowledge diffusion; knowledge transfer; text mining|LOGISTIC GROWTH; MODELS|Linguistics; Language \& Linguistics|0|1|7
Effects of acoustic manipulation on the real-time inflectional processing of children with specific language impairment|2006|Purpose: This study reports the findings of an investigation designed to examine the effects of acoustic enhancement on the processing of low-phonetic-substance inflections (e.g., 3rd-person singular -s, possessive-s) versus a high-phonetic-substance inflection (e.g., present progressive -ing) by children with specific language impairment (SLI) in a word recognition, reaction time (RT) processing task. The effects of acoustic enhancement on the processing of the same morphemes as well as an additional morpheme (comparative-er) were examined in an offline grammaticality judgment task. The grammatical function of 1 of the higher-phonetic-substance inflections, -ing, was presumed to be hypothesized relatively early by children; the function of the other, -er, was presumed to be hypothesized relatively late. Method: Sixteen children with SLI (age(M) = 9 years;O months) and 16 chronological age (CA; age(M) = 8;11) children participated. For both tasks, children listened to sentences containing the target morphemes as they were produced naturally (natural condition) or with acoustic enhancement (enhanced condition). Results: On the RT task, the children with SLI demonstrated RT sensitivity only to the presence of the high-substance inflection, irrespective of whether it was produced naturally or with enhancement. Acoustic enhancement had no effect on these children's processing of low-substance inflections. The CA children, by contrast, showed sensitivity to low-substance inflections when they were produced naturally and with acoustic enhancement. These children also showed sensitivity to the high-substance inflection in the natural condition, but in the enhanced condition they demonstrated significantly slower RT. On the grammaticality judgment task, the children with SLI performed worse than the CA children overall and showed especially poor performance on low-sulostance inflections. Acoustic enhancement had a beneficial effect on the inflectional processing of the children with SLI, but it had no effect on CA children. Conclusion: The findings are interpreted to suggest that the reduced language processing capacity of children with SLI constrains their ability to process low-substance grammatical material in real time. This factor should be considered along with any difficulty that might be attributable to the grammatical function of the inflection.|children; specific language impairment; grammatical morphology; real-time processing|ENGLISH-SPEAKING CHILDREN; GENERALIZED SLOWING HYPOTHESIS; PHONOLOGICAL WORKING-MEMORY; PAST-TENSE; SENTENCE COMPREHENSION; INPUT RATE; SLI; ACQUISITION; MORPHOLOGY; CAPACITY|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|27|0|7
Toward a more valid account of functional text quality: The case of the patient information leaflet|2006|Patient drug and treatment information leaflets are an important adjunct to primary health care for medical practitioners to use with patients. To assess comprehensibility of these documents, readability formulas are still used by medical researchers but are arguably of limited value. Checklists to guide the development of printed information, even when based on asystematic review of the literature, have not provided the desired guidance. An approach based on a systemic functional linguistics framework is offered here as one that can provide insight and directions for the improvement of these materials. A set of 18 rheumatology drug leaflets was analyzed at the levels of genre, discourse semantics, and some aspects of the lexicogrammar, so as to identify their characteristics and possible shortcomings as comprehensible documents for patients. While the drug information leaflet was identifiable as a genre with potentially up to nine structural moves, there was a high degree of variability in inclusion of moves, rhetorical functions within moves' and use of headings. The quality of patient information material can be improved by using an analysis that takes account of suitability of generic structure and rhetorical functions, specialization of lexis, status relations, macro-Theme, lexical density, and modalization. A usability strategy should be employed to support the directions provided by the analysis.|written health-care materials; patient information leaflets; systemic functional linguistics; genre; readability; usability strategy|RANDOMIZED CONTROLLED-TRIAL; RHEUMATOID-ARTHRITIS; DRUG INFORMATION; READABILITY; CARE|Communication; Linguistics; Language \& Linguistics|9|1|7
Beyond emotion archetypes: Databases for emotion modelling using neural networks|2005|There has been rapid development in conceptions of the kind of database that is needed for emotion research. Familiar archetypes are still influential, but the state of the art has moved beyond them. There is concern to capture emotion as it occurs in action and interaction ('pervasive emotion') as well as in short episodes dominated by emotion, and therefore in a range of contexts, which shape the way it is expressed. Context links to modality-different contexts favour different modalities. The strategy of using acted data is not suited to those aims, and has been supplemented by work on both fully natural emotion and emotion induced by various technique that allow more controlled records. Applications for that kind of work go far beyond the `trouble shooting' that has been the focus for application: `really natural language processing' is a key goal. The descriptions included in such a database ideally cover quality, emotional content, emotion-related signals and signs, and context. Several schemes are emerging as candidates for describing pervasive emotion. The major contemporary databases are listed, emphasising those which are naturalistic or induced, multimodal, and influential. (c) 2005 Elsevier Ltd. All rights reserved.|database; emotion; multimodal; elicitation; naturalistic|EXPRESSION; SPEECH; INDUCTION; STRESS; STATES; MOOD|Computer Science, Artificial Intelligence; Neurosciences|53|1|7
Identity commitments in personal stories of mental illness on the Internet|2005|The Internet augments the informational flows that organize biographies in late modernity. Sufferers of bipolar disorder (manic depression) may turn to the Internet for accessible information, to learn about others' experiences and impart their own knowledge. Personal accounts posted in the public domain become themselves part of those informational flows, and thus acquire a dual life at a boundary between private and public domains. This poses certain challenges for the investigation of computer-mediated autobiographical telling, which are identified in this paper and negotiated in an analysis of downloaded personal accounts of bipolar disorder. Two of the stories are selected for a close look. Story I tells about achieving long-term remission through personal resolve and psychological alternatives to medication. Story 2 tells about becoming able to talk about the illness through the achievement of a social identity as ``manic depressive{''}. The stories' similarities, differences, and comparability with the other texts are discussed with a view to theorizing how such texts position their implied author in the illness experience. Building upon Bakhtin's idea of a text's plan and its realization, a concept of ``identity commitments{''} as textual properties is proposed. (Narrative identity, Computer-mediated communication, Bipolar disorder, Bakhtin)|narrative identity; computer-mediated communication; bipolar disorder; Bakhtin|SOCIAL REPRESENTATIONS; NARRATIVE IDENTITY; PSYCHOLOGY; CYBERSPACE; DISORDER; SELF; WEB|Communication; Linguistics; Language \& Linguistics|8|1|7
Conjunction in sentence and discourse: sentence-initial and and discourse structure|2004|The paper deals with the usage of sentence-initial and in Modern as compared to Early Modern English written language. It is argued (1) that the function of discourse marker which and has in interactive discourse applies to connecting written sentences as well, and (2) that the reluctance with which it is used today in most written registers has not evolved entirely by chance. Evidence comes from Early Modem English texts and their changing preferences in terms of discourse structure, and from Modem English written discourse, where the usage of sentence-initial conjunction varies largely across genres. Building on analyses of texts from both periods it is shown that the evolution of academic genres towards becoming less narrative begins in the Early Modem English time, with changing pattems of use of sentence-initial and being one result of this process. This foreshadowed, if not initiated, the more general banishment of initial And from larger parts of the written language. Findings also have relevance for the relation between discourse coherence and discourse type: While and potentially supports speaker continuity both at an ideational and at a pragmatic level, a written discourse type defined by a pragmatic function, such as the argumentative or expository type prevailing in modern science, apparently requires connections to be more explicit and semantic in kind. (C) 2004 Elsevier B.V. All fights reserved.|conjunction; discourse marker; discourse type; written language; narrative; scientific discourse|CONNECTIVES; ENGLISH|Linguistics; Language \& Linguistics|13|0|7
Readers' trait-based models of characters in narrative comprehension|2001|Our experiments explore readers' application of trait-based situation models for narrative characters. In the first episode of each of our experimental stories, characters performed behaviors that allowed readers to construct trait inferences (e.g., Albert's shoes were ``buried under old candy wrappers, crumpled magazines, and some dirty laundry.{''}). Control stories omitted trait-relevant information. The second episode of each story gave readers an opportunity to apply the trait inference to generate expectations about story outcomes. In Experiment 1, participants agreed more readily to explicit outcomes that were consistent with their trait-based models. Experiment 2 demonstrated that readers' expectations were narrowly defined by specific traits (e.g., Albert is sloppy) rather than by more general inferences (e.g., Albert is not a good person). Experiments 3 and 4 suggested that trait-based models have an impact on moment-by-moment reading: Participants were slowed in their reading when story completions were inconsistent with specific trait-based models. Our results have implications both for theories of situation models and readers' causal analyses of narrative texts. (C) 2001 Academic Press.|situation models; inference; character traits; narrative causality|SITUATION MODELS; MEMORY; INFERENCES; TEXT; VIEW; CONSTRUCTION; ATTRIBUTION; COHERENCE; EVENTS|Linguistics; Psychology; Psychology, Experimental|60|1|7
How knowledge drives understanding - matching medical ontologies with the needs of medical language processing|1999|In this article, we introduce a knowledge-based approach to medical text understanding. From an in-depth consideration of deep sentence and text understanding we distill basic requirements for an adequate knowledge representation framework. These requirements are then matched with currently available medical ontologies (thesauri, terminologies, etc.). A fundamental trade-off is recognized between large-scale conceptual coverage on the one hand, and formal mechanisms for integrity preservation and conceptual expressiveness on the ether hand. We discuss various shortcomings of the most wide-spread ontologies to capture medical knowledge in-the-large. As a result, we argue for the need of a formally sound and expressive model along the lines of KL-ONE-style terminological representation systems in the format of description logics. These provide an adequate methodology for designing more sophisticated, flexible medical ontologies serving the needs of `deep' knowledge applications which are by no means restricted to medical language processing. (C) 1999 Elsevier Science B.V. All rights reserved.|natural language processing; text understanding; description logics; pathology domain|INFORMATION-SYSTEMS; TERMINOLOGY SERVER; REPRESENTATION; TAXONOMY; UMLS|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|28|3|7
FORMULAICITY IN AND ACROSS FILM DIALOGUE: CLEFTS AS TRANSLATIONAL ROUTINES|2016|Formulaicity, an inherent feature of language, may typify film discourse. Imitation of conversation is posited to extend to conversational routines in original fictive orality, whereas the language of dubbing is believed to increase its formulaicity through translational routines, reiterated translation solutions generating recurrent strings in the target texts. Despite the role assigned to formulaicity, few corpus-based investigations have set out to account for the types, frequency and functions of formulas in both original and dubbed audiovisual dialogue. By drawing on the Pavia Corpus of Film Dialogue - a unidirectional English-Italian parallel corpus totalling about 500,000 words - this study analyses a special kind of formulas, English demonstrative clefts, and their formulaic translations. It evaluates how closely film language reproduces these frequent features of conversational formulaicity, and to what extent source-based patterns are resorted to in dubbing. The results show that demonstrative clefts of the type That's what I see are frequent in Anglophone film language, where they contribute to the naturalness of the register. In the Italian translations, English demonstrative clefts give way to recurring solutions that are calqued on the original triggers, exhibit a degree of fixedness in the target language and contribute to the specificity of dubbed Italian.|dubbing; formulaic sequences; parallel corpus; demonstrative clefts; routinisation|ENGLISH; CONSTRUCTIONS; LANGUAGE; CORPUS|Linguistics; Language \& Linguistics|2|0|6
Multimodal Personality Recognition in Collaborative Goal-Oriented Tasks|2016|Incorporating research on personality recognition into computers, both from a cognitive as well as an engineering perspective, would facilitate the interactions between humans and machines. Previous attempts on personality recognition have focused on a variety of different corpora (ranging from text to audiovisual data), scenarios (interviews, meetings), channels of communication (audio, video, text), and different subsets of personality traits (out of the five ones from the Big Five Model). Our study uses simple acoustic and visual nonverbal features extracted from multimodal data, which have been recorded in previously uninvestigated scenarios, and consider all five personality traits and not just a subset. First, we look at the human-machine interaction scenario, where we introduce the display of different ``collaboration levels.{''} Second, we look at the contribution of the human-human interaction (HHI) scenario on the emergence of personality traits. Investigating the HHI scenario creates a stronger basis for future human-agents interactions. Our goal is to study, from a computational approach, the emergence degree of the five personality traits in these two scenarios. The results demonstrate the relevance of each of the two scenarios when it comes to the degree of emergence of certain traits and the feasibility to automatically recognize personality under different conditions.|Human-human interaction (HHI); human-machine interaction; map task; non-verbal behavior analysis; personality recognition|NONVERBAL BEHAVIOR; TRAITS; CONVERSATIONS; INTERVIEWS; PSYCHOLOGY; CUES|Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications|3|2|6
Was late Modern English scientific writing impersonal? Comparing Philosophy and Life Sciences texts from the Coruna Corpus|2016|This paper focuses on the use of certain linguistic features conveying impersonal style in late Modern English scientific prose (1700-1900). Samples are taken from two subcorpora of the Coruna Corpus of English Scientific Writing, one from the humanities (Philosophy) and the other from natural sciences (Life Sciences). The methodology applied is based on Biber's (1988) Multidimensional Analysis, consisting of a study of register variation as manifested through sets of co-occurring linguistic features with a shared discursive function. The aim of the present study is to detect variation across scientific disciplines, genres, and subject matter. Findings are compared to those found in both diachronic and contemporary reference corpora.|Scientific register; late Modern English; variation; change; Multidimensional Analysis|EVOLUTION|Linguistics; Language \& Linguistics|0|3|6
Constructing English: pre-service ELA teachers navigating an unwieldy discipline|2016|Purpose - The purpose of this paper is to describe a pedagogical innovation - a matrix construction exercise - intended to help pre-service teachers (PTs) navigate the multiple and oftentimes competing discourses that shape the school subject English Language Arts (ELA). Design/methodology/approach - To explore the various ways the PTs drew on the discursively constructed paradigms of ELA throughout their teacher preparation program, researchers (themselves teacher educators) conducted an intertextual analysis (Prior, 1995) of PTs' classroom texts and interview transcripts. Findings - The intertextual analysis suggested that PTs possessed knowledge of and investment in a range of discourses, which they used to anchor their own pedagogical and curricular decision-making and to anticipate the leanings and ideologies of other stakeholders in ELA. Although the organizational schema of the matrix proved helpful from an orientation standpoint, it also may have disguised the productive tensions between particular discourses for some PTs. Originality/value - Although scholars have long noted the plurality of the school subject English and some studies on innovations in teacher education allude to the difficulties that teachers encounter as they navigate the multiple purposes of ELA, there is little scholarship that considers how pre-service and beginning teachers might best navigate that incoherence and unwieldiness. This study, which contextualizes and explores a pedagogical innovation in an English methods class designed to help PTs navigate the many ``Englishes{''}, attempts to fill this gap. The findings suggest that teacher preparation in ELA would do well to conceive of pedagogical innovations in teacher education that allow teachers to grapple with, rather than solve, the uncertainty and unfinalizability of the discipline.|English language arts; English teaching; Constructions of English; New literacies|KNOWLEDGE; LITERACY; SPACE|Education \& Educational Research; Linguistics; Language \& Linguistics|1|1|6
Globally Minded Text Production Bilingual, Expository Writing of Italian Adolescents Learning English|2016|This study investigated micro- and macrostructural text features, and the impact of language-specific skills, on the bilingual, persuasive writing of 41 high school students learning English in Italy. Participants composed persuasive essays on 2 topics, each in Italian and English, and completed spelling and sentence generation tasks in both languages. Texts were assessed for fluency, productivity, complexity, and discourse quality. Repeated-measures analysis of variance was used to explore group differences between Italian and English writing. Correlations and regression analyses were used to investigate the impact of spelling and sentence generation on writing skills. Texts were more productive in English and more complex in Italian; however, no significant differences emerged between languages for fluency or discourse quality. In Italian writing, sentence generation skills affected only fluency. In English writing, spelling explained most of the variance in fluency and also impacted productivity, complexity, and quality. Results not only suggest cross-language transfer of discourse-level composition skills but also highlight the role of language-specific constraints in written text production.|adolescent writing; bilingual writing; English as a foreign language; expository writing; language transfer; spelling|LINGUA FRANCA; CHILDREN; LANGUAGE; STUDENTS; DYSLEXIA; WRITERS; ACQUISITION; MECHANISMS; EDUCATION; LITERACY|Linguistics; Rehabilitation|3|1|6
TYPING YOUR WAY TO TECHNICAL IDENTITY: INTERPRETING PARTICIPATORY IDEOLOGIES ONLINE|2015|Informal, online environments facilitate creative self-expression through typographic and orthographic stylistics. Yet, ideologies of writing may be invoked to discourage written forms that are purportedly difficult to read. This paper analyzes how members of an online, text-based, gaming community negotiate appropriate, written communications as expressions of technical identity. These encounters may reify communities of technologists who are associated with using or avoiding forms such as abbreviations, capital letters, and ``leet speak.{''} Amid the technologizing of the word, the paper argues that those who do not conform to assumed norms may be indexed as less technical than those who do. By examining troubled encounters, the paper explores how metapragmatic negotiations affect creativity and technical identity performance online. The paper argues that contrary to discourses that online interactants pay little attention to written stylistics, the present participants closely attended to subtle and small forms. Further, it discusses how ideologies may be idiosyncratically applied to assist in forming asymmetrical, technical identities. Finally, it argues that technical affiliations are just as important to study as other variables such as gender, ethnicity, age, and class that have traditionally received attention in analyses of ideologies of writing and New Literacy Studies.|Computer-mediated communication; Language ideology; Technical identities; Literacy; Writing; Conversational trouble; Online participation|LANGUAGE; CHILDREN; GAMES|Linguistics; Language \& Linguistics|2|0|6
When readability meets computational linguistics: a new paradigm in readability|2015|Readability is an almost century-old field that aims to match readers with texts based on reproducible tools. It has a long history, but it is remarkable that the methodology used to coin readability formulas hardly evolved until recently, when traditional readability studies came into contact with the field of Natural Language Processing (NLP). In this paper, we first briefly retrace the milestones in readability research before the advent of this new paradigm, that we propose to call Artificial Intelligence (AI) readability' since it results from the conjunction of two AI-connected domains: NLP and machine learning. We then describe in more detail some of the important studies within this new paradigm, before discussing three main issues of the field that need to be resolved in order to make significant advances and present interesting perspectives for future research.|AI readability; assessing reading difficulty of texts; NLP; psycholinguistic|LATENT SEMANTIC ANALYSIS; READING MATERIALS; DIFFICULTY; FORMULA; TEXT|Linguistics; Language \& Linguistics|0|0|6
A FIRST GLIMPSE AT MOBILE INSTANT MESSAGING: SOME SOCIOLINGUISTIC DETERMINING FACTORS|2015|Despite the vast body of research on the linguistic peculiarities of Instant Messaging and Short Messaging Service, little is known about the language used in Mobile Instant Messaging in a cross-generational and cross-cultural context. To fill this gap, the cross-linguistic study addressed here is an attempt to approach age-specific variation from a blended ethnography approach. The current research is grounded on an analysis of a naturally-occurring dataset of WhatsApp messages from the point of view of oralisation and deviations from standard forms. Two distinct generations of English and Spanish texters provide empirical data on the parameters of the oralised written discourse suggested by Yus (2011): emoticons, orthographic mistakes, phonetic orthography, abbreviations, acronyms and clippings, and the use of words in other languages. Subsequently, an analysis of the interviews held with the writers approaches the factors that may determine language variation in the messages. The conclusions drawn highlight the persistent use of deviations from standard language of English and Spanish teenagers. The study confirms a higher frequency of a conversational style in Spanish than in English. Not only brevity and speed reasons but also familiarity, playfulness and intimacy with the addressee are behind the intentional variations used.|Language variation; WhatsApp text messages; oralised written discourse; cross-cultural and cross-generational linguistic research|DISCOURSE; ONLINE|Linguistics; Language \& Linguistics|0|0|6
The scope of language contact as a constraint factor in language change: The periphrasis haber de plus infinitive in a corpus of language immediacy in modern Spanish|2015|In this work an empirical study grounded in the principles and methods of the comparative variationist framework is conducted to measure the scope of language contact as a factor constraining some potentially diverging uses of a Spanish verbal periphrasis that has undergone a sharp decline over the last century (haber de plus infinitive). The analysis is based on three independent samples of text that correspond to three dialectal areas of peninsular Spanish (monolingual zones, Catalan-speaking linguistic territories and the north-western linguistic area). These samples, extracted from a corpus made up of texts of communicative immediacy from the 19th and the first half of the 20th centuries, confirm the existence of a certain linguistic convergence in the expressive habits of the speakers in the bilingual communities. In each region, however, the outcomes are different, due to parallel differences in the structural position of the periphrasis in each language. However, a thorough analysis of the variable context that surrounds the periphrasis shows that the observed differences do not affect the essence of the underlying grammar of this variant, whose decline (which favours tener que plus infinitive and becomes faster as the 20th century advances) is constrained by identical linguistic and extralinguistic conditioning factors in all the dialectal areas.|Modal periphrases; language contact; historical sociolinguistics; language change; corpus linguistics; texts of communicative immediacy; Spanish; social factors|FRENCH|Linguistics; Language \& Linguistics|2|0|6
DO HEDGES ALWAYS HEDGE? ON NON-CANONICAL MULTIFUNCTIONALITY OF JAKBY IN POLISH|2015|One of the canonical uses of jakby in Polish is that of the Lakoffian hedge, which modifies the propositional content of an utterance by pointing to its fuzziness, inexactitude or approximation. In conversational speech the word is frequently put to excessive use, which appears to significantly deviate from the prescribed one, and as such deserves closer attention. The aim of the present study, which makes use of corpus linguistics tools to collect naturally-occurring data and discourse analysis framework to manually examine them, is twofold. Initially, it sets out to examine the linguistic contexts of jakby, which are assumed to furnish valuable guidelines for sifting out the prototypical uses of the word from the innovative ones. Next, the focus shifts onto indentifying context-sensitive functions of the latter in highly diversified stretches of discourse. The research findings demonstrate that the cotextual settings of the non-canonical jakby exhibit a number of distinctive characteristics, such as frequent co-occurrence of the word with pragmatic markers, reflexive discourse and unfilled pauses, all indicative of its relatively tenuous link with the neighbouring portions of text. As regards the functions of the unconventional jakby, the word emerges as a pragmatically multifunctional yet no longer hedging device, capable of, among others, facilitating floor-holding/-grabbing, helping to plan discourse, marking register clash and introducing elaboration on prior thought. Rich in pragmatic functions and syntactically more detached from the adjacent textual material than its canonical base, the investigated jakby appears to fit into the category of propositionally empty yet strategically salient pragmatic markers.|Hedges; Pragmatic markers; (Non-)propositional meaning; (Non-)canonical use of language|CONTRASTIVE ANALYSIS; DISCOURSE MARKERS; ENGLISH; ARTICLES|Linguistics; Language \& Linguistics|0|1|6
The nature of Old Spanish verb second reconsidered|2015|The view that Old Spanish was a form of verb second (V2) language has been prominently critiqued. Using data from a 14th century Spanish prose text it is argued that (later) Old Spanish in fact provides compelling evidence for a V2 analysis, which assumes head movement of the finite verb into the left periphery of the clause accompanied by merger of a phrasal constituent in the C-layer. V3 matrix clauses involving co-occurrence of a Topic and Focus are not attested in the text and V4 is also not found. On this basis it is argued that Old Spanish is a class of V2 language where the locus of the V2 property is C-Force, a high head in the clausal left periphery. Despite the widely held view that Old Spanish was a symmetrical V2 language, evidence from complement clauses is presented that this is not the case. All cases of embedded V2 are found under a class of predicates known to license so-called `Main Clause Phenomena' cross-linguistically. Later Old Spanish thus patterns with Mainland Scandinavian in allowing a.restricted class of embedded V2 clauses, therefore precluding a symmetrical V2 analysis. (C) 2015 Elsevier B.V. All rights reserved.|Spanish; Verb-Second (V2); Verb-Movement; Main Clause Phenomena; Clausal Structure|LEFT PERIPHERY; UNIVERSAL GRAMMAR; LANGUAGE CHANGE; ARGUMENT-DROP; HEAD MOVEMENT; ROMANCE; GERMAN; FRENCH; SYSTEM; PRO|Linguistics; Language \& Linguistics|3|1|6
The suicide note as a genre: Implications for genre theory|2015|Although most of the work on genre analysis has attended to academic and professional genres, we attempt to explore and extend key issues in genre theory through a move structure analysis of suicide notes, a non-academic, non-professional genre, which has been the focus of interdisciplinary research. These studies, however, have not considered the suicide note as a genre. We propose a move-based account of this genre despite a variety of challenges these texts pose for the framework, including the lack of a discourse community, great variety in length, and the lack of any identifiable obligatory moves or fixed ordering of moves. The results show that not all genres can be characterized in terms of obligatory and optional moves, and we discuss an alternative way for capturing genre membership. We also show that a genre can exhibit patterns of co-occurrence for moves and steps even when it lacks an identifiable linear order. A computational analysis of a set of lexico-grammatical features of the texts shows that these features found in previous research on suicide notes are actually concentrated in particular moves. This paper concludes with a discussion of the implications of this study for genre theory. (C) 2015 Elsevier Ltd. All rights reserved.|Suicide notes; Move structure analysis; Linear order; Discourse community; Genre theory; Computational corpus analysis|WORDS; PERSPECTIVE; PURPOSE; GENUINE|Education \& Educational Research; Linguistics; Language \& Linguistics|0|2|6
Moving on from Genre Analysis An update and tasks for the transitional student|2015|The author first discusses the evolution of two major concepts in Genre Analysis, ``genre{''}, particularly as it relates to purpose and text prototypicality, and ``task{''}, particularly as it relates to context. Then, she draws from evolving understandings of these concepts, the work of Swales and Feak (2012a, 2012b) and of Rhetorical Genre Studies scholars (Bawarshi \& Reiff, 2010; Prior, 2001), to describe pre-writing tasks completed by transitional bilingual (Spanish/English) secondary school students as they prepared responses to prompts for a college application essay, The Personal Statement, a challenging, seemingly anomalous, genre. (C) 2015 Elsevier Ltd. All rights reserved.|Genre analysis; Rhetorical context; Situational analysis; Literacy tasks; Bi-lingual students|ESL|Education \& Educational Research; Linguistics; Language \& Linguistics|4|0|6
The GV-LEx corpus of tales in French Text and speech corpora enriched with lexical, discourse, structural, phonemic and prosodic annotations|2015|A corpus of French tales is presented. Its two parts, a text corpus and a speech corpus, were designed for studying the relationships between the textual structures of tales and speech prosody, with the targeted application of an expressive text-to-speech synthesis system embedded in a humanoid robot. The 89-tale text corpus, and the 12-tale speech corpus were annotated using a common tale description framework. Lexical level annotations include extended definitions of enumerations, time, place and person named entities, as well as part of speech tags. Supra-lexical level annotations include the segmentation of tales into a sequence of episodes, the localization and attribution of direct quotations, together with tale protagonists co-references. Annotation distributions and inter-annotator agreement were analyzed. The largest coverage and strongest agreement were observed for person named entities, characters' direct quotations, and their associated coreference chains. Speech corpus annotations were extended to allow the analysis of the relations between tale linguistic information and prosodic properties observed in associated speech. Word and phoneme boundaries were inferred through semi-automatic procedures, resulting in linguistic annotations aligned with the speech signal. Intonation stylization models were used to ease the visual and statistical analysis of tale's prosody. Additional meta-information is provided with the speech corpus, allowing describing tale characters according to their gender, age, size, valence and kind. The corpora described in this article are publicly available through the European Language Resources Association catalog.|Fairy tale corpus; Annotation scheme; Inter-annotator agreement; Direct quotations; Prosody; Intonation stylization; Text-to-speech; Expressivity|AGREEMENT; STORIES; SYSTEM|Computer Science, Interdisciplinary Applications|0|0|6
CADEC: A corpus of adverse drug event annotations|2015|CSIRO Adverse Drug Event Corpus (CADEc) is a new rich annotated corpus of medical forum posts on patient-reported Adverse Drug Events (ADEs). The corpus is sourced from posts on social media, and contains text that is largely written in colloquial language and often deviates from formal English grammar and punctuation rules. Annotations contain mentions of concepts such as drugs, adverse effects, symptoms, and diseases linked to their corresponding concepts in controlled vocabularies, i.e., SNOMED Clinical Terms and MedDRA. The quality of the annotations is ensured by annotation guidelines, multi-stage annotations, measuring inter-annotator agreement, and final review of the annotations by a clinical terminologist. This corpus is useful for studies in the area of information extraction, or more generally text mining, from social media to detect possible adverse drug reactions from direct patient reports. The corpus is publicly available at https://data.csiro.au.(1) (C) 2015 Elsevier Inc. All rights reserved.|Adverse drug reaction; Medical forum; SNOMED CT; MedDRA; Annotated corpus; Drug safety; Social media; Information extraction; Consumer reviews|SAFETY|Computer Science, Interdisciplinary Applications; Medical Informatics|12|0|6
Communication in open disclosure conversations about adverse events in hospitals|2015|We analyzed eight interactions between clinicians and simulated patients or family members discussing adverse events in patient care. We targeted the interactants' accommodative communication strategies when they discussed the consequent patient harm. In Study 1, 80 psychology students rated eight open disclosure video recordings for the presence of CAT strategies. In the recordings categorized as effective, clinicians demonstrated accommodative emotional expression and interactants engaged in more accommodative interpretability and interpersonal control strategies than in ineffective recordings. In Study 2, the same recordings were analyzed using Discursis (a textual analysis software program). Discursis uses new technology to visualize and identify speaker approximation. Approximation patterns correlated with findings from Study 1. Results provide insights into which CAT strategies assist managing open disclosure. (C) 2014 Elsevier Ltd. All rights reserved.|Adverse events; Open disclosure; Health; Text analytics; Discourse|LANGUAGE; CARE|Communication; Linguistics|8|0|6
The underpinnings of a composite measure for automatic term extraction The case of SRC|2015|The corpus-based identification of those lexical units which serve to describe a given specialized domain usually becomes a complex task, where an analysis oriented to the frequency of words and the likelihood of lexical associations is often ineffective. The goal of this article is to demonstrate that a user-adjustable composite metric such as SRC can accommodate to the diversity of domain-specific glossaries to be constructed from small-and medium-sized specialized corpora of non-structured texts. Unlike for most of the research in automatic term extraction, where single metrics are usually combined indiscriminately to produce the best results, SRC is grounded on the theoretical principles of salience, relevance and cohesion, which have been rationally implemented in the three components of this metric.|automatic term extraction; salience; relevance; cohesion; SRC|MODEL|Linguistics; Language \& Linguistics|5|0|6
Audience Attitude and Translation Reception The case of Genji Monogatari|2015|This article proposes a skopos-based analysis of the English translations of the eleventh century Japanese literary work, Genji monogatari ({''}The Tale of Genji{''}) as a means of understanding the basis for the translations' differing receptions among their target audiences. The translations, by Suematsu Kencho, Arthur Waley, Edward Seidensticker and Royall Tyler, are widely spaced chronologically, being published between 18882001, and were each produced with differing audiences and aims, thus making them a useful corpus for this analysis. In addition, all of the translators have written, with varying degrees of explicitness, about their motivations and purposes in conducting their translations. First, through an analysis of the translators' writings, introductions, and individual circumstances, the article will demonstrate how the skopos for each translation can be determined. Second, through an analysis and comparison of text excerpts, it will demonstrate how the skopos influenced the translation choices of the individual translators, with material being, for example, omitted, changed in psychological tone, or rendered more explicit, depending upon the individual translator's overriding purpose in their work. Finally, through an analysis of the reviews of the various translations, it will consider the extent to which each translator was successful in achieving a positive and intended response to his translation in the target audience.|audience; reception; skopos; Japanese; Genji monogatari|TALE-OF-GENJI|Linguistics; Language \& Linguistics|0|1|6
The research article abstract: Genre analysis in a Nursing corpus of texts|2015|The abstract is a genre that has received a great deal of attention in some areas, such as biomedicine and the social sciences (Salager-Meyer, 1990; Hyland, 2000; Swales \& Feak, 2009); however, its structure and content in other areas, such as nursing, has received less attention. Its importance in the dissemination of science should be an incentive for nursing authors to make it more informative and persuasive. No research has been found that surveyed the issue of whether the abstract should follow the traditional model of a single paragraph or structured with subtitles (Posteguillo Gomez \& Pique-Angordans, 2007). The aim of this study is to describe the content and structure of the traditional abstract, as well as its textual and discursive features. Drawing on the work of Weissberg and Buker (1990), we conducted an analysis of a corpus of 240 abstracts retrieved from twelve nursing journals in which we identified their structural units. One the most striking results was the wide range of variability in terms of the structure and content of the abstracts, with a vast majority of indicative, rather than informative abstracts. These findings suggest the need for a set of agreed upon criteria for writing abstracts in the field of nursing, more clearly aligned with international guidelines for scientific publication.|Research article abstract; genre study; traditional vs. structured abstracts; health sciences; Nursing|STRUCTURED ABSTRACTS; TECHNOLOGY; JOURNALS|Linguistics; Language \& Linguistics|0|1|6
Restricted natural language based querying of clinical databases|2014|Purpose: To elevate the level of care to the community it is essential to provide usable tools for healthcare professionals to extract knowledge from clinical data. In this paper a generic translation algorithm is proposed to translate a restricted natural language query (RNLQ) to a standard query language like SQL (Structured Query Language). Methods: A special purpose clinical data analytics language (CliniDAL) has been introduced which provides scheme of six classes of clinical questioning templates. A translation algorithm is proposed to translate the RNLQ of users to SQL queries based on a similarity-based Top-k algorithm which is used in the mapping process of CliniDAL. Also a two layer rule-based method is used to interpret the temporal expressions of the query, based on the proposed temporal model. The mapping and translation algorithms are generic and thus able to work with clinical databases in three data design models, including Entity-Relationship (ER), Entity-Attribute-Value (EAV) and XML, however it is only implemented for ER and EAV design models in the current work. Results: It is easy to compose a RNLQ via CliniDAL's interface in which query terms are automatically mapped to the underlying data models of a Clinical Information System (CIS) with an accuracy of more than 84\% and the temporal expressions of the query comprising absolute times, relative times or relative events can be automatically mapped to time entities of the underlying CIS and to normalized temporal comparative values. Conclusion: The proposed solution of CliniDAL using the generic mapping and translation algorithms which is enhanced by a temporal analyzer component provides a simple mechanism for composing RNLQ for extracting knowledge from CISs with different data design models for analytics purposes. (C) 2014 Elsevier Inc. All rights reserved.|Restricted natural language querying; Knowledge discovery and reuse; Data analytics|INFORMATION; EXTRACTION|Computer Science, Interdisciplinary Applications; Medical Informatics|2|0|6
Classification of CT pulmonary angiography reports by presence, chronicity, and location of pulmonary embolism with natural language processing|2014|In this paper we describe an efficient tool based on natural language processing for classifying the detail state of pulmonary embolism (PE) recorded in CT pulmonary angiography reports. The classification tasks include: PE present vs. absent, acute PE vs. others, central PE vs. others, and subsegmental PE vs. others. Statistical learning algorithms were trained with features extracted using the NLP tool and gold standard labels obtained via chart review from two radiologists. The areas under the receiver operating characteristic curves (AUC) for the four tasks were 0.998, 0.945, 0.987, and 0.986, respectively. We compared our classifiers with bag-of-words Naive Bayes classifiers, a standard text mining technology, which gave AUC 0.942, 0.765, 0.766, and 0.712, respectively. (C) 2014 Elsevier Inc. All rights reserved.|Natural language processing; NILE; Nested modification structure; Pulmonary embolism; CT pulmonary angiography|VENTRICULAR DIAMETER RATIOS; VENOUS THROMBOEMBOLISM; ABBREVIATIONS; VALIDATION; EXTRACTION; RADIOLOGY; ALGORITHM; MORTALITY; PROGRESS; DEFECTS|Computer Science, Interdisciplinary Applications; Medical Informatics|6|0|6
Head and facial gestures synthesis using PAD model for an expressive talking avatar|2014|This paper proposes to synthesize expressive head and facial gestures on talking avatar using the three dimensional pleasure-displeasure, arousal-nonarousal and dominance-submissiveness (PAD) descriptors of semantic expressivity. The PAD model is adopted to bridge the gap between text semantics and visual motion features with three dimensions of pleasure-displeasure, arousal-nonarousal, and dominance-submissiveness. Based on the correlation analysis between PAD annotations and motion patterns derived from the head and facial motion database, we propose to build an explicit mapping from PAD descriptors to facial animation parameters with linear regression and neural networks for head motion and facial expression respectively. A PAD-driven talking avatar in text-to-visual-speech system is implemented by generating expressive head motions at the prosodic word level based on the (P, A) descriptors of lexical appraisal, and facial expressions at the sentence level according to the PAD descriptors of emotional information. A series of PAD reverse evaluation and comparative perceptual experiments shows that the head and facial gestures synthesized based on PAD model can significantly enhance the visual expressivity of talking avatar.|Text-to-visual-speech; Head motion; Facial expression; Talking avatar|TO-SPEECH SYNTHESIS; EMOTIONAL PARAMETERS; PROSODIC FEATURES; ANIMATION; DRIVEN; MOVEMENT; MOTION|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|11|0|6
ICALL FOR IMPROVING KOREAN L2 WRITERS' ABILITY TO EDIT GRAMMATICAL ERRORS|2014|This study illustrates how a synergy of two technologies-Intelligent Computer-Assisted Language Learning (ICALL) and corpus linguistic analysis-can produce a lasting improvement in L2 learners' ability to edit persistent grammatical errors from their writing. A large written English corpus produced by Korean undergraduate and graduate students enrolled at an American university was analyzed to determine four persistent grammatical errors in their writing assignments. An ICALL program was then designed to improve these L2 learners' awareness of these errors in texts and provide practice in correcting them. A pre-test/post-test experiment revealed a significant improvement in recognizing and correcting the four errors by Korean L2 learners who had taken the ICALL program over a matched control group that had received standard L2 writing instruction. This improvement held up on a second post-test administered five months later. The implications of the results for L2 instruction and the design of iterative ICALL tutors are discussed.|CALL; Corpus Analysis; Persistent Grammatical Errors; L2 Writing|FEEDBACK|Education \& Educational Research; Linguistics|4|0|6
A linguistic framework for studying voices and positions in the climate debate|2014|The public debate on the highly contested issue of climate change is characterized by a multitude of voices as well as position taking by the social actors involved. Studies involving the climate issue have emanated from many fields, notably media science. To date, few linguistics-based studies on climate-related newspaper texts have been undertaken. This paper presents a theoretical framework - the Scandinavian theory of linguistic polyphony - which we argue is particularly well suited to analyze contested issues. To demonstrate how the theory can be operationalized, we present a case study involving four texts from The Guardian. Linguistic polyphony rests on the assumption that all texts are multivoiced. The case study focuses on the interaction of the journalist's voice and external voices, and considers the extent to which implicit (hidden) voices are present in the analyzed texts. The analysis reveals a complex interaction of different voices, integrated in the journalist's own argumentation and positioning.|climate discourse; media discourse; journalism; polyphony; voices; position taking|MEDIA; US; SKEPTICISM; DISCOURSES; COVERAGE; RISK; UK|Communication; Linguistics; Language \& Linguistics|9|0|6
Perfectivity and grounding in Mandarin Chinese|2014|This paper analyses the encoding of perfectivity in Chinese, focusing on its form, interpretation, and grounding functions. Three major points are made based on examinations of narrative text. First, perfectivity is indicated not only by the perfective marker -le, but also by an array of ``bounding expressions{''} that explicitly designate the endpoint of events. Second, Chinese perfective clauses as currently defined vary in grounding roles. They may present bounded dynamic events and play a foregrounding role or denote stative situations and have a backgrounding function. The different grounding functions are determined not by the verb form but by the transitivity features of the clauses and the context in which they occur. Third, the flexibility is closely related to the nature and semantics of perfectivity and the structural components of the Chinese perfective constructions. The study adds unique features of an isolating language to our existing knowledge of grounding.|aspect; perfectivity; grounding; discourse function; Chinese|LINGUISTICS; DISCOURSE; VERBS|Linguistics; Language \& Linguistics|1|0|6
The potentials and limitations of modelling concept concreteness in computational semantic lexicons with dictionary definitions|2013|This paper explores the feasibility of modelling concept concreteness perceived by humans and representing it in computational semantic lexicons, addressing an issue at the crossroads of computational linguistics, lexicography, and psycholinguistics. The inherent distinction between concrete words and abstract words in psychology has relied mostly on subjective human ratings. This practice is hardly scalable and does not consider the effect of polysemy. In view of this, we attempt to obtain a measure of concreteness from dictionary definitions comparable to human judgement, capitalising on conventional lexicographic assumptions and the regularities exhibited in the surface structures of sense definitions. The structural pattern of a definition is analysed and scored on a 7-point scale of concreteness ratings. The definition scores turned out to be quite effective for a dichotomous distinction between concrete and abstract concepts and more consistent with human ratings for the former. Beyond the two-way distinction, however, the results were more variable. The study has thus revealed the potentials and limitations of our approach, suggesting that different defining styles probably reflect the describability of concepts, and describability alone may not be sufficient for differentiating the degree of concreteness. The range of definition patterns has to be reconsidered, in combination with other inseparable factors constituting our perception of concreteness, for better modelling on a finer scale of concreteness distinction to enrich semantic lexicons for natural language processing.|Concept concreteness; Dictionary definitions; Semantic lexicons; Polysemy; Computational lexicography|ABSTRACT WORDS|Computer Science, Interdisciplinary Applications|0|1|6
Distributional Phrasal Paraphrase Generation for Statistical Machine Translation|2013|Paraphrase generation has been shown useful for various natural language processing tasks, including statistical machine translation. A commonly used method for paraphrase generation is pivoting {[}Callison-Burch et al. 2006], which benefits from linguistic knowledge implicit in the sentence alignment of parallel texts, but has limited applicability due to its reliance on parallel texts. Distributional paraphrasing {[}Marton et al. 2009a] has wider applicability, is more language-independent, but doesn't benefit from any linguistic knowledge. Nevertheless, we show that using distributional paraphrasing can yield greater gains in translation tasks. We report method improvements leading to higher gains than previously published, of almost 2 BLEU points, and provide implementation details, complexity analysis, and further insight into this method.|Design; Algorithms; Performance; Semantic similarity; semantic distance; paraphrase generation; statistical machine translation; SMT|INFORMATION-RETRIEVAL; SIMILARITY; MODELS|Computer Science, Artificial Intelligence; Computer Science, Information Systems|2|3|6
A text processing pipeline to extract recommendations from radiology reports|2013|Communication of follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology recommendations is an important barrier to ensuring timely follow-up of patients especially with non-acute incidental findings on imaging examinations. In this paper, we present a text processing pipeline to automatically identify clinically important recommendation sentences in radiology reports. Our extraction pipeline is based on natural language processing (NLP) and supervised text classification methods. To develop and test the pipeline, we created a corpus of 800 radiology reports double annotated for recommendation sentences by a radiologist and an internist. We ran several experiments to measure the impact of different feature types and the data imbalance between positive and negative recommendation sentences. Our fully statistical approach achieved the best f-score 0.758 in identifying the critical recommendation sentences in radiology reports. (c) 2013 Elsevier Inc. All rights reserved.|Natural language processing; Recommendation identification; Section segmentation|LANGUAGE; COMMUNICATION; ALGORITHM; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|16|1|6
Linguistic characterization of text types: the electoral campaign speech as an example|2013|Linguistic characterization of text types: the electoral campaign speech as an example This article focuses on the main linguistic feature of the text types or genres: the textual structure. We propose a textual structure that supplements the sequence of stages (cf. Eggins and Martin, 1887) with the hierarchical organization and the semantic relations maintained between stages. The proposed approach to this structure combines move analysis (cf. Swales, 1990; Upton and Connor, 2009) with theories of coherence relations (cf. Mann and Thompson, 1988; Wolf y Gibson, 2006). The analysis adopts the model of supra-sentential units articulated by Garrido (2007); those units are identified through the changes in patterns of cohesion. Our approach is illustrated with an election campaign speech.|Text type; genre; textual structure; election campaign speech|DISCOURSE|Linguistics; Language \& Linguistics|0|0|6
Hallidayan systemic-functional semiotics and the analysis of the moving audiovisual image|2013|Although linguistically inflected semiotic approaches to film were pursued in the 1960s and 1970s, they have since been almost universally rejected within film studies and film theory even though film is precisely the kind of intentionally produced communicative artifact for which one would have expected semiotics to have much to offer. Traditionally, forms of semiotics modeled on linguistics have offered some of the most finely articulated accounts available but, so far, this has not been shown convincingly for film. This paper argues that the semiotics of the 1960s and 1970s was just too undeveloped to deal with entities as complex as film. In contrast, the multidimensional account of verbal semiotic systems articulated within Hallidayan systemic-functional semiotics over the past forty years is now dissolving many of the original problems and provides renewed impetus for the semiotic analysis of film, reinstating much expanded notions of text and textuality securely at the center of attention.|audiovisual moving image; film; sociofunctional semiotics; textuality; multimodality; discourse; systemic-functional semiotics|FILM|Communication; Linguistics; Language \& Linguistics|2|1|6
Prosody competence when reading aloud: analysis of rythm aspects|2013|The current methodological tendencies give particular importance to the teaching of orality. Thus, several investigations have verified that reading aloud to children contributes positively to their cognitive development. However, in order to achieve the objective proposed with this type of reading, the prosodic aspect should not be forgotten. In spite of the few articles published up to now, the prosodic aspect is considered to be essential to provide a description of young people's prosodic features when reading aloud, especially in order to create general rules that can be taught in our schools and universities. This paper is limited to the analysis of the types of rhythm, and for this, five informants have been selected and asked to read a text written in standard Basque.|competence; reading aloud; rhythm; optimality theory|STRESS; BASQUE|Linguistics; Language \& Linguistics|2|1|6
The visual construction of language hierarchy The case of banknotes, coins and stamps|2013|This paper analyses the way in which the text displayed on bilingual and multilingual currency (banknotes and coins) and stamps constructs and reproduces linguistic hierarchies, reflecting the relative status of the languages within the issuing country. The paper briefly discusses the selection of languages which appear on stamps and money, which is nearly always in accordance with the dominant language ideologies. It then goes on to show how the choice of language and the relative positioning and size of texts in those languages constructs the languages involved as of equal or unequal status. Two case studies are considered: the construction of equality between English and Afrikaans in South Africa on stamps and banknotes of the period 1910 to 1994, reflecting the constitutional requirement that those languages be treated `on a footing of equality'; and the construction of linguistic inequality in the stamps of Palestine and Israel, where first English (under the British Mandate) was displayed as dominant over Arabic and Hebrew, and later Hebrew (in Israel) was shown to dominate over the other two. The paper argues for a dual analysis of text in public texts like stamps and banknotes: on the one hand text is language, and is subject to a (socio)linguistic analysis, while on the other, text has a physical form and dimensions which means that texts are interpreted in terms of their visual features and spatial relationships to other texts. The language hierarchies which are reproduced and transported by stamps and money are thus discursively constructed through a combination of text as language and text as image.|language hierarchies; multilingualism; bilingualism; stamps; banknotes; coins|POSTAGE STAMPS|Linguistics; Language \& Linguistics|3|2|6
A new clustering method for detecting rare senses of abbreviations in clinical notes|2012|Abbreviations are widely used in clinical documents and they are often ambiguous. Building a list of possible senses (also called sense inventory) for each ambiguous abbreviation is the first step to automatically identify correct meanings of abbreviations in given contexts. Clustering based methods have been used to detect senses of abbreviations from a clinical corpus {[}1]. However, rare senses remain challenging and existing algorithms are not good enough to detect them. In this study, we developed a new two-phase clustering algorithm called Tight Clustering for Rare Senses (TCRS) and applied it to sense generation of abbreviations in clinical text. Using manually annotated sense inventories from a set of 13 ambiguous clinical abbreviations, we evaluated and compared TCRS with the existing Expectation Maximization (EM) clustering algorithm for sense generation, at two different levels of annotation cost (10 vs. 20 instances for each abbreviation). Our results showed that the TCRS-based method could detect 85\% senses on average: while the EM-based method found only 75\% senses, when similar annotation effort (about 20 instances) was used. Further analysis demonstrated that the improvement by the TCRS method was mainly from additionally detected rare senses, thus indicating its usefulness for building more complete sense inventories of clinical abbreviations. (C) 2012 Elsevier Inc. All rights reserved.|Natural language processing; Word sense discrimination; Clustering; Clinical abbreviations|UMLS; DICTIONARY; MEDLINE|Computer Science, Interdisciplinary Applications; Medical Informatics|2|0|6
KnoE: A Web Mining Tool to Validate Previously Discovered Semantic Correspondences|2012|The problem of matching schemas or ontologies consists of providing corresponding entities in two or more knowledge models that belong to a same domain but have been developed separately. Nowadays there are a lot of techniques and tools for addressing this problem, however, the complex nature of the matching problem make existing solutions for real situations not fully satisfactory. The Google Similarity Distance has appeared recently. Its purpose is to mine knowledge from the Web using the Google search engine in order to semantically compare text expressions. Our work consists of developing a software application for validating results discovered by schema and ontology matching tools using the philosophy behind this distance. Moreover, we are interested in using not only Google, but other popular search engines with this similarity distance. The results reveal three main facts. Firstly, some web search engines can help us to validate semantic correspondences satisfactorily. Secondly there are significant differences among the web search engines. And thirdly the best results are obtained when using combinations of the web search engines that we have studied.|database integration; data and knowledge engineering; similarity distance|SIMILARITY; RELATEDNESS; WORDNET|Computer Science, Hardware \& Architecture; Computer Science, Software Engineering|3|0|6
The Linguistic Subversion of Mental Representation|2012|Embedded and embodied approaches to cognition urge that (1) complicated internal representations may be avoided by letting features of the environment drive behavior, and (2) environmental structures can play an enabling role in cognition, allowing prior cognitive processes to solve novel tasks. Such approaches are thus in a natural position to oppose the `thesis of linguistic structuring': The claim that the ability to use language results in a wholesale recapitulation of linguistic structure in onboard mental representation. Prominent examples of researchers adopting this critical stance include Andy Clark, Michael Wheeler, and Mark Rowlands. But is such opposition warranted? Since each of these authors advocate accounts of mental representation that are broadly connectionist, I survey research on formal language computation in artificial neural networks, and argue that results indicate a strong form of the linguistic structuring thesis is true: Internal representational systems recapitulate significant linguistic structure, even on a connectionist account of mental representation. I conclude by sketching how my conclusion can nonetheless be viewed as consistent with and complimentary to an embedded/embodied account of the role of linguistic structure in cognition.|Situated cognition; Language; Artificial Neural Networks; Connectionism; Mental representation|RECURRENT NEURAL-NETWORKS; CHIMPANZEES PAN-TROGLODYTES; CONTEXT-FREE; LANGUAGE; DYNAMICS; CONNECTIONISM; COMPUTATION; EXTRACTION; RULES; TASK|Computer Science, Artificial Intelligence|0|0|6
AT THE JUNCTURE OF LITERATURE AND GEOGRAPHY: LITERATURE AS A SUBJECT OF GEOGRAPHIC INQUIRY IN THE CASE OF SLOVENE ISTRIA|2012|Literary works as discursive articulation of the experience of residing in a space are becoming a legitimate subject of geographic inquiry. Postmodern geography also has adopted for its purposes some concepts from literary studies, such as intertextuality and landscape as text or geographic imagination. A qualitative analysis of selected examples of literary texts that thematize the space of Slovene Istria shows how topophilia, the Self/other identity distinction, and feelings of place and placelessness take shape in them. These are contemporary concepts of humanistic geography, which build on the predominantly objectivist, natural and social science tradition by taking into account individual and group apprehension, imagination, and formation of space. Literary works enable geography to analyze our relation to our living environs and the meanings that we attribute to the space or identify ourselves with. Our relations to space are also a fundamental condition for forming identities and societal responsibility.|Slovene Istria; qualitative textual analysis; literary representations of place; geographic imagination; cultural representations|LANDSCAPE|Linguistics; Language \& Linguistics|1|0|6
STORIES OF BRIDAL AND FEMININE EXPERIENCE - PRODUCTION OF GENDERED NARRATIVES IN THE CONTEXT OF MEDIA RECEPTION|2012|The present paper presents gendered narratives produced during research interviews with readers of a wedding magazine. While interpreting media texts, the women gave accounts of their bridal and feminine experience. Of all understandings of a narrative proposed in discourse analysis, the ones taken here are of a situated construction of self in interaction (Taylor 2006) and of an established sequence of life trajectory (Bruner 1991). Accordingly, the lived experience of identity is approached as discursively mediated - by the available set of subject positions and interpretative repertoires. In the analysis, the interviewees are found to employ socio-culturally accumulated resources of self-construction in talk. Their narrative work reveals how speakers (despite their dependency on the intertextual reservoir of notions, images and associations) seek to position themselves as independent and agentic subjects of discourse.|Media discourse; interpretative repertoires; gender identity; subject positions|SINGLENESS; IDENTITY|Linguistics; Language \& Linguistics|1|0|6
Anaphoric reference in clinical reports: Characteristics of an annotated corpus|2012|Motivation: Expressions that refer to a real-world entity already mentioned in a narrative are often considered anaphoric. For example, in the sentence ``The pain comes and goes,{''} the expression ``the pain{''} is probably referring to a previous mention of pain. Interpretation of meaning involves resolving the anaphoric reference: deciding which expression in the text is the correct antecedent of the referring expression, also called an anaphor. We annotated a set of 180 clinical reports (surgical pathology, radiology, discharge summaries, and emergency department) from two institutions to indicate all anaphor-antecedent pairs. Objective: The objective of this study is to describe the characteristics of the corpus in terms of the frequency of anaphoric relations, the syntactic and semantic nature of the members of the pairs, and the types of anaphoric relations that occur. Understanding how anaphoric reference is exhibited in clinical reports is critical to developing reference resolution algorithms and to identifying peculiarities of clinical text that may alter the features and methodologies that will be successful for automated anaphora resolution. Results: We found that anaphoric reference is prevalent in all types of clinical reports, that annotations of noun phrases, semantic type, and section headings may be especially important for automated resolution of anaphoric reference, and that separate modules for reference resolution may be required for different report types, different institutions, and different types of anaphors. Accurate resolution will probably require extensive domain knowledge especially for pathology and radiology reports with more part/whole and set/subset relations. Conclusion: We hope researchers will leverage the annotations in this corpus to develop automated algorithms and will add to the annotations to generate a more extensive corpus. (C) 2012 Elsevier Inc. All rights reserved.|Natural language processing; Clinical reports|RESOLUTION; INFORMATION; EXTRACTION; DISCOURSE; SYSTEM; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|7|0|6
Conceptual Recurrence Plots: Revealing Patterns in Human Discourse|2012|Human discourse contains a rich mixture of conceptual information. Visualization of the global and local patterns within this data stream is a complex and challenging problem. Recurrence plots are an information visualization technique that can reveal trends and features in complex time series data. The recurrence plot technique works by measuring the similarity of points in a time series to all other points in the same time series and plotting the results in two dimensions. Previous studies have applied recurrence plotting techniques to textual data; however, these approaches plot recurrence using term-based similarity rather than conceptual similarity of the text. We introduce conceptual recurrence plots, which use a model of language to measure similarity between pairs of text utterances, and the similarity of all utterances is measured and displayed. In this paper, we explore how the descriptive power of the recurrence plotting technique can be used to discover patterns of interaction across a series of conversation transcripts. The results suggest that the conceptual recurrence plotting technique is a useful tool for exploring the structure of human discourse.|Concept map; recurrence; concept; plotting; conversation analysis; text analysis|SYSTEMS|Computer Science, Software Engineering|24|1|6
CORPUS-BASED MODELLING OF LEXICAL CHANGES IN BIPOLAR DISORDERS: THE CASE OF EDGAR ALLAN POE|2012|Bipolar disorders affect the mind and are probably caused by a biological imbalance in the brain. Language, a reflection of thought and ideas in the mind, and a vehicle for communication among human beings is an excellent display of potential mental disorders. In this study we hypothesize that Poe's bipolar disorders could be reflected in his literary production. Our research will be based on the analysis of the lexical profile obtained out of 42 randomly selected tales by Poe from his total of 69. For that purpose, we have selected standard lexical variables, common in many corpus-based lexical studies. Specifically, we have selected eight lexical variables, grouped into three categories: (i) lexical richness, (ii) lexical features of the mental lexicon, and (iii) lexico-semantic text difficulty. The results reveal significant abnormal linguistic fluctuations, very much in concord with cyclothymic fluctuations in Poe's mood.|Bipolar disorders; mania; euphoria; literary corpus-based research; lexical analysis|SELF-MEDICATION HYPOTHESIS; MOOD DISORDERS; CREATIVITY; BEHAVIOR; DEPRESSION; WRITERS|Linguistics; Language \& Linguistics|0|0|6
Bootstrapping a Game with a Purpose for Commonsense Collection|2012|Text mining has been very successful in extracting huge amounts of commonsense knowledge from data, but the extracted knowledge tends to be extremely noisy. Manual construction of knowledge repositories, on the other hand, tends to produce high-quality data in very small amounts. We propose an architecture to combine the best of both worlds: A game with a purpose that induces humans to clean up data automatically extracted by text mining. First, a text miner trained on a set of known commonsense facts harvests many more candidate facts from corpora. Then, a simple slot-machine-with-a-purpose game presents these candidate facts to the players for verification by playing. As a result, a new dataset of high precision commonsense knowledge is created. This combined architecture is able to produce significantly better commonsense facts than the state-of-the-art text miner alone. Furthermore, we report that bootstrapping (i.e., training the text miner on the output of the game) improves the subsequent performance of the text miner.|Algorithms; Design; Experimentation; Human Factors; Games with a purpose; commonsense; knowledge extraction; natural language processing; Facebook|SEMANTIC RELATIONS; SENSE|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|0|6
Learning to Estimate Slide Comprehension in Classrooms with Support Vector Machines|2012|Comprehension assessment is an essential tool in classroom learning. However, the judgment often relies on experience of an instructor who makes observation of students' behavior during the lessons. We argue that students should report their own comprehension explicitly in a classroom. With students' comprehension made available at the slide level, we apply a machine learning technique to classify presentation slides according to comprehension levels. Our experimental result suggests that presentation-based features are as predictive as bag-of-words feature vector which is proved successful in text classification tasks. Our analysis on presentation-based features reveals possible causes of poor lecture comprehension.|Lecture analytics; lecture comprehension; learning skills; SVM|COGNITIVE-STYLE|Computer Science, Interdisciplinary Applications; Education \& Educational Research|1|0|6
Travelling Certainties Darwin's Doubts and Their Dutch Translations|2011|This article builds on Annie Brisset's chapter `Clemence Royer, ou Darwin en colere' (2002:173-203), in which she argues that Clemence Royer's French translation (1861) of Charles Darwin's On the Origin of Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life (1859) was adapted to the French positivistic style, that Royer's own voice was injected into the translation and that the French translation conveyed a higher degree of certainty than the English original. The comparative study presented here investigates whether two Dutch translations (Winkler 1860 and Hellemans 2000) show similar shifts in certainty or epistemic stance (Karkkainen 2003). Quantitative and qualitative analyses were conducted of Darwin's chapter four on `Natural Selection' and its two translations, focusing on a set of modal words and using an adapted version of Martin and White's epistemic scale of ranking (2005). Comparisons between Darwin's text and its translations reveal a positivistic voice, similar to Royer's, in Winkler's nineteenth-century translation but not in the contemporary translation by Hellemans. The findings are discussed in terms of target audiences, language-inherent characteristics and general translation tendencies.|Epistemic modality; Charles Darwin; Appraisal theory; Nineteenth-century translation; Scientific discourse|MODALITY|Communication; Linguistics; Language \& Linguistics|4|0|6
Exploring a corpus-based approach for detecting language impairment in monolingual English-speaking children|2011|Objectives: This paper explores the use of an automated method for analyzing narratives of monolingual English speaking children to accurately predict the presence or absence of a language impairment. The goal is to exploit corpus-based approaches inspired by the fields of natural language processing and machine learning. Methods and materials: We extract a large variety of features from language samples and use them to train language models and well known machine learning algorithms as the underlying predictors. The methods are evaluated on two different datasets and three language tasks. One dataset contains samples of two spontaneous narrative tasks performed by 118 children with an average age of 13 years and a second dataset contains play sessions from over 600 younger children with an average age of 6 years. Results: We compare results against a cut off baseline method and show that our results are far superior, reaching F-measures of over 85\% in two of the three language tasks, and 48\% in the third one. Conclusions: The different experiments we present here show that corpus based approaches can yield good prediction results in the problem of language impairment detection. These findings warrant further exploration of natural language processing techniques in the field of communication disorders. Moreover, the proposed framework can be easily adapted to analyze samples in languages other than English since most of the features are language independent or can be customized with little effort. (C) 2011 Elsevier B.V. All rights reserved.|Natural language processing; Machine learning; Analysis of orthographic transcriptions; Language impairment; Monolingual English-speaking children|DEVELOPMENTAL OUTCOMES; GRAMMATICAL MORPHOLOGY; KINDERGARTEN-CHILDREN; TYMPANOSTOMY TUBES; NONWORD REPETITION; PRESCHOOL-CHILDREN; DYNAMIC ASSESSMENT; DELAYED INSERTION; WORKING-MEMORY; OTITIS-MEDIA|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|5|0|6
Dialect and Register Hybridity: A Case from Schools|2011|This case study explores the academic writing practices of some African American English-speaking high school students, focusing in particular on interactions of dialect and register. In some instances, students appear to draw from a range of dialect and register resources and to deploy them in hybridized forms in their compositions. One implication of this hybridity is that it suggests the need to include register analysis as part of linguistically informed approaches to writing instruction (i.e., approaches that apply variationist research and methods to educational settings). Additionally, this case study examines some of the reasons that motivate the production of hybridity, analyzing how the linguistic tasks in which students are asked to engage and students' metalinguistic understandings play a role in the creation of hybridized texts. Finally, this study presents analytic methods that, while not new, are applied in a mixed way that attempts to systematically examine both dialect and register in texts.|register variation; African American English; academic writing; metapragmatics; code-switching|LANGUAGE; STUDENTS; DESIGN|Linguistics; Language \& Linguistics|1|0|6
The use of headed and headless DE-marked referential expressions in Chinese mother-child conversation|2011|The development of children's use of referential expressions in discourse is of much interest to researchers in language acquisition. One type of referer tial expression in Mandarin, the headed and headless DE-marked referential forms, lacks dear understanding in terms of how discourse factors might influence the use of these DE-marked expressions. This study details one longitudinal case of the use of Mandarin headed and headless DE-marked referential expressions by a mother-child dyad in their natural conversation. The qualitative and quantitative analyses of the data show that the use of headed and headless DE-marked forms is not determined solely by structural properties. Findings indicate that the DE-marked referential forms are associated with the information status assumed by the interlocutors during the process of communicating. When a new and unfamiliar referent is introduced into discourse for the first time, the head in the DE-marked forms is used. However, once a referent has been treated as given information, the givenness of the referent alone cannot explain the occurrence and non-occurrence of the head in the DE-marked referential forms. We argue that the headed and headless DE-marked referential forms are also frequently linked with discourse-pragmatic factors, such as communicative acts and interactive roles undertaken and played by the interlocutors. Moreover, the child's developmental progress of DE-marked referential expressions aligns with the communicative acts she intends to perform in discourse, and it reflects the child's competence as an active participant in discourse. Our stance is that structural factors may affect overall use of various DE-marked expressions, but the use of headed and headless DE-marked forms should be a discourse matter. (C) 2010 Elsevier Ltd. All rights reserved.|Discourse referencing; Mandarin; Child language; Prenominal modification|REFERRING EXPRESSIONS; DISCOURSE; ACQUISITION; JAPANESE; SPEECH|Linguistics; Language \& Linguistics|0|0|6
Multidocument Summarization of Engineering Papers Based on Macro- and Microstructure|2011|This paper focuses on automatic summarization of multiple engineering papers. A summarization approach based on documents' macro-and microstructure has been proposed. The macrostructure consists of a list of ranked topics from engineering papers. Topics are discovered by extracting and grouping frequently appearing word sequences into equivalence classes. Hence, the macrostructure symbolically presents the topical links in different papers. Meanwhile, the microstructure is defined as the rhetorical structure within a single paper. The identification of microstructure is approached as a classification problem. Each sentence in a paper is automatically labeled with one of the predefined rhetorical categories. Unlike existing summarization methods that first separate documents into nonoverlapping clusters and then summarize each cluster individually, our approach aims to summarize multiple documents according to the characteristics suggested at macro-and microstructure levels. The experimental study showed that our proposed approach outperformed peer systems in terms of recall-oriented understudy for gisting evaluation scores and readers' responsiveness. In an independent manual categorization task using the summaries generated by our approach and peer systems, we also performed better in terms of precision and recall. {[}DOI: 10.1115/1.3563048]|multidocument summarization; macrostructure; microstructure; document structure analysis; summarization evaluation|LITERATURE ABSTRACTS; MULTIPLE DOCUMENTS; TEXT; INFORMATION; CORPUS; SINGLE; WEB|Computer Science, Interdisciplinary Applications; Engineering, Manufacturing|1|0|6
The automated understanding of simple bar charts|2011|While identifying the intention of an utterance has played a major role in natural language understanding, this work is the first to extend intention recognition to the domain of information graphics. A tenet of this work is the belief that information graphics are a form of language. This is supported by the observation that the overwhelming majority of information graphics from popular media sources appear to have some underlying goal or intended message. As Clark noted, language is more than just words. It is any ``signal{''} (or lack of signal when one is expected), where a signal is a deliberate action that is intended to convey a message (Clark, 1996 {[}15]). As a form of language, information graphics contain communicative signals that can be used in a computational system to identify the message that the graphic conveys. We identify the communicative signals that appear in simple bar charts, and present an implemented Bayesian network methodology for reasoning about these signals and hypothesizing a bar chart's intended message. Once the message conveyed by an information graphic has been inferred, it can then be used to facilitate access to this information resource for a variety of users, including 1) users of digital libraries, 2) visually impaired users, and 3) users of devices where graphics are impractical or inaccessible. (C) 2010 Elsevier B.V. All rights reserved.|Natural language processing; Bayesian networks; Bar charts; Communicative signals|PERCEPTUAL TASK EFFORT; PLAN-RECOGNITION; INFORMATION GRAPHICS; SYSTEM; GENERATION; INTENTION; LANGUAGE; DIAGRAM; MODEL; TEXT|Computer Science, Artificial Intelligence|6|1|6
Rich pitch The humorous effects of deaccent and L plus H{*} pitch accent|2011|This paper argues that intonation contributes to the humorous meaning of a certain class of jokes. Examples of both canned and spontaneous jokes show that two intonation patterns, the intonation of contrast, or ``L+H{*} pitch accent{''}, and the intonation of given information, or ``deaccent{''}, can contribute to a humorous effect. Both of these patterns act as cohesive devises in discourse: they trigger a mental search in the mind of a hearer for a cohesive tie that may not be obvious from the lexicogrammatical structure alone. A punch line effect is created if this search yields an unexpected incongruity between the hearer's initial mental model of the joke discourse and a humorous alternative. The hearer must shift his ``script{''} (Raskin 1984) of the discourse in an unexpected way. To the extent that intonation facilitates processing by directing attention to particular elements in the information structure of the discourse (Chafe 1994), the processing of jokes depends in part on their intonation. The implications of this premise for the processing of humorous texts will be discussed for the two intonation patterns in question. It is argued that intonation analysis can lead to a broader understanding of cognitive processes and structures.|ad hoc categories; cognition; contrast; given/new; humor; information structure; intonation; language processing; mental representation; pitch accent; pragmatics; prosody; salience; theme/rheme|JOKES|Linguistics; Language \& Linguistics|2|1|6
``Uma revolucao democratica e sempre uma revolucao inacabada{''} - or - ``A democratic revolution must always remain unfinished{''} Commemorating the Portuguese 1974 revolution in newspaper opinion texts|2011|This article analyses the discursive construction of collective memories and the function of commemorative events for national identity. It focuses on how the 30th anniversary of the Portuguese 1974 revolution was portrayed in the government's Programme of Action issued for the 2004 commemorations and in forty-three newspaper opinion articles also published in 2004. The 1974 revolution ended a 48-year right-wing dictatorship and has shaped subsequent historical events since the 1970s. When the Programme of Action changed the 1974 slogan `April is revolution' into `April is evolution', the written press responded by conducting a debate on this reframing. Using the Discourse-Historical Approach in CDA as the analytical framework, this paper highlights the discursive strategies on which the government's manifesto was built and explores the opinion articles' ongoing political and ideological tensions over the revolution, its commemorations, and how it paved the way into Europe, by describing the main macro-discursive strategies and raising issues regarding the (mis)representation of social actors and social action.|Discourse analysis; discourse-historical approach; national identity; commemorations; Portugal; 1974 revolution|DISCURSIVE CONSTRUCTION|Linguistics; Language \& Linguistics|3|0|6
Justifying and condemning sexual discrimination in everyday discourse Letters to the Editor in the Australian local press|2011|This discourse analysis study identifies the discursive strategies and linguistic resources addressers of Letters to the Editor in Australian community papers employ to construct their view of homosexuality a view which uses the discourses of biology and religion to justify both rejection and acceptance The analysis of the discursive strategies found in the texts identifies the use of certain commonsense arguments as presented in Discursive Psychology to justify and legitimate the addressers positions as well as the use of keywords in relation to Cognitive Linguistics concepts The identification of these elements in the elaboration of the letters discourses helps to recognise the addressers standpoint assumptions and their competing values It was found th it although the same discourse of legitimation (the Bible) is used in some of the arguments addressers apply their own experience to their views of this discourse and thus create opposing arguments What they have in common however is that they are basing the responsibility for rejection or acceptance not on themselves but on the narratives they use This is used as a justification strategy that helps to avoid issues that could be socially condemned in their web of conversations (C) 2010 Elsevier B V All rights reserved|Discriminatory discourse; Letters to the Editor; Everyday genre; Discursive Psychology; Cognitive Linguistics|POLITICAL DISCOURSE; RACISM|Linguistics; Language \& Linguistics|4|1|6
Commentary on Evans and Levinson, the myth of language universals Language diversity, cognitive universality|2010|Evans and Levinson's (2009) article claims that the assumption of Chomskyan generative linguistics that knowledge of natural language draws on a small inventory of principles with fixed parametric variation (i.e., Universal Grammar) is empirically untenable. We agree that the authors point out prima facie limitations of that approach, and we leave it to others to assess how well their criticisms survive closer scrutiny. Here we argue that Evans and Levinson (2009) overstate the dependence of current psycholinguistic research on the Chomskyan idea of Universal Grammar. To show this point, we review cross-linguistic research in sentence processing that shows the influence of two cognitive factors ambiguity and memory demands - on the form of complex sentences within different languages and of the relative ease of understanding different types of sentences within those languages. The complex sentences we focus on contain relative clauses, a construction that has been extensively studied by typologists working in the tradition that seeks conditional statistical generalizations about similarities between languages. We argue that Evans and Levinson do not present a proposal counter to classical claims in generative linguistics that is comprehensive and testable in this domain. (C) 2010 Elsevier B.V. All rights reserved.|Universal grammar; Language typology; Language variation; Cognitive constraints|NOUN PHRASE ACCESSIBILITY; THEMATIC ROLE INFORMATION; LINGUISTIC COMPLEXITY; RELATIVE CLAUSES; EYE-TRACKING; INTERFERENCE|Linguistics; Language \& Linguistics|4|0|6
Bilingual practices and the social organisation of video gaming activities|2010|Grounded in the interactional paradigm for the study of bilingual language use, this paper investigates how players engaged in a collaborative game-playing activity orient to the co-presence of two languages in the setting and deploy bilingual resources in organising their action and participation. The analysis aims to demonstrate how a particular kind of `bilingual order' (Cromdal, 2005) is co-constructed in which the players use their native language (Finnish) for interaction with each other, but systematically draw on the language of the game in constructing their turns as recognisable and building their alignments with respect to activities under way. The analysis highlights how a bilingual gaming activity is organised through the participants' emergent orientations to interactional objects, which include English text and talk, in their own actions. The interaction unfolds through a bilingual medium as the players attend to locally available language resources in co-constructing the sense of particular scenes and events. Code-switching emerges as a key resource for organising the players' participation, managing transitions from one type of activity to another, displaying heightened involvement with particular scenes or events, and co-constructing affect while evaluating and enjoying the game. (C) 2010 Elsevier B.V. All rights reserved.|Bilingual practices; Gaming; Language alternation; Conversational code-switching; Social activity|PARTICIPATION; GAME; RESOURCE; CONTEXT; TALK|Linguistics; Language \& Linguistics|9|0|6
Writing through two languages: First language expertise in a language minority classroom|2010|Language minority students' writing is often measured solely in terms of its distance from native speaker norms, yet doing so may ignore the process through which these texts are realized and the role that the first language plays in their creation. This study analyzes oral interactions among adolescent second language writers during an extended writing activity to address the following questions: 1. How do students use their first language(s) to broker L2 interactions with a monolingual teacher during L2 writing tasks? 2. How do students use their first language(s) in student student interactions to demonstrate expertise during L2 writing tasks? 3. How do students use their first language(s) in student student interactions to seek expertise during L2 writing tasks? Analysis of student teacher and student student interactions reveals that L1 use offers strategic opportunities for student teacher conversation and blurs traditional boundaries between ``expert{''} and ``novice{''} writers. Bilingual students at all levels of English language proficiency utilize the L1 to assert expertise in rhetorical, academic, linguistic, or procedural elements of the task, and students move fluidly between expert and novice roles. There are limits to students' expertise, however, as well as the pedagogical circumstances under which the L1 can be most productively used. These findings offer insight into the writing process as it is influenced by bilingual language proficiencies and classroom interaction. (C) 2010 Elsevier Inc. All rights reserved.|L2 writing; Process; Interaction; Expertise; Bilingual; Language minority; Adolescent|PEER RESPONSE GROUPS; LATINO ADOLESCENTS; L2 CLASSROOM; 2ND-LANGUAGE; WRITERS; L1; TASKS; COMMUNICATION; 1ST-LANGUAGE; PROFICIENCY|Linguistics|21|0|6
Automatic recognition of regional phonological variation in conversational interaction|2010|One key aspect of face-to-face communication concerns the differences that may exist between speakers' native regional accents. This paper focuses on the characterization of regional phonological variation in a conversational setting. A new, interactive task was designed in which 12 pairs of participants engaged in a collaborative game leading them to produce a number of purpose-built names. In each game, the participants were native speakers of Southern French and Northern French, respectively. How the names were produced by each of the two participants was automatically determined from the recordings using ASR techniques and a pre-established set of possible regional variants along five phonological dimensions. A naive Bayes classifier was then applied to these phonetic forms, with a view to differentiating the speakers' native regional accents. The results showed that native regional accent was correctly recognized for 79\% of the speakers. These results also revealed or confirmed the existence of accent-dependent differences in how segments are phonetically realized, such as the affrication of /d/ in /di/ sequences. Our data allow us to better characterize the phonological and phonetic patterns associated with regional varieties of French on a large scale and in a natural, interactional situation. (C) 2010 Elsevier B.V. All rights reserved.|Conversational interaction; Regional phonological and phonetic variation; Automatic speech processing; French; Sociophonetics|SOCIAL DESIRABILITY; SPEECH RECOGNITION; PERCEPTION; LANGUAGE; DIALECT; FRENCH; CONVERGENCE; ACCENT; CORPUS; SCALE|Acoustics; Computer Science, Interdisciplinary Applications|8|0|6
The impact of general and specific vocabulary knowledge on reading and listening comprehension A case of Iranian EFL learners|2010|The present study was carried out to determine the effect of general vocabulary knowledge and gaining familiarity with the specific vocabulary content of a reading or listening comprehension test on a group of Iranian EFL learners' reading and listening comprehension ability Two groups of male and female English majors (N = 58) participated in the study In one group (the treatment group) the participants were given a reading comprehension test accompanied by a glossary which contained the meaning of the most difficult words appearing in the reading comprehension test In the other group (the control group) the students received the same test without the glossary The same procedure was followed for a listening comprehension test in the two groups in another session The analysis of the data revealed that the students in the treatment group significantly outperformed those in the control group in both reading and listening comprehension tests Further analysis of the data indicated that the learners knowledge of the general vocabulary content of the reading and listening comprehension texts only affected their performance on the reading comprehension test The results of the present study shed more light on the influence of knowledge of vocabulary on reading and listening comprehension (C) 2010 Elsevier Ltd All rights reserved|Vocabulary; Listening; Reading; Comprehension; Iranian EFL learners|WORD MEANINGS; INSTRUCTION; LANGUAGE; FREQUENCY; GROWTH|Education \& Educational Research; Linguistics|9|0|6
The different forms of interaction and its status in a science of language: Considerations and questions|2010|This article is the written version of a conference lecture that proposed a survey of the studies on ``language and interaction.{''} The first part proposes a brief commentary on the developement of the current Chomsky's position, which now understands language as a communicative phenomenon, as well as the development of the interpretations of Saussure's work which highlight the importance the scholar gave to the interactions between the levels of discourse and languages. The second part presents a critical summary of three approaches explicitly centered around verbal interactions: initially, the sciences of texts/discourse, which have their foundations on the work by Voloshinov, author who is central to the current conception of dialogism; the different approaches of interactional linguistics, inspired on Ethnomethodology and centered on the situated oral productions; approaches that analyze the effects of the e-learning devices, which constitute a type of natural laboratory for the study of the interactive phenomena. The main analysis refers to the contributions of the interactional linguistics and distinguishes the studies related to the structure itself of verbal interactions, the studies centered on the verbal productions in work situations and those centered on the verbal productions in the devices for the analysis of practices. The conclusion highlights the importance of the interactional epistemology, as it proposes to distinguish five levels: (a) the interactions between the and the gnosiological dimensions of language; (b) the interactions between general praxeology and language praxeology; (c) the constitutive interactions of the signs; (d) the concrete dialogical interactions; (e) the interactions between the structure of the verbal interactions and the different properties of the context.|Dialogism; Discourse; e-learning; Interaction; Language; Praxeology; Sign|FACULTY|Linguistics; Language \& Linguistics|0|1|6
Aphasia and text writing|2010|Aims: The aim was to characterize written narratives produced by a group of participants with aphasia. Methods \& Procedures: Eight persons aged 28-63 years with aphasia took part in the study. They were compared with a reference group consisting of ten participants aged 21-30 years. All participants were asked to write a personal narrative titled `I have never been so afraid' and to perform a picture-based story-generation task called the `Frog Story'. The texts were written on a computer. Outcome \& Results: The group could be divided into participants with low, moderate, and high general performance, respectively. The texts written by the participants in the group with moderate and high writing performance had comparatively good narrative structure despite indications of difficulties on other linguistic levels. Conclusions \& Implications: Aphasia appeared to influence text writing on different linguistic levels. The impact on overall structure and coherence was in line with earlier findings from the analysis of spoken and written discourse and the implication of this is that the written modality should also be included in language rehabilitation.|aphasia; text writing; word-level errors; text structure; coherence|PHONOLOGICAL AGRAPHIA; DISCOURSE; ADULTS; REVISION; LANGUAGE; CHILDREN; EASIER; REPAIR|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|3|0|6
A systemic functional contribution to planning academic genre teaching in a bilingual education context|2010|Commencing study through a foreign language in senior secondary school brings huge challenges because of the cognitive-linguistic demands of academic subjects. This paper argues for the need to blend sociocultural and systemic functional linguistic (SFL) perspectives to address this enormous task. Firstly, readers' attention is drawn to the less than successful history, globally, of helping students overcome the challenges. Secondly, the paper sets out the author's intention to respond to the call by Coyle for bilingual educators working in a predominantly sociocultural paradigm to `connect' with other paradigms. Next, aiming to respond to two exploratory questions regarding the power of SFL to inform planning of language-aware teaching, which is richer and more productive than is evident in sociocultural scholarship, the paper proceeds towards descriptive and comparative analyses of a student's written outcome in science, using the SFL framework based on `text architecture'. The SFL analyses exemplify what might be taught, with brief mention of how SFL practitioners do so, in order to raise awareness of academic genre creation. Finally, drawing on the paper's analyses and evidence from elsewhere, arguments for the paradigmatic blending are synthesised.|bilingual education; explicit instruction; genre analysis; language awareness; writing|IMMERSION CLASSROOMS; HONG-KONG; LANGUAGE; PERSPECTIVES; INSTRUCTION; WORLDS; WORK|Linguistics; Language \& Linguistics|7|0|6
Empiricism versus connoisseurship: Establishing the appropriacy of texts in tests of academic reading|2010|Providers of tests of languages for academic purposes generally claim to provide evidence on the extent to which students are likely to be able to cope with the future demands of reading in specified real-life contexts. Such claims need to be supported by evidence that the texts employed in the test reflect salient features of the texts the test takers will encounter in the target situation as well as demonstrating the comparability of the cognitive processing demands of accompanying test tasks with target reading activities. This paper will focus on the issue of text comparability. For reasons of practicality, evidence relating to text characteristics is generally based on the expert judgement of individual test writers, arrived at through a holistic interpretation of test specifications. However, advances in automated textual analysis and a better understanding of the value of pooled qualitative judgement have now made it feasible to provide more quantitative approaches focusing analytically on a wide range of individual characteristics. This paper will employ these techniques to explore the comparability of texts used in a test of academic reading comprehension and key texts used by first-year undergraduates at a British university. It offers a principled means for test providers and test users to evaluate this aspect of test validity.|automated text analysis; content validity; English for academic purposes; reading; text authenticity|COMPREHENSION; COHESION|Linguistics; Language \& Linguistics|7|0|6
Differences that make the difference: a study of functionalities in synchronous CMC|2010|This paper has a dual aim to situate functionalities among the complex of factors that help shape online interactions and to explore the heterogeneity of audio conferencing, and its implications Following a critical discursive synthesis of the treatment of variables in the literature, attention focuses oil the distinctive and diverse characteristics of synchronous audio environments The existence of a synchronous-asynchronous dichotomy is questioned and the effects of a number of differences are highlighted As a further illustration. the paper next undertakes a comparison of Lyceum and Wimba Voice Direct The main features of the two environments are introduced and a detailed analysis of their, text and voice chat facilities Is carried Out In the last section the benefits of text-based CMC are revisited through the lens of voice chat technology It is concluded that the benefits of CMC appear to have been overstated and that no general claims can be made about voice CMC but that collectively. well documented Studies could provide a useful source of information oil the level of contingency of particular findings.|Audio conferencing; CMC; functionality; language learning environments; variables; voice chat|MEDIATED NEGOTIATED INTERACTION; LANGUAGE; CONVERSATIONS; CLASSROOM; CHAT; TEXT|Education \& Educational Research; Linguistics; Language \& Linguistics|12|0|6
ELE-Intelligent Tutor: A computational parser for the processing of grammatical errors in Spanish as a Foreign Language|2010|Intelligent Tutorial Systems (ITS) are based on the advances in Artificial Intelligence, mainly regarding the use of comprehension techniques for natural language or natural language generation. An ITS is a computer-based programme for teaching and learning and aims to facilitate personalized learning processes. The label of `intelligent' is associated with the system's capacity to analyse the grammar of the language entry and then generate the appropriate feedback according to the student's error. To do this, it is necessary to use natural language processing techniques based on grammar-related theories so that the student's entry can be processed to generate a specific feedback strategy. The interest in learning Spanish as a Foreign Language has increased over the years, and this has resulted in the elaboration of learning environments highly improved by professionals and researchers that effectively support the processes to foster student learning autonomy. As to foreign language learning, the interest that students have in the incorporation of e-learning platforms empowered with Information and Communications Technologies (ICTs) has been empirically proven. However, the limitations of such platforms have also been observed regarding the processing of linguistic forms, specifically in terms of recognizing the different language errors that students make (grammar, lexicon, etc.) and the precariousness and lack of effectiveness in the type of feedback used to process these errors. Corrective feedback and errors are an essential and normal part of the language learning process. The main objective of this article is to meet the need of improving the Spanish as a foreign language learning process through the design and implementation of the parser of an intelligent tutorial system that could identify and classify grammatical errors in Spanish as a foreign language.|Spanish as a Foreign Language; Intelligent Tutorial Systems; parser; Natural Language Processing|COMPUTER; FEEDBACK|Linguistics; Language \& Linguistics|5|1|6
The development of semantic relations in second language speakers: A case for Latent Semantic Analysis|2010|This study explores how a Latent Semantic Analysis (LSA) index provided by Coh-Metrix can be used as a method to examine the development of lexical networks in second language (L2) speakers. Using the LSA index along with an index of lexical development (lexical diversity), a measure of general linguistic development (TOEFL scores) and indices of lexical overlap in a yearlong longitudinal study, this study demonstrates that semantic similarity along with TOEFL and lexical diversity values significantly increase as learners study a second language. Measures of word overlap did not demonstrate significant growth. The findings demonstrate that the LSA value reported by Coh-Metrix can be used to approximate lexical growth and that L2 learners likely begin to develop tighter semantic relations between utterances and words within a short period of time. This finding implies the growth of lexical networks. This study also has important implications for the development of coherent speech patterns in L2 learners.|Latent Semantic Analysis; Lexical Networks; Corpus Linguistics; Lexical Proficiency; Computational Linguistics; MTLD|TEXT; COHERENCE; KNOWLEDGE; LANGUAGE|Linguistics; Language \& Linguistics|12|0|6
Research intelligence involving information retrieval - An example of conferences and journals|2009|This paper reports a work that was intended to reveal the connection between topics investigated by conference papers and journal papers. This work selected hundreds of papers in data mining and information retrieval from well-known databases and showed that the topics covered by conference papers in a year often leads to similar topics covered by journal papers in the subsequent year and vice versa. This study used some existing algorithms and combination of these algorithms to proposed a new detective procedure for the researchers to detect the new trend and get the academic intelligence from conferences and journals. The goal of this research is fourfold: First, the research investigates if the conference papers' themes lead the journal papers'. Second, the research examines how the new research themes can be identified from the conference papers. Third, the research looks at a specific area such as information retrieval and data mining as an illustration. Fourth, the research studies any inconsistencies of the correlation between the conference papers and the journal papers. This study explores the connections between the academic publications. The methodologies of information retrieval and data mining can be exploited to discover the relationships between published papers among all topics. By discovering the connections between conference papers and journal papers, researchers can improve the effectiveness of their research by identifying academic intelligence, This Study discusses how conference papers and journal papers are related. The topics of conference papers are identified to determine whether they represent new trend discussed in journal papers. An automatic examination procedure based on information retrieval and data mining is also proposed to minimize the time and human resources required to predict further research developments. This study develops a new procedure and collects a dataset to verify those problems. Analytical results demonstrate that the conference papers Submitted to journals papers are similar each year. Conference papers certainly affect the journal papers published over three years. About 87.23\% of data points from papers published in 1991-2007 support our assumption. The research is intended to help researchers identify new trend in their research fields, and focus on the urgent topics. This is particularly valuable for new researchers in their field, or those who wish to perform cross-domain studies. (C) 2009 Elsevier Ltd. All rights reserved.|Citation analysis; Scientific web intelligence; Topic discovery and tracking; Data mining; Information retrieval; Academic intelligence|TEXT MINING APPROACH; ONLINE IMPACT; MODEL|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic; Operations Research \& Management Science|6|1|6
A recent advance in the automatic indexing of the biomedical literature|2009|The volume of biomedical literature has experienced explosive growth in recent years. This is reflected in the corresponding increase in the size of MEDLINE(R), the largest bibliographic database of biomedical citations. Indexers at the US National Library of Medicine (NLM) need efficient tools to help them accommodate the ensuing workload. After reviewing issues in the automatic assignment of Medical Subject Headings (MeSH(R) terms) to biomedical text, we focus more specifically on the new subheading attachment feature for NLM's Medical Text Indexer (MTI). Natural Language Processing, statistical, and machine learning methods of producing automatic MeSH main heading/subheading pair recommendations were assessed independently and combined. The best combination achieves 48\% precision and 30\% recall. After validation by NLM indexers, a suitable combination of the methods presented in this paper was integrated into MTI as a subheading attachment feature producing MeSH indexing recommendations compliant with current state-of-the-art indexing practice. (C) 2008 Elsevier Inc. All rights reserved.|Abstracting and Indexing as Topic/methods/statistics \& numerical data; Artificial Intelligence; Dictionaries, Medical; Evaluation Studies as Topic; MEDLINE; Medical Subject Headings; Natural Language Processing|TEXT CATEGORIZATION; DOCUMENTS; ARTICLES; KEYWORDS; MEDLINE|Computer Science, Interdisciplinary Applications; Medical Informatics|31|0|6
Hypothesis testing in rank-size rule regression|2009|This note examines testing methods for Paretoness in the framework of rank-size rule regression. Rank-size rule regression describes a relationship found in the analysis of various topics such as city population. words in texts, scale of companies and so on. In terms of city population, it is basically an empirical rule that log(S((i))) is approximately a linear function of log(i) where S(i) is the number of population of ith largest city in a country. This is closely related to the so-called Zipf's law. It is known that this kind of empirical observation is found when the city population is a random variable following a Pareto distribution. Thus one may be willing to test if city size has a Pareto distribution or not. Rosen and Resnick {[}K.T. Rosen, M. Resnick, The size distribution of cities: ail explanation of the Pareto law and primacy, Journal of Urban Economics 8 (1980), 165-186] and Soo {[}K.T Soo, Zipf's law for cities: a cross country investigation, Regional Science and Urban Economics (35) 2005, 239-263] regress log(S((i))) on log(i) and log(2)(i) and test the null of Paretoness by standard t-test for the latter regressor. It is found that t-statistics take large values and the Paretoness is rejected in many countries. We Study the statistical properties of the t-statistic and show that it explodes asymptotically, in fact, by simulation and thus the t-test does not provide a reasonable testing procedure. We propose an alternative test statistic which seems to be asymptotically normally distributed. We also propose a test with the null hypothesis that the city size distribution is Pareto with exponent unity, which is a modification of the F-test. (c) 2008 IMACS. Published by Elsevier B.V. All rights reserved.|Rank-size rule regressions; Paretoness|CITIES; LAW|Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Mathematics, Applied|3|1|6
A machine learning approach for Arabic text classification using N-gram frequency statistics|2009|In this paper a machine learning approach for classifying Arabic text documents is presented. To handle the high dimensionality of text documents, embeddings are used to map each document ( instance) into R ( the set of real numbers) representing the tri-gram frequency statistics profiles for a document. Classification is achieved by computing a dissimilarity measure, called the Manhattan distance, between the pro. le of the instance to be classified and the profiles of all the instances in the training set. The class ( category) to which an instance ( document) belongs is the one with the least computed Manhattan measure. The Dice similarity measure is used to compare the performance of method. Results show that tri-gram text classification using the Dice measure outperforms classification using the Manhattan measure. (C) 2008 Elsevier Ltd. All rights reserved.|Data mining; Classification; Categorization; Arabic; N-gram; Machine learning|CATEGORIZATION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|26|0|6
Reducing information overloading on the World Wide Web by using human-computer dialogue interactions|2009|This work suggests a natural language processing approach to web-based cooperative dialogs. It focuses on the user's requests automatically generating language-drive interactions that take into account the context, user feedback, and the initial web search results. The different components of natural language processing in the context of dialog discourse interactions are described. The main results of a working prototype aiming to decrease both the number of conversational turns and the information overload are lastly discussed.|Natural Language Processing (NLP); Intelligent Web Search; Information Filtering (IF); Information Retrieval (IR); Natural Language Generation (NLG)|AGENT|Linguistics; Language \& Linguistics|0|0|6
Teachers as critical text analysts: L2 literacies and teachers' work in the context of high-stakes school reform|2008|The authors describe the professional development of L1 and L2 teachers from a comprehensive theoretical perspective that focuses on literacy as a critical social practice, the construction of student/teacher knowledge, and institutional forces that support and/or constrain the academic literacy development of L2 students in the United States. The authors begin with an articulation of the theoretical framework guiding this discussion. Next, they describe how this perspective was enacted in a graduate program designed to support K-12 teachers in developing an understanding of theories, research, and practices that form a critical approach to L2 academic literacy development. Last, following Hyland (2003, 2007), the authors reflect on the challenges, and ultimately the necessity, of critically reconceptualizing L1 and L2 teacher education to include greater attention to genre theory and genre-based pedagogics. This call for a reconceptualization of teacher education in the United States is warranted because of the combined impact of economic, demographic, and educational policies shaping the work of teachers and the literacy practices of L2 students. (c) 2008 Elsevier Inc. All rights reserved.|L2 literacy; English language learners; Teachers professional development; Critical discourse analysis; Genre-based pedagogy|EDUCATION; LANGUAGE; ESL; CLASSROOM; INSTRUCTION; IDENTITY; PEDAGOGY; GRAMMAR|Linguistics|16|0|6
The cost of question concealment: Eye-tracking and MEG evidence|2008|Although natural language appears to be largely compositional, the meanings of certain expressions cannot be straightforwardly recovered from the meanings of their parts. This study examined the online processing of one such class of expressions: concealed questions, in which the meaning of a complex noun phrase (the proof of the theorem) shifts to a covert question (what the proof of the theorem is) when mandated by a sub-class of question-selecting verbs (e.g., guess). Previous behavioral and magnetoencephalographic (MEG) studies have reported a cost associated with converting an entity denotation to an event. Our study tested whether both types of meaning-shift affect the same computational resources by examining the effects elicited by concealed questions in eye-tracking and MEG. Experiment 1 found evidence from eye-movements that verbs requiring the concealed question interpretation require more processing time than verbs that do not support a shift in meaning. Experiment 2 localized the cost of the concealed question interpretation in the left posterior temporal region, an area distinct from that affected by complement coercion. Experiment 3 presented the critical verbs in isolation and found no posterior temporal effect, confirming that the effect of Experiment 2 reflected sentential, and not lexical-level, processing. (c) 2007 Elsevier Inc. All rights reserved.|Semantic composition; Coercion; Concealed questions; N400; AMF; MEG; Eye-tracking|LEFT-HEMISPHERE LESIONS; EVOKED MAGNETIC-FIELDS; SENTENCE COMPREHENSION; BRAIN POTENTIALS; TIME-COURSE; LEXICAL ACTIVATION; SEMANTIC CONTEXT; TEMPORAL CORTEX; WORD; FREQUENCY|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|6|1|6
A statistical language modeling approach to online deception detection|2008|Online deception is disrupting our daily life, organizational process, and even national security. Existing approaches to online deception detection follow a traditional paradigm by using a set of cues as antecedents for deception detection, which may be hindered by ineffective cue identification. Motivated by the strength of statistical language models (SLMs) in capturing the dependency of words in text without explicit feature extraction, we developed SLMs to detect online deception. We also addressed the data-sparsity problem in building SLMs in general and in deception detection in specific using smoothing and vocabulary pruning techniques. The developed SLMs were evaluated empirically with diverse data sets. The results showed that the proposed SLM approach to deception detection outperformed a state-of-the-art text categorization method, as well as traditional feature-based methods.|machine learning; classification; language models; text mining; knowledge management applications; security|COMPUTER-MEDIATED COMMUNICATION; CUES|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|21|0|6
A STUDY OF TEXTUAL ENTAILMENT|2008|In this paper we study a graph-based approach to the task of Recognizing Textual Entailment between a Text and a Hypothesis. The approach takes into account the full lexico-syntactic context of both the Text and Hypothesis and is based on the concept of subsumption. It starts with mapping the Text and Hypothesis on to graph structures that have nodes representing concepts and edges representing lexico-syntactic relations among concepts. An entailment decision is then made on the basis of a subsumption score between the Text-graph and Hypothesis-graph. The results obtained from a standard entailment test data set were promising. The impact of synonymy on entailment is quantified and discussed. An important advantage to a solution like ours is its ability to be customized to obtain high-confidence results.|Textual entailment; syntactic dependencies; natural language processing; graph subsumption|INFERENCES; NEGATION|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|7|0|6
Preferred genres and rhetorical modes in the humanities and social sciences|2008|The article reports on a research project aimed at identifying salient written genres and text types/rhetorical modes in the Faculty of Humanities at a large University in Gauteng, South Africa. The main purpose of the research was to establish an empirical base for the design of intermediate-level undergraduate language courses. A survey was done by means of text analysis: study guides were requested from a representative sample of departments, after which writing prompts were identified and analysed using Wordsmith Tools. In terms of genre it has been established that the humanities prefer essays and critical analyses, while the social sciences prefer project reports and essays. The rhetorical modes required most frequently at undergraduate level are discussion, analysis, argumentation, explanation and description. Discussion, explanation and argumentation are favoured by academic essays, while description and evaluation are favoured by reports, and analysis, argumentation and discussion are favoured by critical analyses. Although most essays presuppose argumentation, it is often not explicated in writing prompts. Other complicating factors are the ambiguity and hidden assumptions associated with certain rhetorical verbs. The outcomes of the research suggest two possible approaches to designing writing courses for undergraduate students in the humanities and social sciences: a subject-specific and a semi-generic approach, of which the latter may be more feasible within the framework of a macro-university.|academic essay; academic writing; genre; humanities; rhetorical mode; social sciences; text type|COURSES|Linguistics; Language \& Linguistics|4|1|6
A TRANSLATION STUDIES ORIENTED INTEGRATIVE APPROACH TO CANADIAN POLITICAL DISCOURSE|2008|By a possible integration of text linguistics (proposition analysis), sociocognitive theory and Critical Discourse Analysis, the present study intends to reveal instances of ideologically charged translation by means of comparing and contrasting certain textual features of an instance of French language Canadian political discourse and its English translation. The aim of the analysis is twofold: to investigate some fundamental differences between source language and target language text production in terms of political power play and persuasion, as well as to demonstrate, by analysing a specific political text, a possible application of the above-mentioned integrative approach within the field of discourse analysis. The paper will also offer numerous possible perspectives oil further research with a view to the Canadian political discourse in question.|proposition analysis; sociocognitive theory; Critical Discourse Analysis; political discourse; Canadian politics|MEMORY; COMPREHENSION; RECOGNITION; TEXT|Linguistics; Language \& Linguistics|2|1|6
Textographies and the researching and teaching of writing|2008|This Paper describes three different. examples Of the use of textographies in the researching and teaching of writing. The first is in examination of the exegeses that art and design students write in their masters degrees. In the second example, a group of teachers looked at the writing section Of Chinese College English tests. The third example describes a course in which second language students carry out an analysis Of the kinds of writing that is required of them in their academic studies. Each of the projects aims to go ``beyond the text{''} (Freedman, 1999) in order to gain all understanding of why the texts are written as they are.|academic writing; genre; ethnographies; textography; research-led teaching|GENRE|Linguistics; Language \& Linguistics|6|0|6
Comprehension of academic texts written in English: Relation between level of comprehension achieved and variables involved|2008|Nowadays, it is considered essential for university students to have psycho-discursive skills that allow them comprehend disciplinary texts successfully. However, as English has become a lingua franca, not only in the fields of international trading and technology development, but also in research and education, in countries where English is not the mother tongue, university students must also develop the ability to comprehend disciplinary texts written in English. Approaching this phenomenon, in this investigation, we examined the process of comprehension carried out by university students when facing disciplinary texts written in English. The students (n= 112) belonged to the Industrial Chemistry program, at Pontificia Universidad Catolica de Valparaiso, Chile. We focused on the level of comprehension these students achieved when facing a disciplinary text written in English and also on the way that level of comprehension was predicted by the participants' English proficiency level, their degree of insertion in the disciplinary community, and their reading skill. We carried out a correlational study, which showed that the relation between the level of comprehension the students achieved and each of the variables considered does not represent a high positive correlation. However, through the analysis we carried out, we could state that the variable that best predicts the level of comprehension of an academic text written in English corresponds to English proficiency level, followed by degree of insertion in the disciplinary community, and, at the end, reading skill.|written discourse comprehension; academia discourse; English for academic purpose|DISCOURSE; KNOWLEDGE|Linguistics; Language \& Linguistics|12|0|6
Academic writing of adolescent English learners: Learning to use ``although{''|2007|increasing calls for equity and accountability in U.S. secondary schools have led to intensified scrutiny of the academic literacy development of English learning (EL) adolescents. This paper discusses some of the challenges that EL secondary students face in achieving the language and literacy skills that will enable them to succeed in their mainstream classes, graduate from high school, and continue their academic careers into college. It presents an instructional approach used to work with students on academic language development and describes the language resources that students were able to take up following instruction. This paper suggests ways that secondary teachers can teach their EL students to use linguistic analysis in order to recognize the expectations of academic writing and produce texts that increasingly incorporate the linguistic features of academic language. (C) 2007 Elsevier Inc. All rights reserved.|academic language; second language writing; English learners; adolescent literacy|LANGUAGE; GRAMMAR; WRITERS|Linguistics|14|1|6
Effects of training on the acoustic-phonetic representation of synthetic speech|2007|Purpose: Investigate training-related changes in acoustic-phonetic representation of consonants produced by a text-to-speech (TTS) computer speech synthesizer. Method: Forty-eight adult listeners were trained to better recognize words produced by a TTS system. Nine additional untrained participants served as controls. Before and after training, participants were tested on consonant recognition and made pairwise judgments of consonant dissimilarity for subsequent multidimensional scaling (MDS) analysis. Results: Word recognition training significantly improved performance on consonant identification, although listeners never received specific training on phoneme recognition. Data from 31 participants showing clear evidence of learning (improvement >= 10 percentage points) were further investigated using MDS and analysis of confusion matrices. Results show that training altered listeners' treatment of particular acoustic cues, resulting in both increased within-class similarity and between-class distinctiveness. Some changes were consistent with current models of perceptual learning, but others were not. Conclusion: Training caused listeners to interpret the acoustic properties of synthetic speech more like those of natural speech, in a manner consistent with a flexible-feature model of perceptual learning. Further research is necessary to refine these conclusions and to investigate their applicability to other training-related changes in intelligibility (e. g., associated with learning to better understand dysarthric speech or foreign accents).|intelligibility; synthetic speech; listener training; perceptual learning|DYSARTHRIC SPEECH; SELECTIVE ATTENTION; PERCEPTUAL MAGNET; HEARING-LOSS; INTELLIGIBILITY; CATEGORIZATION; FAMILIARIZATION; RECOGNITION; ACQUISITION; RULE|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|28|0|6
Ensuring the quality of conceptual representations|2007|High quality data and process representations are critical to the success of system development efforts. Despite this importance, quantitative methods for evaluating the quality of a representation are virtually nonexistent. This is a major shortcoming. However, there is another approach. Instead of evaluating the quality of the final representation, the representation process itself can be evaluated. This paper views the modeling process as a communication channel. In a good communication channel, sufficient error prevention, error detection, and error correction mechanisms exist to ensure that the output message matches the input message. A good modeling process will also have mechanisms for preventing, detecting, and correcting errors at each step from observation to elicitation to analysis to final representation. This paper describes a theoretically-based set of best practices for ensuring that each step of the process is performed correctly, followed by a proof of concept experiment demonstrating the utility of the method for producing a representation that closely reflects the real world.|quality; conceptual representation; modeling process|INFORMATION-SYSTEMS; MODEL; COMPREHENSION; KNOWLEDGE; TEXT|Computer Science, Software Engineering|3|0|6
A word of caution on coercion|2007|Recent work in cognitive linguistics has hired the term coercion which was formerly associated with computational linguistics to apply to a number of instances in the study of natural language in which there is an incongruity between the semantics of a syntactic frame and the semantics of lexical items found in it. Some of these instances illustrate areas which could well be described as extensions of aspectual boundaries in which the harmony between lexical and grammatical aspect has been penetrated; others illustrate mismatch between count and mass noun types, in which the usual parameters that apply to either type have been violated. Although. typical cases of coercion have been associated with the processes of metonymy, the purpose of the present paper is to analyse each individual case as it has been presented in recent accounts, and to investigate whether the processes involved in metonymic inferencing can be summarised in pragmatic terms, or otherwise in the light of their diachronic development and grammaticalisation. If so, it will thus be questioned how coercion can be justified in the context of natural language at all. (C) 2006 Elsevier B.V. All rights reserved.|coercion; metonymy; grammaticalisation; aspect; type-shifting; mismatch|METONYMY|Linguistics; Language \& Linguistics|16|2|6
Modelling thought in language use: At the crossroads between discourse, pragmatics, and cognition|2007|This article studies a number of semantic and pragmatic phenomena with consequences for the development of discourse. Thus, our study of the way we make use of cognitive models in discourse allows us to postulate the principle of ``Metaphoric Source Selection{''}: the metaphorical extension of a concept can only select partial structure from this concept to construct the metaphoric source. The recognition of degrees of centrality in semantic specifications underlies the ``Peripherality Principle{''}, a discourse principle grounded in the ``Principle of Relevance{''}: when the most central characterization of a concept is not capable of creating discourse coherence, speakers turn to less central specifications and select the one that best satisfies the conditions of relevance. We then address the question of the pragmatic grounding of so-called cohesion and coherence in discourse. We claim that ellipsis and substitution are discourse phenomena subject to pragmatic constraints and argue for the existence of the ``Conceptual Structure Selection Principle{''}, which accounts for the semantic scope of ellipsis and substitution devices: these have within their scope as much structure as is not cancelled out by the discourse unit that contains the cohesion device. We have redefined the cohesion-coherence distinction as one between procedural and conceptual connectivity and have formulated two further principles of discourse connectivity: the ``Principle of Iconicity{''} and the ``Principle of Conceptual Prominence{''}. There is a large amount of evidence that iconic arrangements are an important aspect of discourse coherence. Still, there is little work done with respect to the principles that regulate non-iconic arrangements. The Principle of Conceptual Prominence, which accounts for the special discourse status of prominent non-iconic information, fills this vacuum. The final part of this research work focuses upon the analysis of discourse strategies as non-conventional sets of procedures that allow speakers to create and interpret procedurally and conceptually connected texts. Two reverse discourse strategies are formulated, both related to the balance between procedural and conceptual markers of discourse connectivity. To this we add two other discourse principles, the ``Principle of Internal Contrast{''} and the ``Principle of External Contrast{''}. The former is based upon explicit procedural operations, whereas the latter makes use of conceptual connectivity. Lastly, we distinguish two more discourse principles that constrain strategic discourse activity: the ``Principle of Conceivability{''}, which regulates conceptual links with situations in terms of the possibility of creating plausible mental scenarios for them; and the ``Principle of Relative Distance{''}, which helps sort out ambiguities in anaphoric operations on the basis of the relative distance between the anaphoric pronoun and its potential antecedent as licensed by the Principle of Conceivability.|discourse; pragmatics; cognitive models; metaphor; metonymy; cohesion; coherence; discourse connectivity; relevance; ambiguity; iconicity|CONVERSATION|Linguistics; Language \& Linguistics|3|0|6
Media-ted political oratory following terrorist events - International political responses to the 2005 London bombing|2007|Using a computer-assisted content analysis, this study analyzes a 32,000 word corpus drawn from mediated political statements made in response to the July 2005 London bombing. This grounded research led to a focus on the deontic nature of these statements, and also revealed a relative absence of condoling. Although condemnatory, statements did not specifically attribute the `evil' to particular people. Particularly mindful of Widdowson's (2004) distinction between analysis (text) and interpretation (discourse), the paper first identifies the textual features, but then ``hermeneutically{''} interprets their meaning within a wider context of international political discourse. The paper concludes that the statements performed a positive epideictic purpose, although it tended to occlude the compassionate element of public grieving.|condemnation; condolence; deontic modality; discourse; epideictic rhetoric; media genres; political oratory; should; terrorism|LANGUAGE; NEWS|Linguistics; Language \& Linguistics|11|0|6
The use of verbs in research articles - A corpus analysis|2007|The aim of the study described in this article is to examine the lexical characteristics of medical research articles in English. The article describes the results obtained from the analysis of a corpus of medical texts in which the use of verbs is studied in the different sections of the medical research article. After selecting a corpus of 30 texts and tagging them with a POS Tagger, concordances of verbs were obtained. The verbs were then classified according to their meaning in lexical domains. Results show that the lexical domains are distributed differently in each section of the article, reinforcing the rhetorical functions of each section. A proposal is also made for using these results in a more practical manner, for example to enrich an electronic manual, with information that could assist professionals and translators with the writing and translation of medical research articles.|corpus linguistics; medical research article; academic writing; genre; IMRAD; lexical domains|BREAST-CANCER RISK; MAMMARY CARCINOGENESIS; POSTMENOPAUSAL WOMEN; IN-VIVO; CELLS; POLYMORPHISM; RATS; PREVENTION; TAMOXIFEN; GENOTYPE|Linguistics; Language \& Linguistics|1|1|6
Explication and sharing of design knowledge through a novel product design approach|2006|At the beginning of the 21st century, the emergence of knowledge management is viewed as a natural evolution. Knowledge management is defined as the formal management of knowledge for facilitating creation, access, and reuse of knowledge, typically by using advanced technology. To be easily communicated and shared, tacit knowledge has to be explicated as explicit knowledge (e.g., in product specification or a scientific formula or production rules); and this explicit knowledge has to be shared as applicable data through the use of information technology. Product design is such a business process that a great part of the design knowledge is often a tacit type, being difficult to share, or available only in forms of natural language documents. However, the expertise recorded in these documents is an essential resource of successful competition in the market. This paper presents a knowledge explication and sharing approach; specifically focusing on the knowledge management of modular product design. The solution approach involves modeling modular products, formulating the explicit knowledge, discovering new design knowledge with data mining, and sharing the knowledge with web services technology. The proposed approach is to be applied to an actual case of motherboard design/assembly in one of the largest PC manufacturing enterprises.|data mining; data warehouse/data mart; knowledge management; modular products; product design; web services|INFORMATION-TECHNOLOGY; EXPERT-SYSTEM; PERSPECTIVE; MANAGEMENT|Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications|10|1|6
Lexical-semantic similarity in scientific research articles in Spanish: An approach to latent semantic analysis|2006|This research focuses on lexicaL-semantic similarities found in three text variables (key words, abstract, and content in scientific research articles). Two scientific areas (biological sciences and social sciences) from the values of lexica I-semantic similarity are compared. The study employs a representative stratified sample of 22 scientific research articles in these two areas, which have been included in a corpus of 675 scientific articles. To determine lexicaL-semantic similarities among the variables, a computer-statistical method is employed, called Latent Semantic Analysis. The findings help assert, on the one hand, that the abstract `macro-semanticizes' better the global semantic content of the article than do the key words. On the other hand, no meaningful differences among the averages of lexica I-semantic similarity in the scientific areas studied are revealed. These findings are accounted for in terms of the generally complex standardization processes which tend to homogenize the production of this type of articles.|scientific writing; semantic similarity; latent semantic analysis; scientific research article|PIGS|Linguistics; Language \& Linguistics|17|0|6
Reshaping prior text, reshaping identities|2006|This analysis brings together Goffman's concept of alignment, Bakhtin's notion of dialogicality, and A. L. Becker's idea that interaction consists Of `reshaping' old texts into present contexts to consider how one mother reshapes her own and her child's previous discourse across three conversations to construct different alignments with her co-interlocutors and different identities for herself The mother, Janet, who works part-time but spends most of her time caring for her three-year-old daughter, Natalie, tape-recorded nearly all of her interactions for one week. The conversations I examine involve (i) Janet `being Mommy' as she deals with a misbehaving Natalie while also trying to talk on the telephone; (ii) Janet and Natalie reversing roles and playfully re-enacting this incident two days later; and (iii) Janet recounting the re-enactment to three friends the next evening during a dinner party and evaluating it in a way that distances her from the identity of a full-time stay-at-home mom'. The analysis shows how specific bits of prior text are reshaped to create play, build rapport, and construct alignments that put forth particular identities at particular interactional moments. It thus illustrates how `the same' prior text serves as a resource for creating multiple alignments and identities in discourse.|discourse analysis; intertextuality; repetition; family discourse; identity construction; mother|REPORTED SPEECH; DISCOURSE; MOTHER|Communication; Linguistics; Language \& Linguistics|15|0|6
Epistemological positioning and evidentiality in English news discourse: A text-driven approach|2006|This paper uses a text-driven approach to explore epistemological positioning (the expression of assessments concerning knowledge) in English newspapers. The notion of epistemological positioning (EP) often overlaps with evidentiality-the linguistic marking of the basis of speaker/writer knowledge. This is a relatively modern concept in linguistics and, compared to the amount of research it has attracted concerning other languages, it has been somewhat neglected in research focusing on English. Newspaper texts are a particularly good source for looking into EP and evidentiality, because the news story is a genre that is preoccupied with knowledge. The analysis shows that EP in English can be very complex, and that the distinction between attribution and averral (Sinclair 1988) needs to be taken into account when discussing it in naturally occurring texts (particularly in news texts). The resulting elements of EP that are identified for the English language offer a first glance at the possibilities to express EP in English, and open up future research on EP in different registers and text types.|epistemological positioning; evidentiality; attribution; averral; subjectivity; news discourse|CONVERSATION|Communication; Linguistics; Language \& Linguistics|38|0|6
Corpus-based learning of analogies and semantic relations|2005|We present an algorithm for learning from unlabeled text, based on the Vector Space Model (VSM) of information retrieval, that can solve verbal analogy questions of the kind found in the SAT college entrance exam. A verbal analogy has the form A:B::C:D, meaning ``A is to B as C is to D{''}; for example, mason:stone::carpenter:wood. SAT analogy questions provide a word pair, A:B, and the problem is to select the most analogous word pair, C:D, from a set of five choices. The VSM algorithm correctly answers 47\% of a collection of 374 college-level analogy questions (random guessing would yield 20\% correct; the average college-bound senior high school student answers about 57\% correctly). We motivate this research by applying it to a difficult problem in natural language processing, determining semantic relations in noun-modifier pairs. The problem is to classify a noun-modifier pair, such as ``laser printer{''}, according to the semantic relation between the noun (printer) and the modifier (laser). We use a supervised nearest-neighbour algorithm that assigns a class to a given noun-modifier pair by finding the most analogous noun-modifier pair in the training data. With 30 classes of semantic relations, on a collection of 600 labeled noun-modifier pairs, the learning algorithm attains an F value of 26.5\% (random guessing: 3.3\%). With 5 classes of semantic relations, the F value is 43.2\% (random: 20\%). The performance is state-of-the-art for both verbal analogies and noun-modifier relations.|analogy; metaphor; semantic relations; vector space model; cosine similarity; noun-modifier pairs|REPRESENTATION; ASSOCIATIONS; RETRIEVAL; MODEL|Computer Science, Artificial Intelligence|44|1|6
The economics of natural language interfaces: natural language processing technology as a scarce resource|2004|This paper discusses appropriate application areas for natural language interfaces (NLIs) to databases. This requires comparing NLIs with competing approaches, including other user-friendly interfaces, and training of users with less user-friendly interfaces. Also, since NLI technology is still limited, users may need to learn how to use NLIs themselves. This suggests that NLI popularity may snowball at some point, as users become familiar with NLIs. We use a simple prototype NLI to illustrate when NLIs can achieve flexibility unattainable by simpler interfaces. Currently existing commercial NLIs and application-specific customization are also discussed. (C) 2003 Elsevier B.V. All rights reserved.|natural language interfaces; database management systems; network externalities; economics of information systems|INFORMATION-RETRIEVAL; LEXICAL DATABASE; ENGLISH; MONOPOLY; SYSTEM|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|6|1|6
What do certified nurse assistants actually know about dysphagia and feeding nursing home residents?|2004|The purpose of this study was to examine certified nurse assistants' (CNAs') knowledge of dysphagia and how to feed nursing home residents using nonparticipatory structured feeding observation, critique of staged feeding behaviors on film, and semistructured interview in a triangulation methods design. Content analysis of the data confirmed previous studies that suggested CNAs lack knowledge about dysphagia and how to feed residents. A surprising result was the lack of accurate, comprehensive information in CNA texts and classrooms about dysphagia and how to manage challenging feeding behaviors. Speech-language pathologists are uniquely trained to improve CNA communication skills and provide accurate information to nursing colleagues. Specific recommendations of how to improve CNA feeding training programs are provided.|dysphagia; education; nursing; training|NUTRITIONAL-STATUS; PNEUMONIA; MEALTIME; CARE|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|20|0|6
Fever detection from free-text clinical records for biosurveillance|2004|Automatic detection of cases of febrile illness may have potential for early detection of outbreaks of infectious disease either by identification of anomalous numbers of febrile illness or in concert with other information in diagnosing specific syndromes, such as febrile respiratory syndrome. At most institutions, febrile information is contained only in free-text clinical records. We compared the sensitivity and specificity of three fever detection algorithms for detecting fever from free-text. Keyword CC and CoCo classified patients based on triage chief complaints; Keyword HP classified patients based on dictated emergency department reports. Keyword HP was the most sensitive (sensitivity 0.98, specificity 0.89), and Keyword CC was the most specific (sensitivity 0.61, specificity 1.0). Because chief complaints are available sooner than emergency department reports, we suggest a combined application that classifies patients based on their chief complaint followed by classification based on their emergency department report, once the report becomes available. (C) 2004 Elsevier Inc. All rights reserved.|disease outbreaks; fever; natural language processing; computerized patient medical records; public health surveillance; surveillance; infection control|PATIENTS CHIEF COMPLAINTS; EMERGENCY-DEPARTMENT; SURVEILLANCE; SYSTEM; BIOTERRORISM; INFORMATION|Computer Science, Interdisciplinary Applications; Medical Informatics|34|1|6
A conversation analytic study of yes/no questions which convey reversed polarity assertions|2002|Some ``conducive{''} yes/no questions are treated by recipients as conveying an assertion of the opposite polarity to that of the grammatical form of the question. A study of these ``reversed polarity questions (RPQs){''} within a conversation analytic framework suggests that the interpretation of the questions as RPQs, rather than as `real' questions, is not dependent on the design of the question alone, but on the actions which the questions are being used to perform and on the displayed knowledge state or epistemic strength from which the questions are asked. I will show in detail how this interpretation is interactionally accomplished with a type of yes/no question used by teachers in problem-solving sequences in one-on-one second language writing conferences at the post-secondary level. These questions, all of which are affirmative yes/no questions, reverse their polarity from affirmative to negative by conveying a negative assertion which shows what is problematic about a portion of student text or talk and, in the process, points to a possible solution. (C) 2002 Elsevier Science B.V. All rights reserved.|conversation analysis; yes/no questions; pedagogical talk; reversed polarity questions; teacher-student interaction; conduciveness|ORGANIZATION; REPAIR|Linguistics; Language \& Linguistics|83|0|6
Interlingual pragmatic enrichment in translation|2002|This article discusses the notion of pragmatic enrichment in relation to translation. Enrichment is viewed as a pragmatic process whose function is to develop the vagueness found in many natural language utterances in order to arrive at fully determinate thoughts. The notion of enrichment, applied to translation, is defined here as interlingual pragmatic enrichment. This process involves, firstly, the development of a source text into its fully determinate conceptual representation by carrying out an enrichment and, secondly, the translation of this fully enriched thought into another language. The claim is made that interlingual enrichment is carried out on two grounds. First, it may be required for reasons to do with the input, e.g. grammatical incompatibilities. Second, it may be done for reasons to do with the context, e.g. cultural variation. These two types of enrichment correspond to the two information sources involved in the interpretation process and, furthermore, they shed light on the changes undergone by a text during translation. (C) 2002 Elsevier Science B.V. All rights reserved.|translation; semantic representation; proposition expressed; interlingual enrichment; relevance|RELEVANCE|Linguistics; Language \& Linguistics|7|1|6
Radical connectionism: thinking with (not in) language|2002|In this paper we defend a position we call radical connectionism. Radical connectionism claims that cognition never implicates an internal symbolic medium, not even when natural language plays a part in our thought processes. On the face of it, such a position renders the human capacity for abstract thought quite mysterious. However, we argue that connectionism is committed to an analog conception of neural computation, and that representation of the abstract is no more problematic for a system of analog vehicles than for a symbol system. Natural language is therefore not required as a representational medium for abstract thought. Since natural language is arguably not a representational medium at all, but a conventionally governed scheme of communicative signals, we suggest that the role of internalised (i.e. self-directed) language is best conceived in terms of the coordination and control of cognitive activities within the brain. (C) 2002 Elsevier Science Ltd. All rights reserved.|analog; computation; connectionism; representation; resemblance; thought|REPRESENTATION|Communication; Linguistics|11|0|6
Language-switching: Using the first language while writing in a second language|2002|In a protocol analysis of L2 writing from 28 adult participants (9 L2 Japanese, 11 L2 English, and 8 L2 Spanish), this research observed how language-switching (L-S), i.e., L1 use in L2 writing, was affected by L2 proficiency, task difficulty, and language group (i.e., the L1/L2 relationship). ANOVA results suggest that less proficient L2 learners switched to their Us more frequently than more advanced learners (P = 0.004), and that more difficult tasks increased the duration of L1 use in L2 writing (P < 0.001). For students of a cognate language, longer periods of L1 use were related to higher quality L2 texts; for students of a non-cognate language, L-S was related to lower quality texts. Possible reasons for L-S are discussed with examples from the protocols, and suggestions for including L-S in L2 writing models are made. (C) 2002 Elsevier Science Inc. All rights reserved.|language-switching; ANOVA; second language|L1 COLLABORATIVE INTERACTION; COMPOSING PROCESSES; SOCIOCOGNITIVE FUNCTIONS; L2 CLASSROOM; ESL STUDENTS; WORKING; WRITERS; MODEL|Linguistics|46|1|6
Responding to sentence-level errors in writing|2002|The debate between Truscott (1996, 1999) and Ferris (1999) on responding to student errors in writing underscores how difficult this issue is for writing teachers. Conventionally, pedagogies have looked at errors separately from principles of text construction. From an interlanguage perspective, we argue that many perplexing errors are the result of the interaction between developing linguistic competence and basic principles of ordering information in texts which learners already know. We show how this interaction results in errors at the sentence-level. These insights are applied to published comments and corrections of sentence-level errors in student writing. Based on the interlanguage perspective we propose, our analysis of these comments and corrections shows how teachers may misinterpret a learner's text. The framework we propose situates students' sentence-level errors within their developing skill in constructing target-like texts and provides teachers with another perspective on such errors. (C) 2002 Elsevier Science Inc. All rights reserved.|teacher feedback; sentence-level; student errors|INTERLANGUAGE|Linguistics|10|0|6
Situation-based context and the availability of predictive inferences|2001|Four experiments are reported in which the conditions leading to the activation and potential instantiation of a predictive inference were further explored, In the first two experiments, a constraining context containing few semantic associates to a potential predictive inference was established as part of the active portion of the discourse model. Following a delay of several sentences, a reference back to that context produced activation of a predictive inference, indicating that the constraining context can occur anywhere in a passage as long as it is readily available to the reader. In two additional experiments, further support was provided for the finding that although activated, predictive inferences may not be instantiated into the long-term memory representation of a text, The results of all four experiments are discussed within the memory-based view of text processing. (C) 2001 Academic Press.|predictive inference; role of context; memory-based text processing; resonance|LATENT SEMANTIC ANALYSIS; ELABORATIVE INFERENCES; TEXT COMPREHENSION; NARRATIVE TEXT; OCCUR ONLINE; MEMORY; MODEL; INFORMATION; RETRIEVAL; CONSTRUCTION|Linguistics; Psychology; Psychology, Experimental|57|0|6
Using ``Reading to Learn' (R2L) pedagogy to teach discussion genre to non-Chinese-speaking students in Hong Kong|2018|Non-Chinese-speaking (NCS) South Asian students, as ethnic minority group in Hong Kong, are the main disadvantaged social cohort in Chinese language learning. It has been a challenge for L1 Chinese teachers to conduct L2 Chinese teaching to NCS students with diversified native languages and socio-cultural backgrounds. Reading to Learn, Learning to Write' (R2L) pedagogy has proven effective in L2 English teaching to aboriginal students in Australia and has been focusing on teaching English in other parts of the world {[}Rose, D., and J. R. Martin, 2012. Learning to Write, Reading to Learn: Genre, Knowledge and Pedagogy in the Sydney School. London: Equinox]. The current study aims to explore the effectiveness of R2L' pedagogy to teach Chinese written composition of discussion to NCS students in Hong Kong. Through in-class teaching, data were collected from classroom observation and pre/post-tests in order to understand the performance of NCS students in Chinese written composition before and after the application of R2L pedagogy. Students' learning experience in R2L sessions will also be perceived through interviews. Through integration of reading and writing, the R2L pedagogy provides students with abundant support in language input and output. Moreover, NCS students have shown great improvements in writing after R2L teaching.|Discussion genre; text analysis; reading to learn pedagogy; non-Chinese-speaking students|LANGUAGE|Education \& Educational Research; Linguistics; Language \& Linguistics|0|5|5
Vocabulary learning through viewing video: the effect of two enhancement techniques|2018|While most studies on L2 vocabulary learning through input have addressed learners' vocabulary uptake from written text, this study focuses on audio-visual input. In particular, we investigate the effects of enhancing video by (1) adding different types of L2 subtitling (i.e. no captioning, full captioning, keyword captioning, and glossed keyword captioning which provides access to meaning) and (2) informing vs. not informing students that viewing would be followed immediately by a test of vocabulary from the video (Test Announcement). The study adopted a 2 (+/- Test Announcement) x 4 (Type of Captioning) between-subject design, resulting in 8 experimental groups. 227 Dutch-speaking university students watched three French (= L2) videos in one of eight conditions. Results revealed that students in the glossed keyword captions group (with access to meaning) scored best on the form recognition and meaning recall tests. Analyses of the look-up behaviour of students in the glossed keyword captioning group revealed that looking up a given word was positively related to the learning of that word. Test Announcement did not affect word learning or look-up behaviour. Participants' vocabulary size was directly related to their learning gains as well as to their look-up behaviour in the glossed keyword condition.|Vocabulary acquisition; incidental learning; intentional learning; gloss; captioning; video|FOREIGN-LANGUAGE; TELEVISION PROGRAMS; LISTENING COMPREHENSION; READING-COMPREHENSION; LEXICAL COVERAGE; CAPTIONED VIDEO; DICTIONARY USE; 2ND-LANGUAGE; WORDS; ACQUISITION|Education \& Educational Research; Linguistics; Language \& Linguistics|1|5|5
A deep learning-based sports player evaluation model based on game statistics and news articles|2017|Player evaluation is a key component of the question-answering (QA) system in sports. Since existing player evaluation methods heavily rely on game statistics, they cannot capture the qualitative impact of each player during a game, which can be exploited using news articles after the game. In this paper, we propose a deep learning-based player evaluation model by combining both quantitative game statistics and the qualitative analyses provided by news articles. Players are classified as positive or negative based on their performance during certain periods, and news articles in the same period are annotated using the player's class. Then, the relationship between news articles and the annotated polarity is investigated by a deep neural network, which can deal with the high dimensionality of the text data. Since there is no explicit polarity label for news articles, we use the change in game statistics in target periods to annotate related sentences. The proposed system is applied to a Korean professional baseball league (KBO) and it is shown to be capable of understanding the sentence polarity of news articles on player performances. (C) 2017 Elsevier B.V. All rights reserved.|Sports player evaluation; Deep neural network; Sentence polarity; Baseball|SENTIMENT ANALYSIS; GRADIENT DESCENT; NEURAL-NETWORKS; FANS|Computer Science, Artificial Intelligence|0|5|5
Comprehension of synthetic speech and digitized natural speech by adults with aphasia|2017|Using text-to-speech technology to provide simultaneous written and auditory content presentation may help compensate for chronic reading challenges if people with aphasia can understand synthetic speech output; however, inherent auditory comprehension challenges experienced by people with aphasia may make understanding synthetic speech difficult. This study's purpose was to compare the preferences and auditory comprehension accuracy of people with aphasia when listening to sentences generated with digitized natural speech, Alex synthetic speech (i.e., Macintosh platform), or David synthetic speech (i.e., Windows platform). The methodology required each of 20 participants with aphasia to select one of four images corresponding in meaning to each of 60 sentences comprising three stimulus sets. Results revealed significantly better accuracy given digitized natural speech than either synthetic speech option; however, individual participant performance analyses revealed three patterns: (a) comparable accuracy regardless of speech condition for 30\% of participants, (b) comparable accuracy between digitized natural speech and one, but not both, synthetic speech option for 45\% of participants, and (c) greater accuracy with digitized natural speech than with either synthetic speech option for remaining participants. Ranking and Lilcert-scale rating data revealed a preference for digitized natural speech and David synthetic speech over Alex synthetic speech. Results suggest many individuals with aphasia can comprehend synthetic speech options available on popular operating systems. Further examination of synthetic speech use to support reading comprehension through text-to-speech technology is thus warranted.|Synthetic speech; Computer-generated speech; Auditory comprehension; Aphasia|ASSISTIVE TECHNOLOGIES; SYNTHESIZED SPEECH; PEOPLE; INFORMATION; INDIVIDUALS; FREQUENCY; BENEFITS; STROKE; NOISE|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|0|5|5
Text mining applied to electronic cardiovascular procedure reports to identify patients with trileaflet aortic stenosis and coronary artery disease|2017|Background: Interrogation of the electronic health record (EHR) using billing codes as a surrogate for diagnoses of interest has been widely used for clinical research. However, the accuracy of this methodology is variable, as it reflects billing codes rather than severity of disease, and depends on the disease and the accuracy of the coding practitioner. Systematic application of text mining to the EHR has had variable success for the detection of cardiovascular phenotypes. We hypothesize that the application of text mining algorithms to cardiovascular procedure reports may be a superior method to identify patients with cardiovascular conditions of interest. Methods: We adapted the Oracle product Endeca, which utilizes text mining to identify terms of interest from a NoSQL-like database, for purposes of searching cardiovascular procedure reports and termed the tool ``PennSeek{''}. We imported 282,569 echocardiography reports representing 81,164 individuals and 27,205 cardiac catheterization reports representing 14,567 individuals from non-searchable databases into PennSeek. We then applied clinical criteria to these reports in PennSeek to identify patients with trileaflet aortic stenosis (TAS) and coronary artery disease (CAD). Accuracy of patient identification by text mining through PennSeek was compared with ICD-9 billing codes. Results: Text mining identified 7115 patients with TAS and 9247 patients with CAD. ICD-9 codes identified 8272 patients with TAS and 6913 patients with CAD. 4346 patients with AS and 6024 patients with CAD were identified by both approaches. A randomly selected sample of 200-250 patients uniquely identified by text mining was compared with 200-250 patients uniquely identified by billing codes for both diseases. We demonstrate that text mining was superior, with a positive predictive value (PPV) of 0.95 compared to 0.53 by ICD-9 for TAS, and a PPV of 0.97 compared to 0.86 for CAD. Conclusion: These results highlight the superiority of text mining algorithms applied to electronic cardiovascular procedure reports in the identification of phenotypes of interest for cardiovascular research. (C) 2017 Published by Elsevier Inc.|Valvular heart disease; Coronary artery disease; Text mining; Administrative Billing codes|EXTRACTION; ASSOCIATIONS|Computer Science, Interdisciplinary Applications; Medical Informatics|0|4|5
Quantifying the informativeness for biomedical literature summarization: An itemset mining method|2017|Objective: Automatic text summarization tools can help users in the biomedical domain to access information efficiently from a large volume of scientific literature and other sources of text documents. In this paper, we propose a summarization method that combines itemset mining and domain knowledge to construct a concept-based model and to extract the main subtopics from an input document. Our summarizer quantifies the informativeness of each sentence using the support values of itemsets appearing in the sentence. Methods: To address the concept-level analysis of text, our method initially maps the original document to biomedical concepts using the Unified Medical Language System (UMLS). Then, it discovers the essential subtopics of the text using a data mining technique, namely itemset mining, and constructs the summarization model. The employed itemset mining algorithm extracts a set of frequent itemsets containing correlated and recurrent concepts of the input document. The summarizer selects the most related and informative sentences and generates the final summary. Results: We evaluate the performance of our itemset-based summarizer using the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics, performing a set of experiments. We compare the proposed method with GraphSum, TexLexAn, SweSum, SUMMA, AutoSummarize, the term-based version of the itemset-based summarizer, and two baselines. The results show that the itemset-based summarizer performs better than the compared methods. The itemset-based summarizer achieves the best scores for all the assessed ROUGE metrics (R-1: 0.7583, R-2: 0.3381, R-W-1.2: 0.0934, and R-SU4: 0.3889). We also perform a set of preliminary experiments to specify the best value for the minimum support threshold used in the itemset mining algorithm. The results demonstrate that the value of this threshold directly affects the accuracy of the summarization model, such that a significant decrease can be observed in the performance of summarization due to assigning extreme thresholds. Conclusion: Compared to the statistical, similarity, and word frequency methods, the proposed method demonstrates that the summarization model obtained from the concept extraction and itemset mining provides the summarizer with an effective metric for measuring the informative content of sentences. This can lead to an improvement in the performance of biomedical literature summarization. (C) 2017 Elsevier B.V. All rights reserved.|Biomedical text mining; Data mining; Frequent itemset mining; Informativeness Concept-based text analysis; Domain knowledge|TEXT; DOMAIN; KNOWLEDGE|Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods; Engineering, Biomedical; Medical Informatics|1|4|5
``Here's the link{''}: Hyperlinking in service-focused chat interaction|2017|Today, most service organizations offer their clients a range of communication modes, including text-based chat which affords including hyperlinks to relevant sources of information. No studies have yet explored how hyperlinks are used in these interactions. Conversation analysis provides a set of concepts that can be used to explore the actions for which hyperlinks are being employed. We analyzed the use of hyperlinks by professionals in two types of chat services - 25 chat sessions from the Dutch national alcohol and drugs information service and 175 chats from an American university library chat service. We noted three types of hyperlinks: (1) hyperlinks as direct responses to the client's inquiry; (2) hyperlinks as proposed responses with a subset of cases in which parties are navigating to the linked website; (3) hyperlinks offered as supplemental resources. Providing links can influence the service encounter by ending the chat when it represents an acceptable response, by keeping the chat channel open when the client is not actively participating, or by launching a negotiation or collaborative navigation outside of the chat. Hyperlinking facilitates online service provision but may also jeopardize it when the link is treated as a proximate invitation. (C) 2017 Elsevier B.V. All rights reserved.|Hyperlinking; Service encounters; Chat; Conversation analysis; Institutional interaction; Multitasking|ONLINE REFERENCE; COMMUNICATION; LIBRARY; SYSTEM; CALLS; HELP|Linguistics; Language \& Linguistics|0|4|5
Investigating styles in variability modeling: Hierarchical vs. constrained styles|2017|Context: A common way to represent product lines is with variability modeling. Yet, there are different ways to extract and organize relevant characteristics of variability. Comprehensibility of these models and the ease of creating models are important for the efficiency of any variability management approach. Objective: The goal of this paper is to investigate the comprehensibility of two common styles to organize variability into models hierarchical and constrained where the dependencies between choices are specified either through the hierarchy of the model or as cross-cutting constraints, respectively. Method: We conducted a controlled experiment with a sample of 90 participants who were students with prior training in modeling. Each participant was provided with two variability models specified in Common Variability Language (CVL) and was asked to answer questions requiring interpretation of provided models. The models included 9-20 nodes and 8-19 edges and used the main variability elements. After answering the questions, the participants were asked to create a model based on a textual description. Results: The results indicate that the hierarchical modeling style was easier to comprehend from a subjective point of view, but there was also a significant interaction effect with the degree of dependency in the models, that influenced objective comprehension. With respect to model creation, we found that the use of a constrained modeling style resulted in higher correctness of variability models. Conclusions: Prior exposure to modeling style and the degree of dependency among elements in the model determine what modeling style a participant chose when creating the model from natural language descriptions. Participants tended to choose a hierarchical style for modeling situations with high dependency and a constrained style for situations with low dependency. Furthermore, the degree of dependency also influences the comprehension of the variability model. (C) 2017 Elsevier B.V. All rights reserved.|Variability modeling; Feature modeling; Comprehensibility; Hierarchical modeling; Textual constraints; Cognitive aspects; Empirical research; Product line engineering|BUSINESS PROCESS MODELS; COGNITIVE LOAD; EMPIRICAL-EVALUATION; INFORMATION-SYSTEMS; OPTIONAL PROPERTIES; DESIGN; GUIDELINES; EXPRESSIVENESS; GRAMMARS; QUALITY|Computer Science, Information Systems; Computer Science, Software Engineering|0|5|5
Peer interaction in text chat: Qualitative analysis of chat transcripts|2017|Prior research has shown that intermediate-level adult learners of Russian who worked interactively with partners using text chat improved their vocabulary and oral production skills more than students who worked independently (Tare et al., 2014). Drawing on the dataset from Tare et al. (2014), the current study follows up to explore the nature of the students' (N = 25) interactions during the text chat activities to determine potential sources of the gains. All 18 activities developed for the study encouraged interaction to complete tasks in pairs. A detailed coding of 169 text chat transcripts examined instances of peer-peer interactions. Our quantitative and qualitative analyses explored whether and to what extent real-time interactive language tasks foster the kinds of language-related moves that may support greater language learning. Results show that students spontaneously engaged in various behaviors which may support language learning, such as providing language-related assistance (self-and peer-correction, negotiation for meaning), using their partner as a resource (for clarifying information, modeling language use, or helping with unknown vocabulary), and providing encouragement (responding positively to the task and to each other, eliciting information from a partner). The most frequent instances were of positive affect, self-correction, and partner correction.|Computer-Mediated Communication; Language Teaching Methodology; Instructional Design|COMPUTER-MEDIATED COMMUNICATION; 2ND-LANGUAGE ACQUISITION; NEGOTIATED INTERACTION; COLLABORATIVE TASKS; SYNCHRONOUS-CMC; ORAL FLUENCY; LANGUAGE; CLASSROOM; CONVERSATIONS; FEEDBACK|Education \& Educational Research; Linguistics|0|4|5
Interdisciplinary Research at the Intersection of CALL, NLP, and SLA: Methodological Implications From an Input Enhancement Project|2017|Despite the promise of research conducted at the intersection of computer-assisted language learning (CALL), natural language processing, and second language acquisition, few studies have explored the potential benefits of using intelligent CALL systems to deepen our understanding of the process and products of second language (L2) learning. The strategic use of technology offers researchers novel methodological opportunities to examine how incremental changes in L2 development occur during treatment as well as how the longitudinal impacts of experimental interventions on L2 learning outcomes occur on a case-by-case basis. Drawing on the pilot results from a project examining the effects of automatic input enhancement on L2 learners' development, this article explores how the use of technology offers additional methodological and analytical choices for the investigation of the process and outcomes of L2 development, illustrating the opportunities to study what learners do during visually enhanced instructional activities.|second language acquisition; intelligent computer-assisted language learning; natural language processing; research methods; input enhancement|2ND-LANGUAGE RESEARCH; TEXTUAL ENHANCEMENT; LANGUAGE; METAANALYSIS; FORM|Education \& Educational Research; Linguistics|1|3|5
Automated annotation and classification of BI-RADS assessment from radiology reports|2017|The Breast Imaging Reporting and Data System (BI-RADS) was developed to reduce variation in the descriptions of findings. Manual analysis of breast radiology report data is challenging but is necessary for clinical and healthcare quality assurance activities. The objective of this study is to develop a natural language processing (NLP) system for automated BI-RADS categories extraction from breast radiology reports. We evaluated an existing rule-based NLP algorithm, and then we developed and evaluated our own method using a supervised machine learning approach. We divided the BI-RADS category extraction task into two specific tasks: (1) annotation of all BI-RADS category values within a report, (2) classification of the laterality of each BI-RADS category value. We used one algorithm for task 1 and evaluated three algorithms for task 2. Across all evaluations and model training, we used a total of 2159 radiology reports from 18 hospitals, from 2003 to 2015. Performance with the existing rule-based algorithm was not satisfactory. Conditional random fields showed a high performance for task 1 with an F-1 measure of 0.95. Rules from partial decision trees (PART) algorithm showed the best performance across classes for task 2 with a weighted F-1 measure of 0.91 for BIRADS 0-6, and 0.93 for BIRADS 3-5. Classification performance by class showed that performance improved for all classes from Naive Bayes to Support Vector Machine (SVM), and also from SVM to PART. Our system is able to annotate and classify all BI-RADS mentions present in a single radiology report and can serve as the foundation for future studies that will leverage automated BI-RADS annotation, to provide feedback to radiologists as part of a learning health system loop. (C) 2017 The Authors. Published by Elsevier Inc.|Breast Imaging Reporting and Data System (BI-RADS); Information extraction; Natural language processing; Imaging informatics; Machine learning|MAMMOGRAPHY REPORTS; BREAST-CANCER; MEDICATION INFORMATION; CLINICAL NOTES; SYSTEM; EXTRACTION; STATISTICS; MALIGNANCY; SUPPORT; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|0|4|5
Building semantic kernels for cross-document knowledge discovery using Wikipedia|2017|Research into text mining has progressed over the past decade. One of the main challenges now is gauging the difficulty of taking advantage of outside knowledge in the discovery process. In this work, to address the limitations of the traditional bag-of-words model and expand the search scope beyond the document collections at hand, we present a new text mining approach incorporating Wikipedia as the background knowledge. Various semantic kernels are built out of the extensive knowledge derived from Wikipedia and applied to the search scenario of detecting potential semantic relationships between topics. We demonstrate the effectiveness of our approach through comparing with competitive baselines, as well as alternative solutions where only part of Wikipedia resources (e.g., the Wiki-article contents or the associated Wiki-categories) is considered.|Semantic relatedness; Cross-document knowledge discovery; Document representation|RELATEDNESS; MEDLINE|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|2|5
The interplay of global forms of pop culture and media in teenagers' `interest-driven' everyday literacy practices with English in Greece|2017|This paper reports on an ethnographically oriented multiple case study examining the everyday literacy practices in English of Greek teenagers. Informed by theoretical and methodological understandings from the New Literacy Studies, discourse analysis and ethnography, the study extended over a period of eighteen months and employed a combination of data collection tools to provide an `emit' account of the everyday literacy practices in English of fifteen teenagers aged 14-15 living in Athens, Greece. The focus in this paper is on the interplay of global forms of popular culture and media in teenagers' `interest-driven' everyday engagements with English. In particular, I discuss teenagers' everyday English literacy practices as they relate to their interest in various forms of popular culture entertainment such as music, sports and films. I discuss how such practices are characterized by rich intertextuality, circulation of texts and media and genre crossings and illustrate the ways they impact teenagers' positionality. I conclude my paper by discussing broader implications for English language pedagogy. (C) 2017 Elsevier Inc. All rights reserved.|Everyday literacies; Teenagers; Popular culture; New literacy studies; English|CONTEMPORARY RESEARCH; TEACHER-EDUCATION; POPULAR-CULTURE; IDENTITY|Education \& Educational Research; Linguistics; Language \& Linguistics|0|2|5
Prompting MEd students to engage with academia and the professional world through feedback|2017|Little research has been conducted on writing-related issues in Master's level postgraduate professional development (PPD) programs. In such contexts lecturers' responses to student writing make a particularly worthwhile subject of research, as they reveal assumptions about valid knowledge surrounding the relationship between academia and the professional world. In this paper we report a study of a corpus of feedback texts gathered in a Master of Education (MEd) program at a university in Hong Kong. Employing a form of combined thematic and enumerative content analysis, we demonstrate how lecturers prompted students to engage with academia and the professional world at the levels of feedback points and of individual feedback texts, and how a host of lemmas prominent at the level of the corpus participated in constructing the two categories of feedback points that performed different feedback acts. In addition to having methodological and pedagogical implications, our study adds to the current literature on feedback research while aiming to inspire more research on academic writing in PPD contexts. (C) 2017 Elsevier Ltd. All rights reserved.|Master of Education (MEd) program; Analysis of feedback commentaries; Academia versus the professional world; Feedback points; Feedback acts|EDUCATION; GENRE|Education \& Educational Research; Linguistics; Language \& Linguistics|0|1|5
Spatial and dynamical handwriting analysis in mild cognitive impairment|2017|Background and Objectives Standard clinical procedure of Mild Cognitive Impairment (MCI) assessment employs time-consuming tests of psychological evaluation and requires the involvement of specialists. The employment of quantitative methods proves to be superior to clinical judgment, yet reliable, fast and inexpensive tests are not available. This study was conducted as a first step towards the development of a diagnostic tool based on handwriting. Methods In this paper the handwriting sample of a group of 37 patients with MCI (mean age 76.1 +/- 5.8) and 37 healthy controls (mean age 74.8 +/- 5.7) was collected using a Livescribe Echo Pen while completing three tasks: (1) regular writing, (2) all-capital-letters writing, and (3) single letter multiply repeated. Parameters differentiating both groups were selected in each task. Results Subjects with confirmed MCI needed more time to complete task one (median 119.5 s, IQR - interquartile range - 38.1 vs. 95.1 s, IQR 29.2 in control and MCI group, p-value <0.05) and two (median 84.2 s, IQR 49.2 and 53.7 s, IQR 30.5 in control and MCI group) as their writing was significantly slower. These results were associated with a longer time to complete a single stroke of written text. The written text was also noticeably larger in the MCI group in all three tasks (e.g. median height Of the text block in task 2 being 22.3 mm, IQR 12.9 in MCI and 20.2 mm, IQR 8.7 in control group). Moreover, the MCI group showed more variation in the dynamics of writing: longer pause between strokes in task 1 and 2. The all-capital-letters task produced most of the discriminating features. Conclusion Proposed handwriting features are significant in distinguishing MCI patients. Inclusion of quantitative handwriting analysis in psychological assessment may be a step forward towards a fast MCI diagnosis.|Telegeriatrics; Handwriting analysis; Handwriting features; Mild Cognitive Impairment; Automatic handwriting processing|PARKINSONS-DISEASE; ALZHEIMERS-DISEASE; DIAGNOSTIC ENTITY; PROCESS VARIABLES; DEMENTIA; MOCA; NEUROPSYCHOLOGY; DEPRESSION; MOVEMENTS; VALIDITY|Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical \& Computational Biology|0|3|5
Task design for telecollaborative exchanges: In search of new criteria|2017|This study examines the relationship between the criteria used for task evaluation and the process of actual task design using an Exploratory Practice approach. A telecollaborative task-based teacher training course serves as a research environment in which German and Polish students collaborate online in international groups designing and evaluating tasks for prospective telecollaborative learners. Having analysed the processes of teacher trainees' task design and evaluation, the authors argue for more tightly structured telecollaboration tasks and for task sequences which are constructed to enable each task to build on the outcomes of the previous one. As the findings reveal, telecollaboration tasks should conform to pedagogic task-based criteria, rather than to the more open and SLA-oriented CALL task appropriateness criteria proposed in Chapelle (2001). The authors, guided by the analysis of teacher trainees' learner texts and reflections, propose a new set of such criteria to be implemented in telecollaborative task design. (c) 2016 Elsevier Ltd. All rights reserved.|Task design; Pre-service teacher education; Task criteria; Task evaluation; Telecollaboration; Intercultural online exchanges|CONTENT KNOWLEDGE; LEARNING-TASKS; LANGUAGE; TEACHERS; TECHNOLOGY|Education \& Educational Research; Linguistics|1|3|5
Language Use in Nigerian Spam SMSs: A Linguistic Stylistic Analysis|2017|Digital marketing is influential to advertising businesses, with a veritable platform being SMSs. SMSs, with their widespread usage, have generated several academic enquiries. They have, however, been abused by telemarketers who inundate subscribers with spamunsolicited and indiscriminately sent SMSs. A linguistic stylistic analysis of purposively collected spam SMS data provides insight into Nigerian spam SMSs' unique linguistic features. Nigerian spam SMSs include categories such as network/service provider texts, bank texts, sport texts, health texts, religion texts, and bonanza/jackpot texts. Spam SMSs were primarily employed for advertisement, with phone users, the ultimate victims, receiving an average of 3.4 messages per day. Nigerian spam SMSs, despite usually being sent from official sources, contain linguistic features like textese, graphological deviation, and non-conformity to punctuation rules, while also employing code-mixing and internet text notations. They are also persuasive thanks to their use of verbal inducement, emotive language, polite salutations and call-to-action verbs.|computer-mediated communication; digital marketing; spam SMSs; Critical Linguistic Stylistics; Nigeria|COMPUTER-MEDIATED COMMUNICATION|Linguistics; Language \& Linguistics|0|5|5
Those who help us understand our favourite global TV series in a local language Qualitative meta-analysis of research on local fansub groups|2017|The main aim of this article is to critically analyse and systematise the debate concerning non-professional subtitling of TV series and movies in some non-English-speaking countries. Most of the studies on fansubbing deal with a specific problem, and they are based on various theoretical frameworks. This paper attempts to merge them into one coherent framework that can serve as a basis for subsequent research. The article addresses the issue of nonprofessional translation as a solution to the lack of official translations, but also as an alternative strategy for translating the texts of popular culture. The paper is divided into four parts. The first defines the phenomenon of fansubbing. The second shows how professional and non-professional translations differ. The following two parts, based on different national case studies, answer the questions: who are fansubbers, and what are their motivations?|fansubbing; amateur translation; motivations; file sharing; free labour; collective intelligence|LABOR; FANDOM|Linguistics; Language \& Linguistics|0|5|5
Cooperative Epistemic Work in Medical Practice: An Analysis of Physicians' Clinical Notes|2016|We examine an important part of the medical record that has not been studied extensively: physicians' clinical notes. These notes constitute an explanatory medical narrative that documents the patient's illness trajectory by combining each physician's notes into a common text. Although several prior CSCW studies have addressed the role of the medical record in patient care, they have not dealt specifically with the role, structure, and content of these notes. In this article, we present a detailed analysis of a set of physicians' clinical notes recording the acute hospitalization and subsequent treatment of a patient with chronic heart disease. We show that clinical notes are highly structured and conventionalized texts that promote conciseness while at the same time allowing physicians to express themselves in a precise and nuanced way. Based on this analysis, we argue that physicians' clinical notes form the core of the medical record. They serve both as a `tool for thinking' for the individual physician, enabling him or her to make sense of the patient's past history and current condition, and as a coordinative artifact used by physicians, nurses, and other health care professionals. We conclude by discussing the implications of this research for the design of Electronic Medical Record (EMR) systems.|Clinical documentation practices; Organisational communication genre; Clinical notes; Progress notes; Admission notes; Narratives; Medical discourse; Medical reasoning; Sensemaking; Medical record; Electronic health record; Electronic medical record|ELECTRONIC HEALTH RECORDS; PATIENT-CARE; HERMENEUTICS; COMMUNICATION; STORIES; ENGLAND; SYSTEMS; GENRE|Computer Science, Interdisciplinary Applications|0|2|5
A unified framework for evaluating the risk of re-identification of text de-identification tools|2016|Objectives: It has become regular practice to de-identify unstructured medical text for use in research using automatic methods, the goal of which is to remove patient identifying information to minimize re-identification risk. The metrics commonly used to determine if these systems are performing well do not accurately reflect the risk of a patient being re-identified. We therefore developed a framework for measuring the risk of re-identification associated with textual data releases. Methods: We apply the proposed evaluation framework to a data set from the University of Michigan Medical School. Our risk assessment results are then compared with those that would be obtained using a typical contemporary micro-average evaluation of recall in order to illustrate the difference between the proposed evaluation framework and the current baseline method. Results: We demonstrate how this framework compares against common measures of the re-identification risk associated with an automated text de-identification process. For the probability of re-identification using our evaluation framework we obtained a mean value for direct identifiers of 0.0074 and a mean value for quasi-identifiers of 0.0022. The 95\% confidence interval for these estimates were below the relevant thresholds. The threshold for direct identifier risk was based on previously used approaches in the literature. The threshold for quasi-identifiers was determined based on the context of the data release following commonly used de-identification criteria for structured data. Discussion: Our framework attempts to correct for poorly distributed evaluation corpora, accounts for the data release context, and avoids the often optimistic assumptions that are made using the more traditional evaluation approach. It therefore provides a more realistic estimate of the true probability of re-identification. Conclusions: This framework should be used as a basis for computing re-identification risk in order to more realistically evaluate future text de-identification tools. (C) 2016 The Authors. Published by Elsevier inc.|De-identification; Re-identification risk; Medical text; Evaluation framework; Natural language processing; Data sharing|CLINICAL DOCUMENTS; HEALTH DATA|Computer Science, Interdisciplinary Applications; Medical Informatics|1|2|5
Annotating patient clinical records with syntactic chunks and named entities: the Harvey Corpus|2016|The free text notes typed by physicians during patient consultations contain valuable information for the study of disease and treatment. These notes are difficult to process by existing natural language analysis tools since they are highly telegraphic (omitting many words), and contain many spelling mistakes, inconsistencies in punctuation, and non-standard word order. To support information extraction and classification tasks over such text, we describe a de-identified corpus of free text notes, a shallow syntactic and named entity annotation scheme for this kind of text, and an approach to training domain specialists with no linguistic background to annotate the text. Finally, we present a statistical chunking system for such clinical text with a stable learning rate and good accuracy, indicating that the manual annotation is consistent and that the annotation scheme is tractable for machine learning.|Corpus annotation; Annotation guidelines; Clinical text; Chunking; Named entities|TEXT; INFORMATION; CHALLENGE; AGREEMENT|Computer Science, Interdisciplinary Applications|2|0|5
Syntactic and pragmatic transfer effects in reported-speech constructions in three contact varieties of English influenced by Afrikaans|2016|Cross-linguistic influence (CLI) is investigated by various research traditions that examine language contact varieties. This article presents an analysis of syntactic and, pragmatic effects of CLI in three corpora of published, written varieties of English influenced by contact with Afrikaans: native White South African English, English second-language writing by Afrikaans speakers, and texts translated from Afrikaans into English. These varieties differ in the strength of bilingual activation as well as in different sociocognitive conditions of production. Three related reported-speech constructions that exhibit syntactic and pragmatic similarities and differences are analysed, to determine how bilingual activation and sociocognitive factors interact with CLI. The findings indicate that overt syntactic transfer is almost completely absent in the language of highly proficient bilinguals, but covert syntactic transfer takes place where an Afrikaans construction corresponds to only one of two variants available to native varieties of English. Extensive evidence of covert pragmatic transfer is found across various registers. The cognitive strain associated with high levels of bilingual activation overrides syntactic and pragmatic CLI for one construction investigated, in favour of a consistent preference for the explicit and more formal variant. This effect is further enhanced by the selection of the more formal variant during the process of post-production editing. (C) 2016 Elsevier Ltd. All rights reserved.|Cross-linguistic influence; Language contact; Translation; Second-language writing; Reported speech|TRANSLATED LANGUAGE; EXPLICITATION; FEATURES; CORPUS; FRENCH; TEXTS|Linguistics; Language \& Linguistics|0|1|5
Time as a base for establishing structure in text: toward a visualization model|2016|Following Halliday and Hasan (1976, Cohesion in English. London: Longman; Halliday and Hasan 1989, Language, context, and text: Aspects of language in a social-semiotic perspective. 2nd edn. Oxford: Oxford Univ. Press), text can be defined and studied as a united whole. A ``text{''} which does not appear as a united whole can be very hard to understand and describe. Since this kind of text exists for example in the form of student writing, it is important to have methods and models which can handle all kinds of compositions coherent and clearly structured and the opposite. This article suggests such a model. Relative to available methods, it is beneficial for understanding and comparing many different texts. The model is based on temporal unfolding of texts, realized primarily by tense and Aktionsarten. It uncovers the basic structure of the text and visualizes it - a combination that makes the text accessible for further analysis. Four texts with different structures from the national test in Swedish and Swedish as a second language are used to demonstrate the model. The model is used to discuss and compare the texts and how the students respond to the given instruction. It is shown what information the model reveals and how analysis and information can be added; in this case means for understanding the narrative text.|temporal unfolding; text structure; text visualization; student writing; tense; narrative text; Aktionsarten|TEMPORAL ANAPHORA|Communication; Linguistics; Language \& Linguistics|0|2|5
Variations in the use of intertexts at the macro-contextual level: The case of English press news|2016|An intertext (e.g. Home Smart Home) adopts or adapts an earlier source text (e.g. Home Sweet Home) in such a way that the intertextual meaning can be constructed or appreciated in terms of the source text. This article explores variations in the use of intertexts across six English newspapers in different macro contexts. Drawn from the six newspapers were 1,681 full-length news stories, from which 253 intertexts were identified. The ensuing intertextual and macro-contextual analyses of the identified intertexts show that (i) they were largely situated in the context of a large newspaper for speakers of English as a native/official language, (ii) the most adaptable intertextual sources are formulaic expressions, media products, and literary and scholarly works, (iii) intertexts tend to appear in salient discourse units (namely, the headline, lead, and coda) to realize a pragmatic act, and (iv) formal intertexts find greater affordance of playfulness in salient discourse units and in native-speaking contexts than the other intertexts. The survey and analyses have shed some light on the affordance between intertexts and their macro contexts.|English as a world language; english press news; foregrounding; intertexts; macro contexts; pragmatic acts|LANGUAGE|Linguistics; Language \& Linguistics|0|0|5
Do particular design features assist people with aphasia to comprehend text? An exploratory study|2016|BackgroundMuch of the evidence underlying guidelines for producing accessible information for people with aphasia focuses on client preference for particular design features. There is limited evidence regarding the effects of these features on comprehension. AimsTo examine the effects of specific design features on text comprehension. It was hypothesized that font style, letter case and supporting images would all have a significant impact on people with aphasias' ability to comprehend text. Methods \& ProceduresParticipants (N = 9) read 35 paragraphs and selected the most appropriate word or phrase from a choice of four to finish the final sentence. Reading comprehension was assessed in three conditions: font style, letter case and text with a supporting image. One-way analyses of variance (ANOVAs) with Bonferroni post-hoc tests were used to test the effect of each design feature on reading comprehension. Outcomes \& ResultsPeople with aphasia comprehended significantly more written information when presented in sans-serif font than in a serif style (p = .01) and when presented in lower case than in upper case (p = .03). The inclusion of a single supporting image to illustrate a paragraph of text did not have a significant effect on comprehension. Conclusions \& ImplicationsThis research supports the premise that font style and letter case have a significant effect on text comprehension, but that illustrating a paragraph of text with a single image may not significantly improve comprehension when text is written at a low readability level. Although it is critical to produce accessible information, improving comprehension is only one rationale for modified text presentation and therefore these results must be viewed in the context of other recommendations.|aphasia; stroke; reading comprehension; design features; accessible|WRITTEN HEALTH INFORMATION; EDUCATION MATERIALS; READABILITY; PRINCIPLES|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|0|1|5
Playing out loud: Videogame references as resources in friend interaction for managing frames, epistemics, and group identity|2016|This study examines how friends in their mid-twenties appropriate texts from videogames they have played to serve particular functions in their everyday face-to-face conversations. Speakers use references to the videogames Papers, Please and The Oregon Trail to shift the epistemic territories of conversations when they encounter interactional dilemmas. These epistemic shifts simultaneously rekey formerly problematic talk (on topics like rent, money, and injuries) to lighter, humorous talk, reframing these issues as being part of a lived videogame experience. Overlapping game frames are laminated upon real-life frames, and are strengthened by embedded frames containing constructed dialogue. This study contributes to understanding how epistemic shifts relying on intertextual ties can shift frames during interactional dilemmas in everyday conversation, which is ultimately conducive to group identity construction.|Intertextuality; framing; epistemics; identity; interactional sociolinguistics; discourse analysis; humor; videogames|FAMILY; INTERTEXTUALITY; ORGANIZATION; DISCOURSE; KNOWLEDGE; LANGUAGE; PRIVATE; TALK|Linguistics; Sociology|0|1|5
Structural effects of English-German language contact in translation on concessive constructions in business articles|2016|Studies on a variety of languages have observed a shift away from hypotactic, hierarchical structures towards paratactic, incremental structures, and have attributed this to language contact with English in translation. This paper investigates such a shift towards parataxis as the preferred structure of concessive constructions in German business articles. To this effect, a diachronic corpus method that has been applied to popular science articles in existing studies is adopted and applied to business articles, in an attempt to reproduce existing findings for this genre. This method is complemented by a corpus of manuscripts which allow to control for the effect of editing on the translated texts. Based on the analysis of hypotactic and paratactic translations of English concessive conjunctions between 1982/83 and 2008, I argue that hypotactic structures are indeed used less frequently in translated texts, but that this development is restricted to translated language. In non-translated texts, the use of hypotactic conjunctions has increased. The use of sentence-initial conjunctions, however, does seem to spread in this genre (as was reported for popular science), which may be further evidence for it to be a case of language change through contact in translation.|language contact in translation; translation and language change; corpus-based translation studies; business translation; concessive constructions|POPULAR SCIENCE; TEXTS; CONVENTIONS; DISCOURSE|Communication; Linguistics; Language \& Linguistics|0|0|5
Through children's eyes Elementary students respond to the impacts of Indian residential schools|2016|Purpose - The purpose of this study is to explore young students' perceptions about the impacts of Indian residential schools. A hopeful era of reconciliation has been ushered in to confront the injustices committed to approximately 150,000 indigenous children and youth in Canada's Indian residential schools in the not-so-distant past. Of these children, there were at least 6,000 recorded deaths; those who survived, faced the devastating impacts of forced assimilation. In the spirit of making ``relation to and with the past, opening us to a reconsideration of the terms of our lives now as well as in the future{''} (Simon, 2006, p. 189), the author invited eight-and nine-year-olds to depict their thoughts about Indian residential schools. Design/methodology/approach - A practitioner inquiry stance was used in this study. This approach takes into account that teachers are uniquely positioned to carry out highly contextualized classroom research. The data include a documentary analysis, observations of students' work and short interview-like prompts. The data also included stimulated recall using student-participant responses to elicit feelings, thoughts, attitudes and beliefs (Freeman, 1998). A collaborative approach to the data analysis{''} engaging the author's own and students' interpretations of their work{''} allowed for a range of perspectives that address representativeness (Cornish et al., 2014). Findings - Students' representations reveal that even young children engage in political thought by understanding governance structures that are impinged upon young lives in Indian residential schools. The students in this study positioned themselves as ``cultural citizens{''} (Kuttner, 2015) by contributing compelling ideas on power, relationships, displacement, assimilation and identity, in their mixed media texts. Rather than reducing what they had learned only to questions of oppression, they proposed possibilities of living a more ethical present by including teachings about living more ethically than those that have come before them. Originality/value - This work aims to deepen decolonizing possibilities in classroom research, particularly in elementary classrooms.|Art practices; Children as knowledge producers; Cultural citizens; Elementary students; Indian residential schools|EDUCATION|Education \& Educational Research; Linguistics; Language \& Linguistics|0|2|5
Multi-modal referring expressions in human-human task descriptions and their implications for human-robot interaction|2016|Human instructors often refer to objects and actions involved in a task description using both linguistic and non-linguistic means of communication. Hence, for robots to engage in natural human-robot interactions, we need to better understand the various relevant aspects of human multi-modal task descriptions. We analyse reference resolution to objects in a data collection comprising two object manipulation tasks ( 22 teacher student interactions in Task 1 and 16 in Task 2) and find that 78.76\% of all referring expressions to the objects relevant in Task 1 are verbally underspecified and 88.64\% of all referring expressions are verbally underspecified in Task 2. The data strongly suggests that a language processing module for robots must be genuinely multi-modal, allowing for seamless integration of information transmitted in the verbal and the visual channel, whereby tracking the speaker's eye gaze and gestures as well as object recognition are necessary preconditions.|multi-modal communication; human-robot interaction; reference resolution|REFERENCE RESOLUTION; GAZE; OVERSPECIFICATION; CONVERSATION; GENERATION; ATTENTION; COGNITION|Communication; Linguistics|0|4|5
Analysis of familiarity and interest in reading comprehension of Spanish students of English as a foreign language|2016|This quantitative study compares the degree of influence of content familiarity and topic interest on the reading comprehension of 245 Spanish ESL students of 2 degrees and 4 degrees ESO. The comparison is made in general terms, and also by gender, L2 proficiency level, and assessment method (written recall and multiple choice). The data were collected during the 2nd and 3rd week of the second term of the school year 2013-2014 in two religious state-funded schools located in a northern Spanish town. The samples were analyzed by using Student's t-test and ANOVAs with the programme R. The results show that (a) the influence of familiarity outscores significantly that of interest; (b) as proficiency improves, the influence of both variables diminishes; (c) gender does not seem to affect reading comprehension of not gender-biased texts; and (d) the multiple choice task seems to help comprehension to a large extent.|L2 reading comprehension; familiarity; interest; gender; assessment method|TEXT COMPREHENSION; SEX-DIFFERENCES; KNOWLEDGE|Linguistics; Language \& Linguistics|0|2|5
Disciplinary Variation in the Academic Discourse of Biology and Law: A description based on coherence relations|2015|In this study, we compare the way in which coherence is articulated in the written academic discourse in Spanish of two disciplines (Biology and Law). To do so, we use a top down - bottom up framework of analysis from which a series of criteria for the identification and description of coherence relations aroused. Those criteria were applied to a corpus of 27 texts belonging to both disciplines (762.737 words). 38 coherence relations were identified (21 Relational and 17 Additive relations). Reliability of relations that emerged from the analysis was assessed through interjudge coefficient calculations. The frequency of occurrence of coherence relations and its distribution in the corpus constitute empirical evidence for the assumption that coherence is established in a different fashion depending on the disciplinary context. Besides, results prove the feasibility of the top down - bottom up framework of analysis for coherence relations.|coherence; academic discourse in Spanish; coherence relations|COMPREHENSION|Linguistics; Language \& Linguistics|1|0|5
Inscribing the Miraculous Place: Writing and Ritual Communication in the Chapel of a Guatemalan Popular Saint|2015|The analysis of ritual in linguistic anthropology has witnessed significant advances in recent years, particularly those approaches which theorize ritual as fundamentally semiotic and ritual actions being composed of different kinds of sign relations across multiple modalities. Building on Silverstein's (2009) analysis of the interdiscursive chains of signification linking private and public rituals, this article examines how writing in the form of votive text-artifacts is used by Guatemalan devotees to a popular saint as a public metasemiotic index substantiating the successful performance of their private ritual encounters, contributing to our broader understanding of writing's semiotic potential in ritual communication. El analisis del ritual en la antropologia linguistica ha visto avances importantes en los ultimos anos, en particular los enfoques que teorizan ritual como fundamentalmente semiotico y las acciones rituales como se componen de diferentes tipos de relaciones senales a traves de multiples modalidades. Segun el analisis por Silverstein (2009) de las cadenas interdiscursivas de significacion que une rituales privados y publicos, este articulo examina como la escritura en forma de votivas de texto artefactos es utilizado por los devotos de Guatemala a un santo popular como un indice metasemiotica publica que justifique la actuacion exitosa de sus encuentros rituales privados, lo que contribuye a nuestra comprension mas amplia del potencial semiotica de la escritura en la comunicacion ritual.|ritual; writing; semiosis; Guatemala; Palabras claves: ritual; escritura; semiosis; Guatemala|EX-VOTOS; SEMIOTICS; ARCHAEOLOGY; LITERACY|Anthropology; Linguistics; Language \& Linguistics|0|0|5
Turn order and turn distribution in multi-party storytelling|2015|In this paper we examine tumtaking patterns in conversational storytelling. It has long been noted that turntaking in every-day narrative differs on a number of counts from turntaking in regular conversation. The differences, however, have, at best, been researched qualitatively based on casual observations and small datasets. Here, we base our analysis on two specialized corpora of conversational narrative, the Saarbrucken Corpus of Spoken English (SCOSE) containing American English 4- and 5-party stories and the Narrative Corpus (NC) containing British English 4- to 7-party narratives, as well as the conversational component of the British National Corpus (BNC). The analysis is decidedly quantitative and statistical in orientation. Specifically, we are concerned with turn order and turn distribution in conversational multi-party narrative. The aims are twofold. We wish to examine the validity of Sacks' description of storytelling as ``an attempt to control a third slot in talk, from a first{''} (Sacks, 1992:18), a turn order pattern we refer to as the N-notN-N pattern. We further investigate whether individual speakers' turntaking styles have an impact on turn distribution, a measure intimately related to turn order. Moreover, given the structural differences in the data at hand (the SCOSE being raw-text, the NC being densely annotated) we employ largely different methodologies particularly in addressing turn order. The results on turntaking styles suggest that this factor cannot account for the noticeable increase in the narrator's turn share as soon as the conversational activity moves into storytelling. The results on turn order reveal the N-notN-N pattern's statistical overrepresentation in all multi-party narrative types examined. The implications of this finding are far-reaching. First, Sacks et al.'s dictum that turn order is not fixed in advance does not hold true for conversational narrative. Also, turn order in conversational narrative is not locally controlled, on a turn-by-turn basis, but globally, on the basis of the activity the conversationalists are involved in, viz. storytelling. Second, a fundamental correlate of the N-notN-N pattern is the avoidance of double-responses, that is, of two consecutive response turns following the narrator's turn. This avoidance suggests that the turn order system underlying multi-party narrative is that of 2-party talk. Further, the double-response avoidance suggests the possibility that the source of the turn-order bias in narrative is a tacit agreement between the recipients to promote the single-recipient filling the single-response slot to a `spokesperson' taking the turn on behalf of all other recipients. We also note the possibility of there being a recipient-subsystem for turntaking at the single-response slot interacting with the narrator-recipient turntaking organization but still, to an extent, working on its own terms. (C) 2015 Elsevier B.V. All rights reserved.|Multi-party narrative; Turn order and distribution; Dyadic bias; Linguistic individual; Turntaking style|SMALL STORIES; NARRATIVE ANALYSIS; IDENTITY; CONVERSATION; CONSTRUCTIONS; CORPUS; TALK; BIG|Linguistics; Language \& Linguistics|3|0|5
Finding hidden relevant documents buried in scientific documents by terminological paraphrases|2015|Technical terms play an important role of effective queries for many users to search scientific databases. However, authors of scientific literature often employ alternative expressions to represent the meanings of specific terms, in other words, Terminological Paraphrases (TPs) in the literature for certain reasons, which leads to producing relevant documents that are not captured by conventional terms above. In this paper, we propose an effective way to retrieve ``de facto relevant documents{''} which only contain those TPs and cannot be searched by conventional models in an environment with only controlled vocabularies by adapting Predicate Argument Tuple (PAT). The experiment confirms that PAT-based document retrieval is an effective and promising method to discover those kinds of documents and to improve the recall of terminology-based scientific information access models.|facto relevant documents; Terminological paraphrase; Scientific information retrieval; Terminology; Text mining; Predicate argument tuple|QUERY EXPANSION|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|2|0|5
The vocabulary of agriculture semi-popularization articles in English: A corpus-based study|2015|Scientific communication can be represented as a continuum with the research article, addressed to specialized researchers, at one end of the spectrum, and with the popularization article, addressed to lay readers, at the other. In between there exists a distinct genre, the semi-popularization article, which has not received much attention in the English literature. As a contribution to the field, this paper describes the vocabulary of a corpus of 700 agriculture semi-popularization articles in English. The analysis was carried out in two stages that combined quantitative and qualitative methodology: a lexical description of the corpus and the analysis of high-frequency words. The lexical analysis revealed high lexical variation in the corpus and narrow word range. Academic words provided a lower coverage (6\%) than that usually reported for research articles (10-12\%), and a higher coverage than that reported for newspapers (4\%). The analysis of high-frequency words showed that many of these words, including general and academic words, were closely associated with the discipline of agriculture, and therefore represented the technical vocabulary of the texts. (C) 2015 Elsevier Ltd. All rights reserved.|Semi-popularization article; Technical and non-technical vocabulary; Agriculture|ACADEMIC WORD LIST; FREQUENCY; DISCOURSE; SCIENCE; AWL|Linguistics|2|0|5
Digital code-switching between Cypriot and Standard Greek: Performance and identity play online|2015|Studies of code-switching in writing are very limited in comparison with the numerous investigations of this phenomenon in oral communication. Recent research has revealed that in text-based computer-mediated communication internet users bring into play the various languages available in their linguistic repertoire and, consequently, switch between them. In this case study, I investigate digital code-switching between Cypriot and Standard Greek, the two varieties of Greek spoken on the island of Cyprus. Following Auer's conversation analytic approach and Gafaranga's view that conversational structure coexists with social structure, I investigate code-switching in online interactions. The data to be analysed here, unlike those considered in most studies of code-switching, are written data, obtained from channel \#Cyprus of Internet Relay Chat. The results suggest that code-switching in writing is influenced not only by macro-sociolinguistic factors, but they are also shaped by the medium- and social-specific characteristics of Internet Relay Chat. This, in turn, allows internet users to gain access to different roles and perform various identities within this online context.|Code-switching; Cypriot Greek; computer-mediated discourse; identity performance; conversation analysis; dialect|LANGUAGE ALTERNATION; INTERNET; CHATS|Linguistics; Language \& Linguistics|2|1|5
Semantic grounding of social annotations for enhancing resource classification in folksonomies|2015|User-generated annotations in tagging or bookmarking sites such as Flickr or Delicious can provide a promising and interesting source of information for aiding tasks such as Web resource classification. However, the use of tags brings up some challenges. Since there are no constraints on the terms that can be used for tagging, noise and ambiguity are introduced when users annotate resources. Moreover, traditional bag-of-words representations ignore connections between terms and, thus, are affected by synonymity and hyponymia. Althougth tag-based representations are a valuable source for classifying resources, the problems associated with the unsupervised nature of tags may hinder classification results. This paper presents an approach for semantically analysing social annotations in order to attain enriched concept-based representations of Web resources. Representations are enriched with concepts extracted from WordNet and Wikipedia to overcome problems caused by natural language as well as enhancing the quality of information available for performing an effective classification of resources. Several strategies for tag pre-processing, concept disambiguation and incorporation of semantic entities to representations are discussed and evaluated in this paper. Experimental results showed that the strategies proposed to associate tags with conceptual entities allow improving resource classification results, outperforming traditional approaches based on bag-of-words representations.|Social tagging systems; Folksonomies; Semantic-based representations; Resource classification|TAG RECOMMENDATION; WIKIPEDIA|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|0|5
WINNING THE AUDIENCE: A RELEVANCE THEORETIC ANALYSIS OF US-THEM RELATIONSHIPS IN A TEXT ON HIV/AIDS|2015|South Africa faces the greatest HIV infection rate among adolescents on the globe. Most university students are part of this age cohort, and are treated as an essential audience for campaigns aimed at curbing the infection rate. This investigation departs from the observation that the texts disseminated among students may benefit from critical reflection on the discourse through which the sexuality of target audiences is constructed. A pragmatic and metadiscursive analysis is conducted of the devices used in a particular text. This text was selected because in working to directly address the sexuality of the target audience, and by explicitly expounding the communicators' stance toward it, the text assumes a unique approach among those currently designed specifically for the student population. Analysing its construction of the audience's sexuality may therefore yield insights into the way specific pragmatic and metadiscursive devices are used to enhance the relevance of their HIV/AIDS messages.|AIDS; distanciation; HIV; media; metadiscourse; polarisation; proximisation; pragmatics; relevance theory; sexuality|METADISCOURSE; PERSUASION; DISCOURSE; CONSTRUCTION; PRAGMATICS; SEXUALITY; AIDS; RISK|Linguistics; Language \& Linguistics|0|0|5
DEEPEN: A negation detection system for clinical text incorporating dependency relation into NegEx|2015|In Electronic Health Records (EHRs), much of valuable information regarding patients' conditions is embedded in free text format. Natural language processing (NLP) techniques have been developed to extract clinical information from free text. One challenge faced in clinical NLP is that the meaning of clinical entities is heavily affected by modifiers such as negation. A negation detection algorithm, NegEx, applies a simplistic approach that has been shown to be powerful in clinical NLP. However, due to the failure to consider the contextual relationship between words within a sentence, NegEx fails to correctly capture the negation status of concepts in complex sentences. Incorrect negation assignment could cause inaccurate diagnosis of patients' condition or contaminated study cohorts. We developed a negation algorithm called DEEPEN to decrease NegEx's false positives by taking into account the dependency relationship between negation words and concepts within a sentence using Stanford dependency parser. The system was developed and tested using EHR data from Indiana University (IU) and it was further evaluated on Mayo Clinic dataset to assess its generalizability. The evaluation results demonstrate DEEPEN, which incorporates dependency parsing into NegEx, can reduce the number of incorrect negation assignment for patients with positive findings, and therefore improve the identification of patients with the target clinical findings in EHRs. (C) 2015 Elsevier Inc. All rights reserved.|Natural language processing; Dependency parser; Negation|RADIOLOGY REPORTS; EXTRACTION; CLASSIFICATION; ARCHITECTURE; INFORMATION; ALGORITHM|Computer Science, Interdisciplinary Applications; Medical Informatics|2|0|5
Propositional idea density in older men's written language: Findings from the HIMS study using computerised analysis|2015|Decline in linguistic function has been associated with decline in cognitive function in previous research. This research investigated the informativeness of written language samples of Australian men from the Health in Men's Study (HIMS) aged from 76 to 93 years using the Computerised Propositional Idea Density Rater (CPIDR 5.1). In total, 60 255 words in 1147 comments were analysed using a linear-mixed model for statistical analysis. Results indicated no relationship with education level (p = 0.79). Participants for whom English was not their first learnt language showed Propositional Idea Density (PD) scores slightly lower (0.018 per 1 word). Mean PD per 1 word for those for whom English was their first language for comments below 60 words was 0.494 and above 60 words 0.526. Text length was found to have an effect (p = <0.0001). The mean PD was higher than previously reported for men and lower than previously reported for a similar cohort for Australian women.|Ageing; corpus linguistics; idea density; language decline; propositional density|COGNITIVE FUNCTION; LIFE-SPAN; NUN; DEMENTIA; WOMENS; GENDER|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|1|0|5
The discourses of sustainability in news magazines The rhetorical construction of journalistic stance|2015|Sustainability has become a key concept in the debate over global environmental challenges. With the view that at the heart of the environmental debate is undoubtedly the text, this paper examines the rhetorical construction of text and provides linguistic insights into how the concept of sustainability is textualized. Corpus findings show that the discourse of sustainability is constructed by interwoven discourses which depict sustainability as a goal, as a problem, or as an object of analysis or study and implemented by companies and institutions. The rhetorical construction of the argumentation of the discourses of sustainability further suggests that the news magazines convey a multiplicity of obvious or hidden communicative purposes. This paper critically examines how resources such as evaluation, hedging or intertextuality are used in journalistic discourse to convey the author's stance towards sustainability, trying to position the audience and thus to shape the public awareness and acceptance of sustainability.|sustainability; news magazines; communicative purpose; evaluation; stance; positioning; argumentation|CLIMATE-CHANGE; MEDIA; KNOWLEDGE; STORIES; RESPONSIBILITY; NEWSPAPERS; COVERAGE; LANGUAGE; PRESS|Linguistics; Language \& Linguistics|0|0|5
Comparing original and translated Spanish A corpus-based analysis of adjective position|2015|It is a well-known fact that translated texts present a number of peculiarities which distinguish its language from the one found in texts produced originally. Many studies have tried to name some of these phenomena, which are usually grouped together under the umbrella term of `translation universals'. It has been demonstrated that translations do share a number of features irrespective of the source or target languages involved. Other divergences between original and translated texts are due to source language interference and are, therefore, language-dependent. This paper is a corpus-based study of several highly frequent Spanish adjectives in original texts and in texts translated from English. The unmarked position of attributive adjectives is the pre-modifying one in English and the post-modifying one in Spanish, though. Spanish also allows for the pre-modifying position with certain connotations. The aim of this study is to identify differences in behavioral patterns with respect to adjective position in original and translated Spanish and explain these differences in terms of translation universals and/or source language interference. The results have revealed cases of simplification, unique item under-representation and untypical collocations in Spanish translations of English source texts.|translation universals; corpora; adjective position; simplification; untypical collocations|ENGLISH|Linguistics; Language \& Linguistics|0|3|5
ProtAnt A tool for analysing the prototypicality of texts|2015|Corpus-based researchers and traditional qualitative researchers, such as those interested in critical discourse analysis, are often required to select prototypical texts for close reading that include the language features of interest that are present in a much larger corpus. Traditional approaches to this selection procedure have been largely ad hoc. In this paper, we offer a more principled way of selecting texts for close reading based on a ranking of texts in terms of the number of keywords they contain. To facilitate this analysis, we have developed a multiplatform, freeware software tool called ProtAnt that analyses the texts, generates a ranked list of keywords based on statistical significance and effect size, and then orders the texts by the number of keywords in them. We describe various experiments that demonstrate the ProtAnt analysis is effective not only at identifying prototypical texts, but also identifying outlier texts that may need to be removed from a target corpus.|ProtAnt; critical discourse analysis; prototypicality; keywords; qualitative research|ASYLUM SEEKERS; BRITISH; REFUGEES; ENGLISH; CORPUS|Linguistics; Language \& Linguistics|2|0|5
Predictors of Pause Duration in Read-Aloud Discourse|2014|The research reported in this paper is an attempt to elucidate the predictors of pause duration in read-aloud discourse. Through simple linear regression analysis and stepwise multiple linear regression, we examined how different factors (namely, syntactic structure, discourse hierarchy, topic structure, preboundary length, and postboundary length) influenced pause duration both separately and jointly. Results from simple regression analysis showed that discourse hierarchy, syntactic structure. topic structure, and postboundary length had significant impacts on boundary pause duration. However, when these factors were tested in a stepwise regression analysis, only discourse hierarchy, syntactic structure, and postboundary length were found to have significant impacts on boundary pause duration. The regression model that best predicted boundary pause duration in discourse context was the one that first included syntactic structure, and then included discourse hierarchy and postboundary length. This model could account for about 80\% of the variance of pause duration. Tests of mediation models showed that the effects of topic structure and discourse hierarchy were significantly mediated by syntactic structure, which was most closely correlated with pause duration. These results support an integrated model combining the influence of several factors and can be applied to text-to-speech systems.|pause duration; syntactic structure; discourse hierarchy; topic structure; phrase length|TEXT-TO-SPEECH; PROSODY; INTONATION; FRAMEWORK; SWEDISH; MARKERS; ENGLISH|Computer Science, Information Systems; Computer Science, Software Engineering|0|0|5
Newness, givenness and discourse updating: Evidence from eye movements|2014|Three experiments examined the effect of contextual givenness on eye movements in reading, following Schwarzschild's (1999) analysis of givenness and focus-marking in which relations among entities as well as the entities themselves can be given. In each study, a context question was followed by an answer in which a critical word was either given, new, or contrastively (correctively) focused. Target words were read faster when the critical word provided given information than when it provided new information, and faster when it provided new information than when it corrected prior information. Repetition of target words was controlled in two ways: by mentioning a non-given target word in the context in a relation other than that in which it occurred as a target, and by using a synonym or subordinate of a given target to refer to it in the context question. Verbatim repetition was not responsible for the observed effects of givenness and contrastiveness. Besides clarifying previous inconsistent results of the effects of focus and givenness on reading speed, these results indicate that reading speed can be influenced essentially immediately by a reader's discourse representation, and that the extent of the influence is graded, with corrections to a representation having a larger effect than simple additions (C) 2013 Elsevier Inc. All rights reserved.|Information status; Givenness; Focus; Discourse representation; Discourse updating; Reading|LINGUISTIC FOCUS; TEXT; PROMINENCE; REPETITION; ENGLISH; MEMORY|Linguistics; Psychology; Psychology, Experimental|12|0|5
On saying two things at once The historical semantics and pragmatics of Old English emotion words|2014|The article analyzes some aspects of the literal and figurative conceptualizations of shame in Old English. Through the reconstruction and fine-grained analysis of the whole set of literal, metonymic and metaphoric expressions of shame recorded in a corpus of Old English texts, I show here that the embodiment model for the conceptualization of this emotion was not used in Old English until the arrival of Christianity and the new moral standards it brought. The slow but progressive introduction of embodied metonymies and metaphors in Old English is, I will argue here, a direct consequence of the adaptation of patristic texts into the vernacular. The pressure to spread the Christian concept of shame, where this emotion is presented as an internal and subjective experience, and the need to substitute the old, honour-based model favoured the emergence and evolution of new figurative expressions of shame, based on its physiological effects on the experiencer.|Old English; emotions; metaphor; metonymy; shame; conceptual change|MIND|Linguistics; Language \& Linguistics|0|1|5
Creation and evaluation of a dictionary tagged with emotions and weighted for Spanish|2014|This paper presents a method for creation of dictionaries marked with specific values (for example, emotions, polarity) for use in various tasks of automatic natural language processing. In the created dictionary, the selected words are tagged with six basic emotions. For this, they are first analyzed (annotated) manually by multiple annotators and automatically weighted on the basis of these evaluations. The method was applied to the Spanish language. The paradigm chosen for tagging the words that form the dictionary corresponds to basic emotional categories: joy, anger, fear, sadness, surprise and disgust. Unlike other dictionaries, our dictionary contains weightings that correspond to percentages of probability of being used with the sense related to emotion. Each word was evaluated by multiple annotators, and, subsequently, the agreement between them was analyzed with the method of weighted kappa adapted for multiple entries. On the basis of these results, we propose a new measure that estimates the probability of the affective use: probability factor of affective use (PFA), which serves to provide potentially emotional words with the weight. PFA can be used as data in automatic systems for emotional analysis of texts. PFA refers to the use tendency of each word, which is useful for automatic systems.|emotional dictionary; probability factor of affective use; agreement between annotators; sentiment analysis; method of weighted kappa|COEFFICIENT; AGREEMENT; KAPPA|Linguistics; Language \& Linguistics|4|0|5
Analyzing discourses of emotion management on Survivor, using micro- and macro-analytic discourse perspectives|2014|In this paper, we study discourses of emotion management on the reality television show Survivor. We analyze segments of the program that feature emotionally charged interactional moments and examine how these interactions are interwoven with contestants' confessional interviews and framed by the narrator's introductions of the segments. In a two part analysis, we first analyze the talk produced by the contestants and the host as individual texts, using a discourse analytic perspective that focuses on the details of the talk itself. We then consider the ways the talk constitutes a series of layered texts and analyze these texts, using a discourse analytic approach that attends to macro-level and critical perspectives. We conclude that Survivor largely reinforces dominant cultural discourses of emotion management as strategic interactional practice that allow a person to be competitive. Furthermore, the analysis links performances of emotion management to representations of specific aspects of contestants' social identities.|emotion management; reality television; discourse analysis; micro and macro level analysis; gamedoc|REALITY TV; BIG-BROTHER; RACE; CONSTRUCTIONS; TELEVISION; RACISM; WATCH; SHOW|Linguistics; Language \& Linguistics|0|1|5
Basics of Ontology modeling in FunGramKB. The case of burn|2014|The aim of the present study is two-fold. Firstly, we discuss the advantages of a conceptual approach to meaning representation within the framework of a multipurpose Natural Language Processing (NLP) system known as FunGramKB (Peritian and Arcas, 2004, 2005, 2006; Perinan and Mairal, 2009ab, 2010, to name a few). FunGramKB solves some of the problems encountered in relational databases in that it provides morphosyntactic and pragmatic information about lexical units, it avoids language dependency by working with concepts and not words, and it minimizes redundancy by cognitive clustering. Secondly, we offer an outline of the ontological modeling of concepts related to the change-of-state verb burn. FunGramKB is an invaluable knowledge base that can be later used for the development of numerous NLP applications, such as intelligent question-answer systems or cross-linguistic information retrieval applications.|FunGramKB; Natural Language Processing; relational databases; lexico-conceptual knowledge base; the Ontology|KNOWLEDGE|Linguistics; Language \& Linguistics|0|0|5
Using Literary Texts to Reveal Problematic Rules of Usage|2013|This article identifies problematic rules of usage for aspect (preterite/imperfect) in Spanish that are commonly taught in textbooks, citing as evidence examples from Spanish literature. The rules under scrutiny are: (1) the imperfect is used to express emotions in the past, (2) the imperfect is used for descriptions in the past, (3) the preterite and imperfect are associated with certain expressions, and (4) certain verbs change meaning in the preterite. Literary works not only provide an authoritative voice to expose these misleading rules but also furnish rich contexts within which to better understand aspect in general.|aspect; grammar; imperfect; linguistic analysis of literature; preterite|SPANISH LITERATURE; CRITICAL THINKING; TEXTBOOK GRAMMAR; LANGUAGE; SKILLS|Education \& Educational Research; Linguistics|1|0|5
THE SEMANTICS OF POSSESSIVES|2013|We investigate what possessives mean by examining a wide range of English examples, pre- and postnominal, quantified and nonquantified, to arrive at general, systematic truth conditions for them. In the process, we delineate a rich class of paradigmatic possessives having crosslinguistic interest, exploiting characteristic semantic properties. One is that all involve (implicit or explicit) quantification over possessed entities. Another is that this quantification always carries existential import, even when the quantifier over possessed entities itself does not. We show that this property, termed possessive existential import, is intimately related to the notion of narrowing (Barker 1995). Narrowing has implications for compositionally analyzing possessives' meaning. We apply the proposed semantics to the issues of the definiteness of possessives, negation of possessives, partitives and prenominal possessives, postnominal possessives and complements of relational nouns, freedom of the possessive relation, and the semantic relationship between pre- and postnominal possessives.{*|possessive (prenominal and postnominal); compositional semantics; existential import; narrowing; definiteness; partitives; relational noun complements|GENERALIZED QUANTIFIERS; NATURAL-LANGUAGE; HISTORY|Linguistics; Language \& Linguistics|4|0|5
Minimally-supervised learning of domain-specific causal relations using an open-domain corpus as knowledge base|2013|We propose a novel framework for overcoming the challenges in extracting causal relations from domain-specific texts. Our technique is minimally-supervised, alleviating the need for manually-annotated, expensive training data. As our main contribution, we show that open-domain corpora can be exploited as knowledge bases to overcome data sparsity issues posed by domain-specific relation extraction, and that they enable substantial performance gains. We also address longstanding challenges of extant minimally-supervised approaches. To suppress the negative impact of semantic drift, we propose a technique based on the Latent Relational Hypothesis. In addition, our approach discovers both explicit (e.g. ``to cause{''}) and implicit (e.g. to destroy{''}) causal patterns/relations. Unlike existing minimally-supervised techniques, we adopt a principled seed selection strategy, which enables us to discover a more diverse set of causal patterns/ relations. Our experiments reveal that our approach outperforms a state-of-the-art baseline in discovering causal relations from a real-life, domain-specific corpus. (C) 2013 Elsevier B.V. All rights reserved.|Text mining; Knowledge management applications; Causal relations-causality; Natural language processing; Information extraction|EXTRACTION; WIKIPEDIA; WEB|Computer Science, Artificial Intelligence; Computer Science, Information Systems|3|3|5
A sequence labeling approach to link medications and their attributes in clinical notes and clinical trial announcements for information extraction|2013|Objective The goal of this work was to evaluate machine learning methods, binary classification and sequence labeling, for medication-attribute linkage detection in two clinical corpora. Data and methods We double annotated 3000 clinical trial announcements (CTA) and 1655 clinical notes (CN) for medication named entities and their attributes. A binary support vector machine (SVM) classification method with parsimonious feature sets, and a conditional random fields (CRF)-based multi-layered sequence labeling (MLSL) model were proposed to identify the linkages between the entities and their corresponding attributes. We evaluated the system's performance against the human-generated gold standard. Results The experiments showed that the two machine learning approaches performed statistically significantly better than the baseline rule-based approach. The binary SVM classification achieved 0.94 F-measure with individual tokens as features. The SVM model trained on a parsimonious feature set achieved 0.81 F-measure for CN and 0.87 for CTA. The CRF MLSL method achieved 0.80 F-measure on both corpora. Discussion and conclusions We compared the novel MLSL method with a binary classification and a rule-based method. The MLSL method performed statistically significantly better than the rule-based method. However, the SVM-based binary classification method was statistically significantly better than the MLSL method for both the CTA and CN corpora. Using parsimonious feature sets both the SVM-based binary classification and CRF-based MLSL methods achieved high performance in detecting medication name and attribute linkages in CTA and CN.|attribute linkages; natural language processing; multi-layered sequence labeling; clinical trial announcements; clinical notes|DISCHARGE SUMMARIES; AUTOMATIC EXTRACTION; ASSERTIONS; IDENTIFICATION; NARRATIVES; CHALLENGE; DOCUMENTS; RECORDS; SYSTEM; RULES|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|8|1|5
DATA-DRIVEN ANALYSIS OF EMOTION IN TEXT USING LATENT AFFECTIVE FOLDING AND EMBEDDING|2013|Though data-driven in nature, emotion analysis based on latent semantic analysis still relies on some measure of expert knowledge to isolate the emotional keywords or keysets necessary to the construction of affective categories. This makes it vulnerable to any discrepancy between the ensuing taxonomy of affective states and the underlying domain of discourse. This paper proposes a more general strategy which leverages two separate semantic levels: one that encapsulates the foundations of the domain considered, and one that specifically accounts for the overall affective fabric of the language. Exposing the emergent relationship between these two levels advantageously informs the emotion classification process. Empirical evidence suggests that this approach is promising for automatic emotion analysis in text. This bodes well for its deployability in a variety of applications, such as sentiment prediction.|detection and classification of emotional states; emotion analysis from text; latent semantic analysis; latent semantic mapping; sentiment prediction|INFORMATION; MODEL|Computer Science, Artificial Intelligence|1|0|5
The Impact of Reading Expressiveness on the Listening Comprehension of Storybooks by Prekindergarten Children|2013|Purpose: The purpose of this study was to determine the effect of oral reading expressiveness on the comprehension of storybooks by 4- and 5-year-old prekindergarten children. The possible impact of prosody on listening comprehension was explored. Method: Ninety-two prekindergarten children (M age = 57.26 months, SD = 3.89 months) listened to an expressive or inexpressive recording of 1 of 2 similar stories. Story comprehension was tested using assessments of both free recall and cued recall. Results: Children showed statistically significantly better cued recall for the expressive readings of stories compared to the inexpressive readings of stories. This effect generalized across stories and when story length was controlled across both expressive and inexpressive versions. The effect of expressiveness on children's free recall was not significant. Conclusion: Highly expressive readings resulted in better comprehension of storybooks by prekindergarten children. Further, because recordings were used, this effect might be attributed to the facilitation of language processing rather than to enhanced social interaction between the reader and the child.|prosody; listening comprehension; story comprehension|PRESCHOOL-CHILDREN; SPONTANEOUS SPEECH; DIRECTED SPEECH; NATURAL SPEECH; YOUNG-CHILDREN; PROSODIC CUES; VOCAL AFFECT; INTONATION; LANGUAGE; VOCABULARY|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|4|0|5
The commercial value of history: A relevance theoretical analysis of historical signs in print advertisements|2013|This article investigates the use of intertextuality in print advertisements with specific emphasis on those that attempt to establish or reinforce associations between the advertised product and an historical text in the intertext. Within a Relevance Theoretic Framework, the analysis will specify the linguistic devices, which establish the intertext, as well as those which serve to guide readers' interpretation of their relevance to the ad's marketing message (what the ad attempts to say about the product). The results suggest that ads differ significantly in the degree to which they support readers' ability to draw inferences about the intertext's contribution to an ad's marketing message.|advertising; intertextuality; media; pragmatics; relevance theory|DISCOURSE|Linguistics; Language \& Linguistics|1|1|5
Combining open-source natural language processing tools to parse clinical practice guidelines|2013|Natural language processing (NLP) has been used to process text pertaining to patient records and narratives. However, most of the methods used were developed for specific systems, so new research is necessary to assess whether such methods can be easily retargeted for new applications and goals, with the same performance. In this paper, open-source tools are reused as building blocks on which a new system is built. The aim of our work is to evaluate the applicability of the current NLP technology to a new domain: automatic knowledge acquisition of diagnostic and therapeutic procedures from clinical practice guideline free-text documents. In order to do this, two publicly available syntactic parsers, several terminology resources and a tool oriented to identify semantic predications were tailored to increase the performance of each tool individually. We apply this new approach to 171 sentences selected by the experts from a clinical guideline, and compare the results with those of the tools applied with no tailoring. The results of this paper show that with some adaptation, open-source NLP tools can be retargeted for new tasks, providing an accuracy that is equivalent to the methods designed for specific tasks.|knowledge acquisition; natural language processing; knowledge representation; clinical practice guidelines; UMLS; SemRep|INFORMATION EXTRACTION; BIOMEDICAL LITERATURE; IDENTIFICATION; KNOWLEDGE; UMLS|Computer Science, Artificial Intelligence; Computer Science, Theory \& Methods|2|0|5
HR 2499 Puerto Rico Democracy Act of 2010 Language policy and the Burton Amendment|2013|In 2010, the U.S. House of Representatives passed The Puerto Rico Democracy Act, a bill that ostensibly focused on the authorization of a plebiscite on the Island's future political status in relationship to the United States. Nevertheless, the final text included language policy on (a) ballot language, (b) official language legislation, and (c) language ideologies favoring English as the ``language of opportunity{''}. Using CDA, this paper examines the House discussion of the bill on April 29, 2010, as found in the Congressional Record Proceedings and Debates of the 111th Congress. The paper focuses on how the discussion of the bill shifted from political status issues to the inclusion of language policies to be imposed on the Island, the role of the Burton Amendment in shaping these policies, and the ways in which the construction of identity with and through language was both promoted and erased on the House floor.|Critical discourse analysis; Spanish; English; Puerto Rico; legitimate language; erasure; identity construction; language policy|DISCOURSE|Linguistics; Language \& Linguistics|2|0|5
Multimodality in conversational humor|2013|The paper presents the analysis of the humor found in four dyadic conversations. The results of the conversational data match those of previous studies (Pickering et al., 2009): no differences were found in volume or speech-rate between humorous pause units and non-humorous ones. Similarly, pauses were not found to mark humorous turns. However, the result that punch-lines showed lower pitch than non-humorous parts of the text was not replicated: humorous pause units showed no significant differences in pitch from non-humorous ones. Smiling is found to mark humor only in a general sense of ``setting the frame{''} and is not integrated (i.e., co-extensive) with the humor.|humor; conversation; prosody; multimodality; smiling; laughter|DISCOURSE; MARKERS; IRONY|Linguistics; Language \& Linguistics|2|0|5
The semiotics of inter-panel transition in comic-strip postcards|2013|From the viewpoint of genre analysis, this paper discusses generic embedding in a selection of the How to be British postcard series. Produced by Lee Gone Publications in the United Kingdom, the texts display comic strips that target British culture, lifestyle, language, and people. On the grounds of Halliday's systemic functional social semiotics, the examination has adopted Lim's (2004, 2007) and O'Halloran and Lim's (2009) analytical framework for logical-semantic relations between sequential panels. Hence, panel-to-panel relation has been addressed as the crucial narrative mechanism engendering mirth in the corpus. Findings show that if postcards use comic strips to be more attention-catching and entertaining, embedded comic strips tend to simplify their logical-semantic strategies in order to fit the communication system of postcarding.|postcards; generic innovation; mirth generation; multimodality; sequential images; panel transition|TOURIST; IMAGE|Communication; Linguistics; Language \& Linguistics|1|2|5
Reallocation of pronouns through contact: In-the-moment identity construction amongst Southern California Salvadorans|2012|This study uses natural, everyday social interaction within Salvadoran families living in Southern California to examine the use of the 2nd-person singular pronouns tu and vos (and their corresponding morphologies) in this contact variety of Spanish. An in-depth, qualitative analysis reveals that the employment and significance of these forms of address do not conform entirely to Salvadoran norms, nor to those of the surrounding Mexican-based Spanish koine. Accommodation to the pronominal repertoire of the region's majority serves as a communicative resource driven by questions of U.S./Los Angeles identity and solidarity with speakers in-the-moment interlocutor(s), a process which has caused the original Salvadoran pronouns to also be reallocated and refunctionalized (Britain and Trudgill ) as resources for accomplishing Salvadoran identity. Members of this community make active use of their pronominal options in real-time interaction as they navigate the fluid, multifaceted identities that they and their interlocutors now embody in the U.S. context.|Pronominals; voseo; tuteo; language; dialect contact; social interaction; Spanish; identity|NEW-DIALECT FORMATION; ACCOMMODATION|Linguistics|4|1|5
Getting research published internationally in English: An ethnographic account of a team of Finance Spanish scholars' struggles|2012|Intercultural text-based research has shown remarkable differences in the rhetorical structure and devices of research articles (RAs) in different linguistic/cultural contexts of publication, including the Spanish local context and the English international context. However, not much attention has been paid to the research article (RA) writing process, which can throw light into the publication practices of second language (1.2) scholars in particular disciplinary fields and which can help unveil their main writing difficulties. In this paper focus on the ``text histories{''} of a team of Spanish researchers in the field of Finance who struggle to get their research articles published internationally in English. These text histories correspond to 24 papers drafted and (re)submitted over the past 5-6 years. The analysis focuses on the extent to which they aim to publish their RAs in English, how they cope with writing their texts in English, their success in such a task and the kind of negative comments included in the referee reports they receive. Results show that this team of L2 scholars almost exclusively write their RAs in English and aim at publishing them in English-medium international journals; for this demanding task, they draw on a number of strategies. They are partially successful in that they have managed to publish half of their RAs in the first site where they were submitted. Their manuscripts received a lot of negative comments; especially relevant is the inclusion of a high number of unspecific negative comments related to language or style in major revision reports. Looking into the writing process can be of great help to provide L2 scholars with useful guidelines on drafting their RAs in English for international publication and to gain an insight into the forces driving international publication in this context.|English for Academic Purposes (EAP); English for Research Publication Purposes (ERPP); intercultural rhetoric; scholarly writing; research article|RESEARCH ARTICLE ABSTRACTS; MULTILINGUAL SCHOLARS; PUBLICATION|Linguistics; Language \& Linguistics|11|0|5
Semi-automatic semantic annotation of PubMed queries: A study on quality, efficiency, satisfaction|2011|Information processing algorithms require significant amounts of annotated data for training and testing. The availability of such data is often hindered by the complexity and high cost of production. In this paper, we investigate the benefits of a state-of-the-art tool to help with the semantic annotation of a large set of biomedical queries. Seven annotators were recruited to annotate a set of 10,000 PubMed (R) queries with 16 biomedical and bibliographic categories. About half of the queries were annotated from scratch, while the other half were automatically pre-annotated and manually corrected. The impact of the automatic pre-annotations was assessed on several aspects of the task: time, number of actions, annotator satisfaction, inter-annotator agreement, quality and number of the resulting annotations. The analysis of annotation results showed that the number of required hand annotations is 28.9\% less when using pre-annotated results from automatic tools. As a result, the overall annotation time was substantially lower when pre-annotations were used, while inter-annotator agreement was significantly higher. In addition, there was no statistically significant difference in the semantic distribution or number of annotations produced when pre-annotations were used. The annotated query corpus is freely available to the research community. This study shows that automatic pre-annotations are found helpful by most annotators. Our experience suggests using an automatic tool to assist large-scale manual annotation projects. This helps speed-up the annotation time and improve annotation consistency while maintaining high quality of the final annotations. Published by Elsevier Inc.|PubMed queries; Biomedical entities; Annotation standards; Annotation methods|CONSISTENCY; TEXT; LIFE|Computer Science, Interdisciplinary Applications; Medical Informatics|38|0|5
Language features as the pathways to genre: Students' attention to non-prototypical features and its implications|2011|The ESP School of genre study has been noted as increasingly bridging the linguistic and the rhetorical traditions in genre studies. However, some genre theorists have characterized the ESP genre approaches as treating rhetorical contexts as mainly, if not merely, the background for explicating texts. This paper explores this issue through examining how some students made sense of the relationship between context and text in two L2 writing courses that adopted the ESP genre-based framework of learning academic writing. Four examples are presented to show that the students seemed to approach such a relationship in complex, individuated ways that seemingly resist the above portrayal of ESP-oriented genre analysis. Although a sense of rhetorical context seemed to provide some background for the students to single out certain textual features as noteworthy, text was hardly the end goal of these students' analyses. Instead, the students' highlighted language features seemed to function more as the pathways to their enhanced and extended understanding of such complex contextual dimensions of genre as authorial intentions, intertextuality, presupposition and rhetoricity, and disciplinarity in academic writing. These findings help raise several questions for future L2 writing research and practice. (C) 2010 Elsevier Inc. All rights reserved.|Genre learning; English for Specific Purposes; Sociorhetorical context of genre; Academic writing|ACADEMIC LITERACY; ESP; FRAMEWORK|Linguistics|17|1|5
Evaluation of the speech behaviour of reference speakers|2011|In forensic settings, when speech samples have to be compared, or in LADO investigations, it is crucial to be able to differentiate the speech behaviour of cooperative speakers from the speech behaviour of partly cooperative speakers. In order to perform this task, a comprehensive approach which encompasses knowledge from several linguistic subfields is needed. The theoretical framework of Natural Phonology which incorporates phonetic, phonological, sociolinguistic, and psycholinguistic knowledge proves useful for performing this responsible and considerably difficult task and for determining the principles of phonetic and phonological variation. For illustration purposes, the analysis of five case studies will be presented. Results show that phonetic and phonological variation and process application of partly cooperative speakers differs considerably from the results generally obtained in investigations on language variation (drawn from cooperative speakers). In addition, partly cooperative speakers tend to apply substitutions which are in contradiction to phonetic and phonological principles.|REFERENCE SPEAKERS; FORENSIC PHONETICS; PHONOLOGY; SOCIOLINGUISTICS; LANGUAGE VARIATION|LANGUAGE; GERMAN; VOICE|Criminology \& Penology; Linguistics|1|0|5
Irish orthography: what do teachers and learners need to know about it, and why?|2011|Irish has significant State support, but lacks a research base to support the teaching of Irish reading. Current approaches to teaching Irish reading are presented, and outcomes summarised. Issues of consistency and complexity in Irish orthography are discussed in light of an analysis of a corpus of early reader texts, and the formulation of rules for discriminating between words which are regular by letter-sound and grapheme-sound rules is outlined. While the most frequent words show a high level of regularity, underlying rules are very complex. The need to target decoding skills early is discussed. Recommendations regarding the teaching of aspects of Irish orthography are presented.|Irish; orthography; heritage language teaching; teacher training; teaching methods; beginning readers|VOCABULARY; ACQUISITION; READ|Education \& Educational Research; Linguistics; Language \& Linguistics|5|0|5
`The Best Architect Designed This Church': Definite Descriptions in Default Semantics|2011|Jaszczolt examines the default semantic analysis of `the best architect designed this church', uttered when standing in front of El Temple de la Sagrada Familia in Barcelona. At first sight, Jaszczolt's conclusion that the cognitive default reading of the sentence is `Antoni Gaudi designed El Temple de la Sagrada Familia, and the speaker believes him to be the best architect' looks right; but is it in fact an appropriate semantic analysis, even given Jaszczolt's pragmatics-rich approach? Our knowledge of what the particular speaker is likely to know is our only guide here. We will make different assumptions for the speaker who is a four-year-old child, George W. Bush, or a native of Barcelona (and so on). The same goes for the addressee: an adult addressing a four-year-old child will very likely follow up by identifying the architect. We only know whether speaker and hearer correctly identify the architect from the co-text, and this requires considerably more inferencing from contextual and encyclopaedic data than Jaszczolt allows. This paper criticizes some of the assumptions of Default Semantics and suggests some emendations to the theory, including additional machinery showing a mapping from the words uttered to the intended meaning in the case of `the best architect designed this church'.|Common Ground; Context; Definite Descriptions; Default Semantics; Non-monotonic Inference; Pragmatic Inference; Reference (Direct and Indirect)|COMMUNICATION; DISTINCTION|Linguistics; Language \& Linguistics|1|0|5
Analysing university spoken interaction A CL/CA approach|2011|In this article, we consider how corpus linguistics (CL) and conversation analysis (CA) can be used together to provide enhanced descriptions of spoken interaction in the context of small group teaching in higher education. From our analysis of the data, we show how the two approaches can be combined in an iterative process to account for features of spoken discourse at both micro (word) and macro (text) levels. Beginning with CL and focusing largely on words and combinations of words, we then use CA to highlight pertinent interactional features. Our methodology follows an iterative process: from CL to CA, back to CL and so on. This approach to analysis provides powerful insights into the ways in which interactants establish understandings in educational settings and, in particular, highlights the inter-dependency of words, utterances and text in the co-construction of meaning.|conversation analysis; methods and approaches; multi-word units; small-group teaching|SEMINAR; DISCOURSE|Linguistics; Language \& Linguistics|4|0|5
Implicit language learning: Adults' ability to segment words in Norwegian|2010|Previous language learning research reveals that the statistical properties of the input offer sufficient information to allow listeners to segment words from fluent speech in an artificial language. The current pair of studies uses a natural language to test the ecological validity of these findings and to determine whether a listener's language background influences this process. In Study 1, the ``guessibility{''} of potential test words from the Norwegian language was presented to 22 listeners who were asked to differentiate between true words and nonwords. In Study 2, 22 adults who spoke one of 12 different primary languages learned to segment words from continuous speech in an implicit language learning paradigm. The task consisted of two sessions, approximately three weeks apart, each requiring participants to listen to 7.2 minutes of Norwegian sentences followed by a series of bisyllabic test items presented in isolation. The participants differentially accepted the Norwegian words and Norwegian-like nonwords in both test sessions, demonstrating the capability to segment true words from running speech. The results were consistent across three broadly-defined language groups, despite differences in participants' language background.|implicit learning; language; statistical learning; second language acquisition|8-MONTH-OLD INFANTS; ARTIFICIAL-LANGUAGE; DISTRIBUTIONAL CUES; NATURAL-LANGUAGE; STRESS; SPEECH; ACQUISITION; IMPAIRMENT; PATTERNS; UNITS|Linguistics; Psychology, Experimental|4|0|5
` ... that's actually sort of you know trying to get consultants in ... `: Functions and multifunctionality of modifiers in academic lectures|2010|This corpus-based study explores the way pragmatic force modifiers (Nikula, 1996) are employed to achieve multiple functions (ideational, interpersonal and textual) in the British Academic Spoken English (BASE) lecture corpus. The term pragmatic force modifier (PFM) refers to linguistic devices such as actually, sort of, or you know that can be used to strengthen or weaken the force with which propositions are expressed while at the same time realising manifold social pragmatic purposes. Despite their high frequency of occurrences, discussion about these modifiers in the lecture setting appears to be rare in the literature. This study accounts for the functions of PFMs with reference to relevant contextual features and pinpoints functional variations associated with this particular genre. Attention is focused on the way in which one PFM could perform multiple functions, and multiple PFMs with an emphatic or softening effect could contribute to the same functions. Additionally, examining the interplay among various PFMs in a broader co-text improves our understanding of properties that have been overlooked in earlier treatment of modifiers separately. The study finds genre-defined functions and multifunctionality of PFMs in lectures, so there is no definite correlation between forms and functions: for instance, both intensifiers and softeners are associated with positive politeness and the formation of effective argumentation patterns. This approach may benefit the practical analysis of PFMs in other genres. (C) 2009 Elsevier B.V. All rights reserved.|Pragmatic force modifiers; Functions; Multifunctionality; Lectures|UNIVERSITY LECTURES; MENS SPEECH; METADISCOURSE; POLITENESS; CERTAINTY; ARTICLES; ENGLISH; WOMENS|Linguistics; Language \& Linguistics|20|0|5
Knowing the Way. Managing Epistemic Topologies in Virtual Game Worlds|2010|This is a study of interaction in massively multiplayer online games. The general interest concerns how action is coordinated in practices that neither rely on the use of talk-in-interaction nor on a socially present living body. For the participants studied, the use of text typed chat and the largely underexplored domain of virtual actions remain as materials on which to build consecutive action. How, then, members of these games can and do collaborate, in spite of such apparent interactional deprivation, are the topics of the study. More specifically, it addresses the situated practices that participants rely on in order to monitor other players' conduct, and through which online actions become recognizable as specific actions with implications for the further achievement of the collaborative events. The analysis shows that these practices share the common phenomenon of projections. As an interactional phenomenon, projection of the next action has been extensively studied. In relation to previous research, this study shows that the projection of a next action can be construed with resources that do not build on turns-at-talk or on actions immediately stemming from the physical body-in the domain of online games, players project activity shifts by means of completely different resources. This observation further suggests that projection should be possible through the reconfiguration of any material, on condition that those reconfigurations and materials are recurrent aspects of some established practice.|conversation analysis; collaborative gaming; coordinated action; ethnomethodology; gameplay; massively multiplayer online game; projectability; recognizability; virtual action|ORGANIZATION; WORKPLACE; UNITS|Computer Science, Interdisciplinary Applications|10|0|5
HOW TO TEACH EMPATHY TO A SPEECH SYNTHESIZER? ON THE POSSIBILITY OF IDENTIFYING EMOTION SOLELY FROM WRITTEN ESTONIAN SENTENCES|2010|There is a growing need for more naturalness in synthetic Estonian speech. One of the measures to be taken is to teach the computer to apply differentiated acoustic registers according to the different emotions (joy, sadness, anger) or neutrality of the text. The present article deals with how to detect the quality of emotion vs. neutrality relying solely on the information present in the Estonian written text. The first part of the article provides a theoretical overview of how, in principle, emotions can be expressed in speech. Besides the ideational/referentional mode (i.e. the use of a literal emotion term, like sadness) there is a variety of linguistic cues of expressiveness to be detected. As a result of an overview of the literature on sentiment analysis and affective computing it is stated that the approaches vary in many respects. First, there is a variation in what is considered to be the unit of analysis in the first place (text, passage, sentence, or clause). Secondly, what exactly is being looked for: particular emotions in terms of specific categories (e.g. fear, joy, sadness, anger etc.) or more abstract dimensions (e.g. valence, intensity). The third aspect to be noticed is whether the authorial or also non-authorial affect is taken into account. Most of the approaches exploit lexical features and compare the items present in the text with an affective lexicon. In the empirical part of the study the results of a statistical analysis of Estonian sentences (altogether 361) are presented. The sentences were retrieved from the Estonian Emotional Speech Corpus, where 55 test subjects had evaluated their emotion (joy, sadness, anger) or neutrality. To put the results very briefly is to say that identifiying the emotion of a sentence entirely out of context must have been a pretty demanding task. There was not much congruence in the evaluations. Looking for the features which could work for the computer as cues for automatic emotion detection ended up in a list of probabilistic tendencies. Features such as punctuation, length of sentence (in characters), part of speech of the first word, negation etc. were used. Also the main lexical means and some strategies of attributing emotion according to the evaluative value of the sentence were described in some detail. The article ends with a conclusion that enabling a speech synthesizer to imitate human emotions can be compared with modeling human empathy. This is not an easy task. None of the systems created for other languages can be simply adapted for Estonian. This is firstly because emotions and their expressions are culture-specific to some extent and, secondly, because the Emotion Detector should rely on an Estonian affect dictionary, which does not exist, yet. Consequently, there is still a lot to do in the field.|emotions; written text; speech synthesis; sentiment analysis; affective computing; Estonian|RESOURCES; TEXT|Linguistics; Language \& Linguistics|1|0|5
An investigation of use case quality in a large safety-critical software development project|2009|Use case modelling is a much-Used technique for eliciting and documenting functional requirements The. quality of the use cases may have an important impact on the development project and on the resulting software product. This paper presents an empirical study of the changes that were made to the use case models in a large software project during the analysis phase The results show (a) which were the most difficult aspects of use case modelling in this project and (b) how the qualify of the functional requirements, in particular correctness, completeness. and clarity, was improved through the use case modelling process. (C) 2009 Elsevier B.V All rights reserved.|Use case modelling; Software quality; Case study|STRUCTURED ABSTRACTS; KNOWLEDGE; TEXT|Computer Science, Information Systems; Computer Science, Software Engineering|8|0|5
An intercultural study of first-person plural references in biomedical writing|2009|This paper carries out a contrastive analysis of biomedical research articles published in international English-medium journals and written by scholars from two Cultural contexts (Anglo-American and Spanish). It first describes both similarities and differences in terms of the rhetorical effects that first-person plural references ({''}we{''}, ``our{''} and ``us{''}) create across the different sections of the IMRaD pattern (Swales, 1990). Then, the functions of these pronouns are explored following Tang and John's (1999) taxonomy of the discourse roles of personal pronouns. Quantitative results show that, overall, Spanish writers tend to use ``we{''} pronouns more than their native counterparts, thus making themselves more visible in their texts particularly in Introduction and Discussion sections. On the other hand, results also indicate striking similarities regarding the discourse role of ``we{''} as ``guide{''}, ``architect{''}, ``opinion-holder{''} and ``originator{''} -roles which seem to indicate writers' awareness of the specific communicative purposes of ``we{''} references in each RA section. This cross-cultural variation is finally discussed in relation to the dominance of English as the international lingua franca of academic Communication and research (Benfield \& Howard, 2000; Tardy, 2004; Giannoni, 2008a).|contrastive rhetoric; personal pronouns; research articles; biomedical writing; English as a lingua franca|RESEARCH ARTICLES|Linguistics; Language \& Linguistics|12|1|5
Coming back to life: From indicator to stereotype and a strange story of frequency|2009|In the history of Spanish there are five forms, originally from the same lexical item, co-existing: asi, asin, ansi, asina, and ansina, all meaning `like that'. Standard Modern Spanish includes only one of these: asi. This is not the case, however, in New Mexican Spanish. This corpus-based study examines the patterns of synchronic variation in New Mexican Spanish, as well as the near death and transformed rebirth of forms other than standard asi in literature. Multivariate analysis suggests a decline in non-standard variants in New Mexico, associated with rural activities and objects, and with older, less-educated speakers. The synchronic idiosyncrasy of stereotypes is confirmed, while the quantitative diachronic patterns found may prove to be a regular pattern for developing stereotypes in literary texts: a slow decline infrequency followed by a sharp rise.|Linguistic stereotype; lexical variation; frequency; language change; Spanish; New Mexico|ENGLISH; ACCENTS; SPANISH|Linguistics|1|0|5
Acquiring a new second language contrast: an analysis of the English laryngeal system of native speakers of Dutch|2009|This study examines the acquisition of the English laryngeal system by native speakers of (Belgian) Dutch. Both languages have a two-way laryngeal system, but while Dutch contrasts prevoiced with short-lag stops, English has a contrast between short-lag and long-lag stops. The primary aim of the article is to test two hypotheses on the acquisition process based on first language acquisition research: (1) native speakers of a voicing language will succeed in producing short-lag stops in the target aspirating language, since short-lag stops occur early in first language acquisition and can be considered unmarked and since one member of the contrast is formed by short-lag stops in both voicing and aspirating languages, and (2) native speakers of a voicing language will succeed in acquiring long-lag stops in the target language, because aspiration is an acoustically salient realization. The analysis is based on an examination of natural speech data (conversations between dyads of informants), combined with the results of a controlled reading task. Both types of data were gathered in Dutch as well as in Eng(Dutch) (i.e. the English speech of native speakers of Dutch). The analysis revealed an interesting pattern: while the first language (L1) Dutch speakers were successful in acquiring long-lag aspirated stops (confirming hypothesis 2), they did not acquire English short-lag stops (rejecting hypothesis 1). Instead of the target short-lag stops, the L1 Dutch speakers produced prevoiced stops and frequently transferred regressive voice assimilation with voiced stops as triggers from Dutch into English. Various explanations for this pattern in terms of acoustic salience, perceptual cues and training will be considered.|L2 phonology; laryngeal; voicing; VOT; assimilation; Dutch; acoustic salience|VOICE-ONSET TIME; INITIAL STOP CONSONANTS; CROSS-LANGUAGE; ACQUISITION; PHONOLOGY; PERCEPTION; LISTENERS; TYPOLOGY; SPANISH|Education \& Educational Research; Linguistics|12|0|5
HYPOTHESES OF NATURAL PHONOLOGY|2009|Natural Phonology characterizes production and perception of speech in terms of a set of universal phonetically motivated phonological processes. Before their first words, infants identify some processes as inapplicable in their language, which narrows their perceptual universe to its phonemic system and enables them to hear the intention rather than the actuation of speech. They then gradually inhibit the inapplicable processes to achieve mature pronunciation. If some inhibitions are not fully mastered, the child's speech seems to have a sound change, or perhaps a variable pronunciation, or a speech deficit. Processes that remain active govern allophony, variation, automatic alternations, one's native ``accent{''}, and one's ``foreign{''} accent in second-language learning. Inactive processes may (re-)emerge to cope with stresses like injury or fatigue. This paper surveys some of the principal hypotheses of Natural Phonology, and we briefly compare them with Optimality Theory and recent neo-empiricist phonology. We argue that abstraction from actions to intentions is fundamental to learning and understanding language at every level from phonetics to pragmatics.|Perception; intention; phonemes; phonetics; optimality|LANGUAGE; JAPANESE; PATTERNS; STOPS|Linguistics; Language \& Linguistics|7|2|5
Semi-spontaneous oral text production: Measurements in clinical practice|2009|Functionally relevant assessment of the language production of speakers with aphasia should include assessment of connected speech production. Despite the ecological validity of everyday conversations, more controlled and monological types of texts may be easier to obtain and analyse in clinical practice. This article discusses some simple measurements for the analysis of semi-spontaneous oral text production by speakers with aphasia. Specifically, the measurements are related to the production of verbs and nouns, and the realization of different sentence types. The proposed measurements should be clinically relevant, easily applicable, and linguistically meaningful. The measurements have been applied to oral descriptions of the `Cookie Theft' picture by eight monolingual Norwegian speakers, four with an anomic type of aphasia and four without any type of language impairment. Despite individual differences in both the clinical and the non-clinical group, most of the measurements seem to distinguish between speakers with and without aphasia.|Linguistics; language; aphasia; language disorders; language measurement; language assessment; adults|PICTURE DESCRIPTION; SPONTANEOUS SPEECH; APHASIC SPEAKERS; CONVERSATION; DIVERSITY|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|12|2|5
Automatic translation in multilingual business meetings|2009|Purpose - Multilingual meetings continue to be a problem in business communication due to the necessity to translate between different natural language pairs. The paper has developed a new electronic meeting technology that automatically translates comments written in any of 41 languages (e.g. French, Chinese, etc.). The purpose of this paper is to quickly and accurately show on each user's terminal in his or her own native language all comments contributed by the group written in several different tongues. Design/methodology/approach - A prototype system, Polyglot II, utilizes instant messaging on Microsoft Windows PCs to exchange comments between client personal computers and a server which in turn, calls the Google Translate API for each translation. In an attempt to measure the accuracy, reverse translations are conducted, e.g. English to French to English, because of the lack of human experts fluent in all of the languages. The final English translations are analyzed for comprehension by 240 college business students. Findings - This paper uses reverse translations on 32 of the languages (all that are available at the time of the analysis) with historical transcripts of English text, including grammatical errors. Results show an overall comprehension accuracy of 86 percent for all languages. Italian is the most accurate, and Hindi is the least. Originality/value - While other multilingual meeting technologies have been developed, this system provides automatic support for the most languages and is perhaps the most accurate.|Group decision support systems; Meetings; Language; Translation services; Communication; Electronic media|SUPPORT-SYSTEM|Computer Science, Interdisciplinary Applications; Engineering, Industrial|4|0|5
Developing linguistic register across text types The case of modern Hebrew|2009|The study considers the topic of linguistic register by examining how schoolchildren, adolescents, and adults vary the texts that they construct across the dimensions of modality (spoken/written discourse) and genre (narrative/expository discourse). Although register variation is presumably universal, it is realized in language-specific ways, and so our analysis focuses on Israeli Hebrew, a language that evolved under peculiar socio-historical circumstances. An original procedure for characterizing register - as low, neutral, or high - was applied to four text types produced by the same speaker-writers. We found that across all age groups, ``neutral{''} items constituted the bulk of the material, and that the lexicon accounted for some 80\% of variation. Developmentally, we found that acquisition of fully flexible register variation continues beyond adolescence. Finally, we observed that text types range on a cline from everyday colloquial usage in oral narratives to more formal, high-level language in written expository essays. These results are discussed in light of their implications for the nature of register variation, later language development, and the sociolinguistics of contemporary Hebrew.|discourse; genre; Hebrew; language development; register; written and spoken language|DEVELOPMENTAL PERSPECTIVE; EXPOSITORY DISCOURSE; ADOLESCENCE; CHILDREN; ENGLISH; WRITTEN; SPOKEN; DIFFERENTIATION; CONSTRUCTION; ACQUISITION|Linguistics; Language \& Linguistics|22|0|5
Task response and text construction across L1 and L2 writing|2008|This exploratory study, undertaken from a socio-cognitive perspective, aims to investigate the effects of intensive preparatory high school training in L1 and/or L2 essay writing for university entrance exams. The analysis focuses on the task response and structural features in L1 (Japanese) and L2 (English) essays written by first-year Japanese university students (N = 28). The results reveal that the L1 intensive training emphasized the importance of establishing clarity and demonstrating originality for the sake of gaining the reader's approval, whereas the L2 training stressed the need to take a clear position on an issue and include a position statement at the beginning of an essay. Moreover, the interaction between intensive L1 and L2 training was found to reinforce the students' tendency to apply the meta-knowledge they had acquired to their L1 and L2 essay writing. In some cases, undergoing both kinds of training promoted a sense that writing in L1 is different from writing in L2, whereas in other cases, it led to a perception of L1 and L2 writing as being the same. The findings provide evidence for transferability of writing competence across languages. (c) 2007 Elsevier Inc. All rights reserved.|argumentation; exposition; discourse structure; writing instruction; transfer; Japanese essays; English essays|EFL STUDENTS; LANGUAGE; JAPANESE; PROFICIENCY; INSTRUCTION; STRATEGIES; LITERACY; CULTURES|Linguistics|20|1|5
STATISTICAL LANGUAGE MODEL ADAPTATION FOR ESTONIAN SPEECH RECOGNITION|2008|This paper presents a statistical language model adaptation framework for Estonian large vocabulary speech recognition. Estonian is a highly inflected, agglutinative and compounding language. To reduce lexical variety, morphemes are used as basic units in a statistical language model. For language model adaptation, we use a small set of topic-specific sentences as an adaptation seed. Then, latent semantic analysis (LSA) is applied for finding semantically close texts from a large document corpus. The resulting adaptation corpus is used for compiling a topic-specific unigrarm language model for each story. The unigrams are combined with a background N-gram model using fast marginal adaptation, resulting in an adapted N-gram model. We compare words, lemmas and morphemes as basic units in the LSA model. The method is tested on an Estonian broadcast news transcription task. In the first pass of the recognition, a general background language model is used for finding recognition hypotheses for all utterances. The hypotheses are then used as an adaptation seed to compile an adapted language model for each news story. In the second recognition pass, the adapted models are applied to find new recognition hypotheses. We observe a significant improvement in speech recognition quality after applying the adapted models. The 10\% drop in letter error rate when using morpheme-based adaptation is significantly better than when using either word or lemma-based adaptation. The article also discusses some possible reasons behind this observation.|speech recognition; language model adaptation; latent semantic analysis; fast marginal adaptation; morphemes; lemmatization|LATENT SEMANTIC ANALYSIS|Linguistics; Language \& Linguistics|0|0|5
TO WHAT EXTENT DOES GRAMMAR KNOWLEDGE ACCOUNT FOR COMPETENCE IN FL READING COMPREHENSION IN UNIVERSITY STUDENTS?|2008|This study investigates the extent to which linguistic processes account for competence in reading comprehension in university students. The research questions addressed are how far grammar knowledge accounts for FL reading comprehension in university students and whether there. are significant differences between reading comprehension performance and grammar knowledge performance; whether the type question accounts for any difference in the students' marks and if text topic influences the readers' performance. Although significant statistical correlation between the two variables was found, outcomes show that reading comprehension ability cannot substantially be determined by grammar knowledge at the level tested. The students' Performance was worse in grammar tests than in reading comprehension. Some question types prove to be better predictors of overall scoring and achieve significantly higher marks than others. The text topic did not make any difference to the readers performance.|EFL; reading comprehension; grammar knowledge; question types; regression analysis; correlation; quantitative analysis|CONSTRUCT-VALIDATION; ORAL INTERVIEW; PROFICIENCY; COMPONENTS|Linguistics; Language \& Linguistics|4|0|5
Measuring mono-word termhood by rank difference via corpus comparison|2008|Terminology as a set of concept carriers crystallizes our special knowledge about a subject. Automatic term recognition (ATR) plays a critical role in the processing and management of various kinds of information, knowledge and documents, e.g., knowledge acquisition via text mining. Measuring termhood properly is one of the core issues involved in ATR. This article presents a novel approach to termhood measurement for mono-word terms via corpus comparison, which quantifies the termhood of a term candidate as its rank difference in a domain and a background corpus. Our ATR experiments to identify legal terms in Hong Kong (HK) legal texts with the British National Corpus (BNC) as background corpus provide evidence to confirm the validity and effectiveness of this approach. Without any prior knowledge and ad hoc heuristics, it achieves a precision of 97.0\% on the top 1000 candidates and a precision of 96.1\% on the top 10\% candidates that are most highly ranked by the termhood measure, illustrating a state-of-the-art performance on mono-word ATR in the field.|automatic term recognition; corpus comparison; domain corpus; background corpus; rank difference; term; termhood|TERMS|Linguistics; Language \& Linguistics|16|1|5
Events of motion and causation in Hong Kong Sign Language|2007|Recent research that takes events as objects of linguistic analysis proposed that semantics of events features in the predicates of natural languages. Also, events are said to have an internal structure that are decomposable into parts with each organized around our cognitive perception of change, causation and the like. With an event of causation, it is generally assumed that it entails two sub-events-cause and result, and each is expressed by an independent predicate. Adopting the conceptual framework of motion event structure in Talmy (2000), we examine how the meaning components of event are mapped onto the grammar of signed language; in particular, we examine the grammatical processes involved in incorporating Manner and Cause(1) into the classifier predicates of Hong Kong Sign Language (HKSL). We observe that the mapping may involve a process of lexicalization where the semantic components of a motion event are realized by different phonological parameters of HKSL; namely, palm orientation is being selected for encoding manner of spatial configuration, handshape for agentivity, movement shape for manner of motion along a path and manner of causation. Lexicalization aside, we also observe other grammatical processes at the morpho-syntactic level. Incorporating manner of locomotion or manner of causation into the linguistic system will yield a class of imit-signs which, when occurring in a sign sentence, will normally precede a classifier predicate. We propose to analyze this sequence as a morphological V-V compound in HKSL. Incorporating Cause into the verb root whose semantics is devoid of change of state may result in the occurrence of a second, obligatory classifier predicate that is resultative in nature; this sequence of having two classifier predicates is amenable to complex predicates as discussed in the general linguistics literature. (c) 2006 Elsevier B.V. All rights reserved.|events of motion; events of causation; classifier predicates; signed language|CLASSIFIERS|Linguistics; Language \& Linguistics|6|0|5
Auditory speech recognition and visual text recognition in younger and older adults: Similarities and differences between modalities and the effects of presentation rate|2007|Purpose: To examine age-related differences in auditory speech recognition and visual text recognition performance for parallel sets of stimulus materials in the auditory and visual modalities. In addition, the effects of variation in rate of. presentation of stimuli in each modality were investigated in each age group. Method: A mixed-model design was used in which 3 independent groups (13 young adults with normal hearing, 10 elderly adults with normal hearing, and 16 elderly hearing-impaired adults) listened to auditory speech tests (a sentence-in-noise task, time-compressed monosyllables, and a speeded-spelling task) and viewed visual text-based analogs of the auditory tests. All auditory speech materials were presented so that the amplitude of the speech signal was at least 15 A above threshold through 4000 Hz. Results: Analyses of the group data revealed that when baseline levels of performance were used as covariates in the group analyses the only significant group difference was that both elderly groups performed worse than the young group on the auditory speeded-speech tasks. Analysis of individual data, using correlations, factor analysis, and linear regression, was generally consistent with the group data and revealed significant, moderate correlations of performance for similar tasks across modalities, but stronger correlations across tasks within a modality This suggests that performance on these tasks was mediated both by a common underlying factor, such as cognitive processing, as well as modality-specific processing. Conclusion: Performance on measures of auditory processing of speech examined here was closely associated with performance on parallel measures of the visual processing of text obtained from the same participants. Young and older adults demonstrated comparable abilities in the use of contextual information in each modality, but older adults, regardless of hearing status, had more difficulty with fast presentation of auditory speech stimuli than young adults. There were no differences among the 3 groups with regard to the effects of presentation rate for the visual recognition of text, at least for the rates of presentation used here.|hearing loss; central auditory processing; time-compressed speech; speech understanding; aging|HEARING; AGE; NOISE; PERFORMANCE; LISTENERS; CONTEXT; WORDS; PSYCHOPHYSICS; TIME|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|36|0|5
Where do interjections come from? A psycholinguistic analysis of shaw's Pygmalion|2005|Starting from our recent findings regarding emotional and initializing functions of interjections in TV and radio interviews (Kowal \& O'Connell, 2004b; O'Connell \& Kowal, in press; O'Connell, Kowal, \& Ageneau, 2005), we used the book and script of Shaw ( 1916/ 1969) and the audiotape of the motion picture ( Pascal, Asquith, \& Howard, 1938) Pygmalion to investigate how actors use interjections to express emotions. The following hypotheses were tested: (1) The actors use the written cues selectively in their oral performance by substituting, adding, and deleting interjections; (2) primary interjections added by the actors are less conventional than those in the written text; (3) durations and number of syllables of Eliza Doolittle's spoken renditions of her signature interjection ah-ah-ah-ow-ow-ow-oo do not correlate with the length in letters and syllables of the written versions; and (4) there is no evidence for Ameka's (1992b, 1994) characterization of interjections as temporally isolated, i. e., preceded and followed by silent pauses, in consequence of their syntactic isolation. Our findings confirmed all the hypotheses except for one unexpectedly significant correlation between number of syllables in Eliza Doolittle's signature interjection in the written version and duration in seconds of the spoken version thereof. The common thread throughout these data is the actor's need to personalize emotions in a dramatic performance - by means of interjections other than those provided in the written text. In this process of personalization, the emotional and initializing functions of interjections are confirmed.|interjections; dramatic performance; emotional expression; spontaneity; conceptual and medial orality|INTERVIEWS; SPEECH|Linguistics; Psychology, Experimental|5|0|5
Genre analysis and reading of English as a foreign language: Genre schemata beyond text typologies|2005|In schema theoretical views of reading comprehension a distinction has been established between linguistic, conceptual, and formal schemata. Formal schemata have been understood as the (partial) knowledge the learner has about, mainly, the written texts' structure. Research of various kinds has proven that comprehension is favored by if the learner uses this knowledge, when enhanced through explicit instruction. Many of the studies done consist mainly in comparing readers' behavior towards different text typologies or in comparing the reaction toward different text structures by readers from different linguistic backgrounds. This paper seeks to show the need to include the notion of genre in schema research, and more specifically in research on formal schemata. The notion of genre or rhetoric schemata brings up a pragmatic dimension, and incorporates a consideration of the sociocultural conventions for the assessment of reading comprehension. A distinction is made between textual and generic typology; the distinction is illustrated through the comparison of two related genres; the book review and the book printed advertisement, following Paltridge's model for analyzing genres. The comparison shows that the comprehension of textual macrostructure does not necessarily imply comprehension along essential dimensions such as the text's communicative or pragmatic function. (c) 2005 Elsevier B.V. All rights reserved.|genre analysis; foreign language reading comprehension; genre schemata; text types; genre types|PERSPECTIVE|Linguistics; Language \& Linguistics|5|1|5
Acquiring perspective in English: the development of stance|2005|In this paper we examine the development of stance by comparing the use of certain distancing devices: impersonal pronouns, passive constructions, and attitudinal markers, especially modals, in the written narrative and expository texts of English speaking children, adolescents, and adults. The results suggest that even the youngest group use these markers differentially to distinguish the two text types. Thus, analyses center on the expository texts and the development of a more distanced, impersonal stance characteristic of this genre. For each of the target linguistic structures, we found developmental changes, both quantitative and qualitative. The results are discussed with reference to both cognitive and biological frameworks. (C) 2004 Elsevier B.V. All rights reserved.|English; passives; modals; prepositional attitudes; personal and impersonal pronouns|FOCAL BRAIN-INJURY; WILLIAMS-SYNDROME; CHILDREN; NARRATIVES; CHILDHOOD|Linguistics; Language \& Linguistics|37|0|5
Interpersonal engagement in academic spoken discourse: a functional account of dissertation defenses|2005|Whereas former research on academic discourse has paid a great deal of attention to writing and its hedging strategies, this paper aims to show that a complementary and equally important feature of academic spoken discourse is the use of modal certainty. An examination of modal selections in two American Dissertation Defenses additionally reveals that the choices are purposeful and can be related to the speakers' role in the discourse, their commitment to propositions and their aims in such discourse events. On a more speculative level this paper aims to demonstrate that interpersonal meanings structure texts just as much as ideational ones and that modalities contribute to coherence in important ways. Finally, it is argued that a productive analysis of modality in the discourse of dissertation defenses should be based on the view that modal selections in a strict sense are closely related to other choices indicating the speakers' stance in relation to propositions. (C) 2004 The American University. Published by Elsevier Ltd. All rights reserved.|dissertation defense; academic spoken discourse; commitment; decommitment; interpersonal functions|SCIENCE RESEARCH ARTICLES|Linguistics|9|0|5
Beyond the research article: University faculty genres and EAP graduate preparation|2004|In ESP, few studies have explored the range of genres that university faculty write, faculty experiences writing them, or ways of familiarizing potential faculty - including non-native English speakers (NNESs) - with these genres. Studies of writing in academe and related teaching applications have focused heavily on research genres, and there has been little investigation of writing in other areas of faculty work, such as teaching and service. Through a study of faculty writing at one university, our research aims to shed light on some of the genres NNESs may write in some North American university contexts, as well as the different challenges these texts may pose to faculty. Data for the study come from a survey of 106 full-time faculty at a mid-size comprehensive state university in California. The survey findings illuminate the relative time respondents spend writing genres in three areas of their work teaching, research, and service - as well as different features they are conscious of when writing these texts. In addition, the results highlight genres that may be particularly difficult for faculty at this university and the degree to which graduate school prepared them for writing different texts. Based on our analysis, we make recommendations for how graduate EAP curricula and faculty seminars might help prepare future faculty writers. (C) 2004 The American University. Published by Elsevier Ltd. All rights reserved.|genre; faculty; writing; EAP; graduate|POLITENESS; DISCIPLINES|Linguistics|6|1|5
The effect of right cerebral hemisphere damage on collaborative planning in conversation: an analysis of intentional structure|2003|This study investigated the impact of right cerebral hemisphere damage on the capacity to take shared responsibility for the development of an intentional structure in conversation. Intentions are important determiners of both discourse structure and utterance meaning in context. Right-hemisphere damaged (RHD) individuals have been reported to have difficulty in the use of prosody as well as performing and appreciating the process of discourse tailoring which is dependent on recognizing speakers intentions. Audio taped samples of naturalistic conversations between RHD individuals and normal speakers were analysed. Text-level discourse processing analyses involved measures of global discourse structure and self-monitoring accuracy. Prosodic analyses included fundamental frequency (F0) resetting, pause durations and inter-turn intervals. The results revealed that speakers with right cerebral hemisphere damage do not, first, use prosody to alert listeners to changes in discourse structure, and, second, assume equal responsibility for the development and maintenance discourse structure.|discourse analyses; conversation; right hemisphere damage; intentional structure|IMPAIRMENTS; DISCOURSE; LANGUAGE; PROSODY; SPEECH|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|10|0|5
Writing profiles: the effect of the writing mode on pausing and revision patterns of experienced writers|2003|We investigated how writing processes are affected by physical aspects of the task environment, specifically the use of a word processor, with respect to patterns of pausing and revision. Consistent with the tradition of cognitive writing research, the writing processes of experienced writers were examined (60 involving the use of a word processor, 20 involving pen\&paper). In comparison with writers using pen\&paper, those using a word processor (i) spent more time on a first draft and less on finalizing a text, (ii) pursued a more fragmentary writing process, (iii) tended to revise more extensively at the beginning of the writing process, (iv) attended more to lower linguistic levels (letter, word) and formal properties of the text, and (v) did not normally undertake any systematic revision of their work before finishing. By clustering the various processes with respect to twelve relevant parameters, we developed a new typology of writing processes which distinguishes five writing profiles: the initial planner, the fragmentary Stage I writer, the Stage H writer, the non-stop writer, and the average writer. Our quantitative approach to describing the cognitive behavior of the different writers revealed that the profiles they adopt depend greatly on the constraints of the writing environment. (C) 2002 Elsevier Science B.V. All rights reserved.|writing process; word processor; revision; pause analysis; cognitive processes; writing profiles|STRATEGIES; COMPUTER|Linguistics; Language \& Linguistics|46|0|5
Comparing L1 and L2 organizational patterns in the argumentative writing of Japanese EFL students|2003|The relationship between first language (L1) and second language (L2) writing has attracted the attention of L2 writing researchers. Recent studies have pointed to not only differences but also similarities between L1 and L2 writing. The present study compared L1 (Japanese) and L2 (English) organizational patterns in the argumentative writing of Japanese EFL student-writers. The study made within-subject comparisons of L1 and L2 compositions in terms of organizational patterns, organization scores, and overall quality. Student perceptions of L1 and L2 organization were also investigated by incorporating their comparisons of their own L1/L2 compositions into the analysis. The results revealed that (a) a majority of students employed deductive type organizational patterns in both L1 and L2; (b) despite similarities between L1 and L2 organizational patterns, L2 organization scores were not significantly correlated with L1 organization scores; (c) L2 composition total and organization scores differed significantly from those of L1; and (d) some students evidenced problems in organizing both L1 and L2 texts. Possible implications of the results are discussed as they pertain to research, pedagogy, and the dispelling of stereotypes about Japanese and English rhetoric. (C) 2003 Elsevier Science Inc. All rights reserved.|argumentative writing; contrastive rhetoric; EFL; Japanese students; L1 writing; L2 proficiency; L2 writing; organizational patterns; rating scales; self-report data|READERS|Linguistics|47|1|5
The perception of ``sine-wave speech{''} by adults with developmental dyslexia|2003|Numerous studies have shown that, as a group, children or adults with developmental dyslexia perceive isolated syllables or words abnormally. Continuous speech containing reduced acoustic information also might prove perceptually difficult to such listeners. They might, however, exploit the intact syntactic and semantic features present in whole utterances, thereby compensating fully for impaired speech perception. ``Sine-wave speech{''} sentences afford a test of these competing possibilities. The sentences contain only 4 frequency-modulated sine waves, lacking many acoustic cues present in natural speech. Adults with and without dyslexia were asked to orally reproduce 9 sine-wave utterances, each occurring in 4 immediately successive trials. Participants with dyslexia reported fewer words than did control listeners. Practice, phonological contrasts, and word position affected both groups similarly. Comprehension of sine-wave sentences seems impaired in many, but not all, adults with dyslexia. A reduced auditory memory capacity may contribute to this deficit.|speech perception; sine-wave speech; dyslexia; memory|LANGUAGE IMPAIRMENT; PROCESSING PROBLEMS; CHILDREN; DISCRIMINATION; DEFICITS; SOUNDS; SKILLS; CUES|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|6|0|5
Natural selection and cultural selection in the evolution of communication|2002|It has been postulated that aspects of human language are both genetically and culturally transmitted. How might these processes interact to determine the structure of language? An agent-based model designed to study gene-culture interactions in the evolution of communication is introduced. This model shows that cultural selection resulting from learner biases can be crucial in determining the structure of communication systems transmitted through both genetic and cultural processes. Furthermore, the learning bias that leads to the emergence of optimal communication in the model resembles the learning bias brought to the task of language acquisition by human infants. This suggests that the iterated application of such human learning biases may explain much of the structure of human language.|communication; language; evolution; culture; learning|NEURAL-NETWORKS; EMERGENCE; LANGUAGE; POPULATION; HANDICAP; MODEL|Computer Science, Artificial Intelligence; Psychology, Experimental; Social Sciences, Interdisciplinary|11|1|5
Latent semantic analysis for user modeling|2002|Latent semantic analysis (LSA) is a tool for extracting semantic information from texts as well as a model of language learning based on the exposure to texts. We rely on LSA to represent the student model in a tutoring system. Domain examples and student productions are represented in a high-dimensional semantic space, automatically built from a statistical analysis of the co-occurrences of their lexemes. We also designed tutoring strategies to automatically detect lexeme misunderstandings and to select among the various examples of a domain the one which is best to expose the student to. Two systems are presented: the first one successively presents texts to be read by the student, selecting the next one according to the comprehension of the prior ones by the student. The second plays a board game (kalah) with the student in such a way that the next configuration of the board is supposed to be the most appropriate with respect to the semantic structure of the domain and the previous student's moves.|latent semantic analysis; user modeling; tutoring systems; language learning|KNOWLEDGE; TEXT|Computer Science, Artificial Intelligence; Computer Science, Information Systems|11|0|5
A dynamic systems approach to writing assessment in students with language learning problems|2000|Speech-language pathologists have not typically included writing as part of instructional or intervention goals. This omission may be related to the sparse research data on writing development in children with a language learning disability (LLD). Like reading and spelling, writing results from complex interactions among the linguistic and discourse systems and changes over time from an oral style of communication to a more literate style. One purpose of this article is to describe individual differences in the phases of writing development, drawing on examples from students who are typically developing, and those with an LLD. Special emphasis is given to the differentiation of audience and syntactic choices during the school-age years as critical elements in communicating the ``writer' s voice.{''} Using an illustrative case study of a 10-year-old, the second purpose is to demonstrate how school-based writing samples can serve as a dynamic tool for analysis of interactions among the linguistic and discourse systems. The multiple levels addressed include genre knowledge, concept of audience, clausal and nonclausal complexity, spelling, and punctuation. A major assessment issue is whether the writing problems of individual students stem from an unrecognized LLD, instructional inadequacies, or both factors. Suggestions are offered for better meeting individual needs through combining explicit strategy instruction for composing and self-regulation with explicit linguistic strategies that enhance semantic and syntactic options in writing.|audience differentiation; language learning disabilities; spelling; syntactic differentiation; writing development|REGULATED STRATEGY-DEVELOPMENT; SCHOOL-AGE-CHILDREN; WRITTEN LANGUAGE; INTERVENTION; DISABILITIES; SPOKEN; ADULTS; MODEL; TEXT|Linguistics; Rehabilitation|6|0|5
Acoustic parameters in speaker height and weight identification: Sex-specific behaviour|1995|This study examines the ability of listeners to judge speaker height and weight from speech samples. Although previous investigations indicate that listeners are consistent in estimating body characteristics, it is not known which speech signal parameters are being used by the listeners for such estimates. Therefore, a series of listening tests was carried out in which male and female listeners judged the height and weight from male and female speakers reading isolated words and two text paragraphs. Both speaker sex and listener sex turned out to be important factors: Significant correlations between estimated height/weight and actual height/weight were found only for male speakers. The majority of these estimates came from the male listeners. Neither male nor female listeners, however, were able to estimate female speaker height or weight. Regression analysis involving FO, formant frequencies, energy below 1 KHz, and speech rate showed no significant correlations between these parameters and actually measured speaker height and weight, the only exception correlation between male speaker weight and speech rate. Furthermore, ion data suggested that the listeners (correctly) used speech rate information injudging male speaker weight, whereas low FO and formant frequency values (wrongly) were taken to indicate large speaker body dimensions.|fundamental; frequency; speaker height; speaker weight; spectrum; speech rate|SPEECH; VOICE; PERCEPTION; AGE|Audiology \& Speech-Language Pathology; Linguistics; Psychology, Experimental|80|2|5
NONPARAMETRIC TECHNIQUES FOR PITCH-SCALE AND TIME-SCALE MODIFICATION OF SPEECH|1995|Time-scale and, to a lesser extent, pitch-scale modifications of speech and audio signals are the subject of major theoretical and practical interest. Applications are numerous, including, to name but a few, text-to-speech synthesis (based on acoustical unit concatenation), transformation of voice characteristics, foreign language learning but also audio monitoring or film/soundtrack post-synchronization. To fulfill the need for high-quality time and pitch-sealing, a number of algorithms have been proposed recently, along with their real-time implementation, sometimes for very inexpensive hardware. It appears that most of these algorithms can be viewed as slight variations of a small number of basic schemes. This contribution reviews frequency-domain algorithms (phase-vocoder) and time-domain algorithms (Time-Domain Pitch-Synchronous Overlap/Add and the like) in the same framework. More recent variations of these schemes are also presented.|PITCH-SCALE AND TIME-SCALE TRANSFORMATIONS; PHASE VOCODER; PSOLA ANALYSIS-SYNTHESIS; QUASI-HARMONIC MODEL|FOURIER-TRANSFORM; SINUSOIDAL REPRESENTATION; SIGNAL RECONSTRUCTION; MAGNITUDE; PHASE; WAVE|Acoustics; Computer Science, Interdisciplinary Applications|110|2|5
MULTICULTURAL MULTILINGUAL ELECTRONICALLY MEDIATED COMMUNICATION|1994|Modeling of semantic space is discussed with specific reference to the authors' NSF-funded project on knowledge representations in dictionaries, thesauri, and free text. Research findings are discussed in relation to future research needs.|SEMANTIC MODELING; COMPUTING; TEXT ANALYSIS; NATURAL LANGUAGE; SYMBOLIC SYSTEM ACCESS|TRANSCENDENT EXPERT SYSTEMS; KNOWLEDGE RETRIEVAL; LANGUAGES|Computer Science, Interdisciplinary Applications; Information Science \& Library Science; Social Sciences, Interdisciplinary|1|0|5
A flexible text analyzer based on ontologies: an application for detecting discriminatory language|2018|Language can be a tool to marginalize certain groups due to the fact that it may reflect a negative mentality caused by mental barriers or historical delays. In order to prevent misuse of language, several agents have carried out campaigns against discriminatory language, criticizing the use of some terms and phrases. However, there is an important gap in detecting discriminatory text in documents because language is very flexible and, usually, contains hidden features or relations. Furthermore, the adaptation of approaches and methodologies proposed in the literature for text analysis is complex due to the fact that these proposals are too rigid to be adapted to different purposes for which they were intended. The main novelty of the methodology is the use of ontologies to implement the rules that are used by the developed text analyzer, providing a great flexibility for the development of text analyzers and exploiting the ability to infer knowledge of the ontologies. A set of rules for detecting discriminatory language relevant to gender and people with disabilities is also presented in order to show how to extend the functionality of the text analyzer to different discriminatory text areas.|Text analyzer; Document text model; Methodology; Ontology; Discriminatory language|SEMANTIC WEB; SENTIMENT ANALYSIS; CLASSIFICATION; CATEGORIZATION; EXTRACTION; EDUCATION; WORDNET|Computer Science, Interdisciplinary Applications|0|4|4
The use of questions in a synchronous intercultural online exchange project|2018|In this digital era, online intercultural exchange has gained increased popularity in language and culture education. However, concerns arise over its productiveness and efficacy in engaging participants cognitively. In addition, there is a paucity of research on out-of-classroom synchronous online exchange projects, let alone those involving Chinese English learners and English-speaking Chinese learners. Guided by the social constructivist theory, this study examined the productiveness of a small-scale intercultural online exchange project from its quality dimension measured by the participants' use of questions. The purpose was to gain a better understanding of the dynamics and educational value of online synchronous text communication in language and culture learning. Participants were six English learners from China and six English-speaking Chinese learners from the U.S. Unlike many previous intercultural exchanges, this project was entirely independent from the curricula on both sides. Within a certain time frame, participants chose when and where exactly the synchronous text chat took place. Data analyses focused on the self-generated questions found in chat logs. Although participants seemed to self-generate more lower-order than higher-order thinking questions, the latter were frequently used in the process of online discussion to engage learners from both sides in critical thinking and self-reflection. Differences in the use of questions were found across dyads, languages, and groups of participants. Implications for future research and project design were discussed.|online intercultural exchange; synchronous text communication; productiveness of online discussion; use of questions|COMMUNICATION; DISCUSSIONS; THINKING; TELECOLLABORATION; ENVIRONMENTS; QUALITY; FORUMS; GERMAN; SKILLS; CMC|Education \& Educational Research; Linguistics; Language \& Linguistics|0|4|4
A linguistic treatment for automatic external plagiarism detection|2017|Plagiarism is the unauthorized use of the ideas, presentation of someone else's words or work as your own. This paper presents an External Plagiarism Detection System (EPDS), which employs a combination of the Semantic Role Labeling (SRL) technique, the semantic and syntactic information. Most of the available methods fail to capture the meaning in the comparison between a source document sentence and a suspicious document sentence when two sentences have same surface text. Therefore, it leads to incorrect or even unnecessary matching results. However, the proposed method is able to avoid selecting the source text sentence whose similarity with suspicious text sentence is high but its meaning is different. On the other hand, an author may change the sentence from: active to passive and vice versa; hence, the method also employed the SRL technique to tackle the aforementioned challenge. Furthermore, the method used the content word expansion approach to bridge the lexical gaps and identify the similar ideas that are expressed using different wording. The proposed method is able to detect different types of plagiarism such as the exact verbatim copying, paraphrasing, transformation of sentences, changing of word structure. As a result, the experimental results have displayed that the proposed method is able to improve the performance compared with the participating systems in PAN-PC-11 and other existing techniques. (C) 2017 Elsevier B.V. All rights reserved.|Paraphrase recognition; Syntax-semantic; Extrinsic plagiarism; Semantic analysis|INFORMATION; SIMILARITY; COMBINATION|Computer Science, Artificial Intelligence|0|4|4
Recognizing users feedback from non-verbal communicative acts in conversational recommender systems|2017|Conversational recommender systems produce personalized recommendations of potentially useful items by utilizing natural language dialogues for detecting user preferences, as well as for providing recommendations. In this work we investigate the role of affective factors such as attitudes, emotions, likes and dislikes in conversational recommender systems and how they can be used as implicit feedback to improve the information filtering process. We thus developed a multimodal framework for recognizing the attitude of the user during their conversation with DIVA, a Dress-shopping Interactive Assistant aimed at recommending fashion apparel. Wee took into account speech prosody, body poses and facial expressions for providing implicit feedback to the system and for refining the recommendation accordingly. The shopping assistant has been embodied in the Social Robot NAO and has been tested in the dress shopping scenario. Our experimental results show that the proposed method is a promising way to implicitly profile the user and improve the performance of recommendations when explicit feedback is not available, thus demonstrating its effectiveness and viability. (C) 2017 Elsevier B.V. All rights reserved.|Behavioral analysis; User profiling; Conversational recommender systems; Social robots|BEHAVIOR|Computer Science, Artificial Intelligence|0|4|4
Inferring Affective Meanings of Words from Word Embedding|2017|Affective lexicon is one of the most important resource in affective computing for text. Manually constructed affective lexicons have limited scale and thus only have limited use in practical systems. In this work, we propose a regression-based method to automatically infer multi-dimensional affective representation of words via their word embedding based on a set of seed words. This method can make use of the rich semantic meanings obtained from word embedding to extract meanings in some specific semantic space. This is based on the assumption that different features in word embedding contribute differently to a particular affective dimension and a particular feature in word embedding contributes differently to different affective dimensions. Evaluation on various affective lexicons shows that our method outperforms the state-of-the-art methods on all the lexicons under different evaluation metrics with large margins. We also explore different regression models and conclude that the Ridge regression model, the Bayesian Ridge regression model and Support Vector Regression with linear kernel are the most suitable models. Comparing to other state-of-the-art methods, our method also has computation advantage. Experiments on a sentiment analysis task show that the lexicons extended by our method achieve better results than publicly available sentiment lexicons on eight sentiment corpora. The extended lexicons are publicly available for access.|Affective lexicon; sentiment; emotion; word embedding; regression|MODALITY EXCLUSIVITY NORMS; ENGLISH WORDS; EMOTIONS; ASSOCIATION; DOMINANCE; AROUSAL; LEXICON; MODELS; LEMMAS; TEXT|Computer Science, Artificial Intelligence; Computer Science, Cybernetics|0|4|4
Triumph through texting: Restoring learners' interest in grammar|2017|It is usually the case that learners of English as a foreign language (EFL) are exposed to language materials in class only, and of course in such a short space of time, they do not always find enough chance to practice English grammar features and become aware of their grammar mistakes. As a potential solution to this problem, the current study inspects the impact of using cell phones, specifically text messages (via short message service) as supplementary tools, on Iranian elementary level EFL learners' grammar learning. In the first phase of the study, 60 students aged 14 were randomly divided into experimental and comparison groups. Throughout the 12 weeks of treatment, the participants in the experimental group received 120 text messages containing grammar exercises, whereas the participants in the comparison group received a similar number of vocabulary messages as a placebo treatment and were otherwise treated exactly the same as the experimental group. A researcher-made grammar test was used to estimate whether presenting grammar exercises via text messages has any impact on language learners' grammar learning. The results demonstrated that there was a significant difference (p < 0.05) in the grammar learning of the participants who practiced grammar points through text messages and those who did not. The researchers also interviewed various stakeholders, comprising ten students, five parents, the teacher, and the school principal. A qualitative content analysis was carried out to find themes relevant to the stakeholders' beliefs about making use of text messages for learning grammar. The findings suggest that text messages can be useful for learning grammar points, since they engage learners' interest and encourage them to study more in order to text the correct answers when they are outside their classrooms.|mobile learning; mobile assisted language learning (MALL); grammar; text messaging|MOBILE PHONES; SMS|Education \& Educational Research; Linguistics; Language \& Linguistics|0|4|4
Heritage Passions, Heritage Convictions, and the Rooted L2 Self: Music and Gaelic Language Learning in Cape Breton, Nova Scotia|2017|The present research examines the role of music and dance in motivating Gaelic language learning on Cape Breton Island (Canada). The Gaelic language, once thriving in this context, has declined in use but flourishes in both music and dance. This article presents the results of in-depth interviews (60-90 minutes) with 10 accomplished adult musicians and dancers who described in rich detail connections between traditional music and the Gaelic language. The interview texts were analyzed using Leximancer 4.0, text-mining software that performs an automatic analysis by deriving, in a grounded fashion, the key concepts in a text. Semantic and relational co-occurrence information was extracted using artificial intelligence, producing a map of interrelations among concepts. Three interrelated concepts are introduced to describe community-level motivational processes evident in the interviews: Rooted second language (L2) self, heritage passions, and heritage convictions. The rooted L2 self is defined by connections to place and speakers of the language; heritage passions reflect the development of emotional bonds, core values, and strengths; and heritage convictions capture deep-seated beliefs, attitudes, and mindsets. Elements of both Gardner's notion of integrative motivation and Dornyei's L2 self system are evident and are considered within Ushioda's (2009) person-in-context relational model, emphasizing the connections among learners and contexts.|heritage language learning; motivation; emotions; rooted L2 self|MOTIVATION; SHIFT|Education \& Educational Research; Linguistics|2|4|4
Development of an automated assessment tool for MedWatch reports in the FDA adverse event reporting system|2017|Objective: As the US Food and Drug Administration (FDA) receives over a million adverse event reports associated with medication use every year, a system is needed to aid FDA safety evaluators in identifying reports most likely to demonstrate causal relationships to the suspect medications. We combined text mining with machine learning to construct and evaluate such a system to identify medication-related adverse event reports. Methods: FDA safety evaluators assessed 326 reports for medication-related causality. We engineered features from these reports and constructed random forest, L1 regularized logistic regression, and support vector machine models. We evaluated model accuracy and further assessed utility by generating report rankings that represented a prioritized report review process. Results: Our random forest model showed the best performance in report ranking and accuracy, with an area under the receiver operating characteristic curve of 0.66. The generated report ordering assigns reports with a higher probability of medication-related causality a higher rank and is significantly correlated to a perfect report ordering, with a Kendall's tau of 0.24 (P = .002). Conclusion: Our models produced prioritized report orderings that enable FDA safety evaluators to focus on reports that are more likely to contain valuable medication-related adverse event information. Applying our models to all FDA adverse event reports has the potential to streamline the manual review process and greatly reduce reviewer workload.|drug-related side effects and adverse reactions; supervised machine learning|TEXT MINING SYSTEM; PUBLIC VERSION; CLASSIFICATION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|4|4
Cyberbullying Detection Based on Semantic-Enhanced Marginalized Denoising Auto-Encoder|2017|As a side effect of increasingly popular social media, cyberbullying has emerged as a serious problem afflicting children, adolescents and young adults. Machine learning techniques make automatic detection of bullying messages in social media possible, and this could help to construct a healthy and safe social media environment. In this meaningful research area, one critical issue is robust and discriminative numerical representation learning of text messages. In this paper, we propose a new representation learning method to tackle this problem. Our method named semantic-enhanced marginalized denoising auto-encoder (smSDA) is developed via semantic extension of the popular deep learning model stacked denoising autoencoder (SDA). The semantic extension consists of semantic dropout noise and sparsity constraints, where the semantic dropout noise is designed based on domain knowledge and the word embedding technique. Our proposed method is able to exploit the hidden feature structure of bullying information and learn a robust and discriminative representation of text. Comprehensive experiments on two public cyberbullying corpora (Twitter and MySpace) are conducted, and the results show that our proposed approaches outperform other baseline text representation learning methods.|Cyberbullying detection; text mining; representation learning; stacked denoising autoencoders; word embedding|SPARSE LEAST-SQUARES; SELECTION; METAANALYSIS|Computer Science, Artificial Intelligence; Computer Science, Cybernetics|0|4|4
Development of sensitivity versus specificity for print in the visual word form area|2017|An area near the left lateral occipito-temporal sulcus that responds preferentially to print has been designated as the visual word form area (VWFA). Research suggests that specialization in this brain region increases as reading expertise is achieved. Here we aimed to characterize that development in terms of sensitivity (response to printed words relative to non-linguistic faces) versus specificity (response to printed words versus line drawings of nameable objects) in typically reading children ages 7-14 versus young adults as measured by functional magnetic resonance imaging (fMRI). Relative to adults, children displayed equivalent sensitivity but reduced specificity. These findings suggest that sensitivity for print relative to non-linguistic stimuli develops relatively early in the VWFA in the course of reading development, but that specificity for printed words in VWFA is still developing through at least age 14. (C) 2017 Elsevier Inc. All rights reserved.|Reading; VWFA; Lateralization; Text; Visual; fMRI; Specificity; Sensitivity; Development|HUMAN EXTRASTRIATE CORTEX; SURFACE-BASED ANALYSIS; HUMAN BRAIN; HEMISPHERIC LATERALIZATION; INDIVIDUAL VARIABILITY; PROCESSING SYSTEM; VENTRAL STREAM; HEAD MOTION; LANGUAGE; SEGMENTATION|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|0|1|4
Form overrides meaning when bilinguals monitor for errors|2017|Bilinguals rarely produce unintended language switches, which may in part be because switches are detected and corrected by an internal monitor. But are language switches easier or harder to detect than within-language semantic errors? To approximate internal monitoring, bilinguals listened (Experiment 1) or read aloud (Experiment 2) stories, and detected language switches (translation equivalents or semantically unrelated to expected words) and within-language errors (semantically related or unrelated to expected words). Bilinguals detected semantically related within-language errors most slowly and least accurately, language switches more quickly and accurately than within-language errors, and (in Experiment 2), translation equivalents as quickly and accurately as unrelated language switches. These results suggest that internal monitoring of form (which can detect mismatches in language membership) completes earlier than, and is independent of, monitoring of meaning. However, analysis of reading times prior to error detection revealed meaning violations to be more disruptive for processing than language violations. (C) 2016 Elsevier Inc. All rights reserved.|Internal monitoring; Wrong-language intrusion; Within-language semantic error; Listening comprehension; Reading aloud; Language non-selectivity|PERCEPTUAL LOOP THEORY; SPEECH PRODUCTION; WORD RECOGNITION; SENTENCE CONTEXT; NATIVE-LANGUAGE; LEXICAL ACCESS; READING ALOUD; BRAIN POTENTIALS; ELICITED SLIPS; TEXT REVISION|Linguistics; Psychology; Psychology, Experimental|1|1|4
Enriching consumer health vocabulary through mining a social Q\&A site: A similarity-based approach|2017|The widely known vocabulary gap between health consumers and healthcare professionals hinders information seeking and health dialogue of consumers on end-user health applications. The Open Access and Collaborative Consumer Health Vocabulary (OAC CHV), which contains health-related terms used by lay consumers, has been created to bridge such a gap. Specifically, the OAC CHV facilitates consumers' health information retrieval by enabling consumer-facing health applications to translate between professional language and consumer friendly language. To keep up with the constantly evolving medical knowledge and language use, new terms need to be identified and added to the OAC CHV. User-generated content on social media, including social question and answer (social Q\&A) sites, afford us an enormous opportunity in mining consumer health terms. Existing methods of identifying new consumer terms from text typically use ad-hoc lexical syntactic patterns and human review. Our study extends an existing method by extracting n-grams from a social Q\&A textual corpus and representing them with a rich set of contextual and syntactic features. Using K-means clustering, our method, simiTerm, was able to identify terms that are both contextually and syntactically similar to the existing OAC CHV terms. We tested our method on social Q\&A corpora on two disease domains: diabetes and cancer. Our method outperformed three baseline ranking methods. A post-hoc qualitative evaluation by human experts further validated that our method can effectively identify meaningful new consumer terms on social Q\&A. (C) 2017 Elsevier Inc. All rights reserved.|Controlled vocabularies; Consumer health vocabulary; Consumer health information; Social Q\&A; Ontology enrichment|INFORMATION; KNOWLEDGE; RECORDS; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|2|3|4
Assigning clinical codes with data-driven concept representation on Dutch clinical free text|2017|Clinical codes are used for public reporting purposes, are fundamental to determining public financing for hospitals, and form the basis for reimbursement claims to insurance providers. They are assigned to a patient stay to reflect the diagnosis and performed procedures during that stay. This paper aims to enrich algorithms for automated clinical coding by taking a data-driven approach and by using unsupervised and semi-supervised techniques for the extraction of multi-word expressions that convey a generalisable medical meaning (referred to as concepts). Several methods for extracting concepts from text are compared, two of which are constructed from a large unannotated corpus of clinical free text. A distributional semantic model (i.c. the word2vec skip-gram model) is used to generalize over concepts and retrieve relations between them. These methods are validated on three sets of patient stay data, in the disease areas of urology, cardiology, and gastroenterology. The datasets are in Dutch, which introduces a limitation on available concept definitions from expert-based ontologies (e.g. UMLS). The results show that when expert-based knowledge in ontologies is unavailable, concepts derived from raw clinical texts are a reliable alternative. Both concepts derived from raw clinical texts perform and concepts derived from expert-created dictionaries outperform a bag-of-words approach in clinical code assignment. Adding features based on tokens that appear in a semantically similar context has a positive influence for predicting diagnostic codes. Furthermore, the experiments indicate that a distributional semantics model can find relations between semantically related concepts in texts but also introduces erroneous and redundant relations, which can undermine clinical coding performance. (C) 2017 Published by Elsevier Inc.|Clinical coding; Data mining; Text mining; Unsupervised learning; International classification of diseases; Electronic health records; Distributional semantics; Word2vec|INFORMATION; MODELS; EXTRACTION; RETRIEVAL; SEMANTICS; CRITERIA; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|1|2|4
Proposal of indicators for the structural analysis of scientific articles|2017|This study aims to identify variables and indicators that substantiate the development of rules that focus on the structural analysis of scientific articles. Variables and indicators for structural analysis are derived from hypotheses deduced from editorials in important scientific journals. To exemplify and test the indicators, a structural analysis was conducted of 108 scientific articles published in important journals in the field of Management. The hypotheses were mostly tested in accordance with the idea of estimation statistics. The approach that was developed for the structural analysis of the network of texts innovates by employing network analysis indicators (indegree and outdegree). For this purpose, the text matrix is employed through the identification and encoding of cross-references between sections and subsections of each article under study. For the context in question, the field of Management, twelve rules were developed. The interpretations of the possible values for the indicators, expressed in the form of rules, are applied as directives to less experienced scholars in preparing their scientific articles, and for the generation of information to support activities concerning the classification and analysis of scientific articles. (C) 2017 Elsevier Ltd. All rights reserved.|Cross-reference; Article structure; Text matrix; Structural analysis; Article classification|STRATEGIES; MANAGEMENT; TEXT|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|3|4
Quantitative intonation modeling of interrogative sentences for Mandarin speech synthesis|2017|Previous intonational research on Mandarin has mainly focused on the prosody modeling of statements or the prosody analysis of interrogative sentences. To support related speech technologies, e.g., Text-to Speech, the quantitative modeling of intonation of interrogative sentences with a large-scale corpus still deserves attention. This paper summarizes our work on the quantitative prosody modeling of interrogative sentence in Mandarin. A large-scale natural speech corpus was used in this study. By extracting the pitch contours and fitting the intonation curves, we found that F0 declination and final lowering both existed in interrogative sentences, while they were claimed to be absent in Mandarin in some previous studies. In addition, the declination function could be modeled linearly, and the bearing unit of final lowering in Mandarin was found to be the last prosodic word in the utterance, regardless of its length, rather than a fixed duration range. It was argued in this study that the difference between this finding and the commonly believed rising intonation of the interrogative sentences resulted from the nonlinear relationship between prosody production and perception. The underlying mechanism for the existence of Fo declination and final lowering in interrogative sentences is also discussed. (C) 2017 Elsevier B.V. All rights reserved.|F-0 declination; Intonation; Interrogative sentences; Final lowering; Prosody|FUNDAMENTAL-FREQUENCY DECLINATION; ENGLISH; PITCH; TONE; PERCEPTION|Acoustics; Computer Science, Interdisciplinary Applications|0|2|4
A long journey to short abbreviations: developing an open-source framework for clinical abbreviation recognition and disambiguation (CARD)|2017|Objective: The goal of this study was to develop a practical framework for recognizing and disambiguating clinical abbreviations, thereby improving current clinical natural language processing (NLP) systems' capability to handle abbreviations in clinical narratives. Methods: We developed an open-source framework for clinical abbreviation recognition and disambiguation (CARD) that leverages our previously developed methods, including: (1) machine learning based approaches to recognize abbreviations from a clinical corpus, (2) clustering-based semiautomated methods to generate possible senses of abbreviations, and (3) profile-based word sense disambiguation methods for clinical abbreviations. We applied CARD to clinical corpora from Vanderbilt University Medical Center (VUMC) and generated 2 comprehensive sense inventories for abbreviations in discharge summaries and clinic visit notes. Furthermore, we developed a wrapper that integrates CARD with MetaMap, a widely used general clinical NLP system. Results and Conclusion: CARD detected 27 317 and 107 303 distinct abbreviations from discharge summaries and clinic visit notes, respectively. Two sense inventories were constructed for the 1000 most frequent abbreviations in these 2 corpora. Using the sense inventories created from discharge summaries, CARD achieved an F1 score of 0.755 for identifying and disambiguating all abbreviations in a corpus from the VUMC discharge summaries, which is superior to MetaMap and Apache's clinical Text Analysis Knowledge Extraction System (cTAKES). Using additional external corpora, we also demonstrated that the MetaMap-CARD wrapper improved MetaMap's performance in recognizing disorder entities in clinical notes. The CARD framework, 2 sense inventories, and the wrapper for MetaMap are publicly available at https://sbmi.uth.edu/ccb/resources/abbreviation. htm. We believe the CARD framework can be a valuable resource for improving abbreviation identification in clinical NLP systems.|clinical abbreviation; sense clustering; machine learning; clinical natural language processing|WORD SENSE DISAMBIGUATION; BIOMEDICAL DOMAIN; UMLS; TEXT; EXTRACTION; TERMS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|1|4
Theoretical models of comprehension skills tested through a comprehension assessment battery for primary school children|2017|In this study, two alternative theoretical models were compared, in order to analyze which of them best explains primary school children's text comprehension skills. The first one was based on the distinction between two types of answers requested by the comprehension test: local or global. The second model involved texts' input modality: written or oral. For this purpose, a new instrument that assesses listening and reading comprehension skills (ALCE battery; Bonifacci et al., 2014) was administered to a large sample of 1,658 Italian primary school students. The two models were tested separately for the five grades (first to fifth grade). Furthermore, a third model, that included both the types of answers and the texts' input modality, was considered. Results of confirmatory factor analyses suggested that all models are adequate, but the second one (reading vs. listening) provided a better fit. The major role of the distinction between input modalities is discussed in relation to individual differences and developmental trajectories in text comprehension. Theoretical and clinical implications are discussed.|Decoding; diagnostic assessment; inferences; listening comprehension; reading comprehension|GOODNESS-OF-FIT; READING-COMPREHENSION; EUROPEAN ORTHOGRAPHIES; DEVELOPMENTAL DYSLEXIA; COVARIANCE-STRUCTURES; SPEECH-PERCEPTION; INDEXES; STUDENTS; DIFFICULTIES; ACQUISITION|Linguistics; Language \& Linguistics|1|3|4
Use of electronic healthcare records to identify complex patients with atrial fibrillation for targeted intervention|2017|Background: Practice guidelines recommend anticoagulation therapy for patients with atrial fibrillation (AF) who have other risk factors putting them at an elevated risk of stroke. These patients remain undertreated, but, with increasing use of electronic healthcare records (EHRs), it may be possible to identify candidates for treatment. Objective: To test algorithms for identifying AF patients who also have known risk factors for stroke and major bleeding using EHR data. Materials and Methods: We evaluated the performance of algorithms using EHR data from the Partners Healthcare System at identifying AF patients and 16 additional conditions that are risk factors in the CHA2DS2-VASc and HAS-BLED risk scores for stroke and major bleeding. Algorithms were based on information contained in problem lists, billing codes, laboratory data, prescription data, vital status, and clinical notes. The performance of candidate algorithms in 1000 bootstrap resamples was compared to a gold standard of manual chart review by experienced resident physicians. Results: Physicians reviewed 480 patient charts. For 11 conditions, the median positive predictive value (PPV) of the EHR-derived algorithms was greater than 0.90. Although the PPV for some risk factors was poor, the median PPV for identifying patients with a CHA(2)DS(2)-VASc score >= 2 or a HAS-BLED score >= 3 was 1.00 and 0.92, respectively. Discussion: We developed and tested a set of algorithms to identify AF patients and known risk factors for stroke and major bleeding using EHR data. Algorithms such as these can be built into EHR systems to facilitate informed decision making and help shift population health management efforts towards patients with the greatest need.|anticoagulation; stroke; chronic disease; outcomes; quality improvement; algorithms; natural language processing|RISK; STROKE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|2|1|4
Assessing Names? Effects of Name-Based Stereotypes on Teachers' Evaluations of Pupils' Texts|2017|This study investigates the effects of name-based ethnic and social stereotypes on teachers' grading of pupils' texts in contemporary Sweden. A total of 113 practicing Swedish high school teachers assessed an authentic pupil text with one of three male names inserted, each intended to evoke a certain ethnic or social stereotype. Participants also explained their grading and answered questions regarding key features of the text. Both quantitative and qualitative analyses were conducted. The study concludes that name-based stereotypes generally have little influence on teachers' assessment in contemporary Sweden. Results indicate a systematic but small and not statistically relevant name effect. A negative effect can be seen with regard to an ethnically marked name. This effect is shown when teachers evaluate language proficiency, but not for other features of the text. Regarding socioeconomically marked names there is little systematic effect. The study also suggests, however, that there may be compensatory mechanisms limiting the name effect.|socio-onomastics; name-based stereotypes; perceived identity; name bias; text assessment; ethnicity|EXPECTATIONS; ACHIEVEMENT; FIELD|Linguistics; Language \& Linguistics|0|2|4
Clustering of Micro-Messages Using Similarity Upper Approximation|2017|Microblogging platforms like Twitter, Tumblr and Plurk have radically changed our lives. The presence of millions of people has made these platforms a preferred channel for communication. A large amount of User Generated Content, on these platforms, has attracted researchers and practitioners to mine and extract information nuggets. For information extraction, clustering is an important and widely used mining operation. This paper addresses the issue of clustering of micro-messages and corresponding users based on the text content of micro-messages that reflect their primitive interest. In this paper, we performed modification of the Similarity Upper Approximation based clustering algorithm for clustering of micro-messages. We compared the performance of the modified Similarity Upper Approximation based clustering algorithm with state-of-the-art clustering algorithms such as Partition Around Medoids, Hierarchical Agglomerative Clustering, Affinity Propagation Clustering and DBSCAN. Experiments were performed on micro-messages collected from Twitter. Experimental results show the effectiveness of the proposed algorithm.|Microblogging; micro-message; clustering; similarity upper approximation; primitive interest; rough set|ROUGH SET MODEL; SEQUENTIAL INFORMATION; SOCIAL MEDIA|Computer Science, Artificial Intelligence|1|1|4
Translanguaging in multimodal Macao posters: Flexible versus separate multilingualism|2017|Aims: This paper suggests a framework of separate and flexible multilingualism to describe multilingual phenomena in Macao. The aims are to capture both conventional and creative language practice and to explore what exactly is the state of multilingualism in modern Macao under the context of globalization, and more specifically how we can capture variation in multilingual practice. Methodology: The objectives are achieved by analyzing the interplay and distance between languages in multilingual texts, focusing on the multimodality and intertextuality of the texts. Data and analysis: The database is a collection of 300 posters for cultural and entertainment events in Macao. The distance of languages is analyzed at the unit level in multimodal texts; separate and flexible multilingualism are exemplified and further elaborated. Conclusions: Multilingualism in Macao is mainly characterized by separate multilingualism, where different languages are demarcated clearly. However, Macao is undergoing a significant process of globalization, accompanied by a huge flow of people, and concomitantly flexible multilingualism is emergent and coexistent with separate multilingualism. Flexible multilingualism is often manifested in translanguaging. The various practices of translanguaging are performances of creativity and they show criticality by problematizing the widely accepted essentialist conceptions on boundaries between languages and modes. Originality: This paper extends the framework of separate and flexible multilingualism to explain multilingual practice in general. We analyze multimodal data using a combined method of multimodality and multilingualism while focusing on the linguistic elements. The paper treats the posters as a special and less studied type of linguistic landscape in Macao, and it provides an original and realistic interpretation of the written multilingual linguistic landscape in a unique Chinese city. Significance: This paper provides a new way of understanding multilingualism; translanguaging is broadened to account for written data. Multilingualism can be understood better by observing language-related practice in multimodal texts.|Flexible multilingualism; separate multilingualism; translanguaging; Macao (Macau); posters; multimodality|LINGUISTIC LANDSCAPE|Linguistics; Language \& Linguistics|2|0|4
Accurate frequency-based lexicon generation for opinion mining|2017|Sentiment analysis deals with classifying the opinions in text. Twitter is the most popular microblogging platform in social media, with hundreds of millions of tweets posted every day. A considerable number of tweets contain opinions. The goal of this paper is to classify the polarity of the tweets into positive and negative classes using dynamic sentiment lexicons based on frequencies of words in positive and negative classes. We extract five meta-level features incorporating the generated sentiment lexicons and classify the text based on them. We also incorporate some previously known lexicon-based and corpus-based features. The proposed method is assessed on six datasets, and outperforms previous papers on accuracy on four datasets, and on f-measure on three datasets. This method generates sentiment lexicons dynamically. The changes of meanings of words can be captured by the generated lexicons. Our research produces very promising results in sentiment analysis in terms of accuracy and f-measure. The accuracy of our method on four datasets and the f-measure of our method on three datasets are higher than 85\%.|Sentiment analysis; opinion mining; sentiment lexicons; twitter|SENTIMENT ANALYSIS; RESOURCES; TWITTER; EMOTION|Computer Science, Artificial Intelligence|0|4|4
An associative method for Lesk-based word sense disambiguation|2017|One of the most important current problems in natural language processing is word sense disambiguation (WSD). WSD consists of identifying the correct sense of the words in a given text. In this work, we present a novel method for automatic WSD based on the simplified-Lesk algorithm. The proposed method employs Alpha-Beta associative memories for the relatedness computation between the senses of the ambiguous words and its context. The performance of this method was evaluated in terms of precision, recall, and F-score, using the semantically annotated corpora Senseval-2, Semcor, and Semeval-2007. The results show the advantages of the proposed method compared with other Lesk-based state-of-the-art methods.|Computational linguistics; word sense disambiguation; simplified-Lesk algorithm; associative memories; Alpha-Beta associative memories|MEMORIES; ENGLISH|Linguistics; Language \& Linguistics|0|4|4
Opportunities for academic language and literacy development for emergent bilingual students during group work|2017|The present paper argues for a shift in teacher knowledge and beliefs about the role of group work in the teaching and learning of emergent bilingual students. Using case study data from an eighth grade classroom, the authors analyze the role of collaboration in the interaction with grade-level text of emergent bilingual students. The analysis demonstrates that the quality of collaboration mediates in significant ways the opportunities available to emergent bilinguals for both content and language learning. The authors suggest that expanding students' repertoires of practice to include collaborative learning should be a worthwhile instructional goal in mainstream classrooms. The analysis problematizes the currently dominant view of group work as an instructional strategy, and supports the positioning of collaboration as a key disciplinary practice in the new college and career readiness standards. The article offers a conceptual framework for contrasting different types of collaboration that is based on Engestrom's (1993. Developmental Studies on Work as a Testbench of Activity Theory. In Understanding Practice: Perspectives on Activity and Context, edited by S. Chaiklin and J. Lave, 64-103. Cambridge: Cambridge University Press) activity theory.|Emergent bilinguals; second language learning; collaborative learning; national standards; academic language; language arts|LEARNERS; SCIENCE|Education \& Educational Research; Linguistics; Language \& Linguistics|1|4|4
Examining multiple readings of popular culture by ESL students in Hong Kong|2017|The integration of popular culture into English language learning has recently been formalised in the Hong Kong New Senior Secondary curriculum, with the development of critical reading indicated as one of the key objectives. Whether and how students respond to popular culture texts is, however, under-researched. The present paper reports findings from a study that investigated how a group of 33 senior secondary (Grade 11) students from three schools representing different levels of academic performance in Hong Kong conducted reading of an authentic print English advertisement. In small groups, the students articulated in Cantonese, their first language, an analysis of the text including its purpose, target audience, and intended impacts. Insights from Stuart Hall's three major decoder positions (dominant reading, oppositional reading, and negotiated reading) were drawn on to conduct a qualitative content analysis of the students' reading. The findings showed that three-quarters of the students irrespective of their English proficiency levels displayed evidence of critical consumption of the text, but many seemed to have constructed oppositional or negotiated reading positions due to their failure to appreciate linguistic creativity, and spontaneous evaluation of the visual images. The authors argue that language curricula in schools should strengthen students' critical multimodal literacies.|Popular culture; critical thinking; critical multimodal literacies; decoder positions; dominant; oppositional; negotiated reading positions|2ND-LANGUAGE; LITERACY|Education \& Educational Research; Linguistics; Language \& Linguistics|0|3|4
Neophilia ranking of scientific journals|2017|The ranking of scientific journals is important because of the signal it sends to scientists about what is considered most vital for scientific progress. Existing ranking systems focus on measuring the influence of a scientific paper (citations)-these rankings do not reward journals for publishing innovative work that builds on new ideas. We propose an alternative ranking based on the proclivity of journals to publish papers that build on new ideas, and we implement this ranking via a text-based analysis of all published biomedical papers dating back to 1946. In addition, we compare our neophilia ranking to citation-based (impact factor) rankings; this comparison shows that the two ranking approaches are distinct. Prior theoretical work suggests an active role for our neophilia index in science policy. Absent an explicit incentive to pursue novel science, scientists underinvest in innovative work because of a coordination problem: for work on a new idea to flourish, many scientists must decide to adopt it in their work. Rankings that are based purely on influence thus do not provide sufficient incentives for publishing innovative work. By contrast, adoption of the neophilia index as part of journal-ranking procedures by funding agencies and university administrators would provide an explicit incentive for journals to publish innovative work and thus help solve the coordination problem by increasing scientists' incentives to pursue innovative work.|Novel science; Novelty; Journal rankings; Citations; Impact factor; Text analysis|INTELLECTUAL INFLUENCE; RESEARCH QUALITY; IMPACT; SCIENCE; NOVELTY; UNCERTAINTY; INDEX|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|1|1|4
Alveolar and Velarized Laterals in Albanian and in the Viennese Dialect|2016|A comparison of alveolar and velarized lateral realizations in two language varieties, Albanian and the Viennese dialect, has been performed. Albanian distinguishes the two laterals phonemically, whereas in the Viennese dialect, the velarized lateral was introduced by language contact with Czech immigrants. A categorical distinction between the two lateral phonemes is fully maintained in Albanian. Results are not as straightforward in the Viennese dialect. Most prominently, female speakers, if at all, realize the velarized lateral in word-final position, thus indicating the application of a phonetically motivated process. The realization of the velarized lateral by male speakers, on the other hand, indicates that the velarized lateral replaced the former alveolar lateral phoneme. Alveolar laterals are either realized in perceptually salient positions, thus governed by an input-switch rule, or in front vowel contexts, thus subject to coarticulatory influences. Our results illustrate the subtle interplay of phonology, phonetics and sociolinguistics.|Laterals; Albanian; Viennese dialect; Natural Phonology; Sociophonetics|PHONOLOGY; ENGLISH; GERMAN|Audiology \& Speech-Language Pathology; Linguistics; Psychology, Experimental|0|1|4
Cross-document event ordering through temporal, lexical and distributional knowledge|2016|In this paper we present a system that automatically builds ordered timelines of events from different written texts in English. The system deals with problems such as automatic event extraction, cross document temporal relation extraction and cross-document event coreference resolution. Its main characteristic is the application of three different types of knowledge: temporal knowledge, lexical-semantic knowledge and distributional-semantic knowledge, in order to anchor and order the events in the timeline. It has been evaluated within the framework of SemEval 2015. The proposed system improves the current state-of-the-art systems in all measures (up to eight points of Fl-score over other systems) and shows a significant advance in the Cross-document event ordering task. (C) 2016 Elsevier B.V. All rights reserved.|Event ordering; Temporal information processing; Cross-document temporal relation; Cross-document event coreference; Timelines; Distributional semantics|NATURAL-LANGUAGE; SEMANTICS; MODELS|Computer Science, Artificial Intelligence|2|1|4
Does the Advanced Proficiency Evaluated in Oral-Like Written Text Support Syntactic Parsing in a Written Academic Text Among L2 Japanese Learners?|2016|Corpus linguistics identifies the qualitative difference in the characteristics of spoken discourse vs. written academic discourse. Whereas spoken discourse makes greater use of finite dependent clauses functioning as constituents in other clauses, written academic discourse incorporates noun phrase constituents and complex phrases. This claim can be extended to the contrast between academic written texts and more informal oral-like written texts. This study examined whether this qualitative difference in syntactic structures affects second language learners' syntactic parsing in a written academic text. For the purpose of this research, a think-aloud protocol of reading a typical written academic text was carried out with 31 undergraduate students at a U.S. university who demonstrated near-passing scores and above on the Japanese language proficiency test level 2. The statistical analysis, using Kendall's tau, revealed that advanced proficiency in terms of oral-like written texts does not guarantee the ability to parse syntactic structures in written academic texts.|Japanese; pedagogy; qualitative study; quantitative research|LANGUAGE READING-COMPREHENSION; SKILLS; ACQUISITION; KNOWLEDGE; STUDENTS; ENGLISH; LEVEL; L1|Education \& Educational Research; Linguistics|0|0|4
Near-synonym substitution using a discriminative vector space model|2016|Near-synonyms are fundamental and useful knowledge resources for computer-assisted language learning (CALL) applications. For example, in online language learning systems, learners may have a need to express a similar meaning using different words. However, it is usually difficult to choose suitable near synonyms to fit a given context because the differences of near-synonyms are not easily grasped in practical use, especially for second language (L2) learners. Accordingly, it is worth developing algorithms to verify whether near-synonyms match given contexts. Such algorithms could be used in applications to assist L2 learners in discovering the collocational differences between near-synonyms. We propose a discriminative vector space model for the near-synonym substitution task, and consider this task as a classification task. There are two components: a vector space model and discriminative training. The vector space model is used as a baseline classifier to classify test examples into one of the neat-synonyms in a given near synonym set. A discriminative training technique is then employed to improve the vector space model by distinguishing positive and negative features for each near-synonym. Experimental results show that the DT-VSM achieves higher accuracy than both pointwise mutual information and n-gram-based methods that have been used in previous studies. (C) 2016 Elsevier B.V. All rights reserved.|Natural language processing; Lexical substitution; Near-synonym learning; Discriminative training; Vector space model|QUERY EXPANSION; ONTOLOGY; RECOGNITION|Computer Science, Artificial Intelligence|1|2|4
MY FIRST CMC ARTICLE REVISTED: A WINDOW ON SPANISH L2 INTERLANGUAGE|2016|The computer-assisted language learning (CALL) field seems to change overnight with new technological affordances. Blake revisits his 2000 LLT article on computer-mediation communication (CMC) in order to reflect on how the field has examined this topic over the past decade or so. While the Interaction Hypothesis continues to guide researchers in broad terms, the frame of reference has shifted from just text-based analysis to fully synchronous video exchanges.|Computer-mediated Communication; Sociocultural Theory|NEGOTIATION; PERFORMANCE; GERMAN; MODEL|Education \& Educational Research; Linguistics|2|1|4
Multilayered temporal modeling for the clinical domain|2016|Objective To develop an open-source temporal relation discovery system for the clinical domain. The system is capable of automatically inferring temporal relations between events and time expressions using a multilayered modeling strategy. It can operate at different levels of granularity-from rough temporality expressed as event relations to the document creation time (DCT) to temporal containment to fine-grained classic Allen-style relations. Materials and Methods We evaluated our systems on 2 clinical corpora. One is a subset of the Temporal Histories of Your Medical Events (THYME) corpus, which was used in SemEval 2015 Task 6: Clinical TempEval. The other is the 2012 Informatics for Integrating Biology and the Bedside (i2b2) challenge corpus. We designed multiple supervised machine learning models to compute the DCT relation and within-sentence temporal relations. For the i2b2 data, we also developed models and rule-based methods to recognize cross-sentence temporal relations. We used the official evaluation scripts of both challenges to make our results comparable with results of other participating systems. In addition, we conducted a feature ablation study to find out the contribution of various features to the system's performance. Results Our system achieved state-of-the-art performance on the Clinical TempEval corpus and was on par with the best systems on the i2b2 2012 corpus. Particularly, on the Clinical TempEval corpus, our system established a new F1 score benchmark, statistically significant as compared to the baseline and the best participating system. Conclusion Presented here is the first open-source clinical temporal relation discovery system. It was built using a multilayered temporal modeling strategy and achieved top performance in 2 major shared tasks.|natural language processing; electronic medical record; temporal relation discovery; document creation time; narrative container; Allen's temporal interval relations|2012 I2B2 CHALLENGE; INFERENCE; SYSTEM; EVENT; TIME|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|3|0|4
Analysis of written linguistic and discursive competence of first year students in Primary Education Teacher Degree|2016|When students start university, they are supposed to have already acquired a linguistic and literacy background that will allow them to write texts using an academic discourse appropriate to their level. However, most research focuses on the lack of linguistic-discourse competence in university students. After exposing these previous studies, the contents and language skills included in the curriculum of future teachers and the characteristics of university academic discourse, this paper covers an analysis of some writing samples in the tests of Spanish of three groups of first year students in the Degree in Primary Education Teacher Program from the University of Granada (Spain) in order to detect and classify these deficiencies. Results of this empirical-analytical descriptive study show that women, as well as students from Europe, perform better in the subject being evaluated, but most of them have problems in their writing (i.e., phonological, morphological, syntactic, lexical-semantic, spelling and discourse errors), which are specific to previous educational stages, especially those of grammatical type, caused by their limited knowledge about textual and linguistic conventions. Conclusions focus on the need of interdisciplinary solutions from the institution itself. Some general proposals of written discursive practices integrated into the training of these future teachers are raised.|Llinguistic competence; academic writing; linguistic-discursive weaknesses; university students; future teacher|SEX-DIFFERENCES; INTELLIGENCE|Linguistics; Language \& Linguistics|0|0|4
Cataphora, backgrounding and accessibility in discourse|2016|We examine discourse factors that are involved in the occurrence of intra/inter-sentential cataphora. On the basis of a corpus analysis of natural language, we test two cognitive theories that attempt to explain the phenomenon of cataphora: clausal backgrounding (Harris and Bates, 2002) and Accessibility Theory (Ariel, 1990). In the first part of the paper, we investigate the presence of cataphoric he, she, it and they in a corpus annotated with nucleus-satellite labels (Mann and Thompson, 1988), which are interpreted to be discourse correlates of the foreground -background distinction. The analysis shows that cataphora cannot be restricted to backgrounded parts of texts, and that backgrounding as an explanation for the occurrence of cataphora cannot be applied at the discourse level. In the second part of the paper, we investigate a cognitively related phenomenon to backgrounding: accessibility and its influence on cataphora. We demonstrate that in different conditions accessibility parameters such as Givenness, Distance and Unity do not show a clear influence (especially when an instance of cataphora and its antecedent are in different sentences), while Saliency and (non)Competition do play a role in the presence of cataphora (both intra- and inter-sententially). (C) 2015 Elsevier B.V. All rights reserved.|Cataphora; Clausal backgrounding; Accessibility Theory|RHETORICAL STRUCTURE-THEORY; CO-REFERENCE; ANAPHORA; COHERENCE|Linguistics; Language \& Linguistics|0|0|4
Cognitive Grammar and gesture: Points of convergence, advances and challenges|2016|Given its usage-oriented character, Cognitive Grammar (CG) can be expected to be consonant with a multimodal, rather than text-only, perspective on language. Whereas several scholars have acknowledged this potential, the question as to how speakers' gestures can be incorporated in CG-based grammatical analysis has not been conclusively addressed. In this paper, we aim to advance the CG-gesture relationship. We first elaborate on three important points of convergence between CG and gesture research: (1) CG's conception of grammar as a prototype category, with central and more peripheral structures, aligns with the variable degrees to which speakers' gestures are conventionalized in human communication. (2) Conceptualization, which lies at the basis of grammatical organization according to CG, is known to be of central importance for gestural expression. In fact, all of the main dimensions of construal postulated in CG (specificity, perspective, profile-base relationship, conceptual archetypes) receive potential gestural expression. (3) CG's intensive use of diagrammatic notation allows for the incorporation of spatial features of gestures. Subsequently, we demonstrate how CG can be applied to analyze the structure of multimodal, spoken-gestured utterances. These analyses suggest that the constructs and tools developed by CG can be employed to analyze the compositionality that exists within a single gesture (between conventional and more idiosyncratic components) as well as in the grammatical relations that may exist between gesture and speech. Finally, we raise a number of theoretical and empirical challenges.|gesture; cognitive grammar; multimodality; iconicity|SPEECH|Linguistics; Language \& Linguistics|5|0|4
Distributional analysis applied to terminology extraction First results in the domain of psychiatry in Spanish|2016|This paper presents the first results of a new method for terminology extraction based on distributional analysis. The intuition behind the algorithm is that single or multi-word lexical units that refer to specialised concepts will show a characteristic co-occurrence pattern, described as a tendency to appear in the same contexts with other conceptually related terms. E.g. the term fluoxetine will systematically appear in the same sentences with other related terms such as depression, serotonin reuptake inhibitor, obsessive-compulsive disorder and others. Of course, terms will co-occur with general vocabulary units as well, but not with a characteristic pattern as when a conceptual relation holds. Experimental evaluation of this method was conducted in a corpus of psychiatry journals from Spain and Latin America, and concluded that the results are significantly better than other methods.|co-occurrence; distributional semantics; terminology extraction; topic signatures; text-mining|CORPUS; SEMANTICS|Linguistics; Language \& Linguistics|0|1|4
Grandmother, gran, gangsta granny: semiotic representations of grandmotherhood|2016|Age as an important identity dimension has been comparatively neglected within gender studies. Our paper concerns the semiotic representation of a role performed in the main by older women: that of `grandmother', a social category particularly associated with ageing. To explore this, we draw on image banks, corpus data and other texts in order to discuss images, lexical/textual labelling and their intermodal relations. We find in our visual data that grandmothers are contextualised in two ways: sharing semiotic resources of childhood or domestic contexts, or presented as transgressive actors, located in incongruous situations or performing behaviours inappropriate for their `age'. Our discussion of corpus data complements the multimodal analyses, providing further examples of stereotyping: while references to individual grandmothers often evaluate positively, there is also strong evidence of generic, figurative and other usages that trivialise and derogate. Our conclusions point to processes of social devaluation: ageism and sexism are the pervasive and underlining ideologies recurrent in these representations. The broader implications are particularly relevant for the present time, as new forms of grandmothering appear.|AGEISM; CORPUS; EVALUATION; GRANDMOTHERS; IMAGES; REPRESENTATION|AGEISM; BOOKS|Linguistics; Language \& Linguistics; Women's Studies|1|2|4
Authorship attribution and feature testing for short Chinese emails|2016|Features used in English-based authorship attribution demonstrate some constraints when used in authorship attribution of Chinese texts, even though they shed much light on it. Therefore, authorship attribution for short Chinese texts free of handwritten documents will help to promote the progress of legislation in China. This study aims to explore and test some features in pragmatic, discourse semantic and discourse information features for authorship attribution of short Chinese emails, which are representative of communication tools. It is hoped that some effective features can be found for the attribution of short Chinese emails. The texts used in the study include 72 short emails written by six authors. All the possible 57 combinations of the six authors are tested and attributed based on the extracted features. Discriminant analysis is employed, and the results demonstrate significant predictions in all the tests. It is concluded that the extracted features in pragmatics, discourse semantics and discourse information can significantly distinguish short Chinese emails, and the suggested number of suspect authors for authorship attribution of short emails should not exceed five.|AUTHORSHIP ATTRIBUTION; AUTHORSHIP FEATURES; PRAGMATIC FEATURES; DISCOURSE SEMANTIC FEATURES; DISCOURSE INFORMATION FEATURES; SHORT CHINESE EMAILS|IDENTIFICATION; INDIRECTNESS; REQUESTS|Criminology \& Penology; Linguistics|1|0|4
World knowledge affects prediction as quickly as selectional restrictions: evidence from the visual world paradigm|2016|There has been considerable debate regarding the question of whether linguistic knowledge and world knowledge are separable and used differently during processing or not (Hagoort et al, 2004). Integration of word meaning and world knowledge in language comprehension (Matsuki et al, 2011). Event-based plausibility immediately influences on-line language comprehension (Paczynski et al, 2012). Multiple influences of semantic memory on sentence processing: Distinct effects of semantic relatedness on violations of real-world event/state knowledge and animacy selection restrictions (Warren et al, 2007). Investigating effects of selectional restriction violations and plausibility violation severity on eye movements in reading. Previous investigations into this question have provided mixed evidence as to whether violations of selectional restrictions are detected earlier than violations of world knowledge. We report a visual world eye-tracking study comparing the timing of facilitation contributed by selectional restrictions vs. world knowledge. College-aged adults (n=36) viewed photographs of natural scenes while listening to sentences. Participants anticipated upcoming direct objects similarly regardless of whether facilitation was provided by only world knowledge or a combination of selectional restrictions and world knowledge. These results suggest that selectional restrictions are not available earlier in comprehension than world knowledge.|Language comprehension; plausibility; eye tracking; sentence processing; prediction|ANTICIPATORY EYE-MOVEMENTS; LANGUAGE COMPREHENSION; EVENT KNOWLEDGE; TIME-COURSE; INTEGRATION; VERBS; VIOLATIONS; MODELS|Audiology \& Speech-Language Pathology; Behavioral Sciences; Linguistics; Psychology, Experimental|1|0|4
Influence of Collaborative Reasoning discussions on metadiscourse in children's essays|2016|Metadiscourse has been conceptualized as a means to organize discourse, convey interpersonal and evaluative meanings, as well as engage the reader or listener. Importantly, metadiscourse has been theorized to uncover thought mediation during the essay-composing process. This study compares the metadiscourse in the reflective essays of 180 fifth graders, who either participated in small-group discussions using an approach called Collaborative Reasoning (CR), or who did not. Comparative analysis involving six major categories and forty subcategories of metadiscourse revealed, among other findings, that CR-exposed writers better signaled illocutionary force of reasoning, made greater use of engagement imperatives/directives and common-good rather than self-centered attitude marking. CR writers organized their ideas in a more argument-befitting logical-temporal non-list-like structure. Control students made greater use of emphatics, more often introduced hypothetical scenarios, and more frequently linked propositions together with simple additive conjunctions. The findings suggest that CR students have greater concern for how readers will take their arguments and greater appropriation of argument-enhancing formal elements, thus revealing cross-modal transfer from oral to written discourse.|metadiscourse; argumentation; classroom discussion; collaborative reasoning; children's writing; rhetoric|TEXT; ARGUMENTATION; DISCOURSE; KNOWLEDGE; MARKERS; ENGLISH; WRITTEN; TALK|Communication; Linguistics; Language \& Linguistics|0|0|4
Tense in a vectorial model for the conceptualization of time|2015|In this work we assume that the human mind cannot perceive time directly and thus resorts to a metaphor of space in order to conceptualize it (Casasanto \& Boroditsky, 2008; Gentner et al., 2002; Merrit et al., 2010). We argue that time, which is conceptualized in terms of a path image schema, is needed along with spatial coordinates in order to locate a proposition in a possible world so that it can receive a truth-value. In other words, both time and space are needed to evaluate a proposition. The human mind codifies the temporal properties of a proposition by means of three systems, which are based upon Reichenbach's (1947) temporal variables, namely speech time, evaluation time and utterance time: tense, which locates an event or situation along the temporal path image schema (past, present or future); aspect, which represents the speaker's viewpoint of the event or situation conveyed in the utterance (perfectivity and progressivity, among others); and lexical aspect or aktionsart, which encodes the temporal properties of the event or situation itself (i.e. whether it is bound, unbound, or punctual). Specifically, we provide a mathematical model that represents the information codified by these three systems by means of a Euclidean vector (a geometric entity characterized by a magnitude, which in our case is a number times an abstract temporal unit) in a four-dimensional-like mental representation, namely an R-3+(t) over cap mental representation: a three dimensional space (R-3) defined by three versors (a vector whose magnitude equals one unit and defines a line), (x) over cap, (y) over cap and (z) over cap plus a fourth versor (t) over cap that defines the temporal path image schema along which the proposition must be placed in order to receive a truth value. Ultimately, this work aims to offer a novel account of tense using theoretical tools from cognitive linguistics and formal logic, as well as mathematical formalisms, which will allow us to carry out the computational implementation of the model in NLP systems.|tense; time; vector; idealized cognitive model; image schema|SPACE; METAPHORS; HUMANS; THINK|Linguistics; Language \& Linguistics|0|0|4
Researching literacy in context: using video analysis to explore school literacies|2015|This article addresses how methodological approaches relying on video can be included in literacy research to capture changing literacies. In addition to arguing why literacy is best studied in context, we provide empirical examples of how small, head-mounted video cameras have been used in two different research projects that share a common aim: understanding the complex ways in which literacy is a part of school practices. The complexity of literacy practices taking place in classrooms, where students draw on a number of texts for a variety of purposes and different literacy discourses co-exist in the same setting, poses a serious challenge for those who wish to study literacy in educational settings. The methodology presented in this article is our attempt to meet this challenge. Our approach relies on using video equipment in innovative ways to capture multiple perspectives, involving research participants in the data collection process and the early stages of analysis, and analysing video data with digital coding software. These methods are combined to obtain a more systematic and detailed insight into the contexts in which literacy takes place.|video studies; school literacy; research methods; literacy practices|CLASSROOMS; ETHICS|Education \& Educational Research; Linguistics; Language \& Linguistics|5|2|4
Normalization of relative and incomplete temporal expressions in clinical narratives|2015|Objective To improve the normalization of relative and incomplete temporal expressions (RI-TIMEXes) in clinical narratives. Methods We analyzed the RI-TIMEXes in temporally annotated corpora and propose two hypotheses regarding the normalization of RI-TIMEXes in the clinical narrative domain: the anchor point hypothesis and the anchor relation hypothesis. We annotated the RI-TIMEXes in three corpora to study the characteristics of RI-TMEXes in different domains. This informed the design of our RI-TIMEX normalization system for the clinical domain, which consists of an anchor point classifier, an anchor relation classifier, and a rule-based RI-TIMEX text span parser. We experimented with different feature sets and performed an error analysis for each system component. Results The annotation confirmed the hypotheses that we can simplify the RI-TIMEXes normalization task using two multi-label classifiers. Our system achieves anchor point classification, anchor relation classification, and rule-based parsing accuracy of 74.68\%, 87.71\%, and 57.2\% (82.09\% under relaxed matching criteria), respectively, on the held-out test set of the 2012 i2b2 temporal relation challenge. Discussion Experiments with feature sets reveal some interesting findings, such as: the verbal tense feature does not inform the anchor relation classification in clinical narratives as much as the tokens near the RI-TIMEX. Error analysis showed that underrepresented anchor point and anchor relation classes are difficult to detect. Conclusions We formulate the RI-TIMEX normalization problem as a pair of multi-label classification problems. Considering only RI-TIMEX extraction and normalization, the system achieves statistically significant improvement over the RI-TIMEX results of the best systems in the 2012 i2b2 challenge.|temporal reasoning; medical language processing; temporal expression normalization|2012 I2B2 CHALLENGE; INFORMATION EXTRACTION; TEXT; EVENTS; SYSTEM; TIME|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|2|0|4
Therapeutic Writing An Exploratory Speech-Language Pathology Counseling Technique|2015|This exploratory qualitative study investigated the use of therapeutic writing for counseling long-term caregivers of spouses with brain injury and neurogenic communication disorders. Three participants wrote an average of six single-spaced pages of text. After analysis of the written text, the common themes of onset of diagnosis, anger, grief, and similarities in coping mechanisms were identified. Additional information about the value of therapeutic writing was obtained. Therapeutic writing appears to be a promising technique to use for counseling caregivers. On the basis of the caregiver's written text, the counseling needs related to neurogenic communication disorders can be addressed more efficiently.|brain injury; counseling; long-term caregivers; therapeutic writing|PSYCHOTHERAPY; HEALTH; EXPERIENCES|Linguistics; Rehabilitation|1|1|4
The textual profile of antonyms: A corpus-based study|2015|Unlike the traditional approaches that describe and define antonymy on the basis of semantic properties of antonymous pairs in a language system, antonyms are in this paper considered with reference to their roles in actual language use. Antonymy has traditionally been regarded as a paradigmatic relation, but recent studies of antonym co-occurrence in electronic corpora of English and Serbian have identified two major and four minor functions of antonyms in discourse, with its accompanying lexico-syntactic patterns, matching the results of similar analyses in Japanese, Swedish, and Dutch. This paper aims to investigate the performance of three antonymous patterns in retrieving contrastive terms and the possibility to create the contrastive profile of given seed words in Serbian written discourse by means of those patterns. It also examines whether there is a relation between the markedness distinction between members of the antonymous pair and the position of the chosen seed word (i.e., whether it comes in the X or the Y position in the pattern). Results of the study show that it is possible to create the textual profile of antonyms using these lexico-syntactic constructions, and that the unmarked member has a richer contrastive profile in text.|antonymy; language use; antonymous pattern; antonymous profile|DISCOURSE; COOCCURRENCE; ADJECTIVES; ENGLISH|Linguistics; Language \& Linguistics|2|0|4
Automated misspelling detection and correction in clinical free-text records|2015|Accurate electronic health records are important for clinical care and research as well as ensuring patient safety. It is crucial for misspelled words to be corrected in order to ensure that medical records are interpreted correctly. This paper describes the development of a spelling correction system for medical text. Our spell checker is based on Shannon's noisy channel model, and uses an extensive dictionary compiled from many sources. We also use named entity recognition, so that names are not wrongly corrected as misspellings. We apply our spell checker to three different types of free-text data: clinical notes, allergy entries, and medication orders: and evaluate its performance on both misspelling detection and correction. Our spell checker achieves detection performance of up to 94.4\% and correction accuracy of up to 88.2\%. We show that high-performance spelling correction is possible on a variety of clinical documents. (C) 2015 Elsevier Inc. All rights reserved.|Electronic health record; Named entity recognition; Natural language processing; Spelling correction|SPELLING CORRECTION; MEDICAL-RECORDS; RECOGNITION; SAFETY; ERRORS|Computer Science, Interdisciplinary Applications; Medical Informatics|4|1|4
Experimental investigations of ambiguity: the case of most|2015|In the study of natural language quantification, much recent attention has been devoted to the investigation of verification procedures associated with the proportional quantifier most. The aim of these studies is to go beyond the traditional characterization of the semantics of most, which is confined to explicating its truth-functional and presuppositional content as well as its combinatorial properties, as these aspects underdetermine the correct analysis of most. The present paper contributes to this effort by presenting new experimental evidence in support of a decompositional analysis of most according to which it is a superlative construction built from a gradable predicate many or much and the superlative operator -est (Hackl, in Nat Lang Semant 17:63-98, 2009). Our evidence comes in the form of verification profiles for sentences like Most of the dots are blue which, we argue, reflect the existence of a superlative reading of most. This notably contrasts with Lidz et al.'s (Nat Lang Semant 19:227-256, 2011) results. To reconcile the two sets of data, we argue, it is necessary to take important differences in task demands into account, which impose limits on the conclusions that can be drawn from these studies.|Quantification; Superlatives; Experimental design; Language processing; Semantics-cognition interface; Most|LANGUAGE|Linguistics; Language \& Linguistics|2|1|4
A multiple-grammar model of speakers' linguistic knowledge|2015|By using the concept of `multiple grammars,' this paper develops the view of an individual speaker's cognitive organization of grammar. Although conversation, one type of spoken language environment, plays a crucial role in the emergence of grammar, for some speakers in a literate society, the written language environment may also contribute to developing a grammar. The two language environments are expected to provide unique incentives to shaping grammar differently as they diverge greatly in terms of media types (sound vs graph), constraints (online processing vs detachment), and purposes (interaction vs ideational formation), among others. At the same time, speakers may come in contact with and acquire additional sets of grammar for specific genres. Though the grammars acquired in different genre environments may be merged at the most abstract level, each grammar contains genre-specific formulaic expressions and grammatical resources with varying degrees of granularity. Speakers may conduct their routine linguistic activities in an informal conversation by employing reusable formulaic expressions of various types and rudimentary combinatory algorithms, but when they engage in more complex verbal tasks (politicians engaging in a debate, interviewees reconstructing past experiences), they may employ more abstract grammatical resources including those that were acquired from written language. The paper explores these suggestions by performing text and statistical analyses of several Japanese discourse samples.|spoken language; written language; discourse genres; usage-based grammar; ecology of grammar|ENGLISH; CONVERSATION; LANGUAGE; CONSTRUCTIONS; CLAUSES; WRITTEN; USAGE|Linguistics; Language \& Linguistics|1|0|4
Automatic identification of methotrexate-induced liver toxicity in patients with rheumatoid arthritis from the electronic medical record|2015|Objectives To improve the accuracy of mining structured and unstructured components of the electronic medical record (EMR) by adding temporal features to automatically identify patients with rheumatoid arthritis (RA) with methotrexate-induced liver transaminase abnormalities. Materials and methods Codified information and a string-matching algorithm were applied to a RA cohort of 5903 patients from Partners HealthCare to select 1130 patients with potential liver toxicity. Supervised machine learning was applied as our key method. For features, Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) was used to extract standard vocabulary from relevant sections of the unstructured clinical narrative. Temporal features were further extracted to assess the temporal relevance of event mentions with regard to the date of transaminase abnormality. All features were encapsulated in a 3-month-long episode for classification. Results were summarized at patient level in a training set (N=480 patients) and evaluated against a test set (N=120 patients). Results The system achieved positive predictive value (PPV) 0.756, sensitivity 0.919, F1 score 0.829 on the test set, which was significantly better than the best baseline system (PPV 0.590, sensitivity 0.703, F1 score 0.642). Our innovations, which included framing the phenotype problem as an episode-level classification task, and adding temporal information, all proved highly effective. Conclusions Automated methotrexate-induced liver toxicity phenotype discovery for patients with RA based on structured and unstructured information in the EMR shows accurate results. Our work demonstrates that adding temporal features significantly improved classification results.|natural language processing; electronic medical record; pharmacogenetic; rheumatoid arthritis; methotrexate; liver toxicity|CROHNS-DISEASE; HEALTH RECORDS; CLINICAL TEXT; TEMPORAL EXPRESSIONS; ULCERATIVE-COLITIS; EXTRACTION; RISK; SURGERY; EVENTS; SYSTEM|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|12|0|4
Bringing consumption reviews into relief by combining Appraisal and argumentation analysis|2015|Recent years have seen a rapid influx of reviews in the field of different aesthetic and consumption domains, which is indicative of the importance assigned by present-day society to what we choose to experience and consume. Given their prevalence, there is a need to find an adequate analytic framework which allows insightful understanding of the discursive construction of such reviews. This paper aims to propose such a framework by combining tools from the Appraisal model with ideas from argumentation theory. The combined methodology is demonstrated using one text from a corpus of wine reviews written by the extraordinarily influential wine critic Robert Parker. The analysis takes into consideration both meanings that are internal to the text and meanings that are text-external, so-called world knowledge. I argue that the technique of reconstruction adopted from argumentation theory helps to highlight and explain how the appraisal works in the text. The findings are generalizable to the extent that the methodology can be used for any type of review text, especially in the domain of present-day luxury consumption, which is not overtly argumentative but which can still be found to have an assessment-basis format that leads its readers toward a certain worldview that they are invited to co-construct and see as rational.|Appraisal; argumentation; consumerism; discourse analysis; rhetoric; wine review|WINE|Communication; Linguistics; Language \& Linguistics|1|0|4
Two Interpretive Systems for Natural Language?|2015|It is proposed that humans have available to them two systems for interpreting natural language. One system is familiar from formal semantics. It is a type based system that pairs a syntactic form with its interpretation using grammatical rules of composition. This system delivers both plausible and implausible meanings. The other proposed system is one that uses the grammar together with knowledge of how the human production system works. It is token based and only delivers plausible meanings, including meanings based on a repaired input when the input might have been produced as a speech error.|Natural language interpretation; Speech error reversal; Mismatch ellipsis; Syntactic blends; Acceptable ungrammaticality; Noisy channel; Good enough processing|VERB PHRASES; COMPREHENSION; ELLIPSIS; SPEECH; BLENDS|Linguistics; Psychology, Experimental|1|0|4
Metaphonological awareness in multilinguals: a case of L3 Polish|2015|The paper focuses on an unexplored area of metalinguistic awareness in the acquisition of third language (L3) phonology, hereafter referred to as metaphonological awareness. It addresses the role of attention and noticing in input processing. The contribution constitutes a part of a larger scale project on metaphonological awareness in various multilingual settings investigated through the application of stimulated recall verbal protocols. The study involved quasi-concurrent retrospective and introspective protocols, in which the participants were asked to attend to, modify, and comment on their phonological output in L3 Polish after listening to an excerpt of their previous text reading recording. The investigation aimed to explore qualitative and quantitative aspects of metaphonological awareness manifested through the participants' self-repair and modifications of pronunciation mistakes in L3 Polish, reflective metalinguistic analysis of their oral performance in L3, intentional focus on articulatory gestures, self-awareness of problems in L3 pronunciation, the level of metacognitive control, and comments on the pronunciation learning process. Explored from a multilingual perspective, the construct of metaphonological awareness was demonstrated to entail an interaction of metalinguistic awareness as well as cross-linguistic awareness and to be an essential component of multilingual competence.|verbal protocols; L3 acquisition; metaphonological awareness; noticing|2ND-LANGUAGE PRONUNCIATION; METALINGUISTIC AWARENESS; LANGUAGE|Linguistics; Language \& Linguistics|4|2|4
The Discourse of Controlling ``Illegal Immigration{''} in Irish Parliamentary Texts|2015|``Illegal immigration{''} occurs at a quite small scale in the Irish context, especially when compared to other European countries. Nevertheless, there is a significant level of discussion about ``illegal immigration{''} in the Irish Parliament. Through the conceptual frameworks of Foucauldian thought and Critical Discourse Analysis, this paper undertakes a Topoi Analysis to examine discursive representations from the Irish Parliament (2002-2009). It concentrates upon the most common argumentation forwarded by parliamentarians - the need to control ``illegal immigration{''} in Ireland. This argumentation is expressed through various discourses. Notably, these discourses are juxtaposed with positive representations of the ``undocumented Irish{''} in the U.S. Overall, it is argued that negative control discourses about ``illegal immigrants{''} in Ireland provide a number of functions: (i) the legitimization and continuation of the nation-state rationale of governance, (ii) the provision of a forum for implicit expressions of racism, and (iii) the acceptance of ``justified{''} practices of exclusion of unwanted non-EU migrants.|Parliament; Control; Illegal Immigration; Critical Discourse Analysis; Topoi Analysis; Governmentality; National Identity|NORTHERN-IRELAND; POLITICS; POLICY; DEBATE; MATTER; LAW|Linguistics; Language \& Linguistics|0|0|4
The mortgage crisis and its denominations|2015|All living languages have the potential to coin neologisms which is indicative of their vitality to translate new knowledge and the ensuing changes in society. In economic and financial discourse, analysts, experts and popularisers often resort to figures of speech when explaining new realities in this area field, thus enabling them to have a greater impact on the recipients. The aim of this paper, based on a research corpus of texts spanning the 2007-2012 economic crisis taken from the press of four different European countries, is to attempt to resolve the difficulties involved with this kind of terminology. The questions addressed include the following: the attitude of the speakers of Romance languages towards the introduction of new concepts relating to the crisis; the field associated with each expression in the different cultures; to what extent conceptual metaphors coincide between cultures; the terminological variations involved in each case, etc. The answers to these questions can facilitate improved translator performance. The time lapse between the appearance of these terms and their inclusion in dictionaries poses a problem for translators who need to find solutions as quickly as possible, whilst at the same time providing a systematic approach to the problems encountered. Above and beyond solutions provided by dictionaries alone, translators are often faced with a choice between the terms found in vivo and those found in vitro. While an analysis of the way each concept is handled by dictionaries falls beyond the scope of our stated aims, it cannot be ignored completely inasmuch as it makes it possible to shed light on institutional terminological policies as well as divergences between the recommended standard and actual usage. At the same time, it should also be acknowledged that, despite the influx of terms within a globalised economy, there is still room for each community to maintain its own cultural specificity.|sub-prime crisis; metaphor; neologism; terminology; translation|METAPHOR|Linguistics; Language \& Linguistics|0|1|4
Comparison of a semi-automatic annotation tool and a natural language processing application for the generation of clinical statement entries|2015|Background and objective Electronic medical records with encoded entries should enhance the semantic interoperability of document exchange. However, it remains a challenge to encode the narrative concept and to transform the coded concepts into a standard entry-level document. This study aimed to use a novel approach for the generation of entry-level interoperable clinical documents. Methods Using HL7 clinical document architecture (CDA) as the example, we developed three pipelines to generate entry-level CDA documents. The first approach was a semi-automatic annotation pipeline (SAAP), the second was a natural language processing (NLP) pipeline, and the third merged the above two pipelines. We randomly selected 50 test documents from the i2b2 corpora to evaluate the performance of the three pipelines. Results The 50 randomly selected test documents contained 9365 words, including 588 Observation terms and 123 Procedure terms. For the Observation terms, the merged pipeline had a significantly higher F-measure than the NLP pipeline (0.89 vs 0.80, p<0.0001), but a similar F-measure to that of the SAAP (0.89 vs 0.87). For the Procedure terms, the F-measure was not significantly different among the three pipelines. Conclusions The combination of a semi-automatic annotation approach and the NLP application seems to be a solution for generating entry-level interoperable clinical documents.|natural language processing; auto-complete technique; CDA entry level|BIOMEDICAL TEXT; ARCHITECTURE; EXTRACTION; DOCUMENTS; ALGORITHM; SUPPORT; SYSTEM; UMLS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|2|1|4
A novel method of adverse event detection can accurately identify venous thromboembolisms (VTEs) from narrative electronic health record data|2015|Background Venous thromboembolisms (VTEs), which include deep vein thrombosis (DVT) and pulmonary embolism (PE), are associated with significant mortality, morbidity, and cost in hospitalized patients. To evaluate the success of preventive measures, accurate and efficient methods for monitoring VTE rates are needed. Therefore, we sought to determine the accuracy of statistical natural language processing (NLP) for identifying DVT and PE from electronic health record data. Methods We randomly sampled 2000 narrative radiology reports from patients with a suspected DVT/PE in Montreal (Canada) between 2008 and 2012. We manually identified DVT/PE within each report, which served as our reference standard. Using a bag-of-words approach, we trained 10 alternative support vector machine (SVM) models predicting DVT, and 10 predicting PE. SVM training and testing was performed with nested 10-fold cross-validation, and the average accuracy of each model was measured and compared. Results On manual review, 324 (16.2\%) reports were DVT-positive and 154 (7.7\%) were PE-positive. The best DVT model achieved an average sensitivity of 0.80 (95\% CI 0.76 to 0.85), specificity of 0.98 (98\% CI 0.97 to 0.99), positive predictive value (PPV) of 0.89 (95\% CI 0.85 to 0.93), and an area under the curve (AUC) of 0.98 (95\% CI 0.97 to 0.99). The best PE model achieved sensitivity of 0.79 (95\% CI 0.73 to 0.85), specificity of 0.99 (95\% CI 0.98 to 0.99), PPV of 0.84 (95\% CI 0.75 to 0.92), and AUC of 0.99 (95\% CI 0.98 to 1.00). Conclusions Statistical NLP can accurately identify VTE from narrative radiology reports.|support vector machines; automated text classification; deep vein thrombosis; pulmonary embolism; acute care hospital; natural language processing|CLINICAL TEXT CLASSIFICATION; SUPPORT VECTOR MACHINE; POSTOPERATIVE-COMPLICATIONS; INFORMATION-TECHNOLOGY; PULMONARY-HYPERTENSION; FEATURE-SELECTION; IDENTIFICATION; CARE; SURVEILLANCE; PREVENTION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|15|0|4
ASYMMETRIES IN THE PROSODIC PHRASING OF FUNCTION WORDS: ANOTHER LOOK AT THE SUFFIXING PREFERENCE|2014|It is a well-known fact that across the world's languages there is a fairly strong asymmetry in the affixation of grammatical material, in that suffixes considerably outnumber prefixes in typological databases. This article argues that prosody, specifically prosodic phrasing, plays an important part in bringing about this asymmetry. Prosodic word and phrase boundaries may occur after a clitic function word preceding its lexical host with sufficient frequency so as to impede the fusion required for affixhood. Conversely, prosodic boundaries rarely, if ever, occur between a lexical host and a clitic function word following it. Hence, prosody does not impede the fusion process between lexical hosts and postposed function words, which therefore become affixes more easily. Evidence for the asymmetry in prosodic phrasing is provided from two sources: disfluencies, and ditropic cliticization, that is, the fact that grammatical PRoclitics may be phonological ENclitics (i.e. phrased with a preceding host), but grammatical enclitics are never phonological proclitics. Earlier explanations for the suffixing preference have neglected prosody almost completely and thus also missed the related asymmetry in ditropic cliticization. More importantly, the evidence from prosodic phrasing suggests a new venue for explaining the suffixing preference. The asymmetry in prosodic phrasing, which, according to the hypothesis proposed here, is a major factor underlying the suffixing preference, has a natural basis in the mechanics of turn-taking as well as in the mechanics of speech production.{*|affixes; clitics; language processing; turn-taking; grammaticization; explanation in typology; Tagalog|SPONTANEOUS SPEECH; INTONATION UNITS; TURN-TAKING; CONVERSATION; CLITICIZATION; UNIVERSALS; FREQUENCY; PAUSES|Linguistics; Language \& Linguistics|11|0|4
Evaluating the effects of cognitive support on psychiatric clinical comprehension|2014|Objective: Clinicians' attention is a precious resource, which in the current healthcare practice is consumed by the cognitive demands arising from complex patient conditions, information overload, time pressure, and the need to aggregate and synthesize information from disparate sources. The ability to organize information in ways that facilitate the generation of effective diagnostic solutions is a distinguishing characteristic of expert physicians, suggesting that automated systems that organize clinical information in a similar manner may augment physicians' decision-making capabilities. In this paper, we describe the design and evaluation of a theoretically driven cognitive support system (CSS) that assists psychiatrists in their interpretation of clinical cases. The system highlights, and provides the means to navigate to, text that is organized in accordance with a set of diagnostically and therapeutically meaningful higher-level concepts. Methods and materials: To evaluate the interface, 16 psychiatry residents interpreted two clinical case scenarios, with and without the CSS. Think-aloud protocols captured during their interpretation of the cases were transcribed and analyzed qualitatively. In addition, the frequency and relative position of content related to key higher-level concepts in a verbal summary of the case were evaluated. In addition the transcripts from both groups were compared to an expert derived reference standard using latent semantic analysis (LSA). Results: Qualitative analysis showed that users of the system better attended to specific clinically important aspects of both cases when these were highlighted by the system, and revealed ways in which the system mediates hypotheses generation and evaluation. Analysis of the summary data showed differences in emphasis with and without the system. The LSA analysis suggested users of the system were more ``expert-like{''} in their emphasis, and that cognitive support was more effective in the more complex case. Conclusions: Cognitive support impacts upon clinical comprehension. This appears to be largely helpful, but may also lead to neglect of information (such as the psychosocial history) that the system does not highlight. The results have implications for the design of CSSs for clinical narratives including the role of information organization and textual embellishments for more efficient clinical case presentation and comprehension. (C) 2014 Elsevier B.V. All rights reserved.|Biomedical informatics; Cognitive science; Clinical comprehension; Cognitive support; Latent semantic analysis; Propositional analysis; Verbal protocol analysis; Psychiatry; Emergency psychiatry|LATENT SEMANTIC ANALYSIS; MEDICAL DECISION-MAKING; KNOWLEDGE; EXPERTISE|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|1|1|4
De-identification of clinical notes in French: towards a protocol for reference corpus development|2014|Background: To facilitate research applying Natural Language Processing to clinical documents, tools and resources are needed for the automatic de-identification of Electronic Health Records. Objective: This study investigates methods for developing a high-quality reference corpus for the de-identification of clinical documents in French. Methods: A corpus comprising a variety of clinical document types covering several medical specialties was pre-processed with two automatic de-identification systems from the MEDINA suite of tools: a rule-based system and a system using Conditional Random Fields (CRF). The pre-annotated documents were revised by two human annotators trained to mark ten categories of Protected Health Information (PHI). The human annotators worked independently and were blind to the system that produced the pre-annotations they were revising. The best pre-annotation system was applied to another random selection of 100 documents. After revision by one annotator, this set was used to train a statistical de-identification system. Results: Two gold standard sets of 100 documents were created based on the consensus of two human revisions of the automatic pre-annotations. The annotation experiment showed that (i) automatic pre-annotation obtained with the rule-based system performed better (F = 0.813) than the CRF system (F = 0.519), (ii) the human annotators spent more time revising the pre-annotations obtained with the rule-based system (from 102 to 160 minutes for 50 documents), compared to the CRF system (from 93 to 142 minutes for 50 documents), (iii) the quality of human annotation is higher when pre-annotations are obtained with the rule-based system (F-measure ranging from 0.970 to 0.987), compared to the CRF system (F-measure ranging from 0.914 to 0.981). Finally, only 20 documents from the training set were needed for the statistical system to outperform the pre-annotation systems that were trained on corpora from a medical speciality and hospital different from those in the reference corpus developed herein. Conclusion: We find that better pre-annotations increase the quality of the reference corpus but require more revision time. A statistical de-identification method outperforms our rule-based system when as little as 20 custom training documents are available. (C) 2013 Elsevier Inc. All rights reserved.|Confidentiality; Electronic Health Records; France; Information Dissemination; Natural Language Processing|ELECTRONIC HEALTH RECORD; MEDICAL-RECORDS; MIMIC-II; TEXT; INFORMATION; DOCUMENTS; ANONYMIZATION; AGREEMENT; DATABASE; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|6|1|4
Evaluating the effects of machine pre-annotation and an interactive annotation interface on manual de-identification of clinical text|2014|The Health Insurance Portability and Accountability Act (HIPAA) Safe Harbor method requires removal of 18 types of protected health information (PHI) from clinical documents to be considered ``de-identified{''} prior to use for research purposes. Human review of PHI elements from a large corpus of clinical documents can be tedious and error-prone. Indeed, multiple annotators may be required to consistently redact information that represents each PHI class. Automated de-identification has the potential to improve annotation quality and reduce annotation time. For instance, using machine-assisted annotation by combining de-identification system outputs used as pre-annotations and an interactive annotation interface to provide annotators with PHI annotations for ``curation{''} rather than manual annotation from ``scratch{''} on raw clinical documents. In order to assess whether machine-assisted annotation improves the reliability and accuracy of the reference standard quality and reduces annotation effort, we conducted an annotation experiment. In this annotation study, we assessed the generalizability of the VA Consortium for Healthcare Informatics Research (CHIR) annotation schema and guidelines applied to a corpus of publicly available clinical documents called MTSamples. Specifically, our goals were to (1) characterize a heterogeneous corpus of clinical documents manually annotated for risk-ranked PHI and other annotation types (clinical eponyms and person relations), (2) evaluate how well annotators apply the CHIR schema to the heterogeneous corpus, (3) compare whether machine-assisted annotation (experiment) improves annotation quality and reduces annotation time compared to manual annotation (control), and (4) assess the change in quality of reference standard coverage with each added annotator's annotations. Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license.|Natural language processing; Medical informatics; Confidentiality; Patient data privacy; De-identification; Anonymization; Electronic health records; Clinical corpora|HEALTH INFORMATION; DOCUMENTS; SYSTEM; RECORDS; TOOL|Computer Science, Interdisciplinary Applications; Medical Informatics|8|1|4
But qui c'est la difference? Discourse markers in Louisiana French: The case of but vs. mais|2014|This article examines the use of English discourse markers in Louisiana French, focusing in particular on English but and its French counterpart mais. Based on data collected in Terrebonne and Lafourche Parishes, we examine the speech of bilinguals to determine the status of these markers, which provide a window onto the role of discourse markers in situations of language contact. Though the markers show an overlapping semantic and functional distribution, but more often appears in the context of at least one pause. We also provide acoustic evidence and an analysis of the markers in different functions to conclude that the need for iconic contrast via language mixing (Maschler 1994, 1997; de Rooij 2000) is only one possible motivation for the use of foreign markers. We conclude that discourse markers may carry social meaning and be the site of identity construction as much as they are the site of text organization.|Discourse markers; bilingual discourse; codeswitching; language shift|CONVERSATION; SPANISH; GERMAN|Linguistics; Sociology|1|0|4
The pragmatics of insinuation|2014|In this paper, I focus on insinuation as a communicative strategy whereby a speaker intends to make an addressee believe p, but does not want to be held accountable for communicating p. In its micro- or macro-textual format, and in its various degrees of nastiness, insinuation, I claim, is a complex process that presupposes the mind's capability to simultaneously activate and run multiple parallel mental spaces, associated to different intentions. Through the analysis of some examples, indirectness, manipulation, and deception will be shown to be involved in the process to varying degrees. In the final section of the paper I discuss how a Relevance-theoretic framework is able to accommodate the cognitive aspects of insinuation highlighted in the text.|insinuation; indirectness; deception; manipulation; cognition|RELEVANCE|Linguistics; Language \& Linguistics|3|0|4
A semantic model for scholarly electronic publishing in Biomedical Sciences|2014|Despite numerous advancements in information technology, electronic publishing is still based on the print text model. The natural language textual format prevents programs from semantically processing article content. A semantic model for scholarly electronic publishing is proposed, in which the article conclusion is specified by the author and recorded in a machine-understandable format, enabling semantic retrieval, identification of traces of scientific discoveries and knowledge misunderstandings. 89 biomedical articles were analyzed for this purpose. A content model comprising semantic elements and their sequences in articles is developed. Four patterns of reasoning and sequencing of semantic elements were identified in the analyzed articles. The development and testing of a prototype of a Web submission interface to an electronic journal system that partially implements the proposed model are reported.|Electronic publishing; scientific communication; knowledge representation; ontologies; semantic content processing; scientific discovery; e-science|TETRAHYMENA; ONTOLOGIES; TELOMERES; YEAST; WEB|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory \& Methods|1|0|4
A cognitive sociolinguistic approach to metaphor and denominative variation A case study of marine biology terms|2014|This research applied corpus analysis techniques to a corpus of marine biology texts in Peninsular Spanish (PS) and Latin American Spanish (LAS). The results explain why these varieties of Spanish have different designations for the same sea organism. The focus of our research was thus on types of formal onomasiological variation (Geeraerts, Grondelaers, \& Bakema, 1994) and its pervasiveness in Spanish scientific discourse. Also addressed was the incidence of metaphor in specialized concept formation and designation. Domain-specific and standard strategies were used for the semi-automatic retrieval of metaphorical terms. The resulting qualitative and quantitative account of terminological diversity reflected the pervasiveness of intralingual denominative variation in scientific language and also identified its causes.|intralingual variation; cognitive sociolinguistics; metaphor|BRITISH; SYSTEM; CHILE|Linguistics; Language \& Linguistics|0|1|4
Migrating literacies: multimodal texts and digitally enabled text making|2014|This article examines the social shaping of texts in digital environments and proposes the notion of migrating literacies to theorize how urban youth materialize meaning using grammars of digitally enabled design. A working definition of migrating literacies identifies digitally enabled text making as having social, technological, and semiotic affordances for managing affiliations across discourse communities. Drawing from ethnographic data, the analysis will account for the appearance of cultural remix through the shaping of multimodal ensembles and how they move across digital spaces. Key findings contribute to the need for addressing the challenge of multimodality to understanding shifting notions of text in an increasingly diverse and digital society.|multimodality; literacy; text; migration; communities; digital technologies|CLASSROOM PRACTICE; IDENTITIES; MULTILITERACIES; SCHOOL; VIDEO|Communication; Linguistics; Language \& Linguistics|2|0|4
The influence of non-native morphosyntax on the intelligibility of a closely related language|2013|This study investigates the effect of morphosyntactic differences on our ability to comprehend a closely related language. Previous studies of mutual intelligibility, or receptive bilingualism, have focussed largely on the role of extra-linguistic, lexical, or phonetic factors. Although there is reason to believe that differences in morphology and syntax might worsen the ability to comprehend a closely related linguistic variety, this claim is previously untested. This article reports an experimental investigation of whether Danes' comprehension of the closely related language Norwegian is impeded by certain Norwegian grammatical constructions. We tested sentence comprehension experimentally in four different conditions to assess the relative effect of non-native morphosyntactic features as opposed to non-native phonology on intelligibility. Correctness rates of the responses and reaction times were measured. Results indicate that word-order differences cause larger problems for listeners than morphological differences. However, the non-native phonology featured in the experiment impedes comprehension to a larger degree than the morphosyntactic differences do. Our results have implications for work in natural language processing as well as for studies in speech comprehension, particularly those applied to situations of language learning and teaching in areas where receptive bilingualism is widespread. (C) 2013 Elsevier B.V. All rights reserved.|Mutual intelligibility; Syntactic parsing; Non-native morphology; Non-native syntax; Scandinavian languages; Receptive bilingualism|COMPREHENSION|Linguistics; Language \& Linguistics|5|1|4
A methodology for extending domain coverage in SemRep|2013|We describe a domain-independent methodology to extend SemRep coverage beyond the biomedical domain. SemRep, a natural language processing application originally designed for biomedical texts, uses the knowledge sources provided by the Unified Medical Language System (UMLS (c)). Ontological and terminological extensions to the system are needed in order to support other areas of knowledge. We extended SemRep's application by developing a semantic representation of a previously unsupported domain. This was achieved by adapting well-known ontology engineering phases and integrating them with the UMLS knowledge sources on which SemRep crucially-depends. While the process to extend SemRep coverage has been successfully applied in earlier projects, this paper presents in detail the step-wise approach we followed and the mechanisms implemented. A case study in the field of medical informatics illustrates how the ontology engineering phases have been adapted for optimal integration with the UMLS. We provide qualitative and quantitative results, which indicate the validity and usefulness of our methodology. Published by Elsevier Inc.|Natural language processing application; Domain-independent ontology development methodology; Semantic predications; UMLS knowledge sources|BIOMEDICAL TEXT; KNOWLEDGE; ONTOLOGY; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|2|0|4
Reading in Context: The Interpretation of Personal Reference in Ancient Maya Hieroglyphic Texts|2013|The interpretation of deixis in language is heavily context-dependent. In spoken language, the addressee(s) have the context of an utterance to aid in its interpretation. In writing, however, language can become separated from both its creator and the context of its creation. This article investigates the use of certain deicticsfirst and second person markersin ancient Maya hieroglyphics (circa AD 250-900). The temporal and cultural gap that separates modern language scholars from the creators of these texts means that much of the larger cultural context in which these texts would have been interpreted has been lost. An analysis of the way in which first and second person reference was framed and deployed in Maya hieroglyphs, even when identifying the intended referent proves impossible, provides insights concerning how people recontextualize textual language and how the authors of these texts adapted the form of their messages in response to the modality used.|person reference; textuality; Mayan languages; indexicality|LANGUAGE|Anthropology; Linguistics; Language \& Linguistics|6|0|4
A controlled greedy supervised approach for co-reference resolution on clinical text|2013|Identification of co-referent entity mentions inside text has significant importance for other natural language processing (NLP) tasks (e.g. event linking). However, this task, known as co-reference resolution, remains a complex problem, partly because of the confusion over different evaluation metrics and partly because the well-researched existing methodologies do not perform well on new domains such as clinical records. This paper presents a variant of the influential mention-pair model for co-reference resolution. Using a series of linguistically and semantically motivated constraints, the proposed approach controls generation of less-informative/sub-optimal training and test instances. Additionally, the approach also introduces some aggressive greedy strategies in chain clustering. The proposed approach has been tested on the official test corpus of the recently held i2b2/VA 2011 challenge. It achieves an unweighted average F-1 score of 0.895, calculated from multiple evaluation metrics (MUC, B-3 and CEAF scores). These results are comparable to the best systems of the challenge. What makes our proposed system distinct is that it also achieves high average F-1 scores for each individual chain type (Test: 0.897, Person: 0.852, Problem: 0.855, Treatment: 0.884). Unlike other works, it obtains good scores for each of the individual metrics rather than being biased towards a particular metric. (C) 2013 Elsevier Inc. All rights reserved.|Natural language processing; Co-reference resolution; Clinical text; Knowledge engineering; Machine learning|COREFERENCE RESOLUTION; INFORMATION; RECORDS; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|1|1|4
Locality|2013|Natural language syntax is unbounded, but syntactic processes respect fundamental locality principles. The purpose of this paper is to illustrate linguistic locality through various phenomena uncovered by formal and comparative syntacticians, and show the relevance of syntactic locality for the experimental study of language as a cognitive capacity, both in acquisition and in adult speakers. Two major concepts of locality seem to be operative: impenetrability, expressing the fact that certain syntactic configurations are impervious to rules (e.g., island constraints), and intervention locality, blocking movement and other processes across an intervening element. This paper will focus on a subclass of locality effects, looking at intervention on movement dependencies. One crucial property of intervention locality is that it is calculated in hierarchical, not in linear terms, the crucial hierarchical relation being c-command: this is just a subcase of the general fact that linguistic computations are typically sensitive to hierarchical properties (dominance, c-command) rather then to linear properties (precedence in the linear order). The paper will present featural Relativized Minimality, a particularformal implementation of intervention locality, will illustrate its application through various kinds of locality effect in cases of extractions from embedded domains, and will show its explanatory capacity not only on issues of comparative syntax, but also on aspects of the acquisition of syntactic dependencies. (C) 2013 Elsevier B.V. All rights reserved.|Syntax; Acquisition; Locality; Intervention; Relativized minimality; Weak islands|SENTENCE COMPLEXITY; RELATIVE CLAUSES; COMPREHENSION; AGREEMENT|Linguistics; Language \& Linguistics|24|2|4
`It's all red ink': The interpretation of biblical metaphor among Evangelical Christian YouTube users|2013|Among Evangelical Christians on the popular video-sharing site YouTube, the Bible is an important resource for justifying and challenging specific words and actions. Such justifications and challenges provide researchers with an opportunity to study how authoritative text is interpreted in social interaction. To that end, this article presents analysis of a single debate - an episode of what YouTube users call `drama' - around one Evangelical Christian's controversial use of a passage from the Bible to justify calling others `human garbage'. This analysis shows first, that conflicting interpretations and use of the Bible's moral authority led to the development of `drama' because users evidenced differing beliefs about the development of biblical metaphorical language; and second, that users appropriated the Bible's words to their own discourse activity through exegesis and metaphor development. This article thus provides both an empirical case study in the interpretation of figurative language and a challenge to the common assumption that Evangelical Christians are committed to a `literal' interpretation of the Bible.|Argument; Bible; computer-mediated communication; exegesis; metaphor; interpretation; YouTube|LITERARY INTERPRETATION; LANGUAGE|Linguistics; Language \& Linguistics|4|0|4
Iterating semantic automata|2013|The semantic automata framework, developed originally in the 1980s, provides computational interpretations of generalized quantifiers. While recent experimental results have associated structural features of these automata with neuroanatomical demands in processing sentences with quantifiers, the theoretical framework has remained largely unexplored. In this paper, after presenting some classic results on semantic automata in a modern style, we present the first application of semantic automata to polyadic quantification, exhibiting automata for iterated quantifiers. We also discuss the role of semantic automata in linguistic theory and offer new empirical predictions for sentence processing with embedded quantifiers.|Semantic automata; Generalized quantifiers; Iteration; Processing|QUANTIFIER COMPREHENSION; GENERALIZED QUANTIFIERS; NATURAL-LANGUAGE; LINGUISTICS; PSYCHOLOGY; MODEL; LOGIC|Linguistics; Language \& Linguistics|3|0|4
Input processing of Chinese by ab initio learners|2013|We report on a study of first-exposure learners with different first languages (L1s: English, Japanese) to examine their ability to process input for form and meaning. We used a rich set of tasks to tap respectively into processing, comprehension, imitation, and working memory. We show that there are advantages to having a first language (L1) that brings familiarity with the target language. We also show that when presented with natural auditory input, learners are able to process form only minimally. These findings are inconsistent with other studies that suggest that segmentation is easy and rapid. Additionally, we show that such learners comprehend meaning by relying on `top-down' strategies. These findings challenge some of the claims on Input Processing theory.|Keywords Chinese as a second language; form and meaning; input processing|WORKING-MEMORY; ACQUISITION; ENGLISH|Education \& Educational Research; Linguistics|7|0|4
Acquisition and evaluation of verb subcategorization resources for biomedicine|2013|Background: Biomedical natural language processing (NLP) applications that have access to detailed resources about the linguistic characteristics of biomedical language demonstrate improved performance on tasks such as relation extraction and syntactic or semantic parsing. Such applications are important for transforming the growing unstructured information buried in the biomedical literature into structured, actionable information. In this paper, we address the creation of linguistic resources that capture how individual biomedical verbs behave. We specifically consider verb subcategorization, or the tendency of verbs to ``select{''} co-occurrence with particular phrase types, which influences the interpretation of verbs and identification of verbal arguments in context. There are currently a limited number of biomedical resources containing information about subcategorization frames (SCFs), and these are the result of either labor-intensive manual collation, or automatic methods that use tools adapted to a single biomedical subdomain. Either method may result in resources that lack coverage. Moreover, the quality of existing verb SCF resources for biomedicine is unknown, due to a lack of available gold standards for evaluation. Results: This paper presents three new resources related to verb subcategorization frames in biomedicine, and four experiments making use of the new resources. We present the first biomedical SCF gold standards, capturing two different but widely-used definitions of subcategorization, and a new SCF lexicon, BioCat, covering a large number of biomedical sub-domains. We evaluate the SCF acquisition methodologies for BioCat with respect to the gold standards, and compare the results with the accuracy of the only previously existing automatically-acquired SCF lexicon for biomedicine, the BioLexicon. Our results show that the BioLexicon has greater precision while BioCat has better coverage of SCFs. Finally, we explore the definition of subcategorization using these resources and its implications for biomedical NLP. All resources are made publicly available. Conclusion: The SCF resources we have evaluated still show considerably lower accuracy than that reported with general English lexicons, demonstrating the need for domain- and subdomain-specific SCF acquisition tools for biomedicine. Our new gold standards reveal major differences when annotators use the different definitions. Moreover, evaluation of BioCat yields major differences in accuracy depending on the gold standard, demonstrating that the definition of subcategorization adopted will have a direct impact on perceived system accuracy for specific tasks. (c) 2013 Elsevier Inc. All rights reserved.|Verb subcategorization; Lexical resources; Natural language processing; Biomedical text processing|ANNOTATED CORPUS|Computer Science, Interdisciplinary Applications; Medical Informatics|2|0|4
Migrant life stories and the Web: the experience of having your life story made public|2013|The life stories of migrants are increasingly being told, as part of the work of cultural organizations, and websites are well suited to making such life story projects accessible to the public. However, by using the lives of real people as raw material in a public forum, Web projects raise important questions about the terms on which participants are given a voice. This article focuses on a Danish website which depicts the life stories of migrant men through written texts, audio clips, and photographs. It presents a detailed analysis of the life story of one young man from a Muslim background who has openly declared himself an atheist. The article examines his experience of having this somewhat sensitive story made public. The religious aspect inevitably positioned his story in relation to broader political debates about Muslims in Denmark. Since migrants' stories often touch on highly politicized issues, it is crucial that their stories are not co-opted by societal discourses which they do not themselves support.|life stories; websites; migration; Muslim youth; atheism; Denmark|DISCURSIVE PSYCHOLOGY|Humanities, Multidisciplinary; Communication; Linguistics|2|0|4
Discussing culturally relevant books online: A cross-cultural blogging project|2012|This article examines the process and results of a two-year cross-cultural blogging project conducted between American fifth-graders (15 students) and Taiwanese tenth-graders (23 students). The two groups of students used a blog to correspond with each other and share their reading responses of culturally relevant picture books. The goal of the project was to provide the students with opportunities to appreciate reading texts relevant to their cultural experiences, while using the blog to engage in authentic conversations with and reflect on the experiences of people from another culture. Data were collected from multiple sources, including pre-project surveys, students' blog entries, students' retrospective interviews, and the researchers' field notes. Data analysis helped answer the research questions: What were the students' learning experiences, and what factors helped form the experiences? The findings suggest that students gained deeper understandings of another culture, as well as the texts, as they were offered opportunities to communicate authentically with people of another culture. They also displayed more confidence and greater critical thinking skills when discussing culturally relevant picture books.|Blog; culturally relevant literacy; cross-cultural interaction; literature discussion|EXCHANGE; STUDENTS; WINDOW|Education \& Educational Research; Linguistics; Language \& Linguistics|1|0|4
THE MANY NARRATIVE FACES OF MEDICAL CASE REPORTS|2012|This paper presents the two-layered narrative nature of medical case reports. Firstly, individual case reports are complete stories of the patient's disease. These stories consist of several constituent parts dealing with presentation, diagnosis, treatment and recovery. Secondly, some case reports include smaller and more detailed stories, fragmented and scattered throughout the texts, which may deal not so much with all the stages of treatment but with various aspects of the patient's disease. The fragments emerge in various places of the report breaking the impersonal medical account, i.e. the voice of medicine, and introducing the patient's perspective, i.e. the patient's voice, and at times, the perspective of the doctor, i.e. the doctor's voice. The patient's third-person storyline addresses his/her experience of illness or decisions regarding treatment whereas the doctor's first-person storyline concerns possible treatment options or comments on various case-related matters. The examples illustrating the issues to be touched upon will come from the corpus of 56 medical case reports originating from British and American medical journals aimed at health professionals.|Discourse analysis; narrative; medical case reports; patient's voice; voice of medicine|ILLNESS NARRATIVES; PERSPECTIVE; STORIES; PATIENT; TALK; TIME; FORM|Linguistics; Language \& Linguistics|0|0|4
Message classification as a basis for studying command and control communications-an evaluation of machine learning approaches|2012|In military command and control, success relies on being able to perform key functions such as communicating intent. Most staff functions are carried out using standard means of text communication. Exactly how members of staff perform their duties, who they communicate with and how, and how they could perform better, is an area of active research. In command and control research, there is not yet a single model which explains all actions undertaken by members of staff well enough to prescribe a set of procedures for how to perform functions in command and control. In this context, we have studied whether automated classification approaches can be applied to textual communication to assist researchers who study command teams and analyze their actions. Specifically, we report the results from evaluating machine leaning with respect to two metrics of classification performance: (1) the precision of finding a known transition between two activities in a work process, and (2) the precision of classifying messages similarly to human researchers that search for critical episodes in a workflow. The results indicate that classification based on text only provides higher precision results with respect to both metrics when compared to other machine learning approaches, and that the precision of classifying messages using text-based classification in already classified datasets was approximately 50\%. We present the implications that these results have for the design of support systems based on machine learning, and outline how to practically use text classification for analyzing team communications by demonstrating a specific prototype support tool for workflow analysis.|Command and control; Classification; Exploratory sequential data analysis; Workflow mining; Random indexing; Text clustering|SEQUENTIAL DATA-ANALYSIS|Computer Science, Artificial Intelligence; Computer Science, Information Systems|0|0|4
The symbolic construction of communism in Turkish anti-communist propaganda during the Cold War|2012|The aim of this study is to analyse cultural and social referential importance of the stereotypes of communists/communism in the anti-communist propaganda texts circulated in Turkey during the Cold War. The article displays the symbolism underlying anti-communist discourse by re-reading the propaganda material as texts that introduce the reader to ultimate anti-communist fantasies. The analyzed texts were mainly produced by one of the leading participants of anti-communist struggle, namely the Association for Fighting Communism in Turkey (AFCT) (Turkiye Komunizmle Mucadele Dernegi, TKMD, 1963-1977), and its members. The article shows that the analyzed anti-communist propaganda creates mystification as a strategy and builds a narration in which temporal, spatial, and personal references are obscure. The article also shows that anti-communist propaganda operates on traditional dichotomies nature/culture, emotion/reason, and body/mind and that the images of communists/communism are constructed by appealing to a variety of animal species connoting ``danger{''}; the unsocial connoting of the ``absence of rules{''} and animality; and the woman of desire recalling the ``immoral{''} in the popular imagination. It is argued that the texts are all interdiscursive thus allowing for the sexist, Islamist and nationalist arguments to be used as supportive subtopics while defending the anti-communist cause. The analysis also establishes intertextual relationship with the Nazi anti-Jewish and anti-communist discourse.|Discourse analysis; anti-communism in Turkey; Cold War anti-communist propaganda; Pan-Turkism; Nazi anti-Jewish discourse; Nazi anti-communist discourse|TURKEY|Linguistics; Language \& Linguistics|1|0|4
CORPUS ANALYSIS: A PRAGMATIC PERSPECTIVE ON TERM VARIATION|2012|An important issue with regard to terms in linguistics is the detection of term variation, which may be defined as the use of alternative names for the same concept, i.e. synonymy. Its causes include the different practices for the designation of terms employed by language users. For example, the use of alternative words in specific terminology among experts is commonplace, but this practice is not common among general users of language, who prefer to stick to popular terms. The differences may lead to the designation of a concept by means of different terms, a phenomenon known as term variation. As a result, a general user may utilise a term which is different from the one used in the technical corpus. In this paper, we aim to identify the types of term variation that can be found when contrasting specific texts in English and the way in which we can recognise some of the types of variation from a pragmatic perspective, i.e. depending on language use and the purpose of the user. First, we examine the types of variation which commonly occur in corpora compiled from specific texts, explaining the document pre-processing and the methodology followed. In the results and discussion section, we describe the method carried out to extract synonyms and the results are contrasted. Finally we conclude that, from a pragmatic perspective, the specificity of communicative acts plays a vital role in term variation.|Variation; terms; synonyms; specific texts|LANGUAGE; TERMINOLOGY; LINGUISTICS|Linguistics; Language \& Linguistics|0|0|4
Unsupervised Similarity Learning from Textual Data|2012|This paper presents a research on the construction of a new unsupervised model for learning a semantic similarity measure from text corpora. Two main components of the model are a semantic interpreter of texts and a similarity function whose properties are derived from data. The first one associates particular documents with concepts defined in a knowledge base corresponding to the topics covered by the corpus. it shifts the representation of a meaning of the texts from words that can be ambiguous to concepts with predefined semantics. With this new representation, the similarity function is derived from data using a modification of the dynamic rule-based similarity model, which is adjusted to the unsupervised case. The adjustment is based on a novel notion of an information bireduct having its origin in the theory of rough sets. This extension of classical information reducts is used in order to find diverse sets of reference documents described by diverse sets of reference concepts that determine different aspects of the similarity. The paper explains a general idea of the approach and also gives some implementation guidelines. Additionally, results of some preliminary experiments are presented in order to demonstrate usefulness of the proposed model.|Similarity learning; semantic similarity; text mining; feature extraction; bireducts|FEATURES|Computer Science, Software Engineering; Mathematics, Applied|6|0|4
Intertextuality and its role in the positioning of talk show participants|2012|The paper examines the discourse of the Czech weekly talk show Uvolnete se, prosim (Relax, please). For this purpose, we have chosen an interview of the moderator Jan Kraus with the former chairman of the Social Democratic Party of the Czech Republic, Jiri Paroubek, who was invited into the studio on the occasion of his appointment as prime minister in 2005. The analysis focuses on the polyphony of voices arising in the talk show and on the intertextual techniques used in the process of positioning the guest, as well as the self-positioning of the moderator. The interview is thus analyzed as an intertext built upon other texts, which are both external and internal to the current speech situation. The host's practices employ allusions to the voices coming from ``outside{''}, i.e. through the introduction of quotations of the voices of third parties and the guest's prior words, as well as responses to the voices heard ``inside{''} the current interaction, i.e. the host echoes the guest's utterances and moreover, assumes the guest's voice, positioning the prime minister mostly in an unfavorable, but humorous manner. The guest's work with these voices is also traced.|political discourse; intertextuality; talk show; polyphony; irony; parody|INTERVIEWS|Linguistics; Language \& Linguistics|1|0|4
So ADJ/ADV that clause patterns in Early Modern English medical writing|2012|This paper investigates how an intensifying phraseological pattern involving the adverb so followed by a delayed declarative content clause is used in medical English in the early modern period (1500-1700). So may occur with adjectival, nominal or adverbial heads, and the pattern is used for indicating degree, extent or manner. The analysis employs the recently published Early Modern English Medical Texts corpus to show (i) that the pattern was in use throughout the entire period, (ii) that it tends to be more frequently used in learned rather than popular texts, and (iii) that it is typically used for giving descriptions and less often in instructions.|Early Modern English; medical writing; phraseology; corpus linguistics|INTENSIFIERS; CORPUS; WEIRD; COOL|Linguistics; Language \& Linguistics|0|0|4
FRAMED IMAGES AS COUNTERPOINTS IN JAMES JOYCE'S `THE DEAD'|2011|This article aims to analyse the images presented within frames in James Joyce's `The Dead' as if they were descriptions of works of art, or ekphrases. It will be shown that the four main framed images reproduce a certain design established by the initial set, underlying once again the perfect structure as well as the complex intertwining between all the narrative elements of the text. Examining ekphrases involves a symbolic reading of the textual images, often leading to unexpected associations, which, at the same time, reinforce-like counterpoints-central aspects of the story. This analysis has also made it possible to focus on elements usually overlooked by Joycean criticism, such as the waistcoat that Gabriel's mother made for him. Since all the framed images may be considered as exploring and exhibiting Gabriel's inner conflicts, Lacan's psychoanalytic theory has provided an invaluable tool for understanding both the main character's epiphanic experience and the intense dynamics of those around him, including the spectral presences of his mother and Michael Furey. The two ekphrastic descriptions of unframed images-the supper table and the snow-will also be considered.|Ekphrasis; framed images; `The Dead'; Joyce; Lacan; Modernism|`DEAD'|Linguistics; Language \& Linguistics; Literature|1|0|4
Applying semantic-based probabilistic context-free grammar to medical language processing - A preliminary study on parsing medication sentences|2011|Semantic-based sublanguage grammars have been shown to be an efficient method for medical language processing. However, given the complexity of the medical domain, parsers using such grammars inevitably encounter ambiguous sentences, which could be interpreted by different groups of production rules and consequently result in two or more parse trees. One possible solution, which has not been extensively explored previously, is to augment productions in medical sublanguage grammars with probabilities to resolve the ambiguity. In this study, we associated probabilities with production rules in a semantic-based grammar for medication findings and evaluated its performance on reducing parsing ambiguity. Using the existing data set from 2009 i2b2 NLP (Natural Language Processing) challenge for medication extraction, we developed a semantic-based CFG (Context Free Grammar) for parsing medication sentences and manually created a Treebank of 4564 medication sentences from discharge summaries. Using the Treebank, we derived a semantic-based PCFG (Probabilistic Context Free Grammar) for parsing medication sentences. Our evaluation using a 10-fold cross validation showed that the PCFG parser dramatically improved parsing performance when compared to the CFG parser. (C) 2011 Elsevier Inc. All rights reserved.|Natural Language Processing; Parsing; Probabilistic context free grammar; Sublanguage grammars|CLINICAL RADIOLOGY; EXTRACTION SYSTEM; TEXT; RECORDS; REPRESENTATION; INFORMATION; KNOWLEDGE|Computer Science, Interdisciplinary Applications; Medical Informatics|1|1|4
Deriving a probabilistic syntacto-semantic grammar for biomedicine based on domain-specific terminologies|2011|Biomedical natural language processing (BioNLP) is a useful technique that unlocks valuable information stored in textual data for practice and/or research. Syntactic parsing is a critical component of BioNLP applications that rely on correctly determining the sentence and phrase structure of free text. In addition to dealing with the vast amount of domain-specific terms, a robust biomedical parser needs to model the semantic grammar to obtain viable syntactic structures. With either a rule-based or corpus-based approach, the grammar engineering process requires substantial time and knowledge from experts, and does not always yield a semantically transferable grammar. To reduce the human effort and to promote semantic transferability, we propose an automated method for deriving a probabilistic grammar based on a training corpus consisting of concept strings and semantic classes from the Unified Medical Language System (UMLS), a comprehensive terminology resource widely used by the community. The grammar is designed to specify noun phrases only due to the nominal nature of the majority of biomedical terminological concepts. Evaluated on manually parsed clinical notes, the derived grammar achieved a recall of 0.644, precision of 0.737, and average cross-bracketing of 0.61, which demonstrated better performance than a control grammar with the semantic information removed. Error analysis revealed shortcomings that could be addressed to improve performance. The results indicated the feasibility of an approach which automatically incorporates terminology semantics in the building of an operational grammar. Although the current performance of the unsupervised solution does not adequately replace manual engineering, we believe once the performance issues are addressed, it could serve as an aide in a semi-supervised solution. (C) 2011 Elsevier Inc. All rights reserved.|Natural language processing; Biomedical terminology; Semantic grammar; Probabilistic parsing|CLINICAL RADIOLOGY; LANGUAGE SYSTEM; TEXT; LEXICON; IDENTIFICATION; EXTRACTION|Computer Science, Interdisciplinary Applications; Medical Informatics|4|0|4
Spectral measures of the effects of Friedreich's ataxia on speech|2011|This study identifies two measures of the effects of Friedreich's ataxia (FRDA) on speech motor control. Speech samples of 17 healthy controls and 37 speakers with dysarthria associated with FRDA were recorded during one structured and one unstructured speaking task. Two measures of spectral variation were used that relate to the rate and range of changes that occur in the spectral envelope. Linear mixed models revealed significant effects of GROUP, TASK, and GROUP star TASK. FRDA speech samples had slower rate of spectral change and reduced spectral range. Healthy speakers produced faster rates of spectral change in read text compared to conversation, but speakers with dysarthria did not. The results suggest that structured speaking tasks which demand large spectral variation may be particularly useful in assessing the dysarthria. It is concluded that the rate of spectral change is a useful measure of dysarthria associated with FRDA.|Acoustics; measurement; dysarthria|PARKINSONS-DISEASE; ACOUSTIC ANALYSIS; VOCAL INTENSITY; MOTOR CONTROL; DYSARTHRIA; APRAXIA|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|2|0|4
ON THE RECONTEXTUALIZATION OF DISCOURSES CONCERNING A KNOWLEDGE-BASED SOCIETY AND LIFE-LONG LEARNING IN ESTONIA|2011|This article analyses the construction of discourse concerning educational objectives and the factors influencing it. It outlines ideological principles used in the formation of educational policy in society, and seeks answers to the question how joining the European Union has influenced education and beliefs about educational objectives in Estonia. The empirical section of the article is based on Norman Fairclough's model for studying social changes in transitional societies. It is a socio-linguistic study focused on changes in social processes, examining the relation between the discourses verbalizing them. The thesis examines how new discourses become dominant strategies and how they are recontextualized. Development strategy documents and development scenarios are analyzed as discourses through which the vision of a perfect society is framed. Research focused on the recontextualization of the discourse of knowledge-based society and lifelong learning. These new discourses were recontextualized in Estonia in the science and development strategy document ``Knowledge-based Estonia 2002-2006{''}, in the government's strategy documents ``Success Estonia 2014{''} and ``Sustainable Estonia 21{''}. With the development strategy ``Sustainable Estonia 21{''}, the social partnership scenario was rejected as being too expensive. Therefore, of the two goals of the lifelong learning memorandum (forming active citizenship and increasing the capability of breakthrough in the labor market), the second one is in primary focus. The new discourse is legitimized through language usage. A person living or working in the state is phrased as a kind of capital. Metaphors from finance are evoked, such as converting knowledge into knowledge-based economy. Education as a field of activity is addressed as the learning economy. Based on this research, one can make the claim that the discourse of civil society is being subordinated to the objectives of the market economy. Achieving fast economic growth was adopted as the main objective of society; those themes such as civil society and social dialogue that are more vigorously present in the European Union were discarded as being too costly. Neoliberal ideology proved to have a strong impact in the transitional society of Estonia, as justified by arguments that it is the most effective response to changing social, political and economic conditions. Our text analyses indicated that education and research are seen as an opportunities to increase the competitiveness of the state in the global market. According to the scenario of knowledge-based society, the objective of education is to prepare a highly qualified workforce for competitive economic activities relying on research and development.|critical discourse analysis; recontextualization; discourse of knowledge-based society; discourse of lifelong learning|EDUCATION|Linguistics; Language \& Linguistics|0|0|4
A Comparison of Different Retrieval Strategies Working on Medical Free Texts|2011|Patient information in health care systems mostly consists of textual data, and free text in particular makes up a significant amount of it. Information retrieval systems that concentrate on these text types have to deal with the different challenges these medical free texts pose to achieve an acceptable performance. This paper describes the evaluation of four different types of information retrieval strategies: keyword search, search performed by a medical domain expert, a semantic based information retrieval tool, and a purely statistical information retrieval method. The different methods are evaluated and compared with respect to its appliance in medical health care systems.|information retrieval; health care; medicine; evaluation; text mining|LATENT SEMANTIC ANALYSIS; ELECTRONIC INFORMATION-RETRIEVAL; OF-THE-ART; QUERY EXPANSION; CLINICAL-DATA; KNOWLEDGE; SYSTEMS; REPRESENTATION; PHYSICIANS; SEARCH|Computer Science, Software Engineering; Computer Science, Theory \& Methods|7|0|4
An Ironic Fist in a Velvet Glove: Creative Mis-Representation in the Construction of Ironic Similes|2010|Irony is an effective but challenging mode of communication that allows a speaker to express viewpoints rich in sentiment with concision, sharpness and humour. Creative irony is especially common in online documents that express subjective and deeply-felt opinions, and thus represents a significant obstacle to the accurate analysis of sentiment in web texts. In this paper we look at one commonly used framing device for linguistic irony-the simile-to show how even the most creative uses of irony are often marked in ways that make them computationally feasible to detect. We conduct a very large corpus analysis of web-harvested similes to identify the most interesting characteristics of ironic comparisons, and provide an empirical evaluation of a new algorithm for separating ironic from non-ironic similes.|Irony; Mis-representation; Expectation; Pretence; Sentiment|PRETENSE THEORY|Computer Science, Artificial Intelligence|10|0|4
Constructivist Grammatical Learning: A Proposal for Advanced Grammatical Analysis for College Foreign Language Students|2010|The teaching of foreign language advanced grammar (AG) at the college level nowadays continues largely to focus on form, with little attention to its functions and meanings. The practice agrees with neither the Standards for Foreign Language Learning in the 21st Century (National Standards, 2006) nor the advances made in basic language teaching pertaining to the communicative purpose and context of language. Since both second language acquisition and pedagogical research demand more attention to contextual use, as well as the active participation of the student in the analysis of the forms, a revision of current practices becomes necessary. This article proposes the study of AG based on the use of unabridged authentic texts and the application of a Constructivist Grammatical Learning Approach.|Spanish; advanced learning; authentic texts; constructivism; foreign language instruction; grammatical analysis|2ND-LANGUAGE; ACQUISITION|Education \& Educational Research; Linguistics|2|0|4
ELVIS: Entertainment-Led Video Summaries|2010|Video summaries present the user with a condensed and succinct representation of the content of a video stream. Usually this is achieved by attaching degrees of importance to low-level image, audio and text features. However, video content elicits strong and measurable physiological responses in the user, which are potentially rich indicators of what video content is memorable to or emotionally engaging for an individual user. This article proposes a technique that exploits such physiological responses to a given video stream by a given user to produce Entertainment-Led VIdeo Summaries (ELVIS). ELVIS is made up of five analysis phases which correspond to the analyses of five physiological response measures: electro-dermal response (EDR), heart rate (HR), blood volume pulse (BVP), respiration rate (RR), and respiration amplitude (RA). Through these analyses, the temporal locations of the most entertaining video subsegments, as they occur within the video stream as a whole, are automatically identified. The effectiveness of the ELVIS technique is verified through a statistical analysis of data collected during a set of user trials. Our results show that ELVIS is more consistent than RANDOM, EDR, HR, BVP, RR and RA selections in identifying the most entertaining video subsegments for content in the comedy, horror/comedy, and horror genres. Subjective user reports also reveal that ELVIS video summaries are comparatively easy to understand, enjoyable, and informative.|Experimentation; Human Factors; Video summarization; video content; semantics; personalization; physiological response; affect; emotion|OF-THE-ART; RESPIRATORY RESPONSES; EMOTION; PICTURE; MOTION; DIMENSIONS; RETRIEVAL; COMPUTER; AROUSAL|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods|10|0|4
UMLS content views appropriate for NLP processing of the biomedical literature vs. clinical text|2010|Identification of medical terms in free text is a first step in such Natural Language Processing (NLP) tasks as automatic indexing of biomedical literature and extraction of patients' problem lists from the text of clinical notes. Many tools developed to perform these tasks use biomedical knowledge encoded in the Unified Medical Language System (UMLS) Metathesaurus. We continue our exploration of automatic approaches to creation of subsets (UMLS content views) which can support NLP processing of either the biomedical literature or clinical text. We found that suppression of highly ambiguous terms in the conservative AutoFilter content view can partially replace manual filtering for literature applications, and suppression of two character mappings in the same content view achieves 89.5\% precision at 78.6\% recall for clinical applications. Published by Elsevier Inc.|UMLS; Metathesaurus; Content views; Natural Language Processing; Indexing; Clinical text|WORD SENSE DISAMBIGUATION; SEMANTIC LEXICON; RESOURCES; KNOWLEDGE; DOMAIN|Computer Science, Interdisciplinary Applications; Medical Informatics|8|0|4
The rhetorical structure of the architecture design statement for dissemination: a genre analysis|2010|The aim of this study is to offer an overall view of the text organization in architecture design statements for dissemination purposes through an analysis based on existing models in other academic and scientific genres. This article presents some of the results, obtained through an analysis based on the use of computer tools, on the move organization of this type of texts and the rhetorical devices used for the realization of the function fulfilled by each of these moves. The organization patterns of the sixty texts contained in the corpus have been identified, paying attention to aspects such as obligatory nature, cyclical or isolated appearance and hierarchical organization of these devices. Results suggest that, although the contents of an architecture design statement for dissemination appear to be based on certain patterns or prescriptions as far as their organization is concerned, they do not seem to be subject to many restrictions on the aspects they must deal with or on their presentation order. However, it is possible to outline a prototype based on the central category of the genre of architecture design statements which corresponds to the abstraction stored in the memory of the members of the discourse community of architects.|discourse analysis; genre; text organization; architecture design statement; rhetorical devices|APPLIED LINGUISTICS; MOVES|Linguistics; Language \& Linguistics|1|1|4
What is it I am writing? Lexical frequency effects in spelling Russian prefixes: Uncertainty and competition in an apparently regular system|2010|Whole-word frequency effects are shown to exist in what appears to be a completely regular system, the spelling of prefix-final vertical bar z vertical bar in Russian. Russian prefixes that underlyingly end in vertical bar z vertical bar (roz-, bez-, iz-) end in {[}s] on the surface when followed by a voiceless consonant. According to the rules of Russian orthography, the surface form, rather than the underlying form, must be reflected in the spelling. However, spelling errors reflecting the underlying form often occur, especially for the prefix bez-. The present paper reports that the error rate, either in natural typing on the web or in a classroom dictation task, for a given word is negatively correlated with the frequency of the word, suggesting that Russian writers rely, to a significant extent, on memory of complete orthographic forms as opposed to the orthographic rule. The frequency effect holds even within the set of regular inflectional variants of a single lexeme, with more frequent wordforms showing lower error rates. The evidence demonstrates a high degree of reliance on whole-form lexical retrieval even in what appears to be a regular system that is explicitly taught to the writers throughout their schooling in a morphologically rich language and thus provides support for the use of lexical retrieval even when it is not necessary (Baayen et al. 2002, Butter-worth 1983, Bybee 1985, 2000, vs. DiSciullo and Williams 1987, Pinker 1991). However, reliance on retrieval is argued to be especially strong when there is a relatively long period of temporary uncertainty regarding which rule is applicable during processing (see also Albright 2009, Barca et al. 2007, Burani et al. 2006). The importance of temporary uncertainty and resulting rule competition suggests that the regular/irregular distinction needs to be reconsidered as even fully ``regular{''} systems may feature rule competition due to temporary uncertainties about rule applicability. Reliance on retrieval may go largely undetected in Russian during schooling because teaching and test materials focus on the spelling of frequent words, which can be either produced by rule or retrieved as wholes. The largely complementary methodological challenges in studying lexical frequency effects in corpus and experimental data are discussed.|word frequency; lexical retrieval; grammatical computation; regularity; productivity; morphology; orthography; language production; errors; Russian|SPOKEN WORD RECOGNITION; SPEECH PRODUCTION; WRITTEN FRENCH; READING ALOUD; BROCAS AREA; ORTHOGRAPHY; LANGUAGE; RULES; ENGLISH; MORPHOLOGY|Linguistics; Language \& Linguistics|4|0|4
TIME OF NARRATIVE AND TIME OF TRANSLATION: A DISCURSIVE APPROACH|2010|The current article explores temporal relations in fictional narratives by comparing original Spanish works with their translations in Estonian. The focus lies on the role of the so-called narrative imperfect as a device of style and narrative technique in Spanish. Furthermore, the article endeavours to address the problems and possibilities associated with transmitting the narrative imperfect in Estonian in such a way that the reader is able to experience the storyworld in the most similar way possible with respect to its original construction by the author in Spanish. The study is based on a sociocognitive approach. Accordingly, fictional narrative is seen as a sociocultural practice expected to follow certain conventions in creating and interpreting meaning. Interpreting temporal relations in fictional narrative requires relocation to the narrative now-point located within the storyworld. Therefore, the functioning of aspectual categories in a narrative concerns its interaction with this now-point. The narrative imperfect involves the rather exceptional use of the imperfective aspect in the case of a temporal progression of narrative now-point. The present study is intended to point out the main ways of how narrative imperfect can affect mental representations of the storyworld. In addition, the possibilities of expressing the same modifications by means of the Estonian language are discussed. The results of the analysis show that the use of narrative imperfect in Spanish is generally characterized by its contrast with the presupposed use of perfective aspect and with the surrounding context, resulting in modifications in the temporal structure as well as in the spatial dimension and particularly the viewpoint. The special representation of events created by the narrative imperfect is more easily transmittable to Estonian in case of a weak contrast. On the other hand, translation problems increase in the presence of a sharp contrast.|discourse analysis; text analysis; narratology; tense; aspect; Estonian; Spanish|DISCOURSE|Linguistics; Language \& Linguistics|0|0|4
Lexical noun phrases in texts written by deaf children and adults with different proficiency levels in sign language|2010|We report an analysis of lexical noun phrases (NPs) in narrative and expository texts written by Dutch deaf individuals from a bimodal bilingual perspective. Texts written by Dutch deaf children and adults who are either proficient in Sign Language of the Netherlands (SLN) or low-proficient in SLN were compared on structures that either overlap in Dutch and SLN (presence of overt subject and object NPs, NP modifiers, and NP-internal agreement), or are absent in SLN (articles). We found that deaf participants experienced significant difficulty with lexical NPs. Further, deaf proficiently signing children (but not adults) more often omitted obligate articles than deaf low-proficiently signing children. Deaf proficiently signing children and adults did not differ from low-proficiently signing children and adults, however, in the use of NP modifiers, NP-agreement errors and omissions of obligatory NPs. We conclude that proficiency in sign language seems to affect particularly those aspects that differ substantially across sign language and oral language, in this case, articles. We argue that adopting a bimodal bilingual approach is important to understand the writing of deaf children.|bilingualism; education of deaf children; language transfer|HEARING IMPAIRMENTS; EXPOSITORY TEXTS; ENGLISH; PERFORMANCE; CONTEXTS; SPOKEN; DUTCH|Education \& Educational Research; Linguistics; Language \& Linguistics|8|0|4
The Bible in two keys: Traditionalism and Evangelical Christianity on the Fort Apache reservation|2010|This article examines contrasting entextualizations of the Bible across conflicting Traditionalist and Evangelical Christian identities on the Fort Apache reservation in Arizona On the one hand, each makes use of Apache language idioms and genre precedents to underwrite their respective claims to authentic Apache identities On the other hand, each selects different components of that loosely shared repertoire of discursive precedents in their entextualizations of the Bible in order to articulate contrasting transformative projects for their community as well as to assert the contemporary relevance of their voices within differently imagined global orders. This analysis constitutes the local speech community as a locus of ethnolinguistic inquiry in which relations to encompassing social orders are mediated in part by the circulation of texts. In this process conventions and precedents serve as a reservoir of resources mobilized for use in competing strategies advanced by differently affiliated actors in dialogue with one another In this way multiplicity and dynamism as a characteristic of local communities is defined as a crucial dimension of local-global discursive processes (C) 2009 Elsevier Ltd All rights reserved|Intertextuality; Western Apache; Discourse Genres; Christianity; Indigeneity; Entextualization; Language maintenance; Globalism; Mass media; Speech community|WHITE MOUNTAIN; LANGUAGE; MEDIA; TALK|Communication; Linguistics|6|0|4
Investigating readers' mental maps of references in an online system|2009|Referential identification and resolution are considered the keys to help readers grasp the main idea of a text and solve lexical ambiguities. The goal of this study is to design a computer system for helping college students who learn English as a Foreign Language (EFL) develop mental maps of referential identification and resolution in reading. Four modules, Natural Language Processing (NLP), User Interface, Recording, and Feedback Tool, are implemented in the system. Results of this study showed that the more-proficient EFL readers were able to identify and resolve most of the references to form a coherent mental map from different parts of a text. The less-proficient readers commonly resolved references by relying on grammatical rules instead of semantic contextual clues. They often referred references to incorrect objects. To overcome the difficulties in figuring out the relationship between two words, the less-proficient readers usually asked for more feedbacks. As students progressed in reading, they requested fewer feedbacks in the online system. Some recommendations for future studies are discussed. (C) 2009 Elsevier Ltd. All rights reserved.|Evaluation of CAL systems; Reading strategy; Mental map; Reference; Interactive learning environments|COMPREHENSION; KNOWLEDGE; STUDENTS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|1|0|4
Tracking medical students' clinical experiences using natural language processing|2009|Graduate medical students must demonstrate competency in clinical skills. Current tracking methods rely either on manual efforts or on simple electronic entry to record clinical experience. We evaluated automated methods to locate 10 institution-defined core clinical problems from three medical students' clinical notes (n = 290). Each note was processed with section header identification algorithms and the KnowledgeMap concept identifier to locate Unified Medical Language System (UMLS) concepts. The best performing automated search strategies accurately classified documents containing primary discussions to the core clinical problems with area under receiver operator characteristic curve of 0.90-0.94. Recall and precision for UMLS concept identification was 0.91 and 0.92, respectively. Of the individual note section, concepts found within the chief complaint, history of present illness, and assessment and plan were the strongest predictors of relevance. This automated method of tracking can provide detailed, pertinent reports of clinical experience that does not require additional work from medical trainees. The coupling of section header identification and concept identification holds promise for other natural language processing tasks, such as clinical research or phenotype identification. (C) 2009 Elsevier Inc. All rights reserved.|Natural language processing; Medical education; Concept identification; Education portfolios; Competency assessment; Experience tracking; UMLS|PRIMARY-CARE; SCHOOL CURRICULUM; RADIOLOGY REPORTS; EDUCATION; PERFORMANCE; DOCUMENTS; CLERKSHIP; RECORD|Computer Science, Interdisciplinary Applications; Medical Informatics|11|0|4
ConText: An algorithm for determining negation, experiencer, and temporal status from clinical reports|2009|In this paper we describe an algorithm called ConText for determining whether clinical conditions mentioned in clinical reports are negated, hypothetical, historical, or experienced by someone other than the patient. The algorithm infers the status of a condition with regard to these properties from simple lexical clues occurring in the context of the condition. The discussion and evaluation of the algorithm presented in this paper address the questions of whether a simple surface-based approach which has been shown to work well for negation can be successfully transferred to other contextual properties of clinical conditions, and to what extent this approach is portable among different clinical report types. In our study we find that ConText obtains reasonable to good performance for negated, historical, and hypothetical conditions across all report types that contain such conditions. Conditions experienced by someone other than the patient are very rarely found in our report set. A comprehensive solution to the problem of determining whether a clinical condition is historical or recent requires knowledge above and beyond the surface clues picked up by ConText. (C) 2009 Elsevier Inc. All rights reserved.|Natural language processing; Negation; Temporality; Clinical reporting|RADIOLOGY REPORTS; INFORMATION; CLASSIFICATION; EXTRACTION; DOCUMENTS; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|76|0|4
Building a semantically annotated corpus of clinical texts|2009|In this paper, we describe the construction of a semantically annotated corpus of clinical texts for use in the development and evaluation of systems for automatically extracting clinically significant information from the textual component of patient records. The paper details the sampling of textual material from a collection of 20,000 cancer patient records, the development of a semantic annotation scheme, the annotation methodology, the distribution of annotations in the final corpus, and the use of the corpus for development of an adaptive information extraction system. The resulting corpus is the most richly semantically annotated resource for clinical text processing built to date, whose value has been demonstrated through its use in developing an effective information extraction system. The detailed presentation of our corpus construction and annotation methodology will be of value to others seeking to build high-quality semantically annotated corpora in biomedical domains. (C) 2009 Elsevier Inc. All rights reserved.|Corpora; Semantic annotation; Clinical text; Natural language processing; Gold standards; Evaluation; Information extraction; Text mining; Temporal annotation; Annotation guidelines|RETRIEVAL; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|47|1|4
GRAPHEMIC REPRESENTATION OF TEXT-MESSAGING: ALPHABET-CHOICE AND CODE-SWITCHES IN GREEK SMS|2009|The aim of this study is to investigate the choice of alphabetical encoding in Greek text-messaging (or Short Message Service, SMS). The analysis will be based on a corpus of 447 text-messages exchanged among participants who belong to the age group of `youth' (15-25 years old) and live in Athens (Greece). The data analysis will show that the standard practice of writing with Greek characters represents the norm in Greek SMS. The script norm will be discussed in relation to the medium's technological affordances and the participants' stance towards new media. The analysis will then focus on non-standard graphemic choices, such as the use of both, Greek and Roman, alphabets in the encoding of single messages. It will be demonstrated that such marked choices are employed as a means of indexing the participants' affiliation with global popular cultures and enhancing expressivity in a medium of reduced paralinguistic cues.|Text-messaging; Computer-mediated communication research; Graphemic practices; Writing norms; Global-local|SOCIOLINGUISTICS|Linguistics; Language \& Linguistics|6|0|4
Effects of Robust Vocabulary Instruction and Multicultural Text on the Development of Word Knowledge Among African American Children|2009|Purpose: To examine the effect of a systematic vocabulary instructional technique in African American 2nd-grade children with below average vocabulary skills. An additional goal was to examine the role of book type in the retention of novel vocabulary words. Method: Using an adapted alternating treatments design, storybooks were used as a source for contextualizing vocabulary words in the context of robust vocabulary training. Five children's productive definitions were used to assess developing word knowledge using a 4-stage continuum ranging from no knowledge to full concept knowledge. Results: Superior word learning for instruction words in comparison with control words replicated across children provided evidence of behavior change that was attributable to robust vocabulary instruction. Gains in word learning were maintained 2 weeks following conclusion of the study. Use of storybooks that displayed sociocultural images and experiences that were similar to versus different from their own did not have a reliable effect on word learning among these African American children. Conclusions: The findings demonstrate the potential impact of robust vocabulary instruction for facilitating vocabulary development in children with below average vocabulary skills. Analysis of the results indicates that the use of the African American book was not a potent influence in facilitating retention of words.|cultural and linguistic diversity; vocabulary; storybooks; African American; word knowledge|READING-COMPREHENSION; YOUNG-CHILDREN; AT-RISK; ACQUISITION; LANGUAGE; INTERVENTION; STORYBOOKS; KINDERGARTNERS; PRESCHOOLERS; EXPERIENCES|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|5|0|4
A la recherche des clitiques perdus: The dictogloss as a measure of the comprehension of y and en by L2 learners of French|2009|In an effort to ascertain whether the paucity of object clitics in L2 production documented in the extant research may reflect comprehension difficulties, this article reports on the use of a dictogloss task to determine the degree to which intermediate-level L2 learners of French (N = 110) were able to process and reproduce the meaning of the clitics y and en. An analysis of the reconstructed texts revealed the presence of competing interlanguage forms. Overall, deleted objects, strong pronouns, and lexical noun phrases were used with greater frequency than the target forms. Errors related to animacy, argument structure, and referent constituted the primary source of non-target-like usage. Given the learners' frequent use of animate forms in lieu of y and en, it is suggested that teachers might do well to provide explicit instruction on the animacy distinction in prescriptive French.|French as a second language (FSL); pronouns; clitics; listening comprehension; language processing|ACQUISITION|Linguistics|2|1|4
Speaking from experience: narrative schemas, deixis, and authenticity effects in Verena Stefan's feminist confession Shedding|2009|Confessional writing, such as Swiss feminist Verena Stefan's autobiographical novel Shedding (1977) (German: Hautungen, 1977{[}1975]), is often praised as being an expression of a particular individual's authentic voice. This readerly concept of authentic voice has been under-examined in contemporary and postmodem narrative theories, which have tended to emphasize the abstractness, the disembodiedness of voice. In this article I draw from Monika Fludernik's concept of narrative schemas and from theories of deixis in literature within cognitive poetics in order to develop a model by which to explain the authenticity effects attributed to Stefan's book and to other works of testimonial and confessional literature. Through an analysis of stylistic features related to different aspects of deixis, I illustrate how deietic shifts may encourage readers to pay more attention to certain narrative parameters over others within the framework of familiar narrative schemas. thereby creating a greater sense of immersivity in the text and consequently the effect of a narrative that is being experienced even as it is being told.|authenticity; autobiography; deixis; German; schema; voice|VOICE|Linguistics; Language \& Linguistics|10|0|4
TOWARDS CHILEAN SPANISH LANGUAGE DIACHRONIC CORPUS|2009|The conformation of Hispanic diachronic corpora (Spanish and Hispano-American) in order to place the framework of the CorDECh (Corpus Diacronico del Espanol de Chile) is described and analyzed in this paper. The work shows an intersection between traditional disciplines, such as the philolology and the paleography, with linguistic disciplines that have been revitalized in the last years, such as corpus linguistics, in order to shape a Chilean Spanish diachronic corpus. In addition, the criteria of corpus formation is presented in this text (chronological, documentary selection and transcription, diatopics and register varieties); in the same way, some aspects of corpora automatization and the implications and projections for its analysis is discussed here. Finally, the criteria for corpus labelling are reviewed, according to the Text Encoding Initiative (TEI), adopted for the RAE in the Prontuario de Marcacion SGML, used for the CORDE (Spanish Language Diachronic Corpus), together with showing some examples of these aspects, for which the Cooktop 2.5 XML/XSLT editor was used.|Corpus linguistics; diachronic corpus; Chilean Spanish language|HANDWRITTEN DOCUMENTS; TEXT; RECOGNITION|Linguistics; Language \& Linguistics|2|1|4
Identifying Events Using Computer-Assisted Text Analysis|2008|Events such as elections, significant changes in laws, but also extreme weather conditions, may affect societal values and, consequently, public opinion. Accordingly, a central assumption for public opinion surveys is that respondents' behavior is influenced by significant events. It is therefore necessary to consider the impact of potential events when designing a survey and, whenever possible, to control for these. To support the documentation of such societal events, the authors have developed a procedure to identify events using computer-assisted text analysis. Event words are selected and grouped by means of exploratory factor analysis based on a comparison of a large text corpus that forms the reference for a smaller text corpus consisting of media items on significant events. As a result, the factors represent significant events during a specific time period.|computer-assisted text analysis; statistical association approach; reference text corpus; event reporting; newspaper articles|POLICY POSITIONS; POLITICAL TEXTS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science; Social Sciences, Interdisciplinary|6|0|4
Legal discourse and linguistic incongruities in Bardell vs. Pickwick: an analysis of address and reference strategies in The Pickwick Papers trial scene|2008|In this article I intend to show how Pickwick's trial in Dickens's novel The Pickwick Papers is characterized by a strategic use of address and reference forms that produce effects of discoursal incongruities during the opening and the evidence phase of the proceeding. The analysis reveals Dickens's ability to exploit socio-pragmatic features of the speaker-addressee and speaker-referent-addressee relationships in order to foreground the lawyers' manipulative discourse behaviour towards their addressees and referents. In so doing, the writer undermines the assumption according to which the courtroom is a polite setting characterized by the exchange of mutual respect and deference between participants. The manipulation of address strategies is mainly accomplished by violating the sociolinguistic rules expected in the legal setting or by producing a disjunction between the conventional meaning of honorifics and the speaker's pragmatic intention. The result is that many of the honorifics in the text assume a sarcastic function that contrasts with the politic behaviour prescribed by the courtroom. The manipulation of reference strategies, on the other hand, is accomplished by means of a skilful selection of words for the description of persons and events in a way congenial to the story as claimed and supported by the speaker, no matter how far from the truth this may be. Text evidence shows how the lawyer's referent-term selection denigrates the defendant and creates a mismatch between the reader's expectation of formal politeness in the courtroom and the interrogator's strategic use of a controlled but finally effective rudeness.|abuses; address strategies; comic effects; courtroom discourse; Dickens, Charles; (im)politeness; rule-governed rudeness|IMPOLITENESS; LANGUAGE|Linguistics; Language \& Linguistics|3|0|4
The discourse of lending aid on small-scale development project websites: Dutch depreciatory diminutives|2008|This article offers an analysis of the use of language on the websites of Dutch and Flemish small-scale development organisations active in The Gambia. The scope of this research is the websites of 66 organisations found through the hyperlink page http://gambia-hulporganisaties.startpagina.nl. The texts on the websites form a small corpus of around 375 000 words. Methodologically, a discourse-analytical perspective is assumed, heuristically assisted by corpus linguistic software. Thus, the texts are analysed simultaneously from a macro and micro-level: large-scale lexical patterns are combined with smaller-scale, contextualised, individual chunks of text. After a brief outline of the projects' roots in tourism through self-reported histories of involvement and a cursory review of the literature on meanings and functions of diminutives in Dutch and other languages, the role of diminutives in the representation of the Third-World Other is explored. It is argued that diminutives in this context are used in an ambivalent way: diminutives express a sense of sympathy and at the same time reveal a derogative tone in descriptions of the Gambian side of the projects.|development aid; diminutive; Dutch; Internet; The Gambia; the Other; tourism|GAMBIA; GREEK|Linguistics; Language \& Linguistics|1|0|4
A review of methods for automatic understanding of natural language mathematical problems|2008|This article addresses the problem of understanding mathematics described in natural language. Research in this area dates back to early 1960s. Several systems have so far been proposed to involve machines to solve mathematical problems of various domains like algebra, geometry, physics, mechanics, etc. This correspondence provides a state of the art technical review of these systems and approaches proposed by different research groups. A unified architecture that has been used in most of these approaches is identified and differences among the systems are highlighted. Significant achievements of each method are pointed out. Major strengths and weaknesses of the approaches are also discussed. Finally, present efforts and future trends in this research area are presented.|Artificial intelligence; Natural language processing; Mathematical problems; Automated reasoning; Knowledge engineering|COMPUTER-SIMULATION; INSTRUCTION; SYSTEM|Computer Science, Artificial Intelligence|9|0|4
HAL-based evolutionary inference for pattern induction from psychiatry web resources|2008|Negative and stressful life events play a significant role in triggering depressive episodes. Psychiatric services that can identify such events efficiently are vital for mental health care and prevention. Meaningful patterns, e.g., <lost, parents>, must be extracted from psychiatric texts before these services can be provided. This study presents an evolutionary text-mining framework capable of inducing variable-length patterns from unannotated psychiatry web resources. The proposed framework can be divided into two parts: 1) a cognitive motivated model such as Hyperspace Analog to Language (HAL) and 2) an Evolutionary Inference Algorithm (EIA). The HAL model constructs a high-dimensional context space to represent words as well as combinations of words. Based on the HAL model, the EIA bootstraps with a small set of seed patterns, and then iteratively induces additional relevant patterns. To avoid moving in the wrong direction, the EIA further incorporates relevance feedback to guide the induction process. Experimental results indicate that combining the HAL model and relevance feedback enables the EIA to not only induce patterns from the unannotated web corpora, but also achieve useful results in a reasonable amount of time. The proposed framework thus significantly reduces reliance on annotated corpora.|evolutionary computation; knowledge acquisition; natural language processing; text mining|LATENT SEMANTIC ANALYSIS; STRESSFUL LIFE EVENTS; INFORMATION EXTRACTION; ONTOLOGY; RETRIEVAL; ALGORITHM; TEXT|Computer Science, Artificial Intelligence; Computer Science, Theory \& Methods|5|0|4
On the constructional semantics of gerundive nominalizations|2008|This paper starts out from the observation that the semantic labels of `fact' and `action' (Lees 1968{[}1960]) that are traditionally used in the description of English gerundive nominalizations (e.g. 1 worry that my posing the question defines me as a depressive) cannot distinguish gerundives from so-called action -ing nouns (e.g. Saddam's targeting of Israel) and also fail to capture the more subtle semantic distinctions within the system of gerundive nominalization. The descriptive analysis that is presented tries to move beyond the action/fact dichotomy, is firmly grounded in the nominal-constructional properties of the system and covers all subtypes of gerundive nominalization. Building on Schachter (1976), it argues that gerundive -ing nominalizations have shifted from the representational semantics of action -ing nouns to a more schematic, constructional semantics: gerundives, it is suggested, nominalize either a type or kind of process, with no subject implied, or they nominalize an instance of a process, characterized by the (clausal-) constructional link which it implies between the process type and a subject (Davidse 1997, Heyvaert 2003). The system of gerundive nominalization exploits all nominal-constructional options which it has within the structure of the NP to encode the absence or presence of this subject. Gerundives thus opt for non-specific, generic reference to encode the name of a type or class of process (with no subject implied) or to encode,in instance with generic reference. They use specific (definite or indefinite) reference to designate a specific, non-generic instance. The subject is either included in the nominalized clausal unit (and in the oblique case), or it is encoded through nominal means: in the form of bare definite reference of the gerundive NP (signalling control by the matrix clause or anaphoric/exophoric reference with the co(n)text), or in the form of a possessive/genitive determiner. The analysis that is proposed sheds new light on previously undifferentiated categories of gerundive nominalization (such as the control type of bare gerundives), as well as points to interesting resemblances between gerundive nominalization and diachronic changes in other systems of deverbal nominalization. Crucially, it also allows for a better understanding of the semantics of the system and its differences with action -ing nominals, whose nominal-constructional options do not revolve around encoding the presence or absence of a subject but instead allow for a wide range of modifying elements and determiners.|gerundive; nominalization; reference; instantiation; subject|ENGLISH; NOMINALS; CATEGORIES; SUBJECT; GRAMMAR; PHRASES|Linguistics; Language \& Linguistics|8|0|4
Dialogical surface text features in abstracts|2008|A sample driven description of Research Article-Comment-Reply (RA-C-R) abstracts in terms of abstract sentence length, reference, possessive structures, modal verbs and word range was carried Out to find Out Whether their Surface text features showed sonic trace of a dialogical construction of knowledge within the psychology discourse community. The study served an exploratory purpose. A Boolean search was conducted in the PsycLIT database yielding a sample of 149 PsycLIT RA-C-R abstracts (13,978 words). Relative frequency percent distributions were calculated for all variables, including reported speech verbs. Specific comparisons with a Medline corpus were conducted and variations were accounted for in terms of scientific discourse characteristics, field, database policies, and dialogical nature; that is, in the framework provided by the strands of research Of quantitative applied linguistics, social concerns in genre analysis and the model monopoly theory, developed in the implementation in sociology of the systems theory The results Suggest: (i) a word range affected by both psychology as a discipline and the dialogical content on which PsycLIT RA-C-R abstracts report; (ii) a complementarity of reference and possessive structures characterised by features of scientific discourse, feedback genres and dialogical dimensions; (iii) the presence of both deontic and epistemic modality in the modal verbs of Our sample; (iv) and also that abstract length, sentence length and number of sentences per paragraph in our sample may not vary greatly in general terms from those of the social sciences.|corpus linguistics; text features; dialogue; reply abstract; reported speech|DISCOURSE|Linguistics; Language \& Linguistics|0|0|4
Definitional verbal patterns for semantic relation extraction|2008|In this paper we present a description of the role of definitional verbal patterns for the extraction of semantic relations. Several studies show that semantic relations can be extracted from analytic definitions contained in machine-readable dictionaries (MRDs). In addition, definitions found in specialised texts are a good starting point to search for different types of definitions where other semantic relations occur. The extraction of definitional knowledge from specialised corpora represents another interesting approach for the extraction of semantic relations. Here, we present a descriptive analysis of definitional verbal patterns in Spanish and the first steps towards the development of a system for the automatic extraction of definitional knowledge.|definitional context; definitional verbal patterns; definitional knowledge extraction|PREDICATION|Linguistics; Language \& Linguistics|19|1|4
Body, text, and talk in Maroua Fulbe Qur'anic schooling|2008|In this article, I present a language socialization approach to the study of Qur'anic schooling. Integrating insights from holistic study of the community and the institution, analysis of video recordings of Qur'anic school interaction, and video playback and interviews with community members, I describe the apprenticeship of Fulbe children into Qur'anic orality and literacy as a gradual transfer of responsibility for rendering the sacred text. I describe the organization of Qur'anic schooling (it three levels: the stages of the curriculum, the phases of a lesson, and the turn-by- turn organization of child-teacher interaction. I present fine-grained analysis of video to illustrate how teachers and children used specific practices of body positioning, pointing, and eye gaza in conjunction with the written text and utterances in Arabic and Fulfulde to manage the transfer of the text during the first phase of a lesson. I then discuss perspectives on these multimodal practices articulated by Fulbe concerning how these practices contributed to the achievement of desired outcomes of Qur'anic schooling. I conclude by discussing Wit, the language socialization perspective and attention to multiple modalities increase our understanding of Qur'anic schooling as an activity setting in which Muslim subjectivities come into being.|language socialization; Islam; sacred text; reading; multimodality|MEMORIZATION|Communication; Linguistics; Language \& Linguistics|15|0|4
Depth of processing in private and social speech: Its role in the retention of word knowledge by adult EAP learners|2007|This study explored the effect on vocabulary retention of vocalizations involving three cognitive processing depths (repetition, manipulation, and generation). Eight participants in an English for academic purposes (EAP) context encountered five unknown words when working alone and five different words when working in pairs. In each condition, they studied the words from a text and dictionary, completed puzzle and question tasks, and did a stimulated recall. Tests one week and one month later assessed short- and long-term retention. The data were examined to investigate whether vocalization of deeper processing was associated with better retention, how deeper processing facilitated matches between task utterances and test responses, and which condition (solitary or collaborative) produced higher test scores. Quantitative results show that delayed test scores correlated inversely with repetition during collaboration. Qualitative analysis suggests that vocalizations were better remembered when participants deployed deeper processing to create mnemonics, connect input with L1/L2 knowledge, and express opinions. Solitary and collaborative conditions were equally effective in promoting retention.|private speech; collaborative speech; depth of processing; second language vocabulary; repetition in SLA|FOREIGN-LANGUAGE VOCABULARY; SHORT-TERM-MEMORY; ACQUISITION|Linguistics|2|1|4
The co-evolution of number concepts and counting words|2007|Humans possess a number concept that differs from its predecessors in animal cognition in two crucial respects: (1) it is based on a numerical sequence whose elements are not confined to quantitative contexts, but can indicate cardinal/quantitative as well as ordinal and even nominal properties of empirical objects (e.g. `five buses': cardinal; `the fifth bus': ordinal; `the \#5 bus': nominal), and (2) it can involve recursion and, via recursion, discrete infinity. In contrast to that, the predecessors of numerical cognition that we find in animals and human infants rely on finite and iconic representations that are limited to cardinality and do not support a unified concept of number. In this paper, I argue that the way such a unified number concept could evolve in humans is via verbal sequences that are employed as numerical tools, that is, sequences of words whose elements are associated with empirical objects in number assignments. In particular, I show that a certain kind of number words, namely the counting sequences of natural languages, can be characterised as a central instance of verbal numerical tools. I describe a possible scenario for the emergence of such verbal numerical tools in human history that starts from iconic roots and that suggests that in a process of co-evolution, the gradual emergence of counting sequences and the development of an increasingly comprehensive number concept supported each other. On this account, it is language that opened the way for numerical cognition, suggesting that it is no accident that the same species that possesses the language faculty as a unique trait, should also be the one that developed a systematic concept of number. (c) 2006 Elsevier B.V. All rights reserved.|semantics of numerals; evolution of counting sequence; cardinality; number concept; language/number relationship|PRINCIPLES; PERCEPTION; KNOWLEDGE; EVOLUTION; COGNITION; LANGUAGE; INFANTS; RATS|Linguistics; Language \& Linguistics|22|1|4
Discovering event evolution patterns from document sequences|2007|Recent advances in information and networking technologies have contributed significantly to global connectivity and greatly facilitated and fostered information creation, distribution, and access. The resultant ever-increasing volume of online textual documents creates an urgent need for new text mining techniques that can intelligently and automatically extract implicit and potentially useful knowledge from these documents for decision support. This research focuses on identifying and discovering event episodes together with their temporal relationships that occur frequently (referred to as evolution patterns (EPs) in this, paper) in sequences of documents. The discovery of such EPs can be applied in domains such as knowledge management and used to facilitate existing document management and retrieval techniques {[}e.g., event tracking (ET)]. Specifically, we propose and design an EP discovery technique for mining EPs from sequences of documents. We experimentally evaluate our proposed EP technique in the context of facilitating ET. Measured by miss and false alarm rates, the EP-supported ET (EPET) technique exhibits better tracking effectiveness than a traditional ET technique. The encouraging performance of the EPET technique demonstrates the potential usefulness of EPs in supporting ET and suggests that the proposed EP technique could effectively discover event episodes and EPs in sequences of documents.|document clustering; event evolution; event tracking (ET); evolution patterns (EPs); knowledge management; temporal patterns; text mining|KNOWLEDGE MANAGEMENT; TEXT CATEGORIZATION; ONLINE NEWS; RETRIEVAL|Computer Science, Cybernetics; Computer Science, Theory \& Methods|21|0|4
Technoliteracy and learning: An analysis of the quality of knowledge in electronic representations of understanding|2007|Recent educational research from a socio-cognitive perspective has validated students' collaborative engagement with new technologies and heightened understanding of influential factors shaping the effectiveness of peer interactions, learning contexts and computer interfaces for enhancing learning. This paper focuses on an analysis of the complexity of knowledge in student-designed, electronically created texts for what they might reveal about learning with technology. It reports on a study with 17-year-old female students whose collaborative learning process in subject English was mediated by the creation of electronic concept maps and Web files to represent their developing understanding. To analyse these electronic texts, evaluative criteria templates were developed from the Structure of Observed Learning Outcomes (SOLO) taxonomy, integrating levels of understanding with the distinctive characteristics of multimodal text production. Findings indicated not just the incremental acquisition of conceptual understanding equated with cognitive change but that the level of understanding might also be positively influenced by the students' length of exposure to computer-mediated learning practices. As well, the criteria templates have emerged as useful evaluative tools for classroom assessment or further research when analysis of the level of complexity of student-created, electronic artefacts is required. (c) 2005 Elsevier Ltd. All rights reserved.|technoliteracy; computer-mediated learning; evaluation tools for e-learning; collaborative learning process; electronic representation of learning|STUDENTS|Computer Science, Interdisciplinary Applications; Education \& Educational Research|20|0|4
Cognitively inspired NLP-based knowledge representations: Further explorations of Latent semantic analysis|2006|Natural-language based knowledge representations borrow their expressiveness from the semantics of language. One such knowledge representation technique is Latent semantic analysis (LSA), a statistical, corpus-based method for representing knowledge. It has been successfully used in a variety of applications including intelligent tutoring systems, essay grading and coherence metrics. The advantage of LSA is that it is efficient in representing world knowledge without the need for manual coding of relations and that it has in fact been considered to simulate aspects of human knowledge representation. An overview of LSA applications will be given, followed by some further explorations of the use of LSA. These explorations focus on the idea that the power of LSA can be amplified by considering semantic fields of text units instead of pairs of text units. Examples are given for semantic networks, category membership, typicality, spatiality and temporality, showing new evidence for LSA as a mechanism for knowledge representation. The results of such tests show that while the mechanism behind LSA is unique, it is flexible enough to replicate results in different corpora and languages.|knowledge representation; Latent semantic analysis; semantic similarity|LANGUAGE; LSA; RETRIEVAL; DIALOGUE; SYSTEMS; MEMORY; WORDS|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|15|3|4
Misunderstanding of academic monologues by normative speakers of English|2006|Over the past several decades, extensive reading research has shown the beneficial role that contextualization markers play in written text comprehension. However, far less is known about their effects on L2 spoken text comprehension. The few studies concerning the effects of markers on L2 listening comprehension failed to examine their role through a qualitative analysis. To fill this gap, the current study attempts to provide a qualitative analysis of the role of markers in L2 listening comprehension. More specifically, the analysis focuses on how L2 learners misunderstood the text when the markers were absent in the academic monologue. The results show that the lack of markers seems to contribute significantly to L2 learners' misinterpretation of the text. The current findings extend previous research documenting the facilitating role of the markers in listening comprehension. That is, in communication, speakers and listeners share the expectation that listeners are aided in their interpretation of the message by speakers' use of contextualization markers. Listeners expect to be guided in their understanding of message via markers that overtly highlight the relative importance of ideas, and signal cohesive links between ideas. When these markers are missing, listeners experience difficulty understanding the message, and communication problems ensue. (c) 2005 Elsevier B.V. All rights reserved.|discourse analysis; nonnative speakers of English; Korean; contextualization markers; academic monologues|INTERNATIONAL TEACHING ASSISTANTS; DISCOURSE STRUCTURE; MARKERS|Linguistics; Language \& Linguistics|17|3|4
Linguistic correlates of second language literacy development: Evidence from middle-grade learner essays|2005|This paper compares the development of linguistic fluency in the writing of 5th-8th grade, U.S. students enrolled in English as a Second Language (ESL, n = 189) and regular language arts (RLA, n = 546) classes. Linguistic fluency is defined as the use of linguistic structures appropriate to rhetorical and social purposes and is measured using five sets of features shown by Reppen (1994, 2001) {[}Reppen, R. (1994). Variation in elementary student language: A multi-dimensional perspective. Doctoral dissertation, Northern Arizona University.] {[}Reppen, R. (2001). Register variation in student and adult speech and writing. In S. Conrad \& D. Biber (Eds.), Variation in English: Multidimensional studies (pp. 187-199). Harlow, UK: Longman.] to vary in relation to age and topic differences in a large corpus of texts produced by and for 5th grade English L1 writers. The same broad variational patterns found by Reppen in her corpus are shown to exist in the writing of the ESL and RLA students; however, more careful analysis of the individual features associated with each set indicates that the RLA students hold stronger associations between the features and the rhetorical and social functions identified for the set as a whole. It is suggested that the ESL students' lack of fluency results from both limitations in grammatical competency and a lack of practice in writing for varying purposes and audiences. (c) 2004 Elsevier Inc. All rights reserved.|adolescent writing development; multi-dimensional analysis; linguistic fluency|ENGLISH|Linguistics|16|3|4
Verbal and nominal expressions in narrating conflict situations in Hebrew|2005|This study examines the proposal that the use of deverbal and de-adjectival nominals which express predicative content is indicative of linguistic and cognitive development and reflects the ability to take a more distanced, objective, and generic stance when recounting events in which the narrator was personally involved. To this end, we analyze the quantitative distribution of various types of verb and verb-related predicating constructions in Hebrew personal-experience narratives as a function of age (grade-schoolers, adolescents, and adults) and modality (spoken versus oral texts), and proceed to a semantic analysis of types of predicating expressions in relation to thematic content and the lexical and syntactic constructions in which such expressions are embedded. With age and schooling, expression of predicative content relies decreasingly on verbs, which prototypically express narrative content, and involves additional, more marked devices, especially in the form of derived nominals. This applies particularly to written narratives, which overall contain more predicative type content than their spoken counterparts, although generally shorter in length. This shift in the form and content of predicating expressions in mature narratives results in a less concrete, subjective, and involved stance even in talking and writing about highly personal events. (C) 2004 Elsevier B.V. All rights reserved.|verbs; nouns; Hebrew; language development; discourse|(S)VO LANGUAGE; CONSTRUCTIONS; MORPHOLOGY|Linguistics; Language \& Linguistics|13|1|4
Synchronic and diachronic microvariation in English do|2004|In this paper it is shown how an account of the English auxiliary system that has been independently proposed to deal with problems in standard analyses also provides a natural treatment of microvariation among varieties of English. The phenomenon is the use of non-emphatic periphrastic/dummy do in positive declaratives (Mary did visit her brother), here called ``spurious do,{''} as found most famously in the English of the 1500s, but attested also in some modern dialects and registers and in child English, and closely related to the use of tun in colloquial German. The framework adopted dispenses with two standard but problematic claims about English INFL: the exceptional ability of he and have to raise to Tense, even across negation, and the existence of PF affix lowering. Instead it is claimed that English has overt verb raising and that finite be/have are base-generated in INFL, above negation; independent support for the latter is provided from VP ellipsis. The analysis of do is that it is an allomorph of the indicative value of the Mood head, whose other indicative allomorph is zero. Mood is above Tense and is where modals are base-generated. It is shown that this system cannot block the generation of spurious do, because this would require transderivational comparison. Thus, the narrow syntax makes spurious do freely available. Languages and dialects differ on the extent to which they make use of this option. All else equal, it should be dispreferred because it involves one more word than its counterpart without do, but numerous advantages, including processing and rhetorical benefits, can outweigh this. The conclusion is that do cannot be analyzed as a strictly last-resort device in the way proposed in Chomsky's classic analysis. (C) 2003 Elsevier B.V. All rights reserved.|do-support; INFL; auxiliaries; modals; periphrastic tun; Germanic; mood; VP-ellipsis; sigma|AUXILIARIES; MOVEMENT|Linguistics; Language \& Linguistics|11|0|4
Exploring multiple profile's of highly rated learner compositions|2003|Recent research has come a long way in describing the linguistic features of large samples of written texts, although a satisfactory description of L2 writing remains problematic. Even when variables such as proficiency, language background, topic, and audience have been controlled, straightforward predictive relationships between linguistic variables and quality ratings have remained elusive, and perhaps they always will. We propose a different approach. Rather than assuming a linear relationship between linguistic features and quality ratings, we explore multiple profiles of highly rated timed compositions and describe how they compare in terms of their lexical, grammatical, and discourse features. To this end, we performed a cluster analysis on two sets of timed compositions to examine their patterns of use of several linguistic features. The purpose of the analysis was to investigate whether multiple profiles (or clusters) would emerge among the highly rated compositions in each data set. This did indeed occur. Within each data set, the profiles of highly rated texts differed significantly. Some profiles exhibited above-average levels for several linguistic features, whereas others showed below-average levels. We interpret the results as confirming that highly rated texts are not at all isometric, even though there do appear to be some identifiable constraints on the ways in which highly rated timed compositions may vary. (C) 2003 Elsevier Inc. All rights reserved.|multiple profiles; highly rated compositions; linguistic features; cluster analysis|METADISCOURSE; DISCOURSE; STUDENT; WRITTEN; ARTICLES; LANGUAGE; ENGLISH|Linguistics|56|0|4
Conversational dynamics of humour: the telephone game in Greek|2003|The aim of this paper is to investigate humorous exchanges in Greek telephone conversation openings in the light of Raskin's (Raskin, Victor, 1985. Semantic Mechanisms of Humor. D. Reidel, Dordrecht/Boston/Lancaster) and Attardo's (Attardo, Salvatore, 1994. Linguistic Theories of Humor. Mouton de Gruyter, Berlin; Attardo, Salvatore, 2001. Humorous Texts: A Semantic and Pragmatic Analysis. Mouton de Gruyter, Berlin) semantico-pragmatic theories of humour and the principles of conversation analysis regarding telephone interaction {[}Sacks, Harvey, 1995. In: Jefferson, G. (Ed.), Lectures on Conversation, Vols I and II. Blackwell, Oxford (1963, 1970, 1972) (reprint) and Schegloff, Emanuel A., 1972. Sequencing in conversational openings. In: Gumperz, J.J. and Hymes, D. (Eds.), Directions in Sociolinguistics: The Ethnography of Communication. Holt, Rinehart and Winston, New York, pp. 346-380 (1968) (reprint)]. The material analysed (268 humorous exchanges between young adults) shows that such interactions are understood as a game, with interlocutors negotiating and co-constructing tacit rules involving a deliberate attack on social and linguistic conventions while at the same time creating a new code pertaining to in-group members only. The exchanges examined involve wordplay, insincere enquiries, complaints and reprimands. Wordplay in natural conversation has been attributed both an aggressive and a disruptive function (Norrick, Neal R., 1993. Conversational Joking. Indiana University Press, Bloomington, Indianapolis). Our data point to degrees of disruption, in that despite the playfulness of the exchanges, the canonical pattern including preemptive moves is preserved in most cases. Aggression, on the other hand, is also shown to be scalar and to serve primarily bonding purposes. In the light of the findings we propose a bridge between the GTVH, CA and politeness theory (Brown, Penelope and Stephen Levinson, 1987. Politeness: Some Universals in Language Usage. Cambridge University Press, Cambridge), with accompanying modifications considered necessary to account for this type of data and possibly for dialogic material of other types. (C) 2003 Elsevier Science B.V. All rights reserved.|conversation analysis; general theory of verbal humor; politeness; social and linguistic conventions; telephone call openings; Greek|IMPOLITENESS; SOLIDARITY; POWER|Linguistics; Language \& Linguistics|27|0|4
Dynamic context generation for natural language understanding: A multifaceted knowledge approach|2003|We describe a comprehensive framework for text understanding, based on the representation of context. It is designed to serve as a representation of semantics for the full range of interpretive and inferential needs of general natural language processing. Its most distinctive feature is its uniform representation of the various simple and independent linguistic sources that play a role in determining meaning: lexical associations, syntactic restrictions, case-role expectations, and most importantly, contextual effects. Compositional syntactic. structure from a shallow parsing is represented in a neural het-based associative memory, where it then interacts through a Bayesian network with semantic associations and the context or ``gist{''} of the passage carried forward from preceding sentences. Experiments with more than 2000 sentences in different languages are included.|connectionism; context-dependent model; knowledge representation; natural language understanding|DISTRIBUTED REPRESENTATIONS; INFORMATION; MODEL; DISAMBIGUATION; COMPREHENSION; RETRIEVAL; NETWORKS; SYSTEMS|Computer Science, Cybernetics; Computer Science, Theory \& Methods|11|0|4
From ear to cortex: A perspective on what clinicians need to understand about speech perception and language processing|2002|Phoneme-sized phonetic segments are often defined as the most basic unit of language organization. Two common inferences made from this description are that there are clear correlates to phonetic segments in the acoustic speech stream, and that humans have access to these segments from birth. In fact, well-replicated studies have shown that the acoustic signal of speech lacks invariant physical correlates to phonetic segments, and that the ability to recognize segmental structure is not present from the start of language learning. Instead, the young child must learn how to process the complex, generally continuous acoustic speech signal so that phonetic structure can be derived. This paper describes and reviews experiments that have revealed developmental changes in speech perception that accompany improvements in access to phonetic structure. In addition, this paper explains how these perceptual changes appear to be related to other aspects of language development, such as syntactic abilities and reading. Finally, evidence is provided that these critical developmental changes result from adequate language experience in naturalistic contexts, and accordingly suggests that intervention strategies for children with language learning problems should focus on enhancing language experience in natural contexts.|speech perception; phonological processing; phonological awareness; language processing|SHORT-TERM-MEMORY; POOR READERS; STOP CONSONANTS; DEVELOPMENTAL APHASIA; PHONOLOGICAL CODES; IMPAIRED CHILDREN; SERIAL-RECALL; DEFICITS; SIMILARITY; SYLLABLES|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|23|0|4
``Dear Sirs, what would you do if you were in our position?{''}. Discourse strategies in Italian and English money chasing letters|2002|It is nowadays widely accepted that different cultures structure discourse in different ways. Moreover, research has shown that this also holds for discourse genres traditionally considered as highly standardized in their rituals and formulas, written business communication being a case in point. Taking inspiration from such research, a computer-based training (CBT) system using a hybrid technology-case-based reasoning and a neural network-and based on a constructivist paradigm, has been designed to help Italian students write effective business letters in English. `Effective' means that what the system aims at is to help students define and attain communicative goals consonant with proven business discourse practice in the target culture. The present paper offers the theoretical framework for a major addition to the system in its current implementation. The point of departure is the pedagogical principle according to which making students aware of another culture's rhetorical preferences is best achieved by making their own rhetorical tradition visible to them contrastively. The metacognitive awareness developed in this way helps students realize that discourse organization is basically a matter of making choices which are inevitably intrinsically culture bound. To foster such an awareness, the CBT system will be enhanced with a module that, consistent with the underlying constructivist paradigm, will help users to observe, notice, compare and contrast differences and similarities in the discourse patterns characterizing Italian and English business letters. To implement such a module, an initial corpus of authentic Italian and English `money chasing' letters has been analyzed contrastively. This paper reports the findings of that analysis. As to the theoretical framework, at the macro-textual level the analysis focuses on rhetorical structure, mainly drawing on the notion of move. At the micro-textual level the analysis concentrates on mood, reference system, modality and use of metadiscourse. Both the macro- and the micro-level analyses are considered necessary to bring out the divergence in business letter discourse between the two cultures. (C) 2002 Elsevier Science B.V. All rights reserved.|business communication; contrastive rhetoric; discourse organization; genre; move structure analysis; politeness; Italian; English|PERSPECTIVE; REQUESTS; GENRE; TEXT|Linguistics; Language \& Linguistics|13|1|4
Incremental syntactic parsing of natural language corpora with simple synchrony networks|2001|This article explores the use of Simple Synchrony Networks (SSNs) for learning to parse English sentences drawn from a corpus of naturally occurring text. Parsing natural language sentences requires taking a sequence of words and outputting a hierarchical structure representing how those words fit together to form constituents. Feed-forward and Simple Recurrent Networks have had great difficulty with this task, in part because the number of relationships required to specify a structure is too large for the number of unit outputs they have available. SSNs have the representational power to output the necessary O(n(2)) possible structural relationships because SSNs extend the O(n) incremental outputs of Simple Recurrent Networks with the O(n) entity outputs provided by Temporal Synchrony Variable Binding. This article presents an incremental representation of constituent structures which allows SSNs to make effective use of both these dimensions. Experiments on learning to parse naturally occurring text show that this output format supports both effective representation and effective generalization in SSNs. To emphasize the importance of this generalization ability, this article also proposes a short-term memory mechanism for retaining a bounded number of constituents during parsing. This mechanism improves the O(n(2)) speed of the basic SSN architecture to linear time, but experiments confirm that the generalization ability of SSN networks is maintained.|connectionist networks; natural language processing; simple synchrony networks; syntactic parsing; temporal synchrony variable binding|NEURAL NETWORKS; REPRESENTATIONS; MEMORY|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|13|0|4
Concept evolution analysis based on the Dissipative Structure of Concept Semantic Space|2018|In the domain of text semantic processing, concept semantic evolution is a common phenomenon involved in the lasting process of a concept's formation and development at different stages, which leads concept evolution analysis to be difficult in identifying concept evolution states. To solve the problem, the paper proposes a method of concept evolution analysis based on the Dissipative Structure of Concept Semantic Space (CSS). First, a CSS is constructed as surroundings where a concept forms and its semantic evolves. Second, an analogy is made with thermodynamics and the theory of Dissipative Structure is applied to CSS, which models the changing process of CSS from the disordered to the ordered. Third, the evolution of concept is analyzed based on the Dissipative Structure of CSS. Finally, the proposed method is verified by an application and experiments. (C) 2017 Elsevier B.V. All rights reserved.|Concept Semantic Space; Dissipative Structure; Concept evolution; Text semantic; Cyber-physical system|KNOWLEDGE; NETWORKS; ONTOLOGY|Computer Science, Theory \& Methods|1|3|3
The challenging task of summary evaluation: an overview|2018|Evaluation is crucial in the research and development of automatic summarization applications, in order to determine the appropriateness of a summary based on different criteria, such as the content it contains, and the way it is presented. To perform an adequate evaluation is of great relevance to ensure that automatic summaries can be useful for the context and/or application they are generated for. To this end, researchers must be aware of the evaluation metrics, approaches, and datasets that are available, in order to decide which of them would be the most suitable to use, or to be able to propose new ones, overcoming the possible limitations that existing methods may present. In this article, a critical and historical analysis of evaluation metrics, methods, and datasets for automatic summarization systems is presented, where the strengths and weaknesses of evaluation efforts are discussed and the major challenges to solve are identified. Therefore, a clear up-to-date overview of the evolution and progress of summarization evaluation is provided, giving the reader useful insights into the past, present and latest trends in the automatic evaluation of summaries.|Text summarization; Evaluation; Content evaluation; Readability; Task-based evaluation|LOCAL COHERENCE; FRAMEWORK; KNOWLEDGE; QUALITY; SYSTEM|Computer Science, Interdisciplinary Applications|0|3|3
Framing, reframing and the transformation of stance in news translation: a case study of the translation of news on the China-Japan dispute|2018|The growing interest in news translation in the last decade has raised issues regarding the nature of news translation itself, leading to a shift away from the traditional concept of equivalence between source text (ST) and target text (TT) to an interest in the role of journalistic conventions in the process. This article examines variation in the stance adopted in translation between Western press reports (in English) and Reference News (Chinese in pinyin: Cancao Xiaoxi) and argues, on the basis of frame analysis of 27 pairs of news reports on the Sino-Japanese territorial dispute, that news translation of controversial issues is a process in which the stance framed in the original news report is reframed for the target culture. Through quantitative and qualitative analysis, this study identifies three prominent types of framing variationsappropriation variation, labeling variation, and ambiguity variationand examines their respective roles in reframing the stance toward a pro-China and often anti-Japan direction in the translation by Reference News.|News translation; stance; frame analysis; reframing; the Sino-Japanese dispute|DISCOURSE|Linguistics; Language \& Linguistics|0|3|3
A Tabu search heuristic for smoke term curation in safety defect discovery|2018|The ability to detect and rapidly respond to the presence of safety defects is vital to firms and to regulatory agencies. In this paper, we employ a text mining methodology to generate industry-specific ``smoke terms{''} for identifying these defects in the countertop appliances and over-the-counter medicine industries. Building upon prior work, we propose several methodological improvements to enhance the precision of our industry-specific terms. First, we replace the subjective manual curation of these terms with an automated Tabu search algorithm, which provides a statistically significant improvement over a sample of human-curated lists. Contrary to the assumptions of prior work, we find that shorter, targeted smoke term lists produce superior precision. Second, we incorporate non-textual review features to enhance the performance of these smoke term lists. In total, we find greater than a twofold improvement over typical human-curated lists. As safety surveillance is vital across industries, our method has great potential to assist firms and regulatory agencies in identifying and responding quickly to safety defects. (C) 2017 Elsevier B.V. All rights reserved.|Text mining; Online reviews; Tabu search; Heuristics; Defects; Business intelligence|WORD-OF-MOUTH; ONLINE REVIEWS; SOCIAL MEDIA; PRODUCT SALES; SENTIMENT; AGREEMENT; INDUSTRY|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|0|3|3
NLPReViz: an interactive tool for natural language processing on clinical text|2018|The gap between domain experts and natural language processing expertise is a barrier to extracting understanding from clinical text. We describe a prototype tool for interactive review and revision of natural language processing models of binary concepts extracted from clinical notes. We evaluated our prototype in a user study involving 9 physicians, who used our tool to build and revise models for 2 colonoscopy quality variables. We report changes in performance relative to the quantity of feedback. Using initial training sets as small as 10 documents, expert review led to final F(1)scores for the ``appendiceal-orifice{''} variable between 0.78 and 0.91 (with improvements ranging from 13.26\% to 29.90\%). F(1)for ``biopsy{''} ranged between 0.88 and 0.94 (-1.52\% to 11.74\% improvements). The average System Usability Scale score was 70.56. Subjective feedback also suggests possible design improvements.|natural language processing (NLP); electronic health records; machine learning; user-computer interface; medical informatics|EXTRACTION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|1|3|3
The interplay of individual differences and context of learning in behavioral and neurocognitive second language development|2018|In order to understand variability in second language (L2) acquisition, this study addressed how individual differences in cognitive abilities may contribute to development for learners in different contexts. Specifically, we report the results of two short-term longitudinal studies aimed at examining the role of cognitive abilities in accounting for changes in L2 behavioral performance and neurocognitive processing for learners in at-home' and study-abroad' settings. Learners completed cognitive assessments of declarative, procedural, and working memory abilities. Linguistic assessments aimed at determining behavioral sensitivity and online processing of L2 Spanish syntax were administered before and after a semester of study in either a traditional university classroom context (Experiment 1) or a study-abroad context (Experiment 2). At-home learners evidenced behavioral gains, with no detected predictive role for individual differences in cognitive abilities. Study-abroad learners evidenced behavioral gains and processing changes that were partially accounted for by procedural learning ability and working memory. Taken together, these results provide preliminary insight into how individual differences in cognitive abilities may contribute to behavioral and neural processing changes over time among learners in different natural contexts.|declarative memory; event-related potentials; individual differences; procedural memory; second language; study abroad; working memory|EVENT-RELATED POTENTIALS; BRAIN POTENTIALS; WORKING-MEMORY; PROCEDURAL MEMORY; GENDER AGREEMENT; L2 LEARNERS; ACQUISITION; SYNTAX; ABROAD; COMPREHENSION|Education \& Educational Research; Linguistics|6|3|3
Psychological Features for Automatic Text Summarization|2017|Automatically summarizing a document requires conveying the important points of a large document in only a few sentences. Extractive strategies for summarization are based on selecting the most important sentences from the input document(s). We claim here that standard features for estimating sentence importance can be effectively combined with innovative features that encode psychological aspects of communication. We employ Quantitative Text analysis tools for estimating psychological features and we inject them into state-of-the-art extractive summarizers. Our experiments demonstrate that this novel set of features is a good guidance for selecting salient sentences. Our empirical study concludes that psychological features are best suited for hard summarization cases. This motivated us to formally define and study the problem of predicting the difficulty of summarization. We propose a number of predictors to model the difficulty of every summarization problem and we evaluate several learning methods to perform this prediction task.|Automatic text summarization; psychology of natural language use; linguistic inquiry word count; predicting summarization difficulty|WORDS|Computer Science, Artificial Intelligence|0|3|3
Evaluation and instruction in PhD examiners' reports: How grammatical choices construe examiner roles|2017|One of the principal roles of a PhD examiner is to judge both the potential of the researcher and the quality of the research (Holbrook, Bourke, Fairbairn, \& Lovat, 2014, p. 986). While examiners may be guided by criteria supplied by universities, the descriptors they are provided with can often be open to interpretation. Interpreting an examiner's report can present a challenge to students and their supervisors, exacerbated by the often ambiguous use of language in the reports. This article examines the discourses of evaluation and instruction in 142 PhD examiners reports on theses submitted at an Australasian university. The paper draws on systemic functional linguistics, in particular transitivity (Halliday \& Matthiessen, 2014), in order to examine the reports. The study revealed that examiners can adopt up to 10 roles in their reports, each of which can be co-present in a single report. The inability to differentiate between these roles, we argue, is potentially frustrating for the audience of the reports (candidates, supervisors, departmental heads, etc.), particularly when interpreting whether a comment in the text represents an evaluation, an instruction, or an aside. By revealing these multiple, yet co-present, roles in examiners reports and their associated linguistic realisations, we hope to raise examiners awareness of the implications of the language they use when writing their reports as well as draw thesis supervisor and institutional attention to the ambiguities inherent in this underexplored genre. (C) 2017 Elsevier Inc. All rights reserved.|Grammatical choices; PhD thesis; Examiners' reports; Systemic functional linguistics; Discourse analysis; Roles; Language of evaluation; Transitivity; Mood; Theme|THESES; FEEDBACK|Education \& Educational Research; Linguistics; Language \& Linguistics|0|3|3
Investigating intertextuality and interdiscursivity in evaluation: the case of conceptual blending|2017|The present paper investigates the sense making practices of participants in interaction within the context of reception studies of advertising and explores the cognitive nature of intertextuality and interdiscursivity as evidence of conceptual integration. The paper argues that sense making, through its intertextual and interdiscursive nature, is a carrier of attitudinal disposition which is manifested in the lexical selection of evaluative items arising from conceptual integration. The data examined for this study were collected from informants in focus groups when discussing a series of printed adverts that make reference to works of art. The results of the analysis indicate that intertextuality and interdiscursivity can be seen as constituting evidence of the conceptual phenomena of blending theory in sense making from where evaluative disposition emerges. They further suggest that both are processes in the audience's sense making process rather than merely a feature of texts.|intertextuality; interdiscursivity; conceptual blending; appraisal; sense making|ATTITUDES|Linguistics; Language \& Linguistics; Psychology, Experimental|0|3|3
Gradual development of constructional complexity in German spatial language|2017|In this paper, we assess the developmental trajectories by which children approach adult levels of complexity and informativeness in the linguistically and conceptually challenging domain of spatial language. To this end, we look at three types of spatial relations (localization, spontaneous and caused motion) in spontaneous German child speech (age 2; 6 to 2; 11 and 4; 6 to 4; 11), and in elicited Frog Story narratives from German child and adult speakers (3-, 5-, 9-year-olds, and adults. Children are generally sensitive to typological preferences. From early on, their productions reflect target-languagespecific lexicalization patterns. Our analyses show that they still approach adult-like levels of information complexity and density only gradually. This concerns the local complexity (structural repertoire for the conceptual slots figure, verb, path/ground), as also established in previous research, but in particular the global complexity, as investigated in this study. Global complexity measures the structural integration of information, or the combinatorial complexity that surfaces at the utterance level. As predicted by usage-based theories, adult-like degrees of informativeness and information density are only reached gradually, although the component parts at the local level are available earlier in development.|spatial language; first language development; construction complexity; information density; usage-based|ACQUISITION; USAGE; TEXT|Linguistics; Language \& Linguistics|0|3|3
Automated formative writing assessment using a levels of language framework|2017|This study investigates a novel approach to conducting formative writing assessment that involves evaluating students' writing skills across three levels of language (word, sentence, and discourse) using automated measures of word choice, syntax, and cohesion. Writing from students in Grades 6 and 8 (n = 240 each) was analyzed using Coh-Metrix. Multigroup confirmatory factor analysis evaluated a hypothesized three factor levels of language model, and multigroup structural equation modeling determined if these factors predicted performance on a state writing achievement test comprised of a Direct Assessment of Writing (DAW) and an Editing and Revising test (ER). Results indicated that a subset of 9 Coh-Metrix measures successfully modeled three latent levels of language factors at each grade level. Results also indicated that the DAW test was predicted by the latent Discourse factor and the ER test was predicted by the latent Discourse and Sentence factors. Findings provide a proof of concept for automated formative assessment using a levels of language framework. Furthermore, although not the primary goal of the study, results may lay the groundwork for new levels of language detection algorithms that could be incorporated within automated writing evaluation software programs to expand automated + teacher assessment and feedback approaches.|Automated writing evaluation (AWE); Coh-Metrix; Formative assessment; Natural language processing; Writing assessment|TESTING MEASUREMENT INVARIANCE; INTERMEDIATE-GRADE WRITERS; ESSAY EVALUATION SOFTWARE; OF-FIT INDEXES; STUDENTS; SKILLS; DISABILITIES; FEEDBACK; QUALITY; TEXT|Education \& Educational Research; Linguistics|1|3|3
Effects of corpus-based instruction on phraseology in learner English|2017|This study analyses the effects of data-driven learning (DDL) on the phraseology used by 223 English students at an Italian university. The students studied the genre of opinion survey reports through paper-based and hands-on exploration of a reference corpus. They then wrote their own report and a learner corpus of these texts was compiled. A contrastive interlanguage analysis approach (Granger, 2002) was adopted to compare the phraseology of key items in the learner corpus with that found in the reference corpus. Comparison is also made with a learner corpus of reports produced by a previous cohort of students who had not used the reference corpus. Students who had done DDL tasks used a wider range of genre-appropriate phraseology and produced a lower number of stock phrases than those who had not. The study also finds evidence that students use more phrases encountered in paper-based concordancing tasks than in hands-on tasks. Unlike in previous DDL studies, observations of the learning of a specific text-type through DDL in the present study are based on the comparison with both a control learner corpus and an expert corpus. The study also considers the use of DDL with a large class size.|Data-driven Learning; Learner Corpora; Corpus Linguistics; Language Teaching Methodology|LEXICAL BUNDLES; LANGUAGE; PROFICIENCY|Education \& Educational Research; Linguistics|1|3|3
Assessing syntactic sophistication in L2 writing: A usage-based approach|2017|Over the past 45 years, the construct of syntactic sophistication has been assessed in L2 writing using what Bulte and Housen (2012) refer to as absolute complexity (Lu, 2011; Ortega, 2003; Wolfe-Quintero, Inagaki, \& Kim, 1998). However, it has been argued that making inferences about learners based on absolute complexity indices (e.g., mean length of t-unit and mean length of clause) may be difficult, both from practical and theoretical perspectives (Norris \& Ortega, 2009). Furthermore, indices of absolute complexity may not align with some prominent theories of language learning such as usage-based theories (e.g., Ellis, 2002a,b). This study introduces a corpus-based approach for measuring syntactic sophistication in L2 writing using a usage-based, frequency-driven perspective. Specifically, novel computational indices related to the frequency of verb argument constructions (VACs) and the strength of association between VACs and the verbs that fill them (i.e., verb-VAC combinations) are developed. These indices are then compared against traditional indices of syntactic complexity (e.g., mean length of T-unit and mean length of clause) with regard to their ability to model one aspect of holistic scores of writing quality in Test of English as a Foreign Language (TOEFL) independent essays. Indices related to usage-based theories of syntactic development explained greater variance (R-2=.142) in holistic scores of writing quality than traditional methods of assessing syntactic complexity (R-2=.058). The results have important implications for modeling syntactic sophistication, L2 writing assessment, and AES systems.|Automatic essay scoring; corpus-based; natural language processing; syntactic complexity; usage-based; writing assessment|CONTEMPORARY-AMERICAN-ENGLISH; 2ND-LANGUAGE ACQUISITION; COMPLEXITY-MEASURES; CORPUS; CONSTRUCTIONS; LINGUISTICS; JUDGMENTS; INDEXES; QUALITY; VERBS|Linguistics; Language \& Linguistics|0|3|3
An agreement between the Sardians and the Mermnads in the Lydian language?|2017|This paper addresses the interpretation of a Lydian text inscribed on a stele which was placed in the precinct of Artemis in the Anatolian town of Sardis at some point in the 5th-4th centuries BC. Its linguistic analysis is conducive to the conclusion that it defines the status of a privileged group called the m lambda imna-vis-a-vis the Sardians and mandates payments or transfer of property to the m lambda imna-group. The improved interpretation of the text allows me to revive the old hypothesis according to which the m lambda imna-is the Lydian designation of the Mermnad clan, whose representatives held sway in Sardis before the Achaemenid conquest.|Lydian; Carian; decipherment; Sardis; Achaemenid; Mermnad|ORIGIN|Linguistics; Language \& Linguistics|0|3|3
He's more katakana than kanji: Indexing identity and self-presentation through script selection in Japanese manga (comics)|2017|This paper examines the role of script selection in indexing identities and styles of self-presentation within a Japanese manga (comic). By cataloguing where the kanji, hiragana, and katakana scripts are used to represent first person pronouns, I establish the contexts where each script/pronoun combination serves as a locally normative representation. These norms are compared against non-normative representations to gain insight into the local meanings associated with the various scripts. Analysis of the variant forms is combined with an interview with the manga's author. Ultimately, the results reveal that the contribution of script to the meaning of a Japanese text goes beyond any single marked selection, and involves interactions between both locally normative patterns of script use and meaningful local violations of these norms. Selections of script are seen to convey nuances in how meaning is constructed in the text, as well as reflecting wider ideologies about language use in Japan.|Indexicality; Japanese; Japanese writing; script; language ideology; comics|LANGUAGE; HISTORY|Linguistics|0|3|3
The Semantic Processing of Motion Verbs: Coercion or Underspecification?|2017|Underspecification and coercion are two prominent interpretive mechanisms to account for meaning variability beyond compositionality. While there is plentiful evidence that natural language meaning constitution exploits both mechanisms, it is an open issue whether a concrete phenomenon of meaning variability is an instance of underspecification or coercion. This paper argues that this theoretical dispute can be settled experimentally. The test case are standard motion verbs (e.g. walk, ride) in combination with +/- telic directional phrases, for which both underspecifaction and coercion analyses have been proposed in the literature. A self-paced reading study which incorporates motion verbs, directional phrases and durative/completive temporal adverbials (1) aims at determining the aspectual value of such verbs, and (2) compares the hypotheses of the Underspecification and Coercion Accounts. The results of the reading time experiment (flanked by a corpus study and a completion study) indicate that motion verbs are aspectually underspecified. They combine with +/- telic directional phrases with equal ease. The combination with a mismatching temporal adverbial is an instance of coercion, causing additional processing costs.|Motion verbs; Aspectual coercion; Underspecification; Semantic processing|ASPECTUAL COERCION|Linguistics; Psychology, Experimental|1|2|3
The mechanism of additive composition|2017|Additive composition (Foltz et al. in Discourse Process 15:285-307, 1998; Landauer and Dumais in Psychol Rev 104(2):211, 1997; Mitchell and Lapata in Cognit Sci 34(8):1388-1429, 2010) is a widely used method for computing meanings of phrases, which takes the average of vector representations of the constituent words. In this article, we prove an upper bound for the bias of additive composition, which is the first theoretical analysis on compositional frameworks from a machine learning point of view. The bound is written in terms of collocation strength; we prove that the more exclusively two successive words tend to occur together, the more accurate one can guarantee their additive composition as an approximation to the natural phrase vector. Our proof relies on properties of natural language data that are empirically verified, and can be theoretically derived from an assumption that the data is generated from a Hierarchical Pitman-Yor Process. The theory endorses additive composition as a reasonable operation for calculating meanings of phrases, and suggests ways to improve additive compositionality, including: transforming entries of distributional word vectors by a function that meets a specific condition, constructing a novel type of vector representations to make additive composition sensitive to word order, and utilizing singular value decomposition to train word vectors.|Compositional distributional semantics; Bias and variance; Approximation error bounds; Natural language data; Hierarchical Pitman-Yor process|NEURAL NETWORKS; SEMANTICS; MODELS; LAW|Computer Science, Artificial Intelligence|0|2|3
A resource of errors written in Spanish by people with dyslexia and its linguistic, phonetic and visual analysis|2017|In this work we introduce the analysis of DysList, a language resource for Spanish composed of a list of unique spelling errors extracted from a collection of texts written by people with dyslexia. Each of the errors was annotated with a set of characteristics as well as with visual and phonetic features. To the best of our knowledge, this is the largest resource of this kind in Spanish. We also analyzed all the features of Spanish errors and our main finding is that dyslexic errors are phonetically and visually motivated.|Errors; Dyslexia; Visual; Phonetics; Resource; Spanish|SPELLING-ERRORS; READING-DISABILITY; ACQUISITION; ATTENTION; STUDENTS; DEFICIT|Computer Science, Interdisciplinary Applications|0|3|3
Asynchronous group review of EFL writing: Interactions and text revisions|2017|The current paper reports an empirical study of asynchronous online group review of argumentative essays among nine English as foreign language (EFL) Arab university learners joining English in their first, second, and third years at the institution. In investigating online interactions, commenting patterns, and how the students facilitate text revisions, a three-level analysis of learners' comments in terms of the language functions, nature and focus area, and connections to subsequent text revisions was conducted. The learners produced a number of 1792 comments which were exploratory, including scaffolding and non-scaffolding (72\%), procedural (11\%), and social (17\%) comments. In relation to the nature and focus area, 53\% of the exploratory comments were revision-oriented comments-focusing on global (n = 799; 84\%) and local (n = 149; 16\%) issues of learners' essays-whereas non-revision-oriented comments (47\%) focused on learners' socio-relational space (74\%), task management (23\%) and technical challenges (3\%). The findings also showed that 46\% of the overall global (n = 615) and only 10\% of the overall local (n = 838) text revisions were connected to learners' comments, indicating the value of global oriented comments in facilitating learners' global text revisions. Differences of occurrence of these commenting patterns among the three groups were found. Such findings suggest that global text revisions need to be modelled by instructors.|Asynchronous Group Review; Interactions; Text Revisions; EFL Learners|FACE-TO-FACE; COLLEGE-STUDENTS; FOREIGN-LANGUAGE; ONLINE; ENGLISH; TECHNOLOGY; LEARNERS; FEEDBACK; SUPPORT; WRITERS|Education \& Educational Research; Linguistics|1|2|3
Longitudinal changes in linguistic complexity among professional football players|2017|Reductions in spoken language complexity have been associated with the onset of various neurological disorders. The objective of this study is to analyze whether similar trends are found in professional football players who are at risk for chronic traumatic encephalopathy. We compare changes in linguistic complexity (as indexed by the type-to-token ratio and lexical density) measured from the interview transcripts of players in the National Football League (NFL) to those measured from interview transcripts of coaches and/or front-office NFL executives who have never played professional football. A multilevel mixed model analysis reveals that exposure to the high-impact sport (vs no exposure) was associated with an overall decline in language complexity scores over time. This trend persists even after controlling for age as a potential confound. The results set the stage for a prospective study to test the hypothesis that language complexity decline is a harbinger of chronic traumatic encephalopathy. (C) 2017 Elsevier Inc. All rights reserved.|Chronic traumatic encephalopathy; Linguistic complexity; Natural language processing; Type-to-token ratio; Lexical density|TRAUMATIC BRAIN-INJURY; CONVERSATIONAL SPEECH; ALZHEIMERS-DISEASE; OLDER ADULTS; LIFE-SPAN; DISCOURSE; DEMENTIA; MILD; LANGUAGE; NARRATIVES|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|0|0|3
Differentiated eliteness: socialization for academic leadership|2017|This article examines how different forms of eliteness are reflected and produced in discursive practices in texts and participant testimonials published on two websites describing American university leadership development programs. It emphasizes the way that these practices operate to thematize and differentiate forms of eliteness (academic vs. administrative) that have a long tradition of being represented as antithetical forms of knowledge, expertise and ways of life, and to socialize participants with claims to one kind of eliteness to another. Through the examination of the use of titles, characterizations of program participants as pedagogical subjects, narratives of personal transformation and skills discourses {[}Urciuoli, B. 2008. Skills and Selves in the New Workplace. American Ethnologist 35 (2): 211-228.], the analysis shows how discourse is implicated in the production and reproduction of neoliberal subjects and perspectives on institutional functions and roles.|Eliteness; academia leadership; neoliberalism|SELVES|Humanities, Multidisciplinary; Communication; Linguistics|0|0|3
Predicting inpatient clinical order patterns with probabilistic topic models vs conventional order sets|2017|Objective: Build probabilistic topic model representations of hospital admissions processes and compare the ability of such models to predict clinical order patterns as compared to preconstructed order sets. Materials and Methods: The authors evaluated the first 24 hours of structured electronic health record data for >10K inpatients. Drawing an analogy between structured items (e.g., clinical orders) to words in a text document, the authors performed latent Dirichlet allocation probabilistic topic modeling. These topic models use initial clinical information to predict clinical orders for a separate validation set of >4K patients. The authors evaluated these topic model-based predictions vs existing human-authored order sets by area under the receiver operating characteristic curve, precision, and recall for subsequent clinical orders. Results: Existing order sets predict clinical orders used within 24 hours with area under the receiver operating characteristic curve 0.81, precision 16\%, and recall 35\%. This can be improved to 0.90, 24\%, and 47\% (P<10(-20)) by using probabilistic topic models to summarize clinical data into up to 32 topics. Many of these latent topics yield natural clinical interpretations (e.g., ``critical care,{''} ``pneumonia,{''} ``neurologic evaluation{''}). Discussion: Existing order sets tend to provide nonspecific, process-oriented aid, with usability limitations impairing more precise, patient-focused support. Algorithmic summarization has the potential to breach this usability barrier by automatically inferring patient context, but with potential tradeoffs in interpretability. Conclusion: Probabilistic topic modeling provides an automated approach to detect thematic trends in patient care and generate decision support content. A potential use case finds related clinical orders for decision support.|clinical decision support systems; electronic health records; data mining; probabilistic topic modeling; clinical summarization; order sets|ELECTRONIC HEALTH RECORDS; DECISION-SUPPORT-SYSTEMS; PRACTICE GUIDELINES; BIG DATA; ENTRY; KNOWLEDGE; MEDICINE; DESIGN; TRIALS; MENUS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|2|3
NegoChat-A: a chat-based negotiation agent with bounded rationality|2016|To date, a variety of automated negotiation agents have been created. While each of these agents has been shown to be effective in negotiating with people in specific environments, they typically lack the natural language processing support required to enable real-world types of interactions. To address this limitation, we present NegoChat-A, an agent that incorporates several significant research contributions. First, we found that simply modifying existing agents to include an natural language processing module is insufficient to create these agents. Instead, agents that support natural language must have strategies that allow for partial agreements and issue-by-issue interactions. Second, we present NegoChatA's negotiation algorithm. This algorithm is based on bounded rationality, and specifically anchoring and aspiration adaptation theory. The agent begins each negotiation interaction by proposing a full offer, which serves as its anchor. Assuming this offer is not accepted, the agent then proceeds to negotiate via partial agreements, proposing the next issue for negotiation based on people's typical urgency, or order of importance. We present a rigorous evaluation of NegoChat-A, showing its effectiveness in two different negotiation roles.|Human-agent interactions; Negotiation; Algorithms|BY-ISSUE NEGOTIATIONS; REFERENCE POINTS; INFORMATION; PREFERENCE|Automation \& Control Systems; Computer Science, Artificial Intelligence|6|0|3
The prologues to Ruben Dario's Azul ... (1890): reflections and dependencies|2016|Juan Valera's commentaries to Azul ... (1888) meant a kind of literary canonization for the young Dario, who decided to incorporate them into book's second edition, placing them before Eduardo de la Barra's original prologue. Valera's famous letters ended up replacing De la Barra's text, as a consequence of an autopromotion process in which Dario was placing Azul.... as the beginning of Hispanic modernism and the origin of what himself called his ``bregas posteriores{''}. Nevertheless, a detailed analysis of both texts can demonstrate to what extent Valera is debtor of Eduardo de la Barra's remarks and anticipated ideas. Besides, De la Barra penetrated much more than the Spanish novelist in the relationship between Dario's poetics and French literature, and more specifically with Parnassian and Decadent poets. We explain the reflections and dependencies between the two prologues that accompanied the Azul...'s Guatemalan edition (1890), up to now just suggested by some critics.|Ruben Dario; Azul ... Prologues; Juan Valera; Eduardo de la Barra|DARIO,RUBEN; `AZUL'|Linguistics; Language \& Linguistics; Literature, Romance|0|1|3
PLASTIC LETTERS: ALPHABET MIXING AND IDEOLOGIES OF PRINT IN UKRAINIAN SHOP SIGNS|2015|This article examines the complex intersection of language ideologies shaping alphabetic choices in Ukrainian outdoor advertising and shop signs, focusing on alphabet mixing through the insertion of Latin letters into Cyrillic texts and the juxtaposition of parallel or alternating texts using both of these writing systems. Drawing upon ethnographic data from work with graphic designers and consumers as well as analysis of language use in signs, I argue that while alphabet mixing is often characterized as ``faddish{''} or ``youth-oriented{''} these practices also reflect Soviet-era ideological stances towards both Latin typefaces, seen as ``plastic{''} letters associated with Western capitalism, and Cyrillic typefaces, seen as ``rigid{''} forms subject to strong central control by the Soviet state. The increasing availability of personal computers with word-processing and graphic design software in Ukraine has both increased access by individuals to print technology, and promoted a new typographic aesthetic through the dissemination of Cyrillic fonts based on Latin, not Soviet or pre-Soviet Cyrillic, models.|Digraphia; Orthography; Advertising; Ukraine|IDENTITY; LANGUAGE|Linguistics; Language \& Linguistics|0|0|3
Direct object resumption in Hebrew: How modality of presentation and relative clause position affect acceptability|2015|Hebrew is generally considered a language with grammaticized resumption, in which resumptive pronouns (RPs) and gaps alternate freely in direct object position. The current study investigates whether and how speakers' acceptability judgments of direct object RPs in Hebrew are affected by the position of the relative clause in the main clause and the modality in which the sentences are presented. A hundred and eight Hebrew speakers completed an acceptability rating survey which included sentences with relative clauses modifying the main clause subject, direct, or indirect object, with either a gap or a resumptive pronoun. Modality of presentation was visual for half of the participants, and auditory for the other half. Results show that Hebrew speakers consistently judge direct object resumptives as less natural than gaps, particularly when sentences are presented in written form. The position of the relative clause does not interact with the acceptability of the RP. We discuss how different processing considerations may have contributed to the pattern of results observed. (C) 2015 Elsevier B.V. All rights reserved.|Resumption; Resumptive pronouns; Relative clauses; Hebrew; Auditory modality; Acceptability ratings|PRONOUNS; DEPENDENCIES; ENGLISH|Linguistics; Language \& Linguistics|1|0|3
CONDUCTING A TASK WHILE RECONSTRUCTING ITS MEANING: INTERACTION, PROFESSIONAL IDENTITIES AND RECONTEXTUALIZATION OF A WRITTEN TASK ASSIGNMENT|2015|This article investigates the way an institutional task of a meeting is oriented to by different meeting participants and developed in and through local interaction. Our data come from a city organization, where a large organizational change is planned and prepared through a series of face-to-face encounters and accompanying written texts. Using the notion of recontextualization and by connecting it to the conversation analytical method and to the notion of intersubjectivity, the study examines how the institutional task that is verbalized in written form prior to the meeting is conceptualized by meeting participants in their turns of talk. By doing so, the study will particularly shed light on the question of how different recontextualizations are motivated by their sequential position in interaction. Based on this, it also investigates how the meeting participants construct their professional identities through the conceptualizations made. In a wider sense, the article shows how spoken interaction and written texts interweave and form a reciprocal relationship in organizational life. Thus, it contributes to a deeper understanding about the multifaceted connections between the interactional management of meetings and wider organizational practices and processes that these encounters have been set up to advance.|Institutional task; Agenda; Recontextualization; Meeting interaction; Professional identity; Conversation analysis; Intersubjectivity|WORKPLACE MEETINGS; DISCOURSE; PARTICIPATION; CONVERSATION; DISAGREEMENT; ALIGNMENT; SESSIONS; RESOURCE; GENRE; TEAM|Linguistics; Language \& Linguistics|0|0|3
An Analysis of Spanish L2 Learners' Orientation Through Activity Theory|2015|Orientation is defined as the way in which individuals view a task and the means they devise to fulfill it (Appel \& Lantolf, 1994; Roebuck, 2000). This study investigated the orientation of twelve learners enrolled in a fourth-semester Spanish L2 university course through the analysis of their interactions during a collaborative text-reconstruction task and in their post-activity reflections on their participation. Viewed through the lens of activity theory (Appel \& Lantolf, 1994; Wertsch, 1998), learners' behavior and reflections presented an account of their orientation that was rooted in their motives, needs, and goals and materialized in concrete action during the task. Findings demonstrated that (a) learners' orientation changed at various times during the activity depending on how their individual goals were met by the social setting (e.g.,how helpful their partner was in completing the task) and (b) learners' reflections exposed information that was not apparent in activity (e.g., dissatisfaction with the task) but essential for language practitioners who seek to understand learners' goals, needs, and overall orientation toward language learning. Pedagogical implications address the implementation of orientation assessment forms in the L2 classroom.|orientation; interaction; activity theory; spanish|LANGUAGE-DEVELOPMENT; PROFICIENCY; ENGAGEMENT; PATTERNS; L1|Education \& Educational Research; Linguistics|0|0|3
Evolution of reflexive signals using a realistic vocal tract model|2015|We introduce a model of the evolution of reflexive primate signals that incorporates a realistic vocal tract model for generating the signals. Signaler neural networks receive signal types as inputs and produce vocal tract muscle activations as outputs. These muscle activations are input to a model of the primate vocal tract, generating real sounds. Receiver neural networks receive spectrograms of these sounds as inputs and produce signal type classifications as outputs. Incorporating a realistic vocal tract has a substantial effect on the types of signals that can evolve. Compared to a model with abstract signals, the realistic model signals are more similar and have more correlated elements. The realistic, embodied model also exhibits more variability in rate of adaptation, usually adapting more slowly. This may be explained by the more jagged fitness landscapes in the realistic model. The realistic signals also tend to be quiet. Environmental noise results in louder signals but makes the evolutionary process even slower and less robust. These results indicate that signal evolution with a more realistic genotype-phenotype mapping can differ substantially from evolution with abstract signals. Including realistic signal generation mechanisms may enable computational models to provide greater insights into natural signal evolution.|Embodiment; evolution; motor control; neural network; vocal signals; computational model|CENTRAL PATTERN GENERATORS; MONKEY ALARM CALLS; SAIMIRI-SCIUREUS; NEURAL-NETWORKS; SEMANTIC COMMUNICATION; LANGUAGE EVOLUTION; VOWEL ACQUISITION; EMBODIED AGENTS; SPINAL-CORD; SPEECH|Computer Science, Artificial Intelligence; Psychology, Experimental; Social Sciences, Interdisciplinary|0|0|3
Supporting interoperability of genetic data with LOINC|2015|Electronic reporting of genetic testing results is increasing, but they are often represented in diverse formats and naming conventions. Logical Observation Identifiers Names and Codes (LOINC) is a vocabulary standard that provides universal identifiers for laboratory tests and clinical observations. In genetics, LOINC provides codes to improve interoperability in the midst of reporting style transition, including codes for cytogenetic or mutation analysis tests, specific chromosomal alteration or mutation testing, and fully structured discrete genetic test reporting. LOINC terms follow the recommendations and nomenclature of other standards such as the Human Genome Organization Gene Nomenclature Committee's terminology for gene names. In addition to the narrative text they report now, we recommend that laboratories always report as discrete variables chromosome analysis results, genetic variation(s) found, and genetic variation(s) tested for. By adopting and implementing data standards like LOINC, information systems can help care providers and researchers unlock the potential of genetic information for delivering more personalized care.|Genetics; LOINC; Medical records systems; Clinical laboratory information systems; Vocabulary; controlled|ELECTRONIC HEALTH RECORD; CLINICAL DOCUMENT NAMES; ALLELE NOMENCLATURE; SUGGESTIONS; ONTOLOGY; GENOMICS|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|5|1|3
Context as Achilles' heel of translation technologies Major implications for end-users|2015|The tools of translation memories and machine translation can be viewed as (not) being able to draw on different aspects of context that are relevant to a particular translation project, such as bilingual text, portions of a text, versions of a text, related text, or extralinguistic context. The aspects of context that the tools can indeed draw on and how well they do so highlight their most important benefits, whereas the aspects of context that the tools may fail to draw on reveal their weaknesses. In cases where, depending on the context, a piece of text being translated may have more than one meaning or a translation of a piece of text may be rendered in more than one way, the contexts the tools are able to draw on are critical. An analysis of different kinds of context in different applications highlights the circumstances in which users of TM and MT tools may risk accepting semantically and lexically undesirable output, as well as when TM tool users may risk inputting contextually inappropriate translations. Further, context is an important consideration when integrating MT output into TM tools. Although TM and MT technologies differ in how they produce translation output, end-users of both tool types may face similar contextual challenges.|translation; technology; translation memory; machine translation; context; post-editing|TECHNICAL COMMUNICATION; VIEW|Linguistics; Language \& Linguistics|2|2|3
Student writing: gender and visibility; then and now|2015|Purpose - The purpose of this paper is to examine a selection of creative writings by students at one Australian secondary school over a period of 50-plus years, charting the frequency with which key markers of gender appear in student storytelling over this period and sampling the types of gendered representation demonstrated in these stories. Design/methodology/approach - Taken from a larger study, and grounded in feminist and poststructuralist reading practices, the research draws on Critical Discourse Analysis and quantifies verbal processes relating to gender using Halliday and Matthiessen's Systemic Functional Linguistics (SFL) (2004). Findings - The research finds the visibility of females in the selected corpus has increased considerably, yet the nature of female and male participation in these texts remains comparatively unchanged when measured by the process types of Halliday and Matthiessen's SFL (2004). Originality/value - If past decades of (pro) feminist choices are only challenging gendered patterns of representation at the level of quantity but not type, this has significant implications for teachers of English. The paper's conclusion considers what more might be done in present and future teaching to assist students to problematise their own, as well as others', representations of gender.|Critical discourse analysis; Gender representation; School magazines|GIRLS; ACHIEVEMENT; FEMINIST|Education \& Educational Research; Linguistics; Language \& Linguistics|0|0|3
Changing politics, changing language The effect of institutional and communicative changes on political language measured through content analysis of Italian intra-party debates|2015|This paper examines the changes in political language that occurred after 1989 in Italy and focuses on textual documents drafted by intra-party subgroups between 1946 and 2010 that were related to the internal debates of Italian political parties. These documents, which are addressed to party members and activists rather than the wider public, have been analyzed through quantitative text analysis of word frequencies. The results confirm that a few relevant changes occurred that involve the lexicon, tone, and content of messages. However, concepts such as left and right are still relevant, and we observed neither a strong decline in the use of ideological terms nor a wider usage of populist words. Despite the growing personalization of politics, the main political leaders are not frequently mentioned, with two exceptions: Prodi and Berlusconi. Overall, there is a distance between intra-party politics and the logic of entertainment.|ideology; leadership; populism; text analysis; lexicon; left-right|PARTY; MEDIATIZATION; BERLUSCONI; DISCOURSE; LEADERS|Linguistics; Language \& Linguistics|0|0|3
A Corpus-based Study of Fillers among Native Basque Speakers and the Role of Zera|2014|Although speakers often transmit their messages clearly and concisely, their speech also includes disfluencies, including filler words. We have analyzed the kinds of filler-like words (hereafter fillers) that native Basque speakers produce and the role that these fillers have within the discourse. We recorded six Basque L1 speakers in a natural setting designed to trigger spontaneous speech. Because Basque is an agglutinative language it may offer speakers certain options for filler use that have not been observed in studies of languages that do not have such a rich agglutinative morphology (e. g. English). When speakers are close to the retrieval of a to-be-produced word, but not quite able to access it, they may use the agglutinative morphology to give the listener clues to the syntactic category of the intended word. In Basque such clues could be provided by modifying the surface form of a filler. Our corpus includes approximately 300 filler tokens. We provide analyses of the kinds of fillers this population produces and the contexts in which these appear. Certain fillers tend to be produced before beginning large units (e. g. sentences), whereas others usually precede smaller units. One filler (/zera/) behaves differently than the others. In particular, it assumes context-based forms that offer listeners partial information about the almost-retrieved word.|Discourse processing; disfluencies; hesitation markers; filled pauses; spontaneous speech; Basque|HESITATION PHENOMENA; LANGUAGE PRODUCTION; SPONTANEOUS SPEECH; UH; DISFLUENCIES; LISTENERS; UM; COMPREHENSION; SPEAKING|Audiology \& Speech-Language Pathology; Linguistics; Psychology, Experimental|0|0|3
Historical Genres and the Construction of Historical Meaning: a case study of History major students|2014|The aim of this article is to present a characterization of the stages of the academic genre ``History reading test{''} written by students of History major. The purpose of the research that originates this article was to describe the ways by which historical significance is constructed in the written discourse of future historians. 16 written answers made by first to third year of History majors of the Pontifical Catholic University of Chile from different courses of Chilean History from XV century to XIX century compose the corpus of this investigation. Starting from the systematization proposed by Martin \& Rose (2008), it was considered for the analysis of the ``History reading test{''} the analytical framework of the SystemicFunctional Linguistics and the dimensions that build historical significance in the discourse: temporality, evidentiality and causality. The analysis allowed the identification of four stages for building the academic genre of ``History reading test{''}. These stages were grouped into: a) synthesis, b) contextualization, c) argumentation, and c) closing. We conclude that one of the main elements that affects the development of the stages and phases are the purpose of the reading test (content of the question or instruction) and the reformulation of the evidence.|Historical Literacy; Higher Education; Historical Genres; Systemic-Functional Linguistics|TEXTS; SCHOOL; READ|Linguistics; Language \& Linguistics|0|0|3
Lexical expansion in the HAVE and BE perfect in Dutch A constructionist prototype account|2014|This article investigates lexical expansion in the HAVE and BE perfect in Dutch. It is known from previous research that early perfects show more lexical restrictions than their modern counterparts. The aim of this article is to uncover how perfects change their collocational preferences over time. The present study tackles this issue taking a quantitative corpus perspective. The empirical basis for this study is a sample of HAVE and BE perfects taken from a corpus of Dutch legal texts (1250-1800). The sample is analyzed using the method of diachronic distinctive collexeme analysis. The statistical analysis indicates that both perfect constructions show fine-grained shifts in collocational preferences over time. The observed lexical expansion has the following properties: it proceeds (a) gradually, (b) through semantically related verb classes, (c) away from a prototype. These properties are accounted for making use of insights from prototype theory and construction grammar.|perfect; grammaticalization; semantic compatibility; construction grammar; lexical expansion; collostructional analysis; prototype; transitivity|RESULTATIVES; CORPUS; VERBS|Linguistics; Language \& Linguistics|1|0|3
Analysis of the Effect of Content Familiarity and Gender on English as a Foreign Language Reading Comprehension by Spanish University Students|2014|The aim of this paper is to explore the relative effects of gender and content familiarity on English as a Foreign Language reading comprehension. Sixty-eight elementary and intermediate level undergraduate English language students at the Facility of Teacher Training of the University of Oviedo participated in the study. The results of the study show that gender and content familiarity significantly affected the students' overall comprehension of the texts. The study appears to reject the so-called linguistic threshold hypothesis as both the elementary level and intermediate level readers of the study could read with better understanding when the text was familiar, irrespective of their language knowledge and also seems to support the interactive view of L2 reading comprehension.|reading comprehension; gender; content familiarity; language ability|SEX-DIFFERENCES; KNOWLEDGE|Education \& Educational Research; Linguistics; Language \& Linguistics|3|0|3
Multilingual ``texts{''}: code-switching as an affiliation resource in a globalized community|2013|This article explores the forms and the functions of code-switching (CS) in written communication with mobile phones. We present the major results emanating from research on CS in the SMS communication, and an analysis of a large corpus of French (Switzerland) text messages. The analysis identifies the texters hybrid language uses, and resorting to a limited number of CS types, typically morphosyntactically non complex, and related to internationalized words or formulae, associated to a limited number of domains which bare `cool' and/or cosmopolitan connotations. These results suggest that CS is a resource by means of which participants display membership in a translinguistic and globalized community.|multilingualism; code-switching; SMS communication|SMS|Linguistics; Language \& Linguistics|1|0|3
THE USE OF VARIOUS ASSESSMENT TASKS IN THE ANALYSIS OF THE EFFECT OF PRIOR KNOWLEDGE AND INTEREST ON L2 READING COMPREHENSION|2013|The aim of this study was to analyze the effect of both perceived interest and prior knowledge on L2 reading comprehension, assessed by means of several assessment tasks: written recall, sentence completion and multiple choice. Participants were 129 students enrolled in an intermediate level English course at the University of Oviedo. The results of our study show the significant effect of the two factors approached, perceived interest and prior knowledge on L2 reading comprehension. Specifically, the results show that comprehension assessed via written recall and multiple choice questions is enhanced when readers read texts related to their interests and that prior knowledge has a positive effect on the reader's comprehension irrespective of the assessment method used. This study shows the importance of taking into account the differences among assessment methods and how they may affect the relationship between factors like interest and prior knowledge, and L2 reading comprehension.|Interest; prior knowledge; L2 reading; assessment tasks|SITUATIONAL INTEREST; TOPIC INTEREST; TEXT; RECALL; MODEL|Linguistics; Language \& Linguistics|0|0|3
Decrypting the text: the construction and function of disagreement in Bible study sessions|2013|This paper examines how disagreement over the meaning of the text is conducted and managed in a religious peer-group conversation. Using Bible study sessions as data and ethnomethodological conversation analysis as a method, it investigates how different interpretative versions meet, clash, and merge in social interaction. The paper focuses on the oppositional turn and its linguistic composition and describes three disagreement types: denials, contradictions, and corrections and additions. The paper shows that although all of them treat the previous interpretation as insufficient, they are used to accomplish different social actions and are carefully chosen to fit to their local interactional context. Furthermore, these disagreement types vary depending on how explicitly they express the polarity between the presented views, and in so doing may allow several possible interpretations or enforce participants to construct one definite meaning for the discussed text.|disagreement; oppositional turn; text interpretation; religious conversation; institutional interaction; conversation analysis|TALK; CONVERSATION; ARGUMENT|Communication; Linguistics; Language \& Linguistics|1|0|3
Mapping Partners Master Drug Dictionary to RxNorm using an NLP-based approach|2012|Objective: To develop an automated method based on natural language processing (NLP) to facilitate the creation and maintenance of a mapping between RxNorm and a local medication terminology for interoperability and meaningful use purposes. Methods: We mapped 5961 terms from Partners Master Drug Dictionary (MDD) and 99 of the top prescribed medications to RxNorm. The mapping was conducted at both term and concept levels using an NLP tool, called MTERMS, followed by a manual review conducted by domain experts who created a gold standard mapping. The gold standard was used to assess the overall mapping between MDD and RxNorm and evaluate the performance of mTERMS. Results: Overall, 74.7\% of MDD terms and 82.8\% of the top 99 terms had an exact semantic match to RxNorm. Compared to the gold standard, MTERMS achieved a precision of 99.8\% and a recall of 73.9\% when mapping all MDD terms, and a precision of 100\% and a recall of 72.6\% when mapping the top prescribed medications. Conclusion: The challenges and gaps in mapping MDD to RxNorm are mainly due to unique user or application requirements for representing drug concepts and the different modeling approaches inherent in the two terminologies. An automated approach based on NLP followed by human expert review is an efficient and feasible way for conducting dynamic mapping. (c) 2011 Elsevier Inc. All rights reserved.|Terminology; Standards; Natural language processing; Medication systems; RxNorm|MEDICATION; TERMINOLOGIES; VOCABULARY; SYSTEMS; SUPPORT|Computer Science, Interdisciplinary Applications; Medical Informatics|7|0|3
Historical development from subjective to objective meaning: Evidence from the Japanese question particle ka|2012|In this paper I discuss the historical change of the Japanese question particle ka and argue that its development goes in the opposite direction to the one assumed under the view named `subjectification'. ka has been used as a direct question marker since Old Japanese, but it evolved an indirect question use in Middle Japanese. This change is characterized as a loss of speaker-oriented meanings since direct questions are more speaker-oriented than indirect questions, as can be shown by scope relations. The loss of speaker-orientedness can also be observed in the development of indirect question use of ka. In its early stage, ka entails the speaker's uncertainty, inherited from direct questions. However, it does not exhibit that uncertainty in its later stage, used in contexts where the speaker knows the answer of the embedded question. Since speaker-orientedness is a defining property of `subjectivity' and the changes exhibited by ka are considered to be a natural process of language change, those changes of ka constitute a significant piece of counter-evidence to the hypothesis of `subjectification'. (C) 2012 Elsevier B.V. All rights reserved.|Subjectification; Speaker-orientedness; Indirect question; Scope; Knowledge verbs|SUBJECTIFICATION|Linguistics; Language \& Linguistics|1|0|3
Framing entextualization in improv: Intertextuality as an interactional resource|2012|This study explores a type of language play among a community of improvisational theater (improv) performers, focusing on their strategic deployment of texts in interactions collected backstage while the troupe prepares for performance. Building on the work of Bauman \& Briggs (1990), I adopt a process approach to the analysis of intertextuality, suggesting that community-specific ways of using entextualization, decontextualization, and recontextualization add to the work that has been done on intertextuality, given that it is not merely what texts are used but crucially how they are reshaped that can serve an important social function or the why of intertextuality-in this case explored in the context of member socialization.|Intertextuality; interactional sociolinguistics; ethnography of communication; improvisational theater; improv|PRIVATE|Linguistics; Sociology|5|0|3
Contrastive analysis of the linguistic expression of recommendation in two legal genres|2012|Contrastive analysis of the linguistic expression of recommendation in two legal genres Recommendation is a common communicative operation in the work of many types of professionals, for instance, lawyers. The aim of this paper is to compare the linguistic expression of recommendations in two legal genres containing directive speech acts which recommend certain behaviours: the recommendation of the European Commission and the lawyer-client report of advice. Our purpose is to determine the influence that the following aspects have in the manner of recommending: (i) the similarity between the two texts (regarding the field of expertise) and (ii) the distinctive aspects (mainly, the genre and the communicative situation). In order to provide an answer to this question, the main linguistic expressions of recommendations in each gender are classified and contrasted. The results of the analysis show that the field of expertise does not influence the expression of recommendations.|legal language; recommendation; report; professional genres; institutional discourse|ADVICE|Linguistics; Language \& Linguistics|2|0|3
In defence of a linguistic-aware approach to natural language processing|2012|Although natural language processing can be deemed as a discipline between applied linguistics and artificial intelligence, theoretical linguistics has played a remarkably minor role in this field of research. One of the goals of this paper is to portray the reasons of the failed symbiosis between linguists' research and that of computer scientists, where probabilistic approaches haven been steadily overshadowing linguistic models. In spite of this discouraging scenario, FunGramKB, a knowledge base particularly designed for natural language understanding systems, serves to illustrate how a language-aware and cognitively-plausible approach to human-like processing can contribute to the development of enhanced knowledge-engineering projects.|language engineering; natural language processing; computational linguistics; FunGramKB|CATEGORIES; COMMUNICATION|Linguistics; Language \& Linguistics|0|0|3
The situated common-sense knowledge in FunGramKB|2012|It has been widely demonstrated that expectation-based schemata, along the lines of Lakoff's propositional Idealized Cognitive Models, play a crucial role in text comprehension. Discourse inferences are grounded on the shared generalized knowledge which is activated from the situational model underlying the text surface dimension. From a cognitive-plausible and linguistic-aware approach to knowledge representation, FunGramKB stands out for being a dynamic repository of lexical, constructional and conceptual knowledge which contributes to simulate human-level reasoning. The objective of this paper is to present a script model as a carrier of the situated common-sense knowledge required to help knowledge engineers construct more ``intelligent{''} natural language processing systems.|FunGramKB; common-sense knowledge; situated knowledge; script; natural language understanding|CATEGORIES; CALCULUS; LANGUAGE; CYC|Linguistics; Language \& Linguistics|5|1|3
The ``National Left{''} in Israeli public discourse A critique|2012|In 2000 the leftist camp in Israel experienced a crisis of meaning and identity. This was the result of the failure of the 2000 Camp David Talks between Israel and the Palestinian Authority. The atmosphere that emerged amongst the Israeli left was one of despair and disillusion, a void of meaning. Recently, however, a new Zionist ``national left{''} discourse emerged, which refutes the idea of peace and reconstructs the ideology of the Israeli left. This paper engages critically with this discourse by deploying a discourse analytical approach, as it draws on Ernesto Laclau and Chantal Mouffe's theory of hegemony as well as semantic analysis, specifically the use of ``semantic fields{''} and ``semantic networks{''}. This paper looks at a variety of public texts, which are exemplary of the ``national left{''} discourse in Israel.|Left; Israel; Semantic Analysis; Hegemony; Discourse Analysis; Zionism|FOREIGN-POLICY; CONSTRUCTION|Linguistics; Language \& Linguistics|3|0|3
How discourse context shapes the lexicon Explaining the distribution of Spanish f-/h- words|2012|Using a corpus of Medieval Spanish text, we examine factors affecting the Modern Standard Spanish outcome of the initial /f/ in Latin FV- words. Regression analyses reveal that the frequency of a word's use in extralexical phonetic reducing environments and lexical stress patterns significantly predict the modern distribution of f- (VD and h- ((sic)) in the Spanish lexicon of FV- words. Quantification of extralexical phonetic context of use has not previously been incorporated in studies of diachronic phonology. We find no effect of word frequency, lexical phonology, word class, or word transmission history. The results suggest that rather than frequency of use, it is more specifically a word's likelihood of use in contexts favoring reduction that promotes phonological change. The failure to find a significant effect of transmission history highlights the relative importance of language internal sources of change. Results are consistent with usage-based approaches; contextual variation creates differential articulatory pressures among words, yielding variable pronunciations that, when registered in memory, promote diachronic change.|phonological change; word frequency; discourse context; language contact; usage-based approach; extralexical phonetic context; Spanish phonology|FREQUENCY|Linguistics; Language \& Linguistics|13|0|3
The Ideological Construction of Iran in The NYT|2012|This study used Critical Discourse Analysis (CDA) as a multidisciplinary approach to analyse The New York Times (The NYT) news texts in order to examine how systemic structures and properties of language played a role in the portrayal of the Iranian nation and to provide insights into how the information presented in the news texts had ideological implications. Analysis of news discourse in the study concentrated on the headlines and lead paragraphs of The NYT that covered the post-Islamic republic discourse around the Iranian hostage crisis (1979-1980) and the more recent discourse concerning the Iranian presidential election of June 2009. The discursive analysis showed that there was a tendency to polarize between Us (good, righteous, peaceful, etc.) and Them (evil, violent, etc.) to associate stereotypical negative traits to the out-group. It was found that such ideological representations of the Iranian participants were linguistically realized via the dominant processes of transitivity, thematization, and lexicalization.|Critical Discourse Analysis; Discursive Representation; Systemic Functional Linguistics; Transitivity; Thematization; Lexicalization; Iran|NEWS|Linguistics; Language \& Linguistics|3|0|3
Heresthetics in ballot proposition arguments An investigation of California citizen initiative rhetoric|2012|Political actors typically use language with the goal of persuading an audience. But what shapes the use of language in political settings? Is it differences between ideologues - liberals and conservatives - that change language use? Or is it support or opposition to the issue? Using techniques adapted from cognitive psychology we examine arguments used in ballot proposition elections and show them to exhibit systematic patterns in line with the theoretical arguments of Riker (1996). The actor's choice of issue position - for or against - can be seen to imply that the arguments they advance in support of their position are constrained. More specifically, we show that arguments in support of propositions are consistently similar to each other and consistently dissimilar from arguments against a proposal in language use. These patterns of similarity and dissimilarity persist across a wide range of issues and actors. Identification of these patterns helps explain a persistent empirical regularity within ballot proposition politics: the advantage held by ``NO{''} campaigns.|decision-making; high-dimensional text analysis; ballot initiatives; political rhetoric|DIRECT DEMOCRACY; INFORMATION; BEHAVIOR|Linguistics; Language \& Linguistics|3|0|3
`It's insanely useful!' Students' use of instructional concepts in group work and individual writing|2012|This study investigates students' work on analyzing a literary text, a cartoon strip, with focus on their use of instructional, analytical concepts. Excerpts from a group conversation and from individually written texts are analyzed from a sociocultural, dialogical perspective. The analysis of the conversation shows how such concepts help the students to study the text more closely and maintain an analytical focus. The use of concepts thus helps the students understand the text and what text analysis is about. The students' written texts show that they build on the understanding developed in the group discussion. The analytical focus in the discussion helps them maintain the understanding developed in group when they write individually. Thus, the use of analytical concepts contributes to mediating between group reasoning and individual writing.|upper secondary school; analytical concepts; literary analysis; peer interaction; writing|CLASSROOM; LITERARY; ARGUMENT|Education \& Educational Research; Linguistics; Language \& Linguistics|1|0|3
NEGATION AND LEXICAL MORPHOLOGY ACROSS LANGUAGES: INSIGHTS FROM A TRILINGUAL TRANSLATION CORPUS|2011|This paper proposes an exploratory cross-linguistic bird's eye-view of negative lexical morphology by examining English, French and Italian negative derivational affixes. More specifically, it aims to uncover the French and Italian equivalents of the English affixes de, dis, in, non, un and less. These include morphological equivalents (i. e. negative prefixes in French and Italian) as well as non-morphological equivalents (i. e. single words devoid of negative affixation, multi-word units or paraphrases). The study relies on a nine-million-word trilingual translation corpus made up of texts from the Europarl corpus and shows that the systematic analysis of translation data makes it possible to identify the major morphological dissimilarities between the three languages investigated. The frequent use of non-morphological translations in French and Italian reflects fundamental differences between the source language (English) and the two target languages (French and Italian), hence pointing to possible translation difficulties. Morphological translations, on the other hand, bring to light cross-linguistic similarities in the use of negative affixes.|Lexical morphology; derivation; negation; multilingual corpora; translation|FRENCH|Linguistics; Language \& Linguistics|7|1|3
Combining query-by-example and query expansion for simplifying web service discovery|2011|The vision of a worldwide computing network of services that Service Oriented Computing paradigm and its most popular materialization, namely Web Service technologies, promote is a victim of its own success. As the number of publicly available services grows, discovering proper services is similar to finding a needle in a haystack. Different approaches aim at making discovery more accurate and even automatic. However they impose heavy modifications over current Web Service infrastructures and require developers to invest much effort into publishing and describing their services and needs. So far, the acceptance of this paradigm is mainly limited by the high costs associated with connecting service providers and consumers. This paper presents WSQBE+, an approach to make Web Service publication and discovery easier. WSQBE+ combines open standards and popular best practices for using external Web services with text-mining and machine learning techniques. We describe our approach and empirically evaluate it in terms of retrieval effectiveness and processing time, by using a data-set of 391 public services.|Service oriented computing; Web Service discovery; Query expansion|SEMANTIC WEB; ARCHITECTURE; SIMILARITY; USAGE|Computer Science, Information Systems; Computer Science, Theory \& Methods|11|0|3
``There are two different stories to tell{''} - Collaborative text-picture production strategies of TV journalists|2011|What do journalists do when they negotiate their work, solve their problems, and produce their multimodal news items? This article outlines a theoretical framework for analyzing newswriting processes as a societal, organizational and individual activity and applies it to a case study drawn from a large ethnographic research project. The project combines realist social theory, domain theory, grounded theory, and progression analysis. Ethnographic interviews with stakeholders, video recordings of workplace conversations, and keystroke logs of writing processes in the newsroom are triangulated within this framework. We investigate how the Swiss public broadcasting company should, actually does, and could promote public understanding in Switzerland while operating between the poles of a political mandate and competitive market forces. The overall findings show that the knowledge of how to bridge the gap between the broadcasting company's public mandate and market forces cannot be identified in the executive suites, but in the newsrooms. The case study presented in this article illustrates how an experienced professional journalist recognized a critical situation of collaborative text-picture production and overcame an apparently intractable conflict with his emergent solution. This tacit knowledge - the situated, implicit and individual strategies and practices of certain experienced players - can be made available to the corporation as explicit organizational knowledge. (C) 2010 Elsevier B.V. All rights reserved.|Media linguistics; Realist social theory; Progression analysis; Text production; Writing strategy; Collaborative writing|PERSPECTIVE; EMERGENCE|Linguistics; Language \& Linguistics|10|0|3
A practical method for transforming free-text eligibility criteria into computable criteria|2011|Formalizing eligibility criteria in a computer-interpretable language would facilitate eligibility determination for study subjects and the identification of studies on similar patient populations. Because such formalization is extremely labor intensive, we transform the problem from one of fully capturing the semantics of criteria directly in a formal expression language to one of annotating free-text criteria in a format called ERGO annotation. The annotation can be done manually, or it can be partially automated using natural-language processing techniques. We evaluated our approach in three ways. First, we assessed the extent to which ERGO annotations capture the semantics of 1000 eligibility criteria randomly drawn from ClinicalTrials.gov. Second, we demonstrated the practicality of the annotation process in a feasibility study. Finally, we demonstrate the computability of ERGO annotation by using it to (1) structure a library of eligibility criteria, (2) search for studies enrolling specified study populations, and (3) screen patients for potential eligibility for a study. We therefore demonstrate a new and practical method for incrementally capturing the semantics of free-text eligibility criteria into computable form. (c) 2010 Elsevier Inc. All rights reserved.|Eligibility criteria; Clinical trials; Natural-language processing; Ontology; OWL; Relational databases|DECISION-SUPPORT|Computer Science, Interdisciplinary Applications; Medical Informatics|47|0|3
How the officials' styles of recording the asylum seekers' statements in reports affect the assessment of applications: the case of Belgian asylum agencies|2011|This paper aims at describing the styles of asylum officials when eliciting asylum seekers' narratives of persecution and recording them in the report of the hearing. In order to illustrate the effect of these styles on the assessment of the applicant's request, I analyze the recordings of first-stage hearings, their corresponding records, and the asylum agency's decisions, which I gathered during fieldwork in the Belgian asylum agencies between 2004 and 2007. I distinguish in my corpus two different styles of officials interacting with applicants: ``narrative{''} and ``elicitative.{''} The two styles are associated with two different techniques of drafting the reports, i.e., ``simultaneous{''} and ``mediated.{''} The analysis of my data reveals that officials employing an ``elicitative-mediated style{''} delete assessment-relevant elements of the applicant's oral narrative of the persecution.|asylum hearing; narrative of persecution; elicitative account; investigative interview; recontextualization; written report|TALK; TEXT|Communication; Linguistics; Language \& Linguistics|1|0|3
Irony and (in)coherence: interpreting irony using reader responses to texts|2011|The interpretation of ironic texts in this article is based on informants' responses to authentic texts. This approach is illustrated with a set of responses to a (potentially ironic) letter to the editor published in a major Finnish newspaper. Ironic interpretation is seen as being crucially dependent on coherence. Texts that are perceived as incoherent can result in an ironic interpretation, if the incoherence is also perceived as being intentional, and intentionality in turn is a sign of the edge of the ironist. On the basis of the analysis of informants' responses, ironic interpretation is defined as a combination of five factors: (1) an ironic edge that (2) reflects the intention of the ironist, and (3) has a target and (4) a victim, too. Essential to irony is factor (5): one or more of factors 1-4 must be inferred from co(n)text. This definition of irony is crucial in distinguishing irony from non-irony, and it helps to discern the differences as well as the similarities between irony and related phenomena.|irony; coherence; incoherence; multifactorial definition of irony; response analysis; irony in texts|CONVERSATION|Communication; Linguistics; Language \& Linguistics|1|0|3
What is not said on hearing poetry in the classroom|2010|This article considers an exchange between pupils in response to heard poetry, approaching it through a ``conversation analytic mentality{''} informed by the theories of Basil Bernstein. Using his terms, it describes an existing ``pedagogic device{''} of poetry study for schools, to which responses under discussion do not easily correlate. This is more than an issue of discourse, as the modality of the classroom encounter with the poem - in sound - and the ensuing public discussion present distinctive questions of meaning-making extending beyond semantics to intonation and participation, elements not said. These are salient for the epistemology of classroom interactions with poems as audio texts and related discussion between pupils. The nature of responses can be viewed as entirely apt to the context and the nature of the stimulus, and may constitute subtle insight and imply sophisticated cognition. The discussion is developed with attention to current issues in UK poetry teaching, in particular the difficulties reported in examiners' reports that pupils experience in trying to write about poetry in a conventional analytical discourse. One interpretation of the transcript is that pupils can indeed respond sensitively to poetry, though in ways not easily acknowledged by this established discourse of poetry in schools.|Poetry; response; conversation analysis; Basil Bernstein|STYLE|Education \& Educational Research; Linguistics; Language \& Linguistics|3|0|3
An Information-Theoretic Foundation for the Measurement of Discrimination Information|2010|Hitherto, it has not been easy to interpret the meaning of the amount of discrimination information conveyed in a term rationally and explicitly within practical application contexts; it has not been simple to introduce the concept of the extent of semantic relatedness between two terms meaningfully and successfully into scientific discussions. This study is part of an attempt to do this. We attempt to answer two important questions: 1) What is the discrimination information conveyed by a term and how to measure it? 2) What is the relatedness between two terms and how to estimate it? We focus on the first question and present an in-depth investigation into the discrimination measures based on several information measures, which are widely used in a variety of applications. The relatedness measures are then naturally defined according to the individual discrimination measures. Some key points are made for clarifying potential problems arising from using the relatedness measures, and solutions are suggested. Two example applications in the contexts of text mining and information retrieval are provided. The aim of this study, of which this paper forms part, is to establish a unified theoretical framework, with measurement of discrimination information (MDI) at the core, for achieving effective measurement of semantic relatedness (MSR). Due to its generality, our method can be expected to be a useful tool with a wide range of application areas.|Statistical semantic analysis; measurement of discrimination information; measurement of semantic relatedness; informative term identification; key term extraction; text mining; information retrieval|DETERMINING SEMANTIC SIMILARITY; RETRIEVAL|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|8|0|3
Two hemispheres-two networks: a computational model explaining hemispheric asymmetries while reading ambiguous words|2010|A computational model for reading that takes into account the different processing abilities of the two cerebral hemispheres is presented. This dual hemispheric reading model closely follows the original computational lines due to Kowamoto (J Mem Lang 32:474-516, 1993) but postulates a difference in architecture between the right and left hemispheres. Specifically it is assumed that orthographic, phonological and semantic units are completely connected in the left hemisphere, while there are no direct connections between phonological and orthographic units in the right hemisphere. It is claimed that this architectural difference results in hemisphere asymmetries in resolving lexical ambiguity and more broadly in the processing of written words. Simulation results bear this out. First, we show that the two networks successfully simulate the time course of lexical selection in the two cerebral hemispheres. Further, we were able to see a computational advantage of two separate networks, when information is transferred from the right hemisphere network to the left hemisphere network. Finally, beyond reproducing known empirical data, this dual hemispheric reading model makes novel and surprising predictions that were found to be consistent with new human data.|Disambiguation of natural language; Simulation; Neural networks; Corpus collusum; Modeling; Brain hemispheres|RIGHT CEREBRAL HEMISPHERE; LEXICAL AMBIGUITY; SENTENCE COMPREHENSION; RECOGNITION; RESOLUTION; CONTEXT; INFORMATION; SENSITIVITY; MEANINGS; INDEPENDENCE|Computer Science, Artificial Intelligence; Mathematics, Applied|1|0|3
EU discourse: Polyphony and unclearness|2010|The present article discusses the relevance of studying EU political discourse in a linguistically based polyphonic perspective. The claim is that polyphony is a fruitful approach in the sense that it reveals different types of hidden interaction and thus uncovers implicit and unclear messages. Examples are taken from two speeches given by former Prime Minister Tony Blair, on Europe and European integration, speeches which can be characterised as `visionary speeches'. A selection of linguistic features indicating the presence of different voices in these speeches, which are formally monological, will be presented. The analysis will thus help to identify the nature of the postulated unclearness in political discourse and to make explicit the complex relationship between text and context. The theoretical framework used for analysing the speeches will be linguistic polyphony as developed in the ScaPoLine theory. (C) 2009 Elsevier B.V. All rights reserved.|Political discourse; Polyphony; Unclearness; Ambiguity; EURUN/EURLING project|AMBIGUITY|Linguistics; Language \& Linguistics|6|0|3
Prosody and recursion in coordinate structures and beyond|2010|Generalizations about relative prosodic boundary strength are recursive. Initial evidence comes from the fragment of English consisting only of proper names and and and or. A systematic relation between the semantics, the syntactic combinatorics, and the prosodic phrasing of coordinate structures can be captured by recursively building up their prosody, in tandem with assembling their compositional meaning. Alternative edge-based approaches to prosodic phrasing fail to capture the recursive nature of the generalization, a result independent of whether or not prosodic representation itself is assumed to be recursive. The pattern generalizes beyond the grammar of coordination, despite two types of apparent counterexamples: Structures that are prosodically flat but syntactically articulated, and structures with an apparent outright mismatch between prosody and syntax. Closer inspection suggests that the syntax might actually be quite in tune with prosody. In both cases, natural language employs strategies to construe complex meaning with list-like structures rather than nested ones. The privileged status of lists may be due to processing factors.|Prosody; Recursion; Bracketing paradoxes; Lists|ENGLISH; STRESS; BOUNDARIES; LANGUAGE; GRAMMAR; PHRASE; CONSTRAINTS; INTONATION; FACULTY; SYSTEM|Linguistics; Language \& Linguistics|29|0|3
Supporting collocation learning with a digital library|2010|Extensive knowledge of collocations is a key factor that distinguishes learners from fluent native speakers. Such knowledge is difficult to acquire simply because there is so much of it. This paper describes a system that exploits the facilities offered by digital libraries to provide a rich collocation-learning environment. The design is based on three processes that have been identified as leading to lexical acquisition: noticing, retrieval and generation. Collocations are automatically identified in input documents using natural language processing techniques and used to enhance the presentation of the documents and also as the basis of exercises, produced under teacher control, that amplify students' collocation knowledge. The system uses a corpus of 1.3B short phrases drawn from the web, from which 29M collocations have been automatically identified. It also connects to examples garnered from the live web and the British National Corpus.|CALL; collocation learning; collocation activities; automatic answer generation; cherry-picking|LANGUAGE; SEARCH|Education \& Educational Research; Linguistics; Language \& Linguistics|5|1|3
Automatically extracting cancer disease characteristics from pathology reports into a Disease Knowledge Representation Model|2009|We introduce an extensible and modifiable knowledge representation model to represent cancer disease characteristics in a comparable and consistent fashion. We describe a system, MedTAS/P which automatically instantiates the knowledge representation model from free-text pathology reports. MedTAS/P is based on an open-source framework and its components use natural language processing principles, machine learning and rules to discover and populate elements of the model. To validate the model and measure the accuracy of MedTAS/P, we developed a gold-standard corpus of manually annotated colon cancer pathology reports. MedTAS/P achieves F1-scores of 0.97-1.0 for instantiating classes in the knowledge representation model such as histologies or anatomical sites, and F1-scores of 0.82-0.93 for primary tumors or lymph nodes, which require the extractions of relations. An F1-score of 0.65 is reported for metastatic tumors, a lower score predominantly due to a very small number of instances in the training and test sets. (C) 2009 Elsevier Inc. All rights reserved.|Cancer Disease Knowledge Representation Model; Analysis system; Natural language processing; Concept formation; Information retrieval; Medical records|AGREEMENT|Computer Science, Interdisciplinary Applications; Medical Informatics|54|0|3
Personal pronouns in English and Korean texts: A corpus-based study in terms of textual interaction|2009|This article presents a corpus based cross-cultural text analysis of the use of 2nd person and 1st person plural pronouns in English and Korean newspaper science popularizations. Approaching texts from the perspective of `Reader-Involvement Evoking acts' that is, the writer's textual attempt to evoke the reader's involvement in textual interaction - the research compares how the writers of the two cultures manipulate the two pronouns. The analysis reveals that there are quantitative and qualitative differences in the use of the two pronouns. I argue that these are due partly to syntactic dissimilarities between the two languages such as agent omission in Korean. In addition, the results seem to be affected by the socio-cultural context such as, on the one hand the preference for indirectness in text as a means of building a harmonious relation with the reader and the collectivistic tendency in the Korean society, and on the other the writer's attitude towards the reader and scientific phenomena in the British culture. Furthermore, the different degrees of contribution of science to the economy of each country seem in particular to be reflected in the different emphases on the referential scopes of the 1st person plurals in the two corpora. (C) 2009 Elsevier B.V. All rights reserved.|Cross-cultural text analysis; Textual interaction; Reader-involvement evoking acts; 2nd personal pronoun; 1st person plural; Indirectness|DISCOURSE|Linguistics; Language \& Linguistics|9|0|3
Language engineering techniques for the development of e-learning applications|2009|In this paper we propose the use of language engineering techniques to improve and systematize the development of e-learning applications. E-learning specifications usually rely on domain-specific languages that describe different aspects of such final e-learning applications. This fact makes it natural to adopt well-established language engineering principles during the construction of these applications. These principles promote the specification of the structure and the runtime behavior of the domain-specific languages as the central part of the development process. This specification can be used to drive different activities: rapid prototyping, provision of authoring notations and tools, automatic model checking of properties, importation/exportation from/to standards, and deployment of running applications. This language engineering concept also promotes active collaboration between instructors (the users of the languages) and developers (the designers and implementers) throughout the development process. In this paper we describe this language-driven approach to the Construction Of e-learning applications and we illustrate all its aspects using a learning now sequencing language as a case study. (C) 2009 Elsevier Ltd. All rights reserved.|E-learning applications; Language engineering; Domain-specific languages; Authoring; Model checking; Rapid prototyping|OPERATIONAL SEMANTICS; MODEL-CHECKING; SYSTEMS; DESIGN; UNITS|Computer Science, Hardware \& Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering|6|0|3
A new evaluation methodology for literature-based discovery systems|2009|While medical researchers formulate new hypotheses to test, they need to identify connections to their work from other parts of the medical literature. However, the current volume of information has become a great barrier for this task. Recently, many literature-based discovery (LBD) systems have been developed to help researchers identify new knowledge that bridges gaps across distinct sections of the medical literature. Each LBD system uses different methods for mining the connections from text and ranking the identified connections, but none of the currently available LBD evaluation approaches can be used to compare the effectiveness of these methods. In this paper, we present an evaluation methodology for LBD systems that allows comparisons across different systems. We demonstrate the abilities Of Our evaluation methodology by using it to compare the performance of different correlation-mining and ranking approaches used by existing LBD systems. This evaluation methodology should help other researchers compare approaches, make informed algorithm choices, and ultimately help to improve the performance of LBD systems overall. (C) 2008 Elsevier Inc. All rights reserved.|Literature-based discovery; System evaluation|FISH-OIL; GENERATING HYPOTHESES; ALZHEIMERS-DISEASE; CONNECTIONS; KNOWLEDGE; MAGNESIUM; MIGRAINE; RAYNAUDS; RANKING; MEDLINE|Computer Science, Interdisciplinary Applications; Medical Informatics|28|0|3
Toward a New Process-Based Indicator for Measuring Writing Fluency: Evidence from L2 Writers' Think-Aloud Protocols|2009|This article reports oil a study aimed at testing the hypothesis that, because of strategic and temporal variables, composing rate and text quantity may not be valid measures of writing fluency. A second objective was to validate the mean length of writers' translating episodes as a process-based indicator that mirrors their fluent written production rather than the factors that may be related to it. The translating episode is defined as any chunk that has been written down and terminated by a pause of three or more seconds or by any composing behaviour. Data for the study were drawn from the think-aloud protocols generated by 30 Egyptian university students writing in their second language (L2) and from their retrospective interviews. To examine the validity of the three indicators, the participants' composing rates, text quantity, and translating episodes were related to their scores oil an argumentative writing task and on three linguistic tests. The results of the quantitative and qualitative analyses confirm the hypothesis tested and provide evidence for the validity of this newly developed indicator of writing fluency. Implications and suggestions for further research are presented.|writing fluency; writing process; translating episode length; composing rate; text quantity; think-aloud protocols; L2 writing|COMPOSING PROCESSES; STUDENTS|Linguistics|7|0|3
The Role of Natural Class Features in the Acquisition of Phonotactic Regularities|2009|Previous research has shown that phonotactic regularities can be acquired through recent production or auditory experience (e.g., Dell et al., Journal of Experimental Psychology: Learning, Memory, and Cognition, 26(6), 1355-1367, 2000; Onishi et al., Cognition, 83(1), B13-B23, 2002). However, little is known about the role of phonological natural classes in this learning process. This study addressed this question by investigating the acquisition of a contingency relationship between onsets and medial glides by Mandarin speakers. The experiments involved the manipulation of three types of phonotactic regularities. In the Laryngeal version, onsets that preceded the same glide shared a voicing feature. In the Place version, onsets that preceded same glide shared a place feature. In the Neither version, onsets associated with the same glide shared neither a voicing feature nor a place feature. Results showed the Place version and the Laryngeal version were more easily acquired than the Neither version in terms of the amount of exposure needed to acquire the experimentally manipulated phonotactic schema and the sustainability of the acquired schema. The results suggest that the statistical learning mechanism that guides our processing of speech input prefers phonological regularities that follow certain natural class features. This preference may account for the way natural languages are structured phonologically.|Phonotactics; Acquisition; Natural class features; Cognition; Mandarin-Chinese|BRIEF AUDITORY EXPERIENCE; LEXICAL NEIGHBORHOODS; INFANTS SENSITIVITY; SPEECH PRODUCTION; NATIVE LANGUAGE; CONSTRAINTS; WORDS; PATTERNS; SEGMENTATION; PREFERENCE|Linguistics; Psychology, Experimental|12|1|3
Automatic recognition of handwritten medical forms for search engines|2009|A new paradigm, which models the relationships between handwriting and topic categories, in the context of medical forms, is presented. The ultimate goals are: (1) a robust method which categorizes medical forms into specified categories, and (2) the use of such information for practical applications such as an improved recognition of medical handwriting or retrieval of medical forms as in a search engine. Medical forms have diverse, complex and large lexicons consisting of English, Medical and Pharmacology corpus. Our technique shows that a few recognized characters, returned by handwriting recognition, can be used to construct a linguistic model capable of representing a medical topic category. This allows (1) a reduced lexicon to be constructed, thereby improving handwriting recognition performance, and (2) PCR (Pre-Hospital Care Report) forms to be tagged with a topic category and subsequently searched by information retrieval systems. We present an improvement of over 7\% in raw recognition rate and a mean average precision of 0.28 over a set of 1,175 queries on a data set of unconstrained handwritten medical forms filled in emergency environments.|Handwriting analysis; Language models; Pattern matching; Retrieval models; Search process|TEXT CATEGORIZATION; WORD RECOGNIZERS; RETRIEVAL; DOCUMENTS; INFORMATION; ALGORITHM; LEXICONS; NETWORK|Computer Science, Artificial Intelligence|6|1|3
On-line effects of what is expected on the resolution of plural pronouns|2009|According to Presupposition Denial Theory, complement set reference is reference to a shortfall set which can be implied by a negative quantifier. In support of this, Moxey (2006) showed that participants produce plural pronominal reference to the complement set when a character is introduced who expects more than the amount denoted by a positive quantifier. It is not clear however whether the existence of a shortfall influences on-line comprehension. In this paper, we report four experiments measuring the eye movements of participants while they read short passages of text. In each experiment, we manipulate focus on the shortfall by introducing an expected amount before the quantified set. Our results suggest that eye movements are indeed influenced by the existence of a shortfall whether the shortfall is implied by the quantifier, or by the expectations of a salient character. This is consistent with the predictions of Presupposition Denial Theory.|Quantifiers; Focus; Plural pronomial reference|REGRESSION-CONTINGENT ANALYSES; QUANTIFIERS; ACCOUNT|Linguistics; Psychology, Experimental|8|1|3
The predicated Theme in Alan Paton's Cry, the Beloved Country-a resource for written text|2009|In this paper the explore the use of predicated Themes in the novel Cry, the Beloved Country (1948) by Alan Paton, using the systemic functional framework of analysis. We show how this noncanonical structure helps to build the novel's semantic textual design. The analysis of the structural component of predicated Themes (Theme Rheme and Given-New structures and their interactions) will be essential to an understanding of the functions these structures and other grammatical resources play in the novel. This is complemented by a paradigmatic view on the use of predicated Themes: that is, the view these structures as tire realization of systemic options in the grammar of English, functioning as resources for the creation of text. One proposal for theorizing the novel's semantic organization in particular is explored, that of hyper/macro-Theme/-New, as developed by Martin (1992), based upon work by Fries (1981). By employing these concepts, as features in the semantic systems of ``method of development{''} and ``point{''}, we shot, how the use of predicated Themes may be related to the discourse functions they serve and thus, ultimately, to the context of the novel.|predicated Themes; systemic functional linguistics; Alan Paton; discourse semantics; Theme; Rheme; Given; New|IT-CLEFTS; DISCOURSE|Communication; Linguistics; Language \& Linguistics|2|0|3
The place of narrative in human affairs: the implications of Hymes's Amerindian work for understanding text and talk|2009|Throughout his long career, Dell Hymes studied and wrote about American Indian languages and cultures, and this work has enduring significance for how the think about relations between text and talk. In providing an account of that significance, the article focuses on Hymes's writing about American Indians and narrative, exploring the close interrelations among the two, then discussing his speck contributions to ethnopoetic theory, illustrating these with reference to a Tolowa (Athabaskan) narrative. Because he trenchantly critiqued received assumptions about the relation between speaking and writing, Hymes's ethnopoetic work has implications for ongoing debates about literacy and society, which is discussed at length. I conclude that his narrative scholarship raises but ultimately leaves unsettled fundamental questions about the relation between text and context.|narrative analysis; context; critical literacy studies; American Indians; Tolowa|LITERACY|Communication; Linguistics; Language \& Linguistics|8|0|3
Simulating expert clinical comprehension: Adapting latent semantic analysis to accurately extract clinical concepts from psychiatric narrative|2008|Cognitive studies reveal that less-than-expert clinicians are less able to recognize meaningful patterns of data in clinical narratives. Accordingly, psychiatric residents early in training fail to attend to information that is relevant to diagnosis and the assessment of dangerousness. This manuscript presents cognitively motivated methodology for the simulation of expert ability to organize relevant findings supporting intermediate diagnostic hypotheses. Latent Semantic Analysis is used to generate a semantic space from which meaningful associations between psychiatric terms are derived. Diagnostically meaningful clusters are modeled as geometric structures within this space and compared to elements of psychiatric narrative text using semantic distance measures. A learning algorithm is defined that alters components of these geometric structures in response to labeled training data. Extraction and classification of relevant text segments is evaluated against expert annotation, with system-rater agreement approximating rater-rater agreement. A range of biomedical informatics applications for these methods are suggested. (c) 2008 Elsevier Inc. All rights reserved.|Cognition; Text comprehension; Expertise; Latent semantic analysis; Conceptual spaces; Information extraction; Natural language processing|KNOWLEDGE; REPRESENTATION; PERCEPTION; SUMMARIES|Computer Science, Interdisciplinary Applications; Medical Informatics|13|1|3
Stuttering and Natural Speech Processing of Semantic and Syntactic Constraints on Verbs|2008|Purpose: Previous findings from event-related brain potentials (ERPs) indicate that adults who stutter (AWS) exhibit processing differences for visually presented linguistic information. This study explores how neural activations for AWS may differ for a linguistic task that does not require preparation for overt articulation or engage the articulatory loop for silent speech. Method: Syntactic and semantic processing constraints were examined in AWS and adults who are normally fluent (AWNF) by assessment of their behavioral performance and ERPs in a natural speech listening task. Results: AWS performed similarly to AWNF in identifying v erb-agreement violations and semantic anomalies, but ERPs elicited by syntactic and semantic constraints indicated atypical neural functions for AWS. ERPs of the AWNF displayed an expected N400 for reduced semantic expectations and a typical P600 for verb-agreement violations. In contrast, both N400s and P600s for the semantic and verb-agreement conditions were observed in the ERPs of the AWS. Conclusions: The findings suggest that AWS may engage semantic-syntactic mechanisms more generally for semantic and syntactic processing. These findings converge with earlier studies using visual stimuli to indicate that whereas linguistic abilities are normal in AWS, underlying brain activity mediating some aspects of language processing may function differently.|verb-agreement; semantic anomalies; stuttering; language; ERPs|EVENT-RELATED POTENTIALS; BRAIN POTENTIALS; WORKING-MEMORY; NEURAL SYSTEMS; YOUNG-CHILDREN; FLUENT SPEECH; WORD; COORDINATION; COMPLEXITY; SEVERITY|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|17|0|3
Writing Ideology: Hybrid Symbols in a Commemorative Visitor Book in Israel|2008|This article joins recent ethnographies of written documents which shed light on embedded practices and codes in and through which writing is produced and consumed. The article explores the linguistic ideology of writing through examining inscriptions made in a visitor book in a war commemoration museum in Jerusalem, Israel. These settings supply a dual ideological framework, fusing the modern ideologies of authenticity and national commemoration. Under attention are the physical affordances and circumstances of the visitor book and how they contribute to an ``authentic{''} mode of commemoration-cum-participation via inscribing, where language ideology and national ideology reinforce each other. The analysis suggests that the category ``writing{''} is reductionist, and that under embodied sensibilities it should better be viewed as an array of textual, para-textual, and non-textual visual signs that are fused into the production of materialized hybrid inscriptions. Further, the situatedness and corporeality of inscribing practices carries far reaching semiotic implications, including the transformation of the ontic state of ``texts{''} into that of symbols, calling for the rematerialization of inscribing.|handwriting; language ideologies; museum; commemoration; visitor book|CULTURE; AGENCY; WORDS; TEXTS; WOMEN; LIFE|Anthropology; Linguistics; Language \& Linguistics|15|0|3
A COMMUNITY TEXT PATTERN IN THE EUROPEAN COMMISSION PRESS RELEASE? A GENERIC AND GENETIC VIEW|2008|This contribution is concerned with press releases from the European Commission and national ministries. Political press releases may serve other purposes than those issued by business organisations, and they are also a fairly unexplored field in press release research, which this study sets out to remedy, The linguistic dimension of EU communication is also a neglected field of study, and this paper is aimed at introducing the linguistic dimension of the European Commission communication as a field of study worthy of closer examination. Within a genre-based analytical framework, the present paper aims at examining to what extent we can identify a unique community text pattern in European Commission press releases. I propose a macrostructural text analysis in which I compare a number of press releases issued by the European Commission with national equivalents from French and Swedish ministries. In particular, I will focus on three recurrent and characteristic text features of the European Commission press release, viz. the introduction, the quotation and the intertextual references. It is shown that the way they are designed in the European Commission press release is quite special and that this can be explained with reference to the communicative situation of the European Commission. In doing so, I will be drawing on ethnographic data that I gathered from fieldwork at the European Commission, It will be suggested that the results from this study can be extrapolated to the study of press releases in general. That is, press release research may benefit from the genre-based methodological approach chosen here, since, indeed, the press release is a situated practice whose understanding depends on a comprehensive study of the communicative situations it functions within.|Press releases; Text pattern; Genre analysis; Ethnography; EU; European Commission; Intertextuality|COMMUNICATION; LEGITIMACY; DISCOURSE; POLITICS|Linguistics; Language \& Linguistics|5|0|3
Todos Somos Blancos/We Are All White: Constructing Racial Identities Through Texts|2008|Research has revealed an underlying link between identity construction and academic success for adolescents (Nasir \& Saxe, 2003); however, research has not addressed how students' identities are formed and negotiated in the cultural practices of elementary school. This article examines how early elementary Mexicanorigin bilinguals' racial, ethnic, and linguistic identities are constructed and negotiated during a literacy event on Martin Luther King, Jr. Using critical race theory (Ladson-Billings, 1999) and critical discourse analysis (Gee, 1999), a racial and power dichotomy in the text is uncovered. The moment-to-moment interactions around a text expose the students' understandings of race and the racial assumptions of the literacy practices. A critical discourse analysis of the moment-to-moment interactions shows the students' self-identify as ``White.{''} The teacher and researcher collaboratively examine how racial dichotomies in early elementary literacy texts and institutional practices affect the identity construction of young bilinguals.|critical race theory; elementary school; bilingual; English language learners; racial identity; critical discourse analysis|CRITICAL RACE; EDUCATION|Education \& Educational Research; Linguistics; Language \& Linguistics|5|0|3
Discourse metaphors: The link between figurative language and habitual analogies|2007|Cognitive linguists have long been interested in analogies people habitually use in thinking and speaking, but little is known about the nature of the relationship between verbal behaviour and such analogical schemas. This article proposes that discourse metaphors are an important link between the two. Discourse metaphors are verbal expressions containing a construction that evokes an analogy negotiated in the discourse community. Results of an analysis of metaphors in a corpus of newspaper texts support the prediction that regular analogies are form-specific, i.e., bound to particular lexical items. Implications of these results for assumptions about the generality of habitual analogies are discussed.|discourse metaphor; metaphor theory; figurative meaning; corpus linguistics|PSYCHOLINGUISTICS; SYSTEMS; TIME|Linguistics; Language \& Linguistics|29|0|3
Extraterritoriality and extralegality: The United States Supreme Court and Guantanamo Bay|2007|Although the United States Supreme Court plays a pivotal role in American government and American law, its opinions have seldom been the subject of linguistic analysis. Yet these opinions provide fertile ground for sociolinguistic and discourse analytic research. The American common-law system, with its rich rhetorical tradition of adversarial argumentation and judge-made precedents, furnishes the context in which the Court's decision-making takes place; however, the discursive processes by which the Court's opinions are structured have rarely been examined. This paper presents an analysis of Rasul v. Bush, in which foreign nationals detained as `enemy combatants' at the United States Naval Base at Guantanamo Bay, Cuba, challenged the legality of their detention. By examining the parties' development of competing characterizations of the relevant events, I explore the role of adversarial argumentation in legal decision-making. By tracing the manner in which the Court draws upon these characterizations while framing its decision as grounded in existing law, I present an analysis of the intertextual processes of text construction by which the Court produces its decision as an authoritative legal text that both maintains and transforms existing law.|United States Supreme Court; constitutional law; rhetorical; structure; critical discourse analysis|TRIAL|Communication; Linguistics; Language \& Linguistics|5|1|3
The pragmatics of bereavement|2006|In keeping with the Freudian heritage, the psychological study of mourning has traditionally been conducted from a mentalistic and subjectivist perspective. In this paper, we present an alternative to the mentalistic approach by reconsidering mourning from a socio-sermotic perspective that draws heavily on the early philosophical writings of Bakhtin. More specifically, we conceptualize mourning as a process of meaning-making. This conceptualization is illustrated through texts written by women who have experienced stillbirth. Our analysis points out the social illegitimacy of mourning for a stillborn, the related difficulties. and the way stillbirth mothers struggle to overcome these difficulties. (c) 2005 Elsevier B.V. All rights reserved.|pragmatics and psychology; bakhtinian linguistic analysis; mourning; stillbirth|PERINATAL LOSS; PSYCHOANALYSIS; STILLBIRTH|Linguistics; Language \& Linguistics|7|0|3
Adaptive value within natural language discourse|2006|A trait is of adaptive value if it confers a fitness advantage to its possessor. Thus adaptiveness is an ahistorical identification of a trait affording some selective advantage to an agent within some particular environment. In results reported here we identify a trait within natural language discourse as having adaptive value by computing a trait/fitness covariance; the possession of the trait correlates with the replication success of the trait's possessor. We show that the trait covaries with fitness across multiple unrelated discursive groups. In our analysis the trait in question is a particular statistically derived word-in-context, that is, a word set. Variation of the word-usage is measured as the relative presence of the word set within a particular text, that is, the percentage of the text devoted to this set of words. Fitness is measured as the rate in which the text is responded to, or replicates, within an online environment. Thus we are studying the micro-evolutionary dynamics of natural language discourse.|evolution in communication; adaptation; population memetics; cultural evolution|ADAPTATION|Communication; Linguistics|2|2|3
`Wouldst thou withdraw love's faithful vow?' The negotiation of love in the orchard scene - (Romeo and Juliet Act II)|2006|The joint sonnet of the two lovers-to-be at the Capulet feast towards the end of the first act is rightly regarded as the dramatic and poetic climax of the first part of the play. Yet it constitutes, from an interactional point of view, merely a first move and the declarations of love proper occur only later in the orchard scene of the second act. This article explores the complex negotiations that precede the actual confessions of love and investigates how Shakespeare modified his rather simplistic source text, Arthur Brook's Romeus and Juliet (1562), in order to exploit the full interactional and dramatic potential of the situation.|Shakespeare; Romeo and Juliet; historical dialogue analysis; pragmatics; negotiating love|`ROMEO-AND-JULIET'|Linguistics; Language \& Linguistics|0|0|3
The dependency structure of coordinate phrases: A corpus approach|2005|Hudson (1990) proposes that each conjunct in a coordinate phrase forms dependency relations with heads or dependents outside the coordinate phrase (the ``multi-head{''} view). This proposal is tested through corpus analysis of Wall Street Journal text. For right-branching constituents (such as direct-object NPs), a short-long preference for conjunct ordering is observed; this is predicted by the multi-head view, under the assumption that structures resulting in shorter dependencies are preferred. A short-long preference is also observed for left-branching constituents (such as subject NPs), which is less obviously accommodated by the multi-head view but not incompatible with it. The repetition of determiners was also examined (the dog and cat versus the dog and the cat), and a stronger preference was found for repetition with singular count nouns as opposed to mass or plural nouns; this accords well with the multi-head view, under the reasoning that single-determiner constructions require crossing dependencies with count nouns but not with plural or mass nouns.|coordination; corpus analysis; dependency grammar; syntactic complexity|SYNTACTIC AMBIGUITY RESOLUTION; SENTENCE COMPREHENSION; COMPLEXITY; ENGLISH; PERSPECTIVE; DISCOURSE; LANGUAGE; GRAMMAR; DUTCH|Linguistics; Psychology, Experimental|5|0|3
Disambiguation preferences and corpus frequencies in noun phrase conjunction|2003|Gibson and Schutze (1999) showed that on-line disambiguation preferences do not always mirror corpus frequencies. When presented with a syntactic ambiguity involving the conjunction of a noun phrase to three possible attachment sites. participants were faster to read attachments to the first site than attachments to the second one, although the latter were shown to be more frequent in text corpora. In the present study, we investigated whether a particular feature in their items-disambiguation using the pronoun `one'-could account for this discrepancy. The results of a corpus analysis and two on-line reading experiments showed that the presence of this pronoun is indeed responsible for the high attachment preference in the conjunction ambiguity. We conclude that for this syntactic ambiguity there is no discrepancy between on-line preferences and corpus frequencies. Consequently, there is no need to assume different processes underlying sentence comprehension and sentence production on the basis of the noun phrase conjunction ambiguity. (C) 2003 Elsevier Science (USA). All rights reserved.|noun phrase conjunction; corpus frequency; syntactic ambiguity resolution; eye movements|SYNTACTIC AMBIGUITY RESOLUTION; EYE-MOVEMENT CONTROL; SENTENCE COMPREHENSION; MODIFIER ATTACHMENT; PROCESSING DIFFICULTY; AGREEMENT PROCESSES; CONSTRAINTS; VERB; INFORMATION; DISCOURSE|Linguistics; Psychology; Psychology, Experimental|16|1|3
Using nurses' natural language entries to build a concept-oriented terminology for patients' chief complaints in the emergency department|2003|Information about the chief complaint (CC), also known as the patient's reason for seeking emergency care, is critical for patient prioritization for treatment and determination of patient flow through the emergency department (ED). Triage nurses document the CC at the start of the ED visit, and the data are increasingly available in electronic form. Despite the clinical and operational significance of the CC to the ED, there is no standard CC terminology. We propose the construction of concept-oriented nursing terminologies from the actual language used by experts. We use text analysis to extract CC concepts from triage nurses' natural language entries. Our methodology for building the nursing terminology utilizes natural language processing techniques and the Unified Medical Language System. (C) 2003 Elsevier Inc. All rights reserved.|terminology; nursing; emergency department; natural language processing; DEEDS; UMLS|SYSTEMS; COLLABORATION; VOCABULARIES; SURVEILLANCE; BIOTERRORISM; INFORMATICS|Computer Science, Interdisciplinary Applications; Medical Informatics|21|0|3
Towards incremental parsing of natural language using recursive neural networks|2003|In this paper we develop novel algorithmic ideas for building a natural language parser grounded upon the hypothesis of incrementality. Although widely accepted and experimentally supported under a cognitive perspective as a model of the human parser, the incrementality assumption has never been exploited for building automatic parsers of unconstrained real texts. The essentials of the hypothesis are that words are processed in a left-to-right fashion, and the syntactic structure is kept totally connected at each step. Our proposal relies on a machine learning technique for predicting the correctness of partial syntactic structures that are built during the parsing process. A recursive neural network architecture is employed for computing predictions after a training phase on examples drawn from a corpus of parsed sentences, the Penn Treebank. Our results indicate the viability of the approach and lay out the premises for a novel generation of algorithms for natural language processing which more closely model human parsing. These algorithms may prove very useful in the development of efficient parsers.|incremental parsing of natural language; recursive neural networks; learning discrete structures|DISTRIBUTED REPRESENTATIONS; ATTACHMENT|Computer Science, Artificial Intelligence|17|0|3
Towards effective parsing with neural networks: Inherent generalisations and bounded resource effects|2003|This article explores how the effectiveness of learning to parse with neural networks can be improved by including two architectural features relevant to language: generalisations across syntactic constituents and bounded resource effects. A number of neural network parsers have recently been proposed, each with a different approach to the representational problem of outputting parse trees. In addition, some of the parsers have explicitly attempted to capture an important regularity within language, which is to generalise information across syntactic constituents. A further property of language is that natural bounds exist for the number of constituents which a parser need retain for later processing. Both the generalisations and the resource bounds may be captured in architectural features which enhance the effectiveness and efficiency of learning to parse with neural networks. We describe a number of different types of neural network parser, and compare them with respect to these two features. These features are both explicitly present in the Simple Synchrony Network parser, and we explore and illustrate their impact on the process of learning to parse in some experiments with a recursive grammar.|neural networks; resource effects; structured representations; syntactic parsing; systematicity|DISTRIBUTED REPRESENTATIONS; SYSTEMATICITY; SYNCHRONY|Computer Science, Artificial Intelligence|0|0|3
Minimizing the genes for grammar. The minimalist program as a biological framework for the study of language|2003|This paper examines the main ideas of the Minimalist Program (MP) with the aim of evaluating its virtues as a biological framework for the understanding of human language. Our conclusions are basically three. First, the MP favors a certain reconciliation between the abstract characterization of language and characterizations derived from other biological concerns. Second, the MP reduces the role of the genetic endowment for language and relies more on epigenetic processes, in clear agreement with other aspects of the study of the brain. Third, the MP favors an essential identification of the processes of ontogenetic and phylogenetic development of language, a rather controversial conclusion but also a very important one from a theoretical point of view. (C) 2002 Elsevier Science B.V. All rights reserved.|minimalist program; biolinguistics; language development|NATURAL-SELECTION; EVOLUTION; CHILDREN|Linguistics; Language \& Linguistics|17|0|3
Intelligibility of modified speech for young listeners with normal and impaired hearing|2002|Exposure to modified speech has been shown to benefit children with language-learning impairments with respect to their language skills (M. M. Merzenich et al., 1998; P. Tallal et al., 1996). In the study by Tallal and colleagues, the speech modification consisted of both slowing down and amplifying fast, transitional elements of speech. In this study, we examined whether the benefits of modified speech could be extended to provide intelligibility improvements for children with severe-to-profound hearing impairment who wear sensory aids. In addition, the separate effects on intelligibility of slowing down and amplifying speech were evaluated. Two groups of listeners were employed: 8 severe-to-profoundly hearing-impaired children and 5 children with normal hearing. Four speech-processing conditions were tested: (1) natural, unprocessed speech; (2) envelope-amplified speech; (3) slowed speech; and (4) both slowed and envelope-amplified speech. For each condition, three types of speech materials were used: words in sentences, isolated words, and syllable contrasts. To degrade the performance of the normal-hearing children, all testing was completed with a noise background. Results from the hearing-impaired children showed that all varieties of modified speech yielded either equivalent or poorer intelligibility than unprocessed speech. For words, in sentences and isolated words, the slowing-down of speech had no effect on intelligibility scores whereas envelope amplification, both alone and combined with slowing-down, yielded significantly lower scores. Intelligibility results from normal-hearing children listening in noise were somewhat similar to those from hearing-impaired children. For isolated words, the slowing-down of speech had no effect on intelligibility whereas envelope amplification degraded intelligibility. For both subject groups, speech processing had no statistically significant effect on syllable discrimination. In summary, without extensive exposure to the speech processing conditions, children with impaired hearing and children with normal hearing listening in noise received no intelligibility advantage from either slowed speech or envelope-amplified speech.|speech perception; hearing-impaired listeners; time-expansion of speech; envelope modification of speech|TIME-SCALE MODIFICATION; HARD-OF-HEARING; CONVERSATIONAL SPEECH; SPEAKING RATE; STOP CONSONANTS; CHILDREN; COMPRESSION; PERCEPTION; LANGUAGE; CLEAR|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|12|0|3
Content management in the SYNDIKATE system - How technical documents are automatically transformed to text knowledge bases|2000|SYNDIKATE is a family of natural language understanding systems for automatically acquiring knowledge from real-world texts (e.g., information technology test reports, medical finding reports), and for transferring their content to formal representation structures which constitute a corresponding text knowledge base. We present a general system architecture which integrates requirements from the analysis of single sentences, as well as those of referentially linked sentences forming cohesive texts. Properly accounting for text cohesion phenomena is a prerequisite for the soundness and validity of the generated text representation structures. It is also crucial for any information system application making use of automatically generated text knowledge bases in a reliable way, e.g., by inferentially supported fact retrieval. (C) 2000 Published by Elsevier Science B.V. All rights reserved.|natural language processing; text understanding; knowledge acquisition from texts|COHERENCE|Computer Science, Artificial Intelligence; Computer Science, Information Systems|20|0|3
A cognitive bias approach to feature selection and weighting for case-based learners|2000|Research in psychology, psycholinguistics, and cognitive science has discovered and examined numerous psychological constraints on human information processing. Short term memory limitations, a focus of attention bias, and a preference for the use of temporally recent information are three examples. This paper shows that psychological constraints such as these can be used effectively as domain-independent sources of bias to guide feature set selection and weighting for case-based learning algorithms. We first show that cognitive biases can be automatically and explicitly encoded into the baseline instance representation: each bias modifies the representation by changing features, deleting features, or modifying feature weights. Next, we investigate the related problems of cognitive bias selection and cognitive bias interaction for the feature weighting approach. In particular, we compare two cross-validation algorithms for bias selection that make different assumptions about the independence of individual component biases. In evaluations on four natural language learning tasks, we show that the bias selection algorithms can determine which cognitive bias or biases are relevant for each learning task and that the accuracy of the case-based learning algorithm improves significantly when the selected bias(es) are incorporated into the baseline instance representation.|case-based learning; instance-based learning; feature set selection; feature weighting; natural language learning|INDIVIDUAL-DIFFERENCES; LEARNING ALGORITHMS; WORKING MEMORY; LAZY LEARNERS; LANGUAGE; MACHINE; INFORMATION; ADVANTAGE; MENTION; SPANISH|Computer Science, Artificial Intelligence|5|1|3
Evidentiality and deixis in narrative retelling|2000|Evidentiality, the linguistic coding of source and reliability of information, has long been characterized as a deictic phenomenon in language (Jakobson, 1957; Schlichter, 1986; Woodbury, 1986). Although it is generally accepted that evidential forms function to index information to a source and an interpreter of that source (typically the speaker), there has been little study of the ways in which speakers make use of this property in discourse. This paper presents an analysis of evidential use in Macedonian narrative retellings that clarifies the deictic function of evidentiality in discourse. A version of Deictic Center Theory (Duchan et al., 1995), a recent framework developed specifically for narrative analysis, is used to show how evidential markers are used to build the perspective structure of narrative texts and how they are manipulated by speakers to express information from different viewpoints. (C) 2000 Elsevier Science B.V. All rights reserved.|evidentiality; deixis; narrative; Macedonian; discourse; subjectivity|ENGLISH|Linguistics; Language \& Linguistics|11|0|3
Improving browsing in digital libraries with keyphrase indexes|1999|Browsing accounts for much of people's interaction with digital libraries, but it is poorly supported by standard search engines. Conventional systems often operate at the wrong level, indexing words when people think in terms of topics, and returning documents when people want a broader view. As a result, users cannot easily determine what is in a collection, how well a particular topic is covered, or what kinds of queries will provide useful results. We have built a new kind of search engine, Keyphind, that is explicitly designed to support browsing. Automatically extracted keyphrases form the basic unit of both indexing and presentation, allowing users to interact with the collection at the level of topics and subjects rather than words and documents. The keyphrase index also provides a simple mechanism for clustering documents, refining queries, and previewing results. We compared Keyphind to a traditional query engine in a small usability study. Users reported that certain kinds of browsing tasks were much easier with the new interface, indicating that a keyphrase index would be a useful supplement to existing search tools. (C) 1999 Elsevier Science B.V. All rights reserved.|digital libraries; browsing interfaces; text mining; keyphrase extraction; machine learning|VOCABULARY PROBLEM; RETRIEVAL; INTERNET; SYSTEM|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|38|0|3
Automatic text categorization and its application to text retrieval|1999|We develop an automatic text categorization approach and investigate its application to text retrieval. The categorization approach is derived from a combination of a learning paradigm known as instance-based learning and an advanced document retrieval technique known as retrieval feedback. We demonstrate the effectiveness of our categorization approach using two real-world document collections from the MEDLINE database. Next, we investigate the application of automatic categorization to text retrieval. Our experiments clearly indicate that automatic categorization improves the retrieval performance compared with no categorization. We also demonstrate that the retrieval performance using automatic categorization achieves the same retrieval quality as the performance using manual categorization. Furthermore, detailed analysis of the retrieval performance on each individual test query is provided.|text categorization; automatic classification; text retrieval; instance-based learning; query processing|MEDLINE|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|66|0|3
Signed and spoken language: A unique underlying system?|1999|Sign language has only recently become a topic of investigation in cognitive neuroscience and psycholinguistics. In this paper, we review research from these two fields; in particular, we compare spoken and signed language by looking at data concerning either cortical representations or early acquisition. As to cognitive neuroscience, we show that clinical neuropsychological data regarding sign language is partially inconsistent with imaging data. Indeed, whereas both clinical neuropsychology and imagery show the involvement of the left hemisphere in sign language processing, only the latter highlights the importance of the right hemisphere. We discuss several possible interpretations of these contrasting findings. As to psycholinguistics, we survey research on the earliest stages of the acquisition of spoken language, and consider these stages in the acquisition of sign language. We conjecture that under favorable circumstances, deaf children exploit sign input to gain entry into the language system with the same facility as hearing children do with spoken input. More data, however, are needed in order to gain a fuller understanding of the relation of different kinds of natural languages to both the underlying anatomical representations and their early acquisition.|clinical neuropsychology; cortical representation; early acquisition; sign language; spoken language|CORTICAL REPRESENTATION; SPEECH-PERCEPTION; YOUNG INFANTS; 2ND LANGUAGE; HUMAN-BRAIN; ACQUISITION; PATTERNS; ORGANIZATION; EXPERIENCE; CHILDREN|Audiology \& Speech-Language Pathology; Linguistics; Psychology, Experimental|6|0|3
COMPUTING AS COMPRESSION - AN OVERVIEW OF THE SP THEORY AND SYSTEM|1995|This article is an overview of a programme of research based on the conjecture that all kinds of computing and formal reasoning may usefully be understood as information compression by pattern matching, unification and metrics-guided search. The research aims to develop this idea into a theory of computing to integrate and simplify diverse concepts in the field. The research also aims to develop a `new generation' computing system, based on the theory, to integrate and simplify diverse kinds of computing and to achieve more flexibility and `intelligence' than conventional computers. Software simulations of the proposed new system provide a concrete expression of the developing theory and a test-bed for the ideas. The background to the research is briefly reviewed including evidence that information compression is a significant element in biological information processing systems. Concepts of information and redundancy are described as a basis for describing how information compression may be achieved by the comparison or matching of patterns, the merging or unification of patterns which are the same, together with metrics-guided search (e.g., `hill climbing', `beam search') to maximise compression for a given computational effort. The main elements of the SP theory and of the proposed SP system are described with a summary of developments to date. Some of the kinds of computing which be interpreted as information compression are briefly reviewed. These include: the `low level' workings of conventional computers; information retrieval, pattern recognition and de-referencing of identifiers; unsupervised inductive learning (grammatical inference, data mining, automatic organisation of software and of knowledge bases); the execution of mathematical or computing functions; deductive and probabilistic inference; parsing and natural language processing; planning and problem solving. Areas of uncertainty where further work is needed are indicated at appropriate points throughout the article.|INFORMATION COMPRESSION; THEORY OF COMPUTING; LEARNING; INFORMATION RETRIEVAL; PATTERN RECOGNITION; DEDUCTION; ABDUCTION|KOLMOGOROV; COMPLEXITY; MODEL|Computer Science, Hardware \& Architecture; Computer Science, Theory \& Methods|6|0|3
AN HISTORICAL OVERVIEW OF NATURAL-LANGUAGE PROCESSING SYSTEMS THAT LEARN|1994|A fundamental issue in natural language processing is the prerequisite of an enormous quantity of preprogrammed knowledge concerning both the language and the domain under examination. Manual acquisition of this knowledge is tedious and error prone. Development of an automated acquisition process would prove invaluable. This paper references and overviews a range of the systems that have been developed in the domain of machine learning and natural language processing. Each system is categorised into either a symbolic or connectionist paradigm, and has its own characteristics and limitations described.|MACHINE LEARNING; NATURAL LANGUAGE PROCESSING; COGNITIVE MODELING; KNOWLEDGE ACQUISITION; KNOWLEDGE REPRESENTATION|ACQUISITION; MODEL|Computer Science, Artificial Intelligence|2|2|3
FROM VISION TO MULTIMODAL COMMUNICATION - INCREMENTAL ROUTE DESCRIPTIONS|1994|In the last few years, within cognitive science, there has been a growing interest in the connection between vision and natural language. The question of interest is: How can we discuss what we see. With this question in mind, we will look at the area of incremental route descriptions. Here, a speaker step-by-step presents the relevant route information in a 3D-environment. The speaker must adjust his/her descriptions to the currently visible objects. Two major equations arise in this context: 1. How is visually obtained information used in natural language generation? and 2. How are these modalities coordinated? We will present a computational framework for the interaction of vision and natural language descriptions which integrates several processes and representations. Specifically discussed is the interaction between the spatial representation and the presentation used for natural language descriptions. We have implemented a prototypical version of the proposed model, called MOSES.|SPATIAL COGNITION; WAYFINDING; MULTIMODAL PRESENTATION; OBJECT REPRESENTATION|COGNITIVE MAPS; INFORMATION; NAVIGATION; SEARCH; MODEL|Computer Science, Artificial Intelligence|5|0|3
ORGANIZATIONAL DECISION SUPPORT SYSTEMS - THE DESIGN AND IMPLEMENTATION OF A DATA EXTRACTION SCHEME TO FACILITATE MODEL DATABASE COMMUNICATION|1993|The concept of organizational decision support and the criteria for designing such support systems (ODSS) have recently received a great deal of attention. In spite of major differences among the decision processes at the organizational, group, and individual levels, the requirements for securing data from the corporate database in an ODSS still remains a significant issue. In addition, the computer and communication technologies that integrate the subsystems of knowledge, data, and models assume increased relevance in the ODSS. Indeed, the richness of problems of making the most of such technologies becomes even more important in the ODSS environment. In the present work, the issues of integrating models and databases through the use of a data extraction scheme are examined. In particular, certain aspects of the query generation algorithms that allow the user or model to view the database as a single relation are described. The generated query is then translated into TQUEL, resulting in a temporal query reflecting the historical nature of the corporate database.|ORGANIZATIONAL DECISION SUPPORT SYSTEMS; RELATIONAL DATABASES; QUERY GENERATION; HYPERGRAPHS; MODELS|INFORMATION-SYSTEMS; MANAGEMENT-SYSTEMS; NATURAL-LANGUAGE; PERFORMANCE; SEMANTICS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|4|0|3
CAUSAL COHERENCE IN THE ORAL NARRATIVES OF SPANISH-SPEAKING CHILDREN|1992|Forty-six Spanish-speaking children distributed among three age groups (4:0-4:11, 6:0-6:11, and 8:0-8:11 years) were shown a short silent film and asked to tell the investigator what happened in the movie. All narratives were audiotaped and transcribed for analysis. The stories of older children contained more narrative actions and included more mental state/goal causes than those of younger children. With increasing age, children's narratives showed a decrease in the use of two-clause causal sequences, an increase in the use of three-clause causal sequences, and a decrease in the proportion of unrelated statements. The variability in the types of causal links manifested in the stories suggests that absence of certain types of interclausal connections should not be interpreted as reflecting cognitive or comprehension deficits.|CAUSAL COHERENCE; SPANISH; NARRATIVES; DISCOURSE|COHESION; STUDENTS; STORIES; RECALL; TEXT|Language \& Linguistics; Rehabilitation|19|0|3
An open source and modular search engine for biomedical literature retrieval|2018|This work presents the bioMine system, a full-text natural language search engine for biomedical literature. bioMine provides search capabilities based on the full-text content of documents belonging to a database composed of scientific articles and allows users to submit their search queries using natural language. Beyond the text content of articles, the system engine also uses article metadata, empowering the search by considering extra information from picture and table captions. bioMine is publicly released as an open-source system under the MIT license.|biomedical literature; document index; full-text search; information retrieval; natural language processing; natural language query; search engine|RELEVANCE JUDGMENTS; SEMANTIC WEB; KEYWORDS; QUERIES; SYSTEMS; FUTURE|Computer Science, Artificial Intelligence|0|2|2
The Contribution of Stemming and Semantics in Arabic Topic Segmentation|2018|Topic Segmentation is one of the pillars of Natural Language Processing. Yet there is a remarkable research gap in this field, as far as the Arabic language is concerned. The purpose of this article is to improve Arabic Topic Segmentation (ATS) by inquiring into two segmenters: ArabC99 and ArabTextTiling. This study is carried out on two independent levels: the pre-processing level and the segmentation level. These levels represent the basic steps of topic segmentation. On the pre-processing level, we examine the effect of using different Arabic stemming algorithms on ATS. We find out that Light10 is more appropriate for the pre-processing step. Based on this conclusion, we proceed to the second level by proposing two Arabic segmenters called ArabC99-LS-LSA and ArabTextTiling-LS-LSA. These latter use external semantic knowledge related to the Latent Semantic Analysis (LSA). Based on the evaluation results, we notice that LSA provides improvements in this field. Hence, the main outcome of this article emphasizes the multilevel improvement of ATS based on Light10 and LSA.|Arabic topic segmentation; Arabic stemming algorithms; Arabc99; ArabTextTiling|TEXT; SIMILARITY; MANAGEMENT; OPERATIONS; RETRIEVAL; ALGORITHM|Computer Science, Artificial Intelligence|0|2|2
Speaking `the Other'?: Youths' regimentation and policing of contemporary urban vernacular|2018|This article analyses youths' commentary on the contemporary urban vernacular Forortssvenska in an inner-city senior high school in Sweden. Combining a linguistic landscape approach with analytical tools from linguistic anthropology, this paper explores how political discourse are articulated in imagery and texts in the high school and refracted in meta-linguistic commentary among the students. The analysis show how the students draw on US-activist discourse as they insert the notion of `cultural appropriation' into discussions on the use, and policing, of Forortssvenska at the high school. This everyday regimentation of urban vernacular is entangled with negotiations of identity, multiculturalism and space. (C) 2017 Elsevier Ltd. All rights reserved.|Contemporary urban vernacular; Language regimentation; Linguistic landscape; School ethnography; Stylization; Cultural appropriation|RINKEBY SWEDISH; LANGUAGE; LANDSCAPE|Communication; Linguistics|0|2|2
A semiotic study of regional branding reflected in the slogans of Korean regions|2018|The purpose of the present analyses of regional slogans is to provide a semiotic perspective for understanding the symbolic communication systems involved in the construction of Korean regional governments. This study attempts to evaluate the slogans in terms of the semantic and morphological aspects of the texts. Findings show an overuse of signs within the slogans of regional governments that weakened the delivery of information regarding local identity. A leading slogan for a large region may create a unique identity in relative terms, whereas second-tier regions tend to mimic the success of others. The present research illustrates that each region of Korea cannot be differentiated in terms of a semantic analysis of linguistic signs. The communication tendencies that influence the creation of slogans for Korean regions are morphologically complex but semantically simple, resulting in the failure of these regions to secure distinctiveness in their individual brand identities.|Korean regions; regional branding; visual identity; slogan; semiotics; plastic sign; iconic sign; linguistic sign|TOURISM; IMAGES; DESTINATIONS; IDENTITY; SHAPES; EQUITY|Humanities, Multidisciplinary; Communication; Linguistics|0|2|2
Reliable predictors of reduced redundancy test performance: The interaction between lexical bonds and test takers' depth and breadth of vocabulary knowledge|2018|The present study intended to investigate whether test takers' breadth and depth of vocabulary knowledge can contribute to their efficient use of lexical bonds while restoring damaged texts in reduced redundancy tests. Moreover, the moderating role of general language proficiency was investigated in this interaction. In so doing, Vocabulary Levels Test (VLT), Word Associates Test (WAT), and a series of C-tests with high and low lexical bonds were administered to two groups of 85 upper-intermediate and 50 lower-intermediate EFL learners. Results of multiple regression analyses indicated the following: (a) breadth and depth of vocabulary knowledge played dissimilar roles for test takers with different levels of language proficiency; (b) depth of vocabulary knowledge was a better predictor for high-bond texts; and (c) test takers with higher levels of language proficiency made more efficient use of lexical bonds as contextual cues. The findings point to the necessity of improving learners' depth of vocabulary knowledge, especially at lower levels of language proficiency where vocabulary knowledge is mostly a matter of size rather than quality.|Breadth of vocabulary knowledge; depth of vocabulary knowledge; language proficiency; lexical bonds; reduced redundancy tests|SIZE TEST; WORD KNOWLEDGE; COMPREHENSION; VALIDATION; ENGLISH; COHESION; LEARNERS; CONTEXT|Linguistics; Language \& Linguistics|0|2|2
Automatic Sarcasm Detection: A Survey|2017|Automatic sarcasm detection is the task of predicting sarcasm in text. This is a crucial step to sentiment analysis, considering prevalence and challenges of sarcasm in sentiment-bearing text. Beginning with an approach that used speech-based features, automatic sarcasm detection has witnessed great interest from the sentiment analysis community. This article is a compilation of past work in automatic sarcasm detection. We observe three milestones in the research so far: semi-supervised pattern extraction to identify implicit sentiment, use of hashtag-based supervision, and incorporation of context beyond target text. In this article, we describe datasets, approaches, trends, and issues in sarcasm detection. We also discuss representative performance values, describe shared tasks, and provide pointers to future work, as given in prior works. In terms of resources to understand the state-of-the-art, the survey presents several useful illustrations-most prominently, a table that summarizes past papers along different dimensions such as the types of features, annotation techniques, and datasets used.|Sarcasm; sentiment; opinion; sarcasm detection; sentiment analysis|VERBAL IRONY; DISCOURSE; NEGATION; PRETENSE|Computer Science, Theory \& Methods|0|2|2
Visually Grounded Meaning Representations|2017|In this paper we address the problem of grounding distributional representations of lexical meaning. We introduce a new model which uses stacked autoencoders to learn higher-level representations from textual and visual input. The visual modality is encoded via vectors of attributes obtained automatically from images. We create a new large-scale taxonomy of 600 visual attributes representing more than 500 concepts and 700 K images. We use this dataset to train attribute classifiers and integrate their predictions with text-based distributional models of word meaning. We evaluate our model on its ability to simulate word similarity judgments and concept categorization. On both tasks, our model yields a better fit to behavioral data compared to baselines and related models which either rely on a single modality or do not make use of attribute-based input.|Cognitive simulation; computer vision; distributed representations; concept learning; connectionism and neural nets; natural language processing|FEATURE PRODUCTION NORMS; SEMANTIC MEMORY; LARGE SET; MODEL; CATEGORIZATION; RECOGNITION; ATTRIBUTES; SIMILARITY; LANGUAGE; NETWORK|Computer Science, Artificial Intelligence; Engineering, Electrical \& Electronic|0|2|2
Using Pathfinder networks to discover alignment between expert and consumer conceptual knowledge from online vaccine content|2017|This study demonstrates the use of distributed vector representations and Pathfinder Network Scaling (PFNETS) to represent online vaccine content created by health experts and by laypeople. By analyzing a target audience's conceptualization of a topic, domain experts can develop targeted interventions to improve the basic health knowledge of consumers. The underlying assumption is that the content created by different groups reflects the mental organization of their knowledge. Applying automated text analysis to this content may elucidate differences between the knowledge structures of laypeople (heath consumers) and professionals (health experts). This paper utilizes vaccine information generated by laypeople and health experts to investigate the utility of this approach. We used an established technique from cognitive psychology, Pathfinder Network Scaling to infer the structure of the associational networks between concepts learned from online content using methods of distributional semantics. In doing so, we extend the original application of PFNETS to infer knowledge structures from individual participants, to infer the prevailing knowledge structures within communities of content authors. The resulting graphs reveal opportunities for public health and vaccination education experts to improve communication and intervention efforts directed towards health consumers. Our efforts demonstrate the feasibility of using an automated procedure to examine the manifestation of conceptual models within large bodies of free text, revealing evidence of conflicting understanding of vaccine concepts among health consumers as compared with health experts. Additionally, this study provides insight into the differences between consumer and expert abstraction of domain knowledge, revealing vaccine-related knowledge gaps that suggest opportunities to improve provider-patient communication. (C) 2017 Elsevier Inc. All rights reserved.|Distributional semantics; Vaccination; Consumer health; Knowledge acquisition; Mental models; Natural language processing; Social media; Public health informatics; Big data; Semantic spaces; Consumer informatics|RANDOMIZED CONTROLLED-TRIAL; ADDRESSING PARENTS CONCERNS; LATENT SEMANTIC ANALYSIS; RISK INFORMATION; MAGNETIC-FIELDS; FOLLOW-UP; HEALTH; FREQUENCY; MODELS; AUTISM|Computer Science, Interdisciplinary Applications; Medical Informatics|0|2|2
Classifying patient portal messages using Convolutional Neural Networks|2017|Objective: Patients communicate with healthcare providers via secure messaging in patient portals. As patient portal adoption increases, growing messaging volumes may overwhelm providers. Prior research has demonstrated promise in automating classification of patient portal messages into communication types to support message triage or answering. This paper examines if using semantic features and word context improves portal message classification. Materials and methods: Portal messages were classified into the following categories: informational, medical, social, and logistical. We constructed features from portal messages including bag of words, bag of phrases, graph representations, and word embeddings. We trained one-versus-all random forest and logistic regression classifiers, and convolutional neural network (CNN) with a softmax output. We evaluated each classifier's performance using Area Under the Curve (AUC). Results: Representing the messages using bag of words, the random forest detected informational, medical, social, and logistical communications in patient portal messages with AUC5: 0.803, 0.884, 0.828, and 0.928, respectively. Graph representations of messages outperformed simpler features with AUC5: 0.837, 0.914, 0.846, 0.884 for informational, medical, social, and logistical communication, respectively. Representing words with Word2Vec embeddings, and mapping features using a CNN had the best performance with AUC5: 0.908 for informational, 0.917 for medical, 0.935 for social: and 0.943 for logistical categories. Discussion and conclusion: Word2Vec and graph representations improved the accuracy of classifying portal messages compared to features that lacked semantic information such as bag of words, and bag of phrases. Furthermore, using Word2Vec along with a CNN model, which provide a higher order representation, improved the classification of portal messages. (C) 2017 Elsevier Inc. All rights reserved.|Convolutional Neural Network; Word embedding; Patient portals; Text mining; Word2Vec|CLASSIFICATION; COMPLEXITY; MANAGEMENT; SURGEONS; FEATURES; GROWTH; DEEP; CARE|Computer Science, Interdisciplinary Applications; Medical Informatics|0|2|2
Metaphors in texts about climate change|2017|This article discusses the use of metaphors and metonyms in texts about climate change in different registers, with a particular focus on the information given to young people, and what they understand about the topic. It begins by considering the role of metaphorical thinking and language in science, and reviews some of the work on scientific metaphor in expert and popular genres. The article analyses the different functions of metaphors in two texts about anthropogenic climate change from different genres, arguing that in the popular text analysed metaphors tend to have the function of entertaining and dramatizing, and introducing and concluding (interpersonal and textual), as opposed to their informational (ideational) function in the research article that was analysed. I then discuss a corpus and discourse analysis of young people's talk about climate change. The young people's use of figurative language is compared with that of researchers and educationalists. The analysis finds that, consistent with work on scientific popularisations, written texts for non-specialists tend to ``open up{''} in Knudsen's (2003) terms experts' metaphors, extending them creatively. I found that on occasion this seems to lead to, or reflect, misunderstandings of the underlying science. I also find that young people reference Arctic and Antarctic animals as symbols of the problem of climate change.|metaphor; science; climate change; education; schools|BALANCE|Linguistics; Language \& Linguistics|0|2|2
Sprinkled semantic diffusion kernel for word sense disambiguation|2017|Word sense disambiguation (WSD), the task of identifying the intended meanings (senses) of words in context, has been a long-standing research objective for natural language processing (NLP). In this paper, we are concerned with kernel methods for automatic WSD. Under this framework, the main difficulty is to design an appropriate kernel function to represent the sense distinction knowledge. Semantic diffusion kernel, which models semantic similarity by means of a diffusion process on a graph defined by lexicon and co-occurrence information to smooth the typical ``Bag of Words{''} (BOW) representation, has been successfully applied to WSD. However, the diffusion is an unsupervised process, which fails to exploit the class information in a supervised classification scenario. To address the limitation, we present a sprinkled semantic diffusion kernel to make use of the class knowledge of training documents in addition to the co-occurrence knowledge. The basic idea is to construct an augmented term document matrix by encoding class information as additional terms and appending them to training documents. Diffusion is then performed on the augmented term-document matrix. In this way, the words belonging to the same class are indirectly drawn closer to each other, hence the class-specific word correlations are strengthened. We evaluate our method on several Senseval/Semeval benchmark examples with support vector machine (SVM), and show that the proposed kernel can significantly improve the disambiguation performance over semantic diffusion kernel in terms of different measures and yield a competitive result with the state-of-the-art kernel methods for WSD. (C) 2017 Elsevier Ltd. All rights reserved.|Word sense disambiguation (WSD); Semantic diffusion kernel; Class information; Support vector machine (SVM); Kernel method|SUPPORT VECTOR MACHINES; CLASSIFICATION; POLARIZATION|Automation \& Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical \& Electronic|0|2|2
Some New Ways of Modeling T/D Deletion in English|2017|The paper is concerned with the morpheme-final inter-consonantal T/D deletion in Standard British English. Its main aim is to explore some new ways of modeling this phenomenon and to test several new variables. Among the innovations suggested in the study are separate treatments of /t/ and /d/ as dependent variables, analysis of so-called neutralized contexts, testing of several previously unstudied predictors (including usage-based predictors), recategorization of most of the traditional formal linguistic predictors, and a proposition of a new articulatory-gestural model of T/D deletion. It is concluded that the strongest constraints on T/D deletion are the presence of the following consonant (a phonetic predictor) and the influence of /CC/-sequence text frequency (a usage-based predictor). The results of the study show that although the traditional (formal) linguistic predictors play a prominent role in T/D deletion, this process cannot be adequately explained without taking into account the frequency of occurrence and the mutual interplay of language patterns.|T; D deletion; coronal stop deletion; consonant cluster reduction; elision; Standard British English; token frequency|PHONOLOGICAL VARIATION; ACQUISITION; FREQUENCY; USAGE|Linguistics; Language \& Linguistics|0|2|2
DrugSemantics: A corpus for Named Entity. Recognition in Spanish Summaries of Product Characteristics|2017|For the healthcare sector, it is critical to exploit the vast amount of textual health-related information. Nevertheless, healthcare providers have difficulties to benefit from such quantity of data during pharmacotherapeutic care. The problem is that such information is stored in different sources and their consultation time is limited. In this context, Natural Language Processing techniques can be applied to efficiently transform textual data into structured information so that it could be used in critical healthcare applications, being of help for physicians in their daily workload, such as: decision support systems, cohort identification, patient management, etc. Any development of these techniques requires annotated corpora. However, there is a lack of such resources in this domain and, in most cases, the few ones available concern English. This paper presents the definition and creation of DrugSemantics corpus, a collection of Summaries of Product Characteristics in Spanish. It was manually annotated with pharmacotherapeutic named entities, detailed in DrugSemantics annotation scheme. Annotators were a Registered Nurse (RN) and two students from the Degree in Nursing. The quality of DrugSemantics corpus has been assessed by measuring its annotation reliability (overall F = 79.33\% {[}95\%CI: 78.35-80.31]), as well as its annotation precision (overall P = 94.65\% {[}95\%CI: 94.11-95.19]). Besides, the gold-standard construction process is described in detail. In total, our corpus contains more than 2000 named entities, 780 sentences and 226,729 tokens. Last, a Named Entity Classification module trained on DrugSemantics is presented aiming at showing the quality of our corpus, as well as an example of how to use it. (C) 2017 Elsevier Inc. All rights reserved.|Corpus; Reliability; Precision; Named Entity Recognition; Spanish; Summary of Product Characteristics|OF-THE-ART; CLINICAL TEXT; PRE-ANNOTATION; INFORMATION; AGREEMENT; DRUGS; EXTRACTION; CHALLENGE; RETRIEVAL; LABELS|Computer Science, Interdisciplinary Applications; Medical Informatics|0|1|2
RysannMD: A biomedical semantic annotator balancing speed and accuracy|2017|Recently, both researchers and practitioners have explored the possibility of semantically annotating large and continuously evolving collections of biomedical texts such as research papers, medical reports, and physician notes in order to enable their efficient and effective management and use in clinical practice or research laboratories. Such annotations can be automatically generated by biomedical semantic annotators - tools that are specifically designed for detecting and disambiguating biomedical concepts mentioned in text. The biomedical community has already presented several solid automated semantic annotators. However, the existing tools are either strong in their disambiguation capacity, i.e., the ability to identify the correct biomedical concept for a given piece of text among several candidate concepts, or they excel in their processing time, i.e., work very efficiently, but none of the semantic annotation tools reported in the literature has both of these qualities. In this paper, we present RysannMD (Ryerson Semantic Annotator for Medical Domain), a biomedical semantic annotation tool that strikes a balance between processing time and performance while disambiguating biomedical terms. In other words, RysannMD provides reasonable disambiguation performance when choosing the right sense for a biomedical term in a given context, and does that in a reasonable time. To examine how RysannMD stands with respect to the state of the art biomedical semantic annotators, we have conducted a series of experiments using standard benchmarking corpora, including both gold and silver standards, and four modern biomedical semantic annotators, namely cTAKES, MetaMap, NOBLE Coder, and Neji. The annotators were compared with respect to the quality of the produced annotations measured against gold and silver standards using precision, recall, and F-1 measure and speed, i.e., processing time. In the experiments, RysannMD achieved the best median F-1 measure across the benchmarking corpora, independent of the standard used (silver/gold), biomedical subdomain, and document size. In terms of the annotation speed, RysannMD scored the second best median processing time across all the experiments. The obtained results indicate that RysannMD offers the best performance among the examined semantic annotators when both quality of annotation and speed are considered simultaneously. (C) 2017 Elsevier Inc. All rights reserved.|Automated semantic annotation; Entity linking; UMLS metathesaurus; Biomedical ontologies; Natural language processing; Medical terminology|WORD SENSE DISAMBIGUATION; DOMAIN; CORPUS|Computer Science, Interdisciplinary Applications; Medical Informatics|0|2|2
YOUNG BASQUE BILINGUALS' PROSODIC COMPETENCE FEATURES IN READING ALOUD: THE TONAL PEAKS|2017|The purpose of this paper is to describe the relation between the different tonal peaks of a prosodic group in Basque language to identify the different combination models of peaks and the relation and use of the models according to endogenous (linguistics) and exogenous (gender, linguistic group, provenance) factors. To create this corpus a text read by 101 bilingual young men and women has been used. Their mother tongue was Basque and Spanish in some cases and Basque and French in other cases. They come from the Basque Country territories, some learnt Basque within the family environment and others at school. Data analysis has been carried out in three levels: on the lexical level, at syntactic level and in the prosodic group. The conclusions are that there are no statistically significant differences according to the three levels mentioned; the interaction of all the levels show variety and dispersion referring the tonal peak and, finally, the position of the tonal peak is influenced by the way the informants have learnt Basque as well as their geographical origin.|Basque language; prosodic competence; tonal peaks; reading aloud|FLUENCY; COMPREHENSION; CHILDREN; READERS|Linguistics; Language \& Linguistics|0|2|2
Textual trajectories: Theoretical roots and institutional consequences|2017|This article maps out and reviews work on textual trajectories and related concepts from sociolinguistics, linguistic ethnography, discourse and literacy studies. The first part of the article argues that work on entextualization and recontextualization, and their incorporation in recent research on textual chains or trajectories, contributes to a new language of description which conceptualizes texts in dynamic terms while still maintaining a sense of their coherence and durability. The article traces how conceptions of dialogicality and recontextualization have been used to develop transcontextual approaches to analysis which have highlighted the ideological work of textual movement and resemiotization. It argues that envisaging linked series of entextualizations and recontextualizations as institutionally consequential trajectories not only illuminates micro-level practices, but also indicates their dynamic interconnection with macro-level institutional processes and ideologies. In this sense, the concept of textual trajectories contributes to meso-level theorizing of the interrelationship of language with social life. Examples of research from institutional contexts are reviewed to examine how textual trajectories are used to produce specialized knowledge, the instantiation of institutional procedures and the articulation of participant positionings and identities.|textual trajectory; entextualization; dialogicality; recontextualization; resemiotization; positioning/identity|LANGUAGE; PERSPECTIVES; LITERACY; ASYLUM|Communication; Linguistics; Language \& Linguistics|0|1|2
Blog posts and traditional assignments by first-and second-language writers|2017|This study investigates differences in the language and discourse characteristics of course blogs and traditional academic submissions produced in English by native (L1) and advanced second language (L2) writers. One hundred and fifty two texts generated by 38 graduate students within the context of the same Master's level course were analysed using Coh-Metrix indices at the surface code, textbase and situation model levels. The two text types differed in their lexical sophistication, syntactic complexity, use of cohesion and agency. Overall, the traditional course assignments were more formal, lexically sophisticated and syntactically complex, while the blog posts contained more semantic and situational redundancy, resulting in higher readability, and communicated a clearer sense of agency. There were also reliable differences between the textual artefacts generated by the L1 and L2 writers, one of which was a more traditional impersonal academic style of the L2 texts. Although no interaction was observed between the two independent variables in the Coh-Metrix analyses, an additional analysis of human ratings showed that the blog posts were rated lower on the use of language than traditional assignments for the L2, but not L1, writers. Limitations of the computational text analysis and pedagogical implications of the findings are considered.|Academic Writing; Digital Texts; Discourse Analysis; Corpus Analysis|SYNTACTIC COMPLEXITY; WRITING QUALITY; DISCOURSE COMPREHENSION; COH-METRIX; LANGUAGE; STUDENTS; FEATURES; SKILLS; TEXT; PERCEPTIONS|Education \& Educational Research; Linguistics|0|2|2
Surrogate-assisted feature extraction for high-throughput phenotyping|2017|Objective: Phenotyping algorithms are capable of accurately identifying patients with specific phenotypes from within electronic medical records systems. However, developing phenotyping algorithms in a scalable way remains a challenge due to the extensive human resources required. This paper introduces a high-throughput unsupervised feature selection method, which improves the robustness and scalability of electronic medical record phenotyping without compromising its accuracy. Methods: The proposed Surrogate-Assisted Feature Extraction (SAFE) method selects candidate features from a pool of comprehensive medical concepts found in publicly available knowledge sources. The target phenotype's International Classification of Diseases, Ninth Revision and natural language processing counts, acting as noisy surrogates to the gold-standard labels, are used to create silver-standard labels. Candidate features highly predictive of the silver-standard labels are selected as the final features. Results: Algorithms were trained to identify patients with coronary artery disease, rheumatoid arthritis, Crohn's disease, and ulcerative colitis using various numbers of labels to compare the performance of features selected by SAFE, a previously published automated feature extraction for phenotyping procedure, and domain experts. The out-of-sample area under the receiver operating characteristic curve and F-score from SAFE algorithms were remarkably higher than those from the other two, especially at small label sizes. Conclusion: SAFE advances high-throughput phenotyping methods by automatically selecting a succinct set of informative features for algorithm training, which in turn reduces overfitting and the needed number of goldstandard labels. SAFE also potentially identifies important features missed by automated feature extraction for phenotyping or experts.|electronic medical records; phenotyping; data mining; machine learning|ELECTRONIC MEDICAL-RECORDS; HEALTH RECORDS; RHEUMATOID-ARTHRITIS; PHENOME-WIDE; RETROSPECTIVE ANALYSIS; EMERGE NETWORK; ELASTIC-NET; DISEASE; RISK; MORTALITY|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|1|1|2
Argument-structure and implicational constructions in a knowledge base|2017|This paper provides formalized, machine-tractable representations of two broad kinds of constructional configuration, argument-structure and implicational constructions, on the basis of previous linguistic analyses. It discusses computational implementation requirements on constructional description. In this respect, the paper argues that the Goldbergian approach (cf. Goldberg, 2006) provides the best fit for the implementation of implicational constructions, while a ``mini-constructionist{''} account (cf. Boas, 2014) is suitable for argument-structure constructions. Because of their representativeness, we have chosen to illustrate our discussion by making reference to the family of English resultatives, which are argument-structure constructions, and to the family of Wh-attitudinal constructions, which are implicational. Computational implementation demands that the members of the family of the resultative be split into mini-constructions, while the complexity of implicational configurations requires that different formal variants be grouped together under one single computational representation. The paper further makes explicit proposals for the machine tractability of lexical-constructional integration and of meaning implications that have reached constructional status through entrenchment, two problems that remain unsolved within standard computational approaches to language processing.|Constructions; Construction Grammar; cognitive models; knowledge-base; Lexical Constructional Model; Natural Language Processing|GRAMMATICAL CONSTRUCTIONS; FAMILY|Linguistics; Language \& Linguistics|0|1|2
Reported literacy, media consumption and social media use as measures of relevance of Spanish as a heritage language|2017|Aims and objectives: This paper explores one dimension of language maintenance among college-aged heritage speakers of Spanish (HSS) in three communities of the U.S. Midwest. The aim was to understand whether Spanish was relevant at a point in life in which they were developing their own networks away from their families. Research questions: Were reading and writing in Spanish relevant for the participants? Did they use Spanish when on social media? Did they text in Spanish? Was Spanish relevant for them when consuming content on electronic media? Methodology: This analysis is part of a larger study on HSS in communities of recent Latino settlement. Respondents participated in an oral interview and responded to an online survey. Data and analysis: Results presented here come from a study designed to gather data on reported interlocutors, reading and writing, electronic media consumption, and social media use. Respondents were 71 HSS between the ages of 19 and 29. Results were compared with two control groups: 23 L2 speakers and 24 native speakers attending the same schools. Higher relevance was assumed when an event was reported closest to the moment of response. Reading and writing were classified as school, personal interest, employment, other. Relevance as related to social media, music, and internet use was determined by reported frequency. Findings: Highest relevance was reported for texting and listening to music; lowest was reported for consumption of internet content. Results for texting, social media and personal interest reading/ writing suggest that for these speakers Spanish was viable for accrual of bonding social capital. Reading/ writing reports suggest that for many, Spanish was also viable to attain specific academic goals. Environmental pressures to shift are evidenced in the uses not (or barely) reported: reading/ writing related to work, religion and daily living, and consumption of internet content. Originality: This paper focuses on maintenance of relevance of a heritage language in the first stage of adult life. Implications: Results suggest that in using Spanish, respondents were not bound by physical context or immediate availability of interlocutors, but by their perceptions of viability.|Heritage speakers; language maintenance; Spanish; literacy; social media; Midwest|NETWORKING SITES; VITALITY; FACEBOOK; ONLINE|Linguistics; Language \& Linguistics|1|0|2
Multimodal Exemplification: The Expansion of Meaning in Electronic Dictionaries|2017|This article investigates electronic dictionaries under the framework of Systemic-Functional Multimodal Discourse Analysis (SF-MDA) and argues for improving their exemplification multimodally. Multimodal devices, if well coordinated, can help optimize e-dictionary examples in informativity, diversity, dynamicity and interactivity. The term multimodal exemplification is tentatively proposed under the umbrella of multimodal lexicography (Lew 2010), and defined as the selection and presentation of examples with multimodal devices for achieving greater effectiveness in exemplifying than language does alone, especially in an e-dictionary. Evidence shows that multimodal exemplification can expand the three metafunctional meanings of the e-dictionary discourse: ideational, interpersonal and textual. Ideational meaning can be enriched by not only multimodal examples per se but also cross-modal example-definition ties, and hyperlinks facilitate meaning flow in the semantic network. Interpersonal meaning can be expanded by user participation and design options, including those for page layout (spatial mode) and example genre style (verbal mode). Textual meaning can be reinforced by information value, composition, salience and framing. This article makes a first attempt to explore the intermodal relationship between a definition and the examples under the same sense, and to present a diagram illustrating a typical design of visual space in e-dictionaries. By exploring the special features of multimodal example texts, it may deepen our understanding of the emerging multimodal lexicography and complement multimodal discourse studies from a lexicographical perspective.|E-DICTIONARY; EXAMPLE; METAFUNCTIONAL MEANING; MULTIMODAL DISCOURSE ANALYSIS; MULTIMODAL EXEMPLIFICATION; MULTIMODAL LEXICOGRAPHY|ONLINE DICTIONARIES; DIGITAL REVOLUTION; EXAMPLE SENTENCES; LEXICOGRAPHY; COMMUNICATION; COLLOCATIONS; DISCOURSE; LANGUAGE; CORPUS; USERS|Linguistics; Language \& Linguistics|0|2|2
Multi-Dimensional Analysis, text constellations, and interdisciplinary discourse|2017|Multi-Dimensional Analysis (MDA) has been widely used to explore register variation. This paper reports on a project using MDA to explore the features of an interdisciplinary academic domain. Six dimensions of variation are identified in a corpus of 11,000 journal articles in environmental studies. We then focus on articles in one interdisciplinary journal, Global Environmental Change (GEC). It is expected that these articles will diverge sufficiently to produce differences that are analogous to register differences. Instead of identifying these ``registers{''} on external criteria, we use the dimensional profiles of individual texts to identify `constellations' of texts sharing combinations of features. Six such constellations are derived, consisting of texts with commonalities in their approaches to research: the development of predictive models; quantitative research; discussions of theory and policy; and human-environment studies focusing on individual voices. The identification of these constellations could not have been achieved through an a priori categorisation of texts.|Multi-Dimensional Analysis; interdisciplinary discourse; text constellations|RESEARCH ARTICLES; DISCIPLINARY VARIATION; CORPUS|Linguistics; Language \& Linguistics|0|2|2
FrameBase: Enabling integration of heterogeneous knowledge|2017|Large-scale knowledge graphs such as those in the Linked Open Data cloud are typically stored as subject-predicateobject triples. However, many facts about the world involve more than two entities. While n-ary relations can be converted to triples in a number of ways, unfortunately, the structurally different choices made in different knowledge sources significantly impede our ability to connect them. They also increase semantic heterogeneity, making it impossible to query the data concisely and without prior knowledge of each individual source. This article presents FrameBase, a wide-coverage knowledge base schema that uses linguistic frames to represent and query n-ary relations from other knowledge bases, providing multiple levels of granularity connected via logical entailment. Overall, this provides a means for semantic integration from heterogeneous sources under a single schema and opens up possibilities to draw on natural language processing techniques for querying and data mining.|Knowledge representation; semantic web; n-ary relations; frames; reification; semantic integration|ONTOLOGY DESIGN PATTERNS; SEMANTIC WEB; WIKIPEDIA; ALIGNMENT|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory \& Methods|0|1|2
The labyrinth of ethics in journalistic translated discourse|2017|Given that both translation ethics and journalistic translation are still two underexplored areas in translation research, this study sets out to discover the ethical model of Iranian translators' performance in a climate of conflict. To achieve the objective, the researchers monitored and collected the translated journalistic texts concerning the Iranian nuclear negotiations published by a state-run news agency from three days before the Almaty I nuclear talks to three days after the Almaty II negotiations. The monitoring phase resulted in 20 pairs of STs and TTs. The comparative textual analysis indicated patterned and motivated ideological interference in translations which could be accounted for by resorting to teleological models of ethics. Theoretical analysis revealed conceptual overlap between ethics and ideology that could explain the reduction of ethics into ideology in the news agency.|ethics of translation; ideology; translation and conflict; Iranian nuclear negotiations|NEWS TRANSLATION; IDEOLOGY; IRAQ|Linguistics; Language \& Linguistics|0|2|2
The appropriateness of standardised tests in academic literacy for diploma programmes of study|2017|Standardised tests in higher education have become widespread as a mechanism to provide additional information for student placements in appropriate programmes of study. Much has been written about these tests for entry to formative degree programmes. This study contributes to this discussion by determining the alignment between the academic literacy test specifications of a standardised test and reading practices for diploma subjects. Theoretical approaches to standardised testing and academic literacies framed the analysis and findings of this study. The multiple-case study approach was used to explore reading practices of first-year diploma subjects, and semi-structured interviews and document analysis were used for data generation. The findings revealed two dominant content representations - text-dominant and visual literacy-dominant orientations - that influenced the application of different literacy practices. It is concluded that while academic literacy is integral to knowledge acquisition in academia, disciplinary literacies within diploma qualifications have a profound presence and should be accommodated in standardised testing to ensure that what is tested resonates with subject literacies.|academic literacy; diplomas; disciplinary literacy; higher education; placement; standardised tests|DISCIPLINARY LITERACY|Linguistics; Language \& Linguistics|0|1|2
K-12 multimodal assessment and interactive audiences: An exploratory analysis of existing frameworks|2017|Multimodal writing today often occurs through membership in an online, participatory culture; thus, based on affordances of online compositions, the audience for student writers has shifted from imagined readers to actual, accessible readers and responders. Additionally, recent content and technology standards for students in US schools emphasize the importance of distributing multimodal compositions to wider audiences. In this article, we closely examine attention to interactive audience and collaboration in a purposive sample of kindergarten through 12th grade (K-12) assessment frameworks, as well as how these frameworks define multimodal composition. We found that multimodal composition is being defined consistently across all frameworks as composition that includes multiple ways of communicating. However, many multimodal composition examples were texts that were non-interactive composition types even though many authors acknowledged the emergence of interactive online composition types that afford the writer the ability to communicate and collaborate with an audience. In addition, the frameworks reviewed tended to focus on the final product and less often on the process or dynamic collaboration with the audience. In the discussion, implications for classroom teachers as well as considerations for researchers exploring the construct of online multimodal writing are offered. (C) 2016 Elsevier Inc. All rights reserved.|Assessment; Multimodal composition; K-12; Interactive audience|LITERACY; CLASSROOM; ENGLISH; STORY; TEXTS|Education \& Educational Research; Linguistics|0|0|2
The sequential organization of text and speech in multimodal synchronous computer-mediated communication|2017|This study uses conversation analysis to describe the sequential and functional relationship between text and speech turns in an English conversational lesson conducted in multimodal synchronous computer-mediated communication ( SCMC) involving text and speech modes. Focusing on repair sequences, I examine the relative timing of turns in each mode, the interactional practices that participants employed to handle timing discrepancy, and how both modes were utilized to maintain the pedagogical and interpersonal purposes of the encounter. The analysis shows that synchronous timing between text and speech turns was rare. In time lags between text and speech turns, if the repair was a self-initiated other-repair initiated by the tutee, speech turns did not seem to orient to the time lag. In other types of repair, the tutor utilized a range of practices to accommodate for the time lags, such as extreme slow speech tempo, pivot turns, and topic pursuits. The tutor also used the silent and visual features of text to insert and project an upcoming teaching episode in the midst of unfolding topical talk. The findings suggest that multimodal SCMC is a holistic process in which the affordances of modes can be employed dynamically and integratively to achieve social actions.|multimodal discourse; SCMC; text-and-voice chat; repair; conversation analysis|CONVERSATION; REPAIR; TALK; CHAT; CLASSROOM|Communication; Linguistics; Language \& Linguistics|1|1|2
A HOLISTIC HUMANITIES OF SPEAKING: FRANZ BOAS AND THE CONTINUING CENTRALITY OF TEXTS|2017|We take up Boas's commitment to the establishment of a large corpus of texts from the indigenous languages and peoples of the Americas, examining what we take to be his fundamental principles: using texts as the philological record from which to document and explore language, culture, and intellectual life on their own terms; training speakers to engage in documentation through the creation and analysis of texts; and a focus on the emergence of patterns and interrelationships. We then outline what we see as his influence up to now, both directly through the kinds of projects he promoted and indirectly through a broader application of Boasian principles that has animated a series of later movements. Finally, we discuss the prospects for a more comprehensive text-and documentation-centered approach to language and culture that welds together these themes and movements, and which we envision as a holistic humanities of speaking.|Boas; language documentation; texts; speech play and verbal art; philology|LANGUAGE; DISCOURSE; GRAMMAR; MIXTECO; CULTURE; POETICS; INDIANS; SPANISH; VOICES; POETRY|Linguistics; Language \& Linguistics|1|0|2
Decision support environment for medical product safety surveillance|2016|We have developed a Decision Support Environment (DSE) for medical experts at the US Food and Drug Administration (FDA). The DSE contains two integrated systems: The Event-based Text-mining of Health Electronic Records (ETHER) and the Pattern-based and Advanced Network Analyzer for Clinical Evaluation and Assessment (PANACEA). These systems assist medical experts in reviewing reports submitted to the Vaccine Adverse Event Reporting System (VAERS) and the FDA Adverse Event Reporting System (FAERS). In this manuscript, we describe the DSE architecture and key functionalities, and examine its potential contributions to the signal management process by focusing on four use cases: the identification of missing cases from a case series, the identification of duplicate case reports, retrieving cases for a case series analysis, and community detection for signal identification and characterization. Published by Elsevier Inc.|Natural language processing; Text mining; Network analysis; Post-marketing surveillance; Information retrieval|EVENT REPORTING SYSTEM; STEM-CELL TRANSPLANTATION; TEXT MINING SYSTEM; NETWORK ANALYSIS; US VACCINE; ADVERSE; CLASSIFICATION; IMPROVE; DISEASE; ASSOCIATION|Computer Science, Interdisciplinary Applications; Medical Informatics|2|2|2
Building an RRG computational grammar|2016|Several grammatical models have shown a growing interest for the development of the conditions necessary to satisfy the so-called criterion of computational adequacy. Within Role and Reference Grammar (RRG {[}Van Valin \& LaPolla, 1997; Van Valin, 2005; Pavey, 2010]), there have been some works seeking to implement the model in different computational environments (Diedrichsen, 2011, 2013; Guest, 2009; Nolan \& Perinan-Pascual, 2014; Salem et al., 2008). In this scenario, the works of Van Valin \& Mairal (2014), Perinan-Pascual (2013) and Perinan-Pascual \& Arcas (2014) have set up the guidelines to devise a parsing system called ARTEMIS (Automatically Representing TExt Meaning via an InterlinguaBased System) for the computational treatment of the syntax and semantics of sentences. The goal of this paper is to contribute to the development of ARTEMIS focusing specifically on the design of the rules necessary for the effective computational parsing of unmarked simple clauses following the format of the Layered Structure of the Clause as described in RRG. Such rules should yield, as a result for every sentence, a parsed tree following the format of grammatical analyses in RRG.|Role and Reference Grammar; FunGramKB; computational grammar; constructions; lexical rules; syntactic rules; constructional rules; attribute-value matrix; conceptual modeling; the layered structure of the clause|FRAMENET|Linguistics; Language \& Linguistics|3|2|2
Linguistic-discursive variations in written narratives by elementary school children in Northern Patagonia|2016|In this paper we study the written narratives used by 54 third- and seventh graders in elementary schools with different socio-educational characteristics in Northern Patagonia, Argentina, when writing individually, on paper, and during class, a text of their choice. We aim to capture the various ways in which these students solve the narrative production, considering the adjustment to specific prescriptions for written language and to conventional features of narrative structure, as of the lexicogrammatical choices according to grammar and genre. We categorized the 54 texts according to three linguistic levels: textual (unit of analysis: text), lexicogrammatical, and morpho-orthographic (unit of analysis: word). We applied diverse techniques of Multivariate Descriptive Statistics, in order to capture associations between categories in each linguistic level and children's grade/school. Results showed socio-educational trends at the textual and morpho-orthographic levels, and stilistic patterns at the lexicogrammatical level, related to socio-cultural traits. In sum, these results account for a variety of degrees and ways of appropriating narrative writing, which emerge from the double perspective of adjustment to prescriptions, as well as exploration and exploitation of a range of options.|Writing; narratives; elementary school children; linguistic levels; literacy|LEARNING-DISABILITIES; STUDENTS|Linguistics; Language \& Linguistics|0|1|2
Translating the style of Aganaktismenoi (Indignants) on Facebook|2016|The paper discusses translation challenges associated with the linguistic and multisemiotic stylistic ways (Kress 2010; Coupland 2007) Aganaktismenoi, the Greek indignants' movement, employ to produce a digital sense of their community and subsequent identities. It argues for the transfer of the cultural and sociopolitical element as being the hardest to translate into languages other than Greek. In light of this challenge, it is suggested that a functional variationist translation model (Theodoropoulou 2007), which takes into consideration the general context and the functions of individual illocutionary acts (Austin 1962), i.e. intended meanings, performed digitally could remedy this weakness by yielding translations that do justice to the original utterances. This is also enhanced by the fact that a multisemiotic style, such as a picture posted on Facebook Wall, offers lots of background information (e.g., colors and facial expressions, to mention just a few), which act synergistically in the deciphering and consequent translation of the text. The expansion of the use of the aforementioned sociopragmatic model of translation into multisemiotic texts is made on the basis of linguistic and multimodal analysis of posts with pictures and text from the Aganaktismenoi pages on Facebook and their translation into English.|multimodality; Greek indignants; functional variation; translation; style|IDEOLOGY; LANGUAGE|Linguistics; Language \& Linguistics|0|1|2
Improving ontology-based text classification: An occupational health and security application|2016|Information retrieval has been widely studied due to the growing amounts of textual information available electronically. Nowadays organizations and industries are facing the challenge of organizing, analyzing and extracting knowledge from masses of unstructured information for decision making process. The development of automatic methods to produce usable structured information from unstructured text sources is extremely valuable to them. Opposed to the traditional text classification methods that need a set of well-classified trained corpus to perform efficient classification; the ontology-based classifier benefits from the domain knowledge and provides more accuracy. In a previous work we proposed and evaluated an ontology based heuristic algorithm {[}28] for occupational health control process, particularly, for the case of automatic detection of accidents from unstructured texts. Our extended proposal is more domain dependent because it uses technical terms and contrast the relevance of these technical terms into the text, so the heuristic is more accurate. It divides the problem in subtasks such as: (i) text analysis, (ii) recognition and (iii) classification of failed occupational health control, resolving accidents as text analysis, recognition and classification of failed occupational health control, resolving accidents. (C) 2015 Elsevier B.V. All rights reserved.|Text classification; Ontology; Oil and gas industry|LATENT SEMANTIC ANALYSIS|Computer Science, Artificial Intelligence; Computer Science, Theory \& Methods; Mathematics, Applied; Logic|1|0|2
Discursive organisation of two genres in students from three school levels and different social groups|2016|The study aims to identify the effect of school level and social context in the discursive organization of two written genres. We analysed 240 personal stories and explicative articles written by 120 students from three school levels - 7th grade (12 years old), 9th (14 years olds) and 11th (16 years old)- and two social groups: middle- low socioeconomic status (MSS) and high socioeconomic status (HSS). The texts were elicited by a short video on the uses of Internet and social networks, and then coded with CLAN. T Tests and a design of mixed factorial ANOVA with two intergroup factors (level and social group) were applied for data analysis. The results show that in the MSS group, the stories become less eventive and more evaluative with age/school level, but the explicative texts do not change their discursive organization. In the HSS group, there are evaluation at all school levels, but what evolves is the use of these evaluations in complex and longer texts; the explicative articles change considerably in both length and organization. We conclude that the incorporation of new organization resources and also the efficient use of them to elaborate the information in extended texts, are characteristics of the path to a competent discursive production.|Development; discursive organisation; personal story; explicative article|TEXT CONSTRUCTION; STANCE|Linguistics; Language \& Linguistics|0|0|2
Clinical Case Study Genre: Rhetorical organization of the macromove Case Report in chilean medical journals|2016|The Clinical Case Study is one of the oldest medical discursive genres where a new medical or unusual illness-related event, symptomatology or treatment is reported. It is necessary to deepen the knowledge of the patterns of regularity that underlie the way this genre is rhetorically organized as it carries a high pedagogical value in vocational training and in determining the success of young medical professionals who start publishing (Uribarri, 2007; Serrano, 2010). As part of a wider project, this article describes the rhetorical organization of the Case Report, a unit that corresponds to one of the main macromoves that shape the Clinical Case Study genre (Burdiles, 2012). The purpose of this study is to determine, by means of Genre Analysis (Swales, 1990, 2004), the rhetorical organization of the macromove Case Report of a corpus of 969 texts from nine medical specialties (Corpus CCM-2009). According to the results, this macromove has a rhetorical organization made up of three moves and eight rhetorical steps. It was observed, on one hand, that this pattern appears fairly regularly in the nine medical specialties, which would prove the existence of a common system of rhetorical conventions expressed in genre writing. On the other hand, it was found that these conventions have some variations associated with the nature of the various medical specialties.|Rhetorical organization; rhetorical move; case report; discourse of medicine; discursive genre|SCIENTIFIC-KNOWLEDGE; RESEARCH ARTICLES; PUBLICATION|Linguistics; Language \& Linguistics|0|1|2
Extracting genetic alteration information for personalized cancer therapy from ClinicalTrials.gov|2016|Objective: Clinical trials investigating drugs that target specific genetic alterations in tumors are important for promoting personalized cancer therapy. The goal of this project is to create a knowledge base of cancer treatment trials with annotations about genetic alterations from ClinicalTrials.gov. Methods: We developed a semi-automatic framework that combines advanced text-processing techniques with manual review to curate genetic alteration information in cancer trials. The framework consists of a document classification system to identify cancer treatment trials from ClinicalTrials.gov and an information extraction system to extract gene and alteration pairs from the Title and Eligibility Criteria sections of clinical trials. By applying the framework to trials at ClinicalTrials.gov, we created a knowledge base of cancer treatment trials with genetic alteration annotations. We then evaluated each component of the framework against manually reviewed sets of clinical trials and generated descriptive statistics of the knowledge base. Results and Discussion: The automated cancer treatment trial identification system achieved a high precision of 0.9944. Together with the manual review process, it identified 20 193 cancer treatment trials from ClinicalTrials.gov. The automated gene-alteration extraction system achieved a precision of 0.8300 and a recall of 0.6803. After validation by manual review, we generated a knowledge base of 2024 cancer trials that are labeled with specific genetic alteration information. Analysis of the knowledge base revealed the trend of increased use of targeted therapy for cancer, as well as top frequent gene-alteration pairs of interest. We expect this knowledge base to be a valuable resource for physicians and patients who are seeking information about personalized cancer therapy.|personalized cancer therapy; natural language processing; clinical trial|ENTITY RECOGNITION; RESOURCE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|3|0|2
Systematical Approach for Detecting the Intention and Intensity of Feelings on Social Network|2016|Online posts not only represent the records of people's lives but also reveal their satisfaction with life and relationships as well as potential mental illnesses. The detection of (strong or general) negative as well as (strong or general) positive feelings of people from online posts can keep us from carelessly missing their important moments, difficult or great, due to the overloaded information in the daily life and lead to a better society. Therefore, in this paper, we build a Feeling Distinguisher system based on supervised Latent Dirichlet Allocation (sLDA), Latent Dirichlet Allocation, and SentiWordNet methodologies for detecting a person's intention and intensity of feelings through the analysis of his/her online posts. Experimental results on posts collected from five social network websites demonstrate the effectiveness of FeD. The performance of FeD is about 1.08-1.18 folds that of SVM and sLDA.|Feeling intensity; latent Dirichlet allocation (LDA); supervised LDA (sLDA)|DEPRESSION; DIAGNOSIS; TEXT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical \& Computational Biology; Medical Informatics|0|1|2
Negotiation of expertise and multifunctionality: PowerPoint presentations as interactional activity types in workplace meetings|2016|This article investigates exchanges between the presenter and another participant within PowerPoint presentations in workplace meetings. Using ethnomethodological conversation analysis as a method, it examines 1) how participants orient to each other's expertise, 2) what is accomplished through the exchange and 3) how the PowerPoint slide is interwoven with the process. The results show how the exchanges establish the presentation as information delivery in which the complexity of professional knowledge is displayed and negotiated. Moreover, there is an orientation to directive functions of the presentation activity. The PowerPoint slides as a text and as a material object are evoked for these purposes. (C) 2016 Elsevier Ltd. All rights reserved.|PowerPoint presentation; Workplace interaction; Speaker change; Epistemics; Deontics; Conversation analysis|SOCIAL-RELATIONS; KNOWLEDGE; ORGANIZATION; AUTHORITY; LANGUAGE|Communication; Linguistics|0|0|2
Revisiting the loss of verb movement in the history of English|2016|Most of the discussions of the loss of verb movement in the history of English have focused on data related to the rise of do-support. In this paper, we extend the empirical basis to evidence from adverb placement. Our analysis of the distribution of finite main verbs with respect to adverbs in a range of prose texts in the history of English shows that the decline of V-movement in English starts in the middle of the 15th century and that verb movement past adverbs is lost to a large extent around the middle of the 16th century. These observations differ considerably from what data involving the sentential negator not indicate. According to that evidence, the loss of verb movement is a rather long process starting in the 16th century and coming to completion over 200 years later. In order to reconcile the conflicting diachronic evidence from adverb placement and the syntax of negation, we propose that the loss of verb movement in English is not a single event but occurs sequentially. In a first phase, verb movement to T is lost while movement to a lower inflectional head is maintained. In a second phase, verb movement starts being lost completely. We show that the Rich Agreement Hypothesis, which has been very prominent in accounts of variation with respect to verb movement, cannot capture these developments in a satisfactory way. Instead, it is verbal morphology more generally that will be argued to play a role in connection with the occurrence of verb movement. However, we do not postulate a strong correlation between morphology and syntax and propose that the loss of verb movement in English is the result of a combination of factors: changes in the verbal morphosyntax (loss of subjunctive, rise of periphrastic forms), an acquisitional bias towards simpler structures, the decline of the subject-verb inversion grammar found in early English, and effects of dialect contact.|Adverbs; Early Modern English; History of English; Middle English; Old English; Negation; Verb movement; Word order change|OLD-ENGLISH|Linguistics; Language \& Linguistics|1|0|2
``Long, boring, and tedious{''}: youths' experiences with complex, religious texts|2016|Growing out of the renewed attention to text complexity in the United States and the large population of youth who are deeply committed to reading scripture, this study explores 16 Latter-day Saint and Methodist youths' experiences with complex, religious texts. The study took place in the Midwestern United States. Data consisted of an academic year of participant observations and 59 extensive, semi-structured interviews conducted over 2 years. Constant comparative analysis revealed two primary areas of struggle that participants had with the Book of Mormon and the Bible: scriptural language and contradictions with and within scripture. Struggles with the antiquated language of scripture included having difficulty with its diction, syntax and literacy devices. Struggles with text contradictions included the intratextual inconsistencies and youths' personal conflicts with what they believed scripture said. Similarities and differences were manifest across the two congregations within the aforementioned areas. This study raises important questions about the use of complex texts for instructional purposes, motivating youth to engage with complex texts, and the development of new lines of literacy research focused on religious texts and youths' experiences with these texts.|Latter-day Saints; Methodist; religion; scripture; text complexity|LITERACY; SCHOOL|Education \& Educational Research; Linguistics; Language \& Linguistics|2|0|2
The Effect of Bipolar Mood Disorder on Sadegh Hedayat's Letters|2016|This paper studies linguistic characteristics of bipolar mood disorder in Sadegh Hedayat's letters. It attempts to explore the possibility of diagnosing bipolar disorder through qualitative analysis of text. The personal letters of Iranian author Sadegh Hedayat addressed to Shahid Nouraie are studied. The addressee is fixed to reduce effective factors, including linguistic differences among different registers and styles. Therefore, interpersonal variation is also neutralized. Letters are chosen to reduce the potential effects of aesthetic manipulation used in the author's narratives and published works. To analyze the data, semantic fields used in the letters are studied, and to find any instance of pressured speech and poverty of speech, topical shifts and moves are analyzed as well. Linguistic study of each letter reveals that different types of bipolar mood episodes (i.e., hypomanic, depressed, euthymic and mixed) can be diagnosed with this methodology. Other semantic criteria are explored, including themes of humiliation and ridicule.|Bipolar mood disorder; Move; Sadegh Hedayat; Semantic field|WRITERS|Linguistics; Psychology, Experimental|1|0|2
Motivation in the tertiary art and design studio: A multi-perspectival discourse analysis|2016|This paper investigates the nature of motivation in the context of a tertiary art and design studio through a multi-perspectival and mixed methodological study of situated text and talk. Drawing upon the analytical resources of linguistic ethnography, multimodal interaction, and functional linguistics, among others, the study finds that motivation in the studio, while perceived by the tutors in terms of the students' willingness to complete required project work, is, on further examination, a more complex phenomenon, dynamically related to wider socio-institutional discourses and the students' conception of their future selves. The paper concludes by reconceptualizing motivation in the art and design studio as a discursively constructed and contested phenomenon, intersubjectively realized across the trajectory of studio genres and inherently related to identity and power. The findings contribute to understandings of motivation, particularly within the context of art and design educational studies.|discourse analysis; motivation; art education; multi-perspectival; mixed-methodology; multimodal interaction|VIEW|Communication; Linguistics; Language \& Linguistics|1|1|2
Similar and/or Different Writing Processes? A Study of Spanish Foreign Language and Heritage Language Learners|2016|Following a cognitively-oriented framework, this study builds upon the authors' previous work (Elola and Mikulski 2013; Mikulski and Elola 2011), which analyzed writing processes (planning time, execution time, revision time), fluency, and accuracy of Spanish heritage language (SHL) learners when composing in English and in Spanish. By analyzing Spanish foreign language (SFL) learners' writing processes when composing in English and Spanish, the current study compares writing behaviors in both languages within the SFL group, as well as provides a comparison between the writing behaviors of the SHL and SFL learners completing the same writing tasks. SFL learners wrote less fluently, performed more surface revisions, and demonstrated less accuracy when writing in Spanish than in English, but monitored more in English. However, they allocated similar amounts of time to execution and planning across languages. Compared to their SHL counterparts, SFL learners wrote less fluently and accurately and devoted less time to Spanish intersentential planning and English monitoring. The SFL learners performed more surface revisions in Spanish and fewer meaning revisions in English and Spanish than the SHL learners. Insights into cross-linguistic transfer of writing skills and pedagogical suggestions are provided.|cognitive approach; foreign language learners; Spanish heritage language learners; time allocation; writing processes|FORMULATION PROCESSES; TEMPORAL ANALYSIS; GENERATING TEXT; STUDENT WRITERS; SPEAKERS; L1; L2; ACQUISITION; PROFICIENCY; ACCURACY|Linguistics; Language \& Linguistics; Literature, Romance|1|1|2
Gender Classification by Means of Online Uppercase Handwriting: A Text-Dependent Allographic Approach|2016|This paper presents a gender-classification schema based on online handwriting. Using samples acquired with a digital tablet that captures the dynamics of the writing, it classifies the writer as a male or a female. The method proposed is allographic, regarding strokes as the structural units of handwriting. Strokes performed while the writing device is not exerting any pressure on the writing surface, pen-up (in-air) strokes, are also taken into account. The method is also text-dependent meaning that training and testing is done with exactly the same text. Text-dependency allows classification be performed with very small amounts of text. Experimentation, performed with samples from the BiosecurID database, yields results that fall in the range of the classification averages expected from human judges. With only four repetitions of a single uppercase word, the average rate of well-classified writers is 68 \%; with sixteen words, the rate rises to an average of 72.6 \%. Statistical analysis reveals that the aforementioned rates are highly significant. In order to explore the classification potential of the pen-up strokes, these are also considered. Although in this case, results are not conclusive, and an outstanding average of 74 \% of well-classified writers is obtained when information from pen-up strokes is combined with information from pen-down ones.|Biometric recognition; Gender recognition; Handwriting; Stroke; Pen-up stroke; Pen-down stroke|WRITER IDENTIFICATION; SEX-DIFFERENCES; RECOGNITION; JUDGMENTS; FEATURES; ENGLISH; SPEECH; SYSTEM; FACES|Computer Science, Artificial Intelligence; Neurosciences|2|0|2
Bayesian group factor analysis with structured sparsity|2016|Latent factor models are the canonical statistical tool for exploratory analyses of low-dimensional linear structure for a matrix of p features across n samples. We develop a structured Bayesian group factor analysis model that extends the factor model to multiple coupled observation matrices; in the case of two observations, this reduces to a Bayesian model of canonical correlation analysis. Here, we carefully define a structured Bayesian prior that encourages both element-wise and column-wise shrinkage and leads to desirable behavior on high-dimensional data. In particular, our model puts a structured prior on the joint factor loading matrix, regularizing at three levels, which enables element-wise sparsity and unsupervised recovery of latent factors corresponding to structured variance across arbitrary subsets of the observations. In addition, our structured prior allows for both dense and sparse latent factors so that covariation among either all features or only a subset of features can be recovered. We use fast parameter-expanded expectation-maximization for parameter estimation in this model. We validate our method on simulated data with substantial structure. We show results of our method applied to three high-dimensional data sets, comparing results against a number of state-of-the-art approaches. These results illustrate useful properties of our model, including i) recovering sparse signal in the presence of dense effects; ii) the ability to scale naturally to large numbers of observations; iii) flexible observation- and factor-specific regularization to recover factors with a wide variety of sparsity levels and percentage of variance explained; and iv) tractable inference that scales to modern genomic and text data sizes.|Bayesian structured sparsity; canonical correlation analysis; sparse priors; sparse and low-rank matrix decomposition; mixture models; parameter expansion|PRINCIPAL COMPONENT ANALYSIS; CANONICAL CORRELATION-ANALYSIS; VARIABLE SELECTION; MAXIMUM-LIKELIHOOD; FACTOR MODELS; MATRIX DECOMPOSITION; EM ALGORITHM; REGRESSION; IDENTIFICATION; OPTIMIZATION|Automation \& Control Systems; Computer Science, Artificial Intelligence|2|0|2
The cognitive and rhetorical role of term variation and its contribution to knowledge construction in research articles|2016|This study explored the behaviour and functions of term variation in research articles in order to better understand the process of knowledge construction within texts. A semantic analysis of term variation in 19 Spanish-language psychology research articles was carried out. Variants were classified according to the semantic distance from the base term. Analysis revealed that term variation provides information about the concept's content and its relationships with other concepts within the conceptual structure. Furthermore, an examination of the distribution of term variants across text sections revealed three rhetorical functions of term variation: a naming function, present in the title, abstract and keyword sections; an explanatory function, in the introduction and discussion sections; and a particularizing function, in the method and results sections. This analysis confirmed that intratextual term variation plays a cognitive and rhetorical function in research articles, helping to construct and transfer knowledge within the text and to realize the communicative purposes of the genre.|term variation; research articles; knowledge construction; rhetorical structure; academic discourse|INFORMATION; DYNAMICS|Linguistics; Language \& Linguistics|0|0|2
National and post-national discourses and the construction of linguistic identities by students of Albanian origin in Greece|2016|Drawing on Critical Discourse Analysis and, more specifically, on the relationship between the macro-level of dominant discourses and the microlevel of individual positionings, we examine the way linguistic identities are constructed by immigrant students of Albanian origin in Greece. We elaborate on two `ompetitive' discourses: the national, homogenizing one and the post-national, deconstructing one, and the way they influence the construction of immigrant students' linguistic identities. Our data come from lyceum immigrant students' essays which are analyzed in order to trace their positionings towards the two `competitive' discourses, and in particular, towards the linguistic dimension of these discourses. For a systematic investigation of immigrant students' linguistic identities we employ the membership categorization device living populations in Greece which includes the categories immigrant people and majority people as a standardized relational pair. We focus on the category-bound predicates of the category immigrant people and particularly on those related to the knowledge of the majority language. Our main finding is that the immigrant students of Albanian origin in our data are positively positioned towards the national, homogenizing discourse and particularly towards Greek monolingualism, thus looking forward to the social benefits of speaking Greek.|Critical Discourse Analysis; (post-)national discourses; linguistic identities; membership categorization device; category-bound predicate|VARIETIES; LANGUAGE; TEXTS|Linguistics; Language \& Linguistics|1|0|2
On the social life of a city anthem: semiotic objects, ideologies of belonging, and the reproduction of sociocultural difference|2015|This article takes a closer look at the role of semiotic objects such as texts, monuments, songs, and flags in the definition of both sociocultural boundaries and legitimation of the resulting relations of difference. The focus is a specific anthem, Z'Basel an mym Rhy {[}In Basel on my Rhine], which is the official anthem of Basel, a city in northwest Switzerland. In line with Appadurai's {[}1996. The Social Life of Things. Cambridge: Cambridge University Press] claim in favor of a complex analysis of an object's social life, this article is a historiographical investigation of the circulation of this semiotic object across time and space - from the moment of its conception as a poem in 1806, to the present day. The analysis centers on how this specific semiotic object has been re-appropriated and transformed continuously, throughout its social life, by new actors, in new contexts, and for new purposes. Indeed, from its origin as a romantic ode for intimate private consumption, this text gradually emerged as an object of cultural consumption on a larger scale, taking on the role of an instrument of pride and power, and becoming a tool to legitimize social structuration.|ideology; nationalism; semiosis; sociocultural difference; anthem|DISCOURSE; LANGUAGE|Humanities, Multidisciplinary; Communication; Linguistics|0|0|2
Lexical analysis of student research drafts in computing|2015|Lexical Richness is a competence that students acquire while advancing in education. This article presents results analyzing lexical richness of drafts of students, in terms of lexical density, variety, and sophistication. A computational model allows reviewing some essential elements in drafts. Results show that there exists a difference in lexical richness between graduate and undergraduate texts, and that sophistication is the measure that best differentiates them. We also report results of a pilot test. (c) 2015 Wiley Periodicals, Inc. Comput Appl Eng Educ 23:638-644, 2015; View this article online at ; DOI|lexical richness analysis; lexical variety; lexical density; sophistication|QUALITY|Computer Science, Interdisciplinary Applications; Education, Scientific Disciplines; Engineering, Multidisciplinary|0|1|2
Keyword Extraction from Arabic Documents using Term Equivalence Classes|2015|The rapid growth of the Internet and other computing facilities in recent years has resulted in the creation of a large amount of text in electronic form, which has increased the interest in and importance of different automatic text processing applications, including keyword extraction and term indexing. Although keywords are very useful for many applications, most documents available online are not provided with keywords. We describe a method for extracting keywords from Arabic documents. This method identifies the keywords by combining linguistics and statistical analysis of the text without using prior knowledge from its domain or information from any related corpus. The text is preprocessed to extract the main linguistic information, such as the roots and morphological patterns of derivative words. A cleaning phase is then applied to eliminate the meaningless words from the text. The most frequent terms are clustered into equivalence classes in which the derivative words generated from the same root and the non-derivative words generated from the same stem are placed together, and their count is accumulated. A vector space model is then used to capture the most frequent N-gram in the text. Experiments carried out using a real-world dataset show that the proposed method achieves good results with an average precision of 31\% and average recall of 53\% when tested against manually assigned keywords.|Algorithms; Languages; Experimentation; Keyword extraction; Arabic natural language processing; text analysis; term equivalence classes|MODEL; TEXT|Computer Science, Artificial Intelligence|1|0|2
THE DECAY OF THE PRETERITE IN LUXEMBOURGISH With an Overview about Behavior of the Subjunctive II and an Excursion to Preterite Border Region|2015|The decay of the preterite (Prateritumsschwund), a process which can now be observed in Luxembourgish, is the focus of this analysis. The goal here is to identify relict verbs, pose questions about the grammaticalization of some individual verbs as well as discuss the interaction of past tenses that occur in narratives. Type and token frequency values of the relict verbs will be dealt with and illustrated using current corpus data, for which diachronic data will be consulted for comparison. Furthermore, the multi-functional subjunctive II (Konjunktiv II) will briefly be described. Thereafter, a digression will follow on the retention of preterite forms in the most northern part of the Luxembourgish language area. This empirical contribution pertains to the domains of linguistic economy, dynamic synchrony, and quantitative linguistics.|oral and intended proximity in text corpora; grammaticalization; dynamic synchrony; semi-auxiliaries; quantitative linguistics; Nahe und intendierte Miindlichkeit in Textkorpora; Grammatikalisierung; dynamische Synchronie; Halb-Auxiliare; quantitative Linguistik|GERMAN; TENSE|Linguistics; Language \& Linguistics|1|0|2
An empirical study of lay comprehension of Chinese legal reference texts in Hong Kong|2015|This socio-legal study empirically assesses the use of plain language in improving comprehension of legal reference texts by laypeople in Hong Kong, where common-law Chinese was newly engineered. Our study shows that native Chinese speakers have problems understanding the materials, but simple modifications of the texts can significantly improve their comprehension. The results suggest that the seeming incapability of expressing law in a language may not be related to the choice of code, but to how it is written. Based on the data, this study contributes to the improvement of legal communication by identifying features of common-law Chinese that make these materials difficult to understand, and proposes language-specific plain-language strategies that can improve comprehensibility.|PLAIN LANGUAGE; COMMON-LAW CHINESE; TEXTUAL ANALYSIS; LEGAL COMMUNICATION; COMPREHENSION|JURY INSTRUCTIONS; MIRANDA WARNINGS; COMMON-LAW; REALISM|Criminology \& Penology; Linguistics|0|0|2
Constructions of motherhood and fatherhood in newspaper articles on maternal and paternal postpartum depression|2015|Postpartum depression (PPD) is typically constructed as a medical condition that is defined by prevalence rates, time of onset, duration, symptoms, causes and treatments. Presentations of PPD in popular texts have also revealed that it is a site for constructions of mothering/motherhood. While PPD has traditionally been assumed to be the domain of women, researchers have recently focused attention on PPD and men. Using articles on maternal and paternal PPD published in Canadian and American newspapers between 2008 and 2012, we analysed how constructions of mothering/motherhood and fathering/fatherhood were inscribed in this public forum. We show how mothering/motherhood was foregrounded via dominant evaluative discourses and highly imbued with expectations while fathering/fatherhood was kept in the background and characterised by the unavailability of clear expectations. We conclude that maternal PPD remains primary and normative while paternal PPD remains `othered' despite the supposed attention to it in these public texts.|DISCOURSE ANALYSIS; FATHERHOOD; MOTHERHOOD; NEWSPAPER ARTICLES; POSTPARTUM DEPRESSION|BLUES|Linguistics; Language \& Linguistics; Women's Studies|0|0|2
Cue-based assertion classification for Swedish clinical text-Developing a lexicon for pyConTextSwe|2014|Objective: The ability of a cue-based system to accurately assert whether a disorder is affirmed, negated, or uncertain is dependent, in part, on its cue lexicon. In this paper, we continue our study of porting an assertion system (pyConTextNLP) from English to Swedish (pyConTextSwe) by creating an optimized assertion lexicon for clinical Swedish. Methods and material: We integrated cues from four external lexicons, along with generated inflections and combinations. We used subsets of a clinical corpus in Swedish. We applied four assertion classes (definite existence, probable existence, probable negated existence and definite negated existence) and two binary classes (existence yes/no and uncertainty yes/no) to pyConTextSwe. We compared pyConTextSwe's performance with and without the added cues on a development set, and improved the lexicon further after an error analysis. On a separate evaluation set, we calculated the system's final performance. Results: Following integration steps, we added 454 cues to pyConTextSwe. The optimized lexicon developed after an error analysis resulted in statistically significant improvements on the development set (83\%F-score, overall). The system's final F-scores on an evaluation set were 81\% (overall). For the individual assertion classes, F-score results were 88\% (definite existence), 81\% (probable existence), 55\% (probable negated existence), and 63\% (definite negated existence). For the binary classifications existence yes/no and uncertainty yes/no, final system performance was 97\%/87\% and 78\%/86\% F-score, respectively. Conclusions: We have successfully ported pyConTextNLP to Swedish (pyConTextSwe). We have created an extensive and useful assertion lexicon for Swedish clinical text, which could form a valuable resource for similar studies, and which is publicly available. (C) 2014 The Authors. Published by Elsevier B.V. All rights reserved.|Assertion classification; Clinical text mining; Dictionaries; Medical Language Processing; Information extraction; Electronic health records|NEGATION; RADIOLOGY; ALGORITHM; LANGUAGE|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|0|0|2
RECONTEXTUALISATION, RESEMIOTISATION AND THEIR ANALYSIS IN TERMS OF AN FDG-BASED FRAMEWORK|2014|``Recontextualisation{''} is the process whereby content that has been given expression in one context (the ``source{''} context) is subsequently reused in a different context (the ``destination{''} context). It is often accompanied by ``resemiotisation{''}, the process whereby content is lifted from one text (the ``antecedent{''} text, situated in the source context) and recast in a modified form during the production of a subsequent text (the ``derivative{''} text, situated in the destination context). The aim of the present paper is to evaluate the adequacy of FDG, incorporating an extended model of context (EMC), as a basis for the analysis of the process of recontextualisation and of the accompanying resemiotisation. The study is based on the analysis of a corpus of texts consisting of one antecedent and six derivative texts, all drawn from the field of science communication. The texts are subjected to a contextual analysis in terms of the categories afforded by an analytical framework based on the EMC. From these contextual analyses, the differences between the source context and each of the six destination contexts are identified. These differences encapsulate the changes that constitute the essence of recontextualisation. In addition, each of the texts is analysed in terms of a three-tier framework based as far as possible on FDG. The resulting analyses are then compared, in order to identify the changes that constitute the essence of resemiotisation. Finally, the relationship between the recontextualisation and resemiotisation is discussed. From the point of view of evaluating the linguistic models employed, it transpires that the categories offered by the EMC appear to be viable as units for the analysis of recontextualisation. As for the analysis of resemiotisation, it turns out that a theoretical foundation for a substantial part of this, though not all, can be supplied by current FDG.|Context; Functional Discourse Grammar; Recontextualisation; Resemiotisation; Science Communication; Science Popularisation|SCIENCE; POPULARIZATION; LITERACY; ARTICLES|Linguistics; Language \& Linguistics|1|0|2
Towards explaining the cognitive efficacy of Euler diagrams in syllogistic reasoning: A relational perspective|2014|Although diagrams have been widely used as methods for introducing students to elementary logical reasoning, it is still open to debate in cognitive psychology whether logic diagrams can aid untrained people to successfully conduct deductive reasoning. In our previous work, some empirical evidence was provided for the effectiveness of Euler diagrams in the process of solving categorical syllogisms. In this paper, we discuss the question of why Euler diagrams have such inferential efficacy in the light of a logical and proof-theoretical analysis of categorical syllogisms and diagrammatic reasoning. As a step towards an explanatory theory of reasoning with Euler diagrams, we argue that the effectiveness of Euler diagrams in supporting syllogistic reasoning derives from the fact that they are effective ways of representing and reasoning about relational structures that are implicit in categorical sentences. A special attention is paid to how Euler diagrams can facilitate the task of checking the invalidity of an inference, a task that is known to be particularly difficult for untrained reasoners. The distinctive features of our conception of diagrammatic reasoning are made clear by comparing it with the model-theoretic conception of ordinary reasoning developed in the mental model theory. (C) 2013 Elsevier Ltd. All rights reserved.|Diagrammatic reasoning; Euler diagram; Efficacy; Categorical syllogisms; Relational inferences; Mental model theory|CONSTRAINT DIAGRAMS; NATURAL-LANGUAGE; SYSTEM; REPRESENTATIONS; QUANTIFIERS; INCLUSION; EXCLUSION; INFERENCE; CIRCLES; LOGIC|Computer Science, Software Engineering|6|0|2
Sketching a ``low-cost{''} text-classification technique for text topics in English|2014|The aim of this paper is to sketch a potential methodology for automatic text classification which allows text topic discrimination as a prior step to new case assignment to previously established text topics. Such case assignment will be performed by means of Discriminant Function Analysis based on a series of easily-computable linguistic parameters, in order to reduce computational costs.|automated text classification; discriminant function analysis; classification functions; English language; text topics|AUTHORSHIP ATTRIBUTION; CATEGORIZATION|Linguistics; Language \& Linguistics|0|0|2
Ideological closure in newspaper political language during the US 1872 election campaign|2014|This paper studies political language in late nineteenth century partisan newspapers by (a) evaluating the degree of pragmatic force, or ideological closure in political editorial content published during the 1872 election year in three leading Iowa newspapers; and (b) linking variations in the degree of ideological closure of these texts to the institutional and social-political contexts of their production, i.e. the political role of editors and the web of relationships within which they performed their work. The degree of ideological closure is evaluated by analysing a range of rhetorical and discursive practices. The study identified variations in degree of closure both between newspapers affiliated with the same party and within a single newspaper over time. Such variations are interpreted as reflecting editors' need to mitigate an intricate set of political interests and obligations. The analysis also brings to light the richness of partisan editorial language of this time. These finds demonstrate the complexity of the political language and discourse of Gilded Age newspapers.|political language; ideological closure; rhetorical practices; discursive practices; Gilded Age; Iowa; 1872 elections|CRITICAL DISCOURSE ANALYSIS; RHETORICAL VISION; FANTASY; FIGURES; NEWS|Linguistics; Language \& Linguistics|0|0|2
Edge Effects in Warlpiri Yawulyu Songs: Resyllabification, Epenthesis, Final Vowel Modification|2013|Song genres vary as to which aspects of language and music are matched to create a well-formed song. For example, English folk songs match stressed syllables to strong musical beats. Some song styles have no requirements on how language and music should align. This article analyses how text and music align in Warlpiri women's songs from central Australia and finds there are text-setting' rules for setting text to musical rhythm. We first identify the formal units of the text and music and then account for their combination by two matching rules. In Warlpiri, text-setting involves matching each syllable to one metrical (rhythmic) position and aligning phonological phrase edges with bar edges. Linguistic units smaller than the phrase, such as those in reduplications and other polymorphemic words, require no such alignment. Alignment is often met through lengthening the right edge of a phrase, which often results in a distortion of the patterns of syllabic prominence in speech. Preferred structures for both text and music can lead to variations of a song based on a reordering of these preferences. This can be exploited to restructure songs when words must be avoided for social reasons.|Warlpiri; Yawulyu; Prosody; Rhythmic Patterns; Metre; Text-Setting; Song|VERSE|Linguistics; Language \& Linguistics|2|0|2
The use of a systematic writing teaching model: A case study in year 7 of early immersion|2013|This case study examined the writing development of French immersion students in relation to an opinion text. The teacher adopted a systematic teaching unit that included exemplary practices in writing, the traits of good writing according to the genre being studied, the writing process and the counterbalanced approach. Twenty-seven students from one grade 7 French immersion class and their teacher participated in the study. These students wrote an initial opinion text and a second text after the systematic teaching unit. Both texts were analyzed according to a rubric incorporating six traits of effective writing. Quantitative data analysis involved the percentage of students who performed better on the second text overall and according to each writing trait. The texts were also analyzed qualitatively and these data were supplemented by classroom observations during the writing process. Results seem to indicate that the writing model was effective insofar as 23/27 students (85\%) improved on at least one writing trait and nearly 30\% improved on all six identified traits. Qualitative analyses of specific examples support these figures. The results also seem to indicate that the counterbalanced approach can be applied effectively with regard to the development of textual competence.|writing; immersion; second language; exemplary practices|LANGUAGE|Linguistics|1|0|2
Assertion modeling and its role in clinical phenotype identification|2013|This paper describes an approach to assertion classification and an empirical study on the impact this task has on phenotype identification, a real world application in the clinical domain. The task of assertion classification is to assign to each medical concept mentioned in a clinical report (e.g., pneumonia, chest pain) a specific assertion category (e.g., present, absent, and possible). To improve the classification of medical assertions, we propose several new features that capture the semantic properties of special cue words highly indicative of a specific assertion category. The results obtained outperform the current state-of-the-art results for this task. Furthermore, we confirm the intuition that assertion classification contributes in significantly improving the results of phenotype identification from free-text clinical records. (C) 2012 Elsevier Inc. All rights reserved.|Natural language processing; Clinical information extraction; Assertion classification; Pneumonia identification; Statistical feature selection|NEGATION DETECTION; RADIOLOGY REPORTS; FEATURE-SELECTION; CLASSIFICATION; DOCUMENTS; SYSTEM; UMLS; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|6|1|2
Memory-prediction framework theory and cognits in language's origin and cortical organization|2013|Traditionally, language was regarded as an example of a cultural and a social phenomenon, as opposed to a natural or a biological one. This distinction of culturally acquired (nurture) against the naturally (nature) reflects, in fact, the previous gap between the two cultures of human and natural sciences that Snow tried to solve since 1951. Today it is considered that the language has a deep biological basis with well-established evidence in the scientific community. For the assertion that the power of language depends on the genes, it is needed a more comprehensive understanding of human cognition where language would be integrated with other neurogenetic cognitive processes and neurophysiological interaction between humanity and reality.|genetics of language; cognits; hierarchical temporal memory; memory-prediction framework theory|BEHAVIOR|Linguistics; Language \& Linguistics|0|1|2
Assessment of respondent acceptability for preference measures in stuttering|2012|Purpose: To assess the feasibility of using one or more of four standard economic preference measures to assess health-related quality of life in stuttering, by assessing respondents' views of the acceptability of those measures. Method and results: A graphic positioning scale approach was used with 80 adults to assess four variables previously defined as reflecting the construct of respondent acceptability (difficulty of decision making, clarity of text, reasonableness for decision making, and comfort in decision making) for four types of preference measurement approaches (rating scale, standard gamble, time trade-off, and willingness to pay). A multivariate repeated measures analysis of variance (p < .001) and follow-up univariate repeated measures analyses of variance (all p <.01) were all significant, indicating that respondents perceived differences among the preference measurement methods on all four acceptability variables. Conclusion: The rating scale was perceived as the easiest, clearest, most reasonable, and most comfortable tool, but it is not a measure of utility (an economic term for desirability or worth). If utility is the objective, such as for cost-utility analyses in stuttering, then the present results suggest the use of standard gamble (rather than time trade-off). These results also support the use of willingness to pay assessments for cost-benefit analyses in stuttering. These findings supplement results previously obtained for other chronic conditions. Learning outcomes: The reader will be able to: (1) describe how four standard economic preference measures {[}rating scale (RS), time trade-off (TTO), standard gamble (SG), and willingness to pay (WTP)] can be used in economic analyses; (2) describe how RS, TTO, SG and WTP can be measured; and (3) describe how respondents perceive the use of RS, TTO, SG and WTP in measuring changes in stuttering. (C) 2012 Elsevier Inc. All rights reserved.|Utility; Standard gamble; Time trade-off; Willingness to pay; Graphic positioning scale; Stuttering|WILLINGNESS-TO-PAY; QUALITY-OF-LIFE; SPEECH-ASSOCIATED ATTITUDES; COST-EFFECTIVENESS ANALYSIS; GRAPHIC POSITIONING SCALE; CONTINGENT VALUATION; HEALTH STATES; ECONOMIC-EVALUATION; BENEFIT-ANALYSIS; PAYMENT SCALE|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|1|0|2
Initial subordinate clauses in Old French: Syntactic variation and the clausal left periphery|2012|This paper examines word order variation and change in Old French, in which subordinate clauses that immediately precede a main declarative can occur in at least two distinct syntactic positions with respect to the main clause. Data from a corpus of Old French texts from the 10th until the early 14th centuries show that most initial subordinates are situated outside the main clause proper, although some examples occur in the first position of the main clause. Adopting a richly articulated clausal left periphery (Beninca, 2006), the Scene Setting projection of FrameP is proposed as the default syntactic position for extra-clausal initial subordinates. Although Old French is considered a verb-second language, initial subordinates often yield sequences in which the finite verb of the main clause appears in third or higher position. Following Labelle (2007) and others, I argue that a complex left periphery accounts for descriptively non-V2 word orders, while upholding a V2 analysis for Old French. Finally, following Vance et al. (2010), who examined the role of initial subordinates in the loss of V2 in Old French, I show that for most of the Old French period, the grammar of main declaratives that follow initial subordinates is characteristically V2. Only over the course of the 13th century does the subject-verb order become dominant. (C) 2012 Elsevier B.V. All rights reserved.|Old French; Syntax; Variation; Change; Subordinates; Left periphery; Verb-second|PRO; ARCHITECTURE; PRONOUNS; ROMANCE|Linguistics; Language \& Linguistics|8|0|2
Functions of epistolary formulae in Dutch letters from the seventeenth and eighteenth centuries|2012|Wray (2002) distinguishes three main functions of formulaic language relating to processing, interaction and discourse marking. In this paper, we show that Wray's analysis of the functions of formulaic language also applies to historical letter-writing in a corpus of seventeenth- and eighteenth-century Dutch letters. Discourse is marked with formulae indicating the text type or the text structure. Interaction is covered by intersubjective formulae communicating health, greetings, wishes for renewed contact, as well as Christian-ritual formulae. The processing function is operationalised in terms of literacy and writing experience, assuming that the use of prefabricated formulae reduces the writing effort. Therefore, we expect less-experienced letter-writers to use more formulae than more-experienced writers. We will show that less-experienced writers are indeed more likely to use epistolary formulae, and conclude that Wray's ``reduction of the speaker's processing effort{''} in online speech production, also applies to written seventeenth- and eighteenth-century Dutch.|formulaic language; epistolary formulae; letter-writing; Dutch; literacy; historical sociolinguistics; writing experience|LANGUAGE|Linguistics; Language \& Linguistics|6|0|2
Expository Language Skills of Young School-Age Children|2011|Purpose: This research investigated the expository language skills of young school-age children with the ultimate aim of obtaining normative data for clinical practice. Specifically, this study examined (a) the level of expository language performance of 6- and 7-year-old children with typical development and (b) age-related differences between young and older school-age children. Method: Expository discourse was elicited from two groups of children using the favorite game or sport (FGS) task. Performance of the younger age group (n = 61), age 6; 0 (years; months) to 7; 11, was compared to that of a group of twenty 11-year-old children from an earlier study. Samples were analyzed on measures of verbal productivity, syntactic complexity, grammatical accuracy, and verbal fluency. Results: The FGS task was effective in eliciting text-level discourse from young school-age children. These children produced discourse that resulted in a fairly normal distribution across some of the language production measures. Age-related differences were observed on measures of verbal productivity, grammatical accuracy, and verbal fluency, but not on syntactic complexity. Conclusion: The findings suggest that expository discourse sampling may be a useful addition to a language assessment protocol, even for very young school-age children.|children; expository discourse; language sample analysis; assessment; school-age|IMPAIRMENT; DISABILITY; DISCOURSE|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|10|0|2
Carnivalesque politics: A Bakhtinian case study of contemporary Arab political humor|2011|This paper is a case study of contemporary Arab political jokes in the light of Bakhtinian theory of carnival and the carnivalesque. According to this analysis, these political jokes represent a variety of texts whose topics revert around ``glorifying{''}, mocking, parodying, scatologizing, and ultimately betraying the ruler These types of political jokes reflect a textual representation of the life cycle of the oppressive ruler, which begins with comic ``crowning{''} and glorification and ends in ``decrowning{''} and comic death. Within this cycle, political jokes represent a kind of hidden dialogue between the oppressed and their marginalized discourse, and the regime and its dominant autocratic discourse. These jokes are disturbing to the regime, leading perhaps to punishment, but they do not necessarily either undermine or actually support the regime. Like carnival, the telling of these jokes in a repressive context merely builds a second world outside the oppressive world of the regime and offers an alternative framework to the regime's policies.|political humor; carnival; carnivalesque; decrowning; dialogism; grotesque realism; parody|JOKES; LAUGHTER|Language \& Linguistics; Psychology, Multidisciplinary|8|0|2
THE BASIC DICTIONARY OF ESTONIAN: THE HISTORICAL CONTEXT AND THE PRINCIPLES OF COMPILATION|2011|The paper describes in an historical perspective what kind of information is presented in entries of Estonian-Russian learners' dictionaries on the level of morphology, word formation, syntagmatic relations and lexico-semantic relations. To achieve the aim of the study nine learners' dictionaries, which were published during the last 160 years, were investigated. The analysis of the Estonian-Russian learners' dictionaries indicated that dictionary compilers provide dictionary users mostly with information about inflectional formation and the Russian equivalent; meanwhile, information about word formation, syntagmatic and lexico-semantic relations is neglected or presented implicitly. For this reason, analyzed dictionaries can be classified mostly as passive dictionaries (i. e. for understanding of texts). On the other hand, learners' dictionaries meant for speakers of Estonian as a first language provide much more information concerning inflectional formation, word formation, synonyms, antonyms, paronyms-all of which is presented explicitly. The information on syntagmatic relations is presented mostly implicitly by means of examples at the level of phrases, clauses and sentences. The analysis revealed that there is a need to elaborate new format for explicit presentation of word formation, syntagmatic and lexico-semantic information in learners' dictionaries of Estonian Language as a Second Language. In order to achieve this goal and in view of positions taken by modern theoretical lexicography on what kind of information should explicitly be presented in a production dictionary, the authors elaborated the basic principles of compilation of the corpus-based productive Basic Dictionary of Estonian. This dictionary will supply users with pronunciation, emotional valence, inflectional, word formation information, government structures, lexical collocations, idioms, synonyms, antonyms and paronyms. The usage of government structures, lexical collocations and idioms will be illustrated by means of example sentences.|learner's dictionary; morphology; word formation; syntagmatic relations; lexico-semantic relations; Estonian as a second language|ENCODING DICTIONARIES; COLLOCATION; COLLIGATION|Linguistics; Language \& Linguistics|3|0|2
Summaries assessment in Spanish using Latent Semantic Analysis: A possible implementation|2011|Assessment is a complex task, due to the problems related to sistematicity and to the time it takes. These problems have motivated the study of reliable automatized assessment methods. In this scenario, the aim of this work is to identify an efficient method for assessing summaries, based on Latent Semantic Analysis (LSA). The summaries were written by students from secondary school in the city of Valparaiso, Chile. To acomplish the mentioned aim, we correlated the scores asigned by three teachers to 244 summaries of predominantly expository texts and 129 summaries of predominantly narrative texts with the scores provided by three computational methods, based on LSA. The methods are: 1) comparison of summaries with the source text, 2) comparison of summaries with a summary developed by the consensus of a group of linguists, and 3) comparison of summaries with three summaries constructed by three language teachers. General results show that the scores asigned by method 2 and 3 are statistically similar to the scores asigned by the teachers, when the source texts are predominantly narrative. However, this similarity is not so when the source text is predominantly expositive.|Automatic summary assessment; text comprehension; semantic similarity; Latent Semantic Analysis; narrative texts; expository texts|TEXT COMPREHENSION; KNOWLEDGE; MODEL|Linguistics; Language \& Linguistics|1|0|2
The meaning of {[}exiting]: toward a grammaticalization of architecture|2011|Descriptions of grammars need not be restricted to language. Many attempts at the grammaticalization of nonlinguistic communicative events have been based on the theoretical tenets of systemic functional linguistics; however, in order to account for the affordances of these different semiotic systems, some of the models deviate from the Hallidayan model. With respect to architecture, this article suggests that perhaps it is not the model that needs modification; rather, architecture could be viewed from a different perspective. This article hypothesizes that the pathways that thread throughout spatial texts are analogous to clauses in spoken and written texts. This article develops a fundamental system network which formalizes the choice of pathway that people make as they move through buildings. The system network follows faithfully those that Halliday has developed for language, displaying paradigmatic and syntagmatic agnation as well as a system to structure cycle. I demonstrate that Halliday's model, as is, provides a suitable analytical tool for spatial discourse, that is, meaning beyond the pathway|promenade; foyer; systemic functional linguistics; architecture; spatial discourse analysis; movement|SPACE|Communication; Linguistics; Language \& Linguistics|1|1|2
A comprehensive account of full-verb inversion in English|2010|Despite the abundant corpus-based research on full-inversion constructions in which the subject follows the entire verb phrase in a declarative clause, the analysis of this construction in the spoken mode has traditionally been neglected since it has been suggested that natural speech is not a good source of inversions. The article shows that speech, too, can be a good source of data for full inversion and that the spoken and the written modes do not differ in the overall distribution of the construction but rather in the types of inversion used and in the pragmatic functions these inversions serve in discourse. The article also casts light on the lack of consensus regarding the distribution of full inversion in written fictional and non-fictional texts, and in the pragmatic function the construction serves in both genres.|corpus linguistics; word order; inversion; pragmatics; iconicity|LOCATIVE INVERSION; WORD-ORDER; GRAMMAR|Linguistics; Language \& Linguistics|1|0|2
Disambiguation of ambiguous biomedical terms using examples generated from the UMLS Metathesaurus|2010|Researchers have access to a vast amount of information stored in textual documents and there is a pressing need for the development of automated methods to enable and improve access to this resource. Lexical ambiguity, the phenomena in which a word or phrase has more than one possible meaning, presents a significant obstacle to automated text processing. Word Sense Disambiguation (WSD) is a technology that resolves these ambiguities automatically and is an important stage in text understanding. The most accurate approaches to WSD rely on manually labeled examples but this is usually not available and is prohibitively expensive to create. This paper offers a solution to that problem by using information in the UMLS Metathesaurus to automatically generate labeled examples. Two approaches are presented. The first is an extension of existing work (Liu et al., 2002 {[}1]) and the second a novel approach that exploits information in the UMLS that has not been used for this purpose. The automatically generated examples are evaluated by comparing them against the manually labeled ones in the NLM-WSD data set and are found to outperform the baseline. The examples generated using the novel approach produce an improvement in WSD performance when combined with manually labeled examples. (c) 2010 Elsevier Inc. All rights reserved.|Natural Language Processing; NLP; Word Sense Disambiguation; WSD; Unified Medical Language System; UMLS|WORD SENSE DISAMBIGUATION; INFORMATION; DISCOVERY; SYSTEM|Computer Science, Interdisciplinary Applications; Medical Informatics|4|1|2
Referring expressions in English and Korean political news|2010|Referring expressions have been a topic of debate in the philosophy of language and in pragmatics, and numerous research studies have been put forward on the basis of constructed texts or naturally occurring discourses. Nevertheless, not much attention has been paid to uncover how referential terms are deployed in written media discourse, including news articles, particularly from a contrastive perspective. Political news articles provide a suitable starting point for a discussion of referring expressions, as public figures are deemed the most prominent news actors. This paper investigates what types of referring expressions are used in English and Korean political news and how they are related to the activation or accessibility of the entities to which they are intended to refer. For this purpose, two sets of data are sampled from several online news sites, and referring expressions in the data are extracted for the analysis. The results of the analysis suggest that the use of the referential terms in the two languages conform to the memory activation or accessibility scale theories. In addition, the varying range of deployed referential terms in the two languages is accounted for in terms of different discursive conventions in the two linguistic communities. (c) 2010 Elsevier B.V. All rights reserved.|Accessibility hierarchy; Contrastive discourse analysis; Political news; Referring expressions; Discursive/cultural conventions|ACCESSIBILITY|Linguistics; Language \& Linguistics|0|0|2
On the role of visual references in collaborative visualization|2010|Multi-Viewer Display Environments (MVDE) provide unique opportunities to present personalized information to several users concurrently in the same physical display space. MVDEs can support correct 3D visualizations to multiple users, present correctly oriented text and symbols to all viewers and allow individually chosen subsets of information in a shared context. MVDEs aim at supporting collaborative visual analysis, and when used to visualize disjoint information in partitioned visualizations they even necessitate collaboration. When solving visual tasks collaboratively in a MVDE, overall performance is affected not only by the inherent effects of the graphical presentation but also by the interaction between the collaborating users. We present results from an empirical study where we compared views with lack of shared visual references in disjoint sets of information to views with mutually shared information. Potential benefits of 2D and 3D visualizations in a collaborative task were investigated and the effects of partitioning visualizations both in terms of task performance, interaction behavior and clutter reduction. In our study of a collaborative task that required only a minimum of information to be shared, we found that partitioned views with a lack of shared visual references were significantly less efficient than integrated views. However, the study showed that subjects were equally capable of solving the task at low error levels in partitioned and integrated views. An explorative analysis revealed that the amount of visual clutter was reduced heavily in partitioned visualization, whereas verbal and deictic communication between subjects increased. It also showed that the type of the visualization (2D/3D) affects interaction behavior strongly. An interesting result is that collaboration on complex geo-time visualizations is actually as efficient in 2D as in 3D. Information Visualization (2010) 9, 98-114. doi:10.1057/ivs.2009.2; published online 14 May 2009|collaborative visualization; dynamic perspective view; multi-viewer display; 3D visualization; space-time cube|INFORMATION VISUALIZATION|Computer Science, Software Engineering|0|1|2
Doing time: an exploration of timescapes in literacy learning and research|2010|This article has two purposes. At the theoretical level it is intended to contribute to debates about how learning happens over time. At the methodological level it is intended to suggest how a complex understanding of time can enrich both ethnographic methods and linguistic analysis. It uses the concept of timescapes to interpret ethnographic and linguistic data drawn from a study of identity and learning in adult literacy education in England. It makes three interconnected arguments. Firstly, learning and research do not just happen in time, but involve the social production of time. Secondly, learning and research do not happen in isolatable `moments', but each moment is temporally extended to include the past and the future. Thirdly, analytical approaches that treat time as a static container or decontextualised measure of experience cannot fully account for the complexity of learning, which involves the creation of multi-dimensional timescapes.|literacy; ethnography; writing; research methodology|CONTEXT; TEXT|Education \& Educational Research; Linguistics; Language \& Linguistics|4|0|2
The studio interaction as a contextual resource for TV-production|2008|The present text focuses on the complex context of TV-production. The study shows how the dynamics of the studio interaction can be made relevant as a crucial contextual resource for the production crew filming and broadcasting the very same interaction. The mutual intelligibility of the crew's indexical practices (e.g. talk, switches and camera movement) is shown to be grounded in a state of mutual attention to the unfolding studio interaction. Based on a number of recordings made in the control room during the live production of the French TV-show Rideau Rouge (January 20, 2004) the study describes in particular the crew's orientations towards three dimensions of the endogenous organization of the studio interaction: turn construction, sequence organization, and activity constitution. The analysis confirms the general relevance of these orders of organization for talk-in-interaction, and shows how each can be used for the practical purposes of the production of the show. The study also reflects upon possible mediating effects when perceiving the studio interaction at a distance. In the control room, the studio interaction can only be observed through the technological system at hand, which is shown to be of some importance for the way in which it can be understood. (c) 2008 Elsevier B.V. All rights reserved.|context; TV-production; TV-interviews; mediated interaction; intersubjectivity|TURN-TAKING; CONVERSATION; ORGANIZATION|Linguistics; Language \& Linguistics|16|0|2
Semantic representation of Korean numeral classifier and its ontology building for HLT applications|2008|The complexity of Korean numeral classifiers demands semantic as well as computational approaches that employ natural language processing (NLP) techniques. The classifier is a universal linguistic device, having the two functions of quantifying and classifying nouns in noun phrase constructions. Many linguistic studies have focused on the fact that numeral classifiers afford decisive clues to categorizing nouns. However, few studies have dealt with the semantic categorization of classifiers and their semantic relations to the nouns they quantify and categorize in building ontologies. In this article, we propose the semantic recategorization of the Korean numeral classifiers in the context of classifier ontology based on large corpora and KorLex Noun 1.5 (Korean wordnet; Korean Lexical Semantic Network), considering its high applicability in the NLP domain. In particular, the classifier can be effectively used to predict the semantic characteristics of nouns and to process them appropriately in NLP. The major challenge is to make such semantic classification and the attendant NLP techniques efficient. Accordingly, a Korean numeral classifier ontology (KorLexClas 1.0), including semantic hierarchies and relations to nouns, was constructed.|numeral classifier; classifier ontology; semantic representation; ontological relations; natural language processing (NLP) techniques; Human language technology (HLT)|JAPANESE|Computer Science, Interdisciplinary Applications|3|1|2
Sequencers in different text genres: Academic writing, journalese and fiction|2008|This paper presents the results of a descriptive analysis of discourse structuring devices in written texts. It discusses typologies of metadiscourse (Hyland, 1998; Hyland and Tse, 2004) and establishes a categorisation of organisational metadiscourse markers, i.e. linguistic items that signpost the discourse organisation on the metadiscourse level. One particular group of these markers, sequencers, will be defined more precisely and described by means of a qualitative analysis of their structural parameters. A manual corpus analysis (Degand and Bestgen, 2004), allying quantitative and qualitative analyses, gives a detailed picture of their actual use in written discourse and of their distribution among the three text genres of academic writing, journalese and fiction. (c) 2007 Elsevier B.V. All rights reserved.|metadiscourse; organisational metadiscourse markers; descriptive corpus analysis; text genre; text production|METADISCOURSE; DISCOURSE|Linguistics; Language \& Linguistics|12|0|2
The pragmatics of and-conjunctives in Middle English medical recipes - A relevance theory description|2008|The present paper seeks to explore the multiple meanings of the conjunction and in Middle English medical recipes. The corpus used contains a total number of 6,300 words, mainly from the Middle English Medical Texts compiled by Taavitsainen, Pahta and Makinen (2005). The framework of analysis is Relevance Theory as in Sperber and Wilson (1995). Jucker (1993), Blakemore and Carston (1999), and Carston (2002) have proved that this theory can neatly describe the various functions and meanings of discourse markers, such as and, but and well. As I show in the conclusion, and constructions must be studied in detail so that we may identify their particular meaning, which is mostly context-dependent rather than semantically constrained. By doing so, we will have a better understanding of texts and this will benefit the comprehension of medieval English. Whether the meanings of and occur similarly in other genres is left for a future, contrastive analysis.|conjunctions; discourse markers; medical recipes; genre studies; relevance theory|DISCOURSE|Linguistics; Language \& Linguistics|1|0|2
Making visible an ideological dilemma in an interview narrative about social trauma|2008|This article builds on contemporary understandings that identity is accomplished interactionally and discursively through storyteller/interviewer engagement inside the telling of the story. It introduces a new notion of narrative inquiry through the concept of ``transactional positioning{''} to achieve an imagined interaction between a listener outside the institutional interview context and a tale told in an interview narrative some time ago. Texts are arranged by a select listener in a pre-thought out way to imaginatively fill gaps between what the narrator said and what he could have said during the interview but did not. The intertextual activity on the part of the listener aims to expand, retrospectively, the positioning of the interviewee so as to make more visible his ideological dilemma, uncovered through conversation analysis and critical discourse analysis of an interview narrative about the social trauma of being an Italian-Australian interned during World War II.|interactional identity; transactional positioning; discourse analysis|CONVERSATION; ORGANIZATION|Communication; Linguistics; Language \& Linguistics|7|0|2
Deixis, taqiyya, and textual mediation in crypto-Muslim Aragon|2008|The present article is an analysis of the scribal and lectoral activities f crypto-Muslim minority communities within sixteenth-century Aragon (Spain). Looking specifically at traditional Islamic texts translated into Ibero-Romance and copied out in Arabic script (a largely ad hoc writing system that modern scholars have termed aljamiado {[}pronounced.- al-xam-yAH-oo]), this article focuses on the ways in which these texts index specific frameworks of lectoral performance and mediation that lie at the very center of processes of textual interpretation and cultural practice within the clandestine religious communities that made use of them. Central to this study is an analysis of the different forms of deictic reference encoded within these texts. The specific argument that underlies this article is that such reference links these written texts-which junctioned as complex symbolic tools-to the social world of scribes, readers, and the listening public in profound and concrete ways. Looked at in this manner, the extant manuscript texts of Aragonese crypto-Muslims allow modern researchers a powerful form of access to the micro- and macro-level social practice of this large, sixteenth-century minority community.|reading; religion; deixis; mediation; Islam; Iberia|PERFORMANCE; LANGUAGE|Communication; Linguistics; Language \& Linguistics|0|0|2
The pragmatics of reading prayers: Learning the Act of Contrition in Spanish-based religious education classes (doctrina)|2008|In this article I investigate the convergence of a number of linguistic, interactional, and textual resources employed in religious reading activities in Spanish-based Catholic religious instruction (doctrina) for school-age Mexican immigrant children. I examine the use of these resources through an analysis of the reading and memorization of the Act of Contrition (AOC), a prayer said during the religious ritual that involves the confession and absolution of sins. I discuss examples of a classroom reading activity that centers on the interactions of four female students and their teacher as they read the AOC. The analysis of their interactions illustrates the ways in which their collaborative reading engages a ritualization process that focuses and constructs text as sacred. The reading activity supported this ritualization process through (i) parallel refraining and interpretation of the words being read and (ii) verbalifations of cognitive activity related to ways of reading text. I also discuss how the activities of ritualization socialize attention to both text and other participants in the activity. Descriptions of doctrina instruction and the origins of the AOC are also provided.|language socialization; reading; religious communities; prayer; ritual; sacred text|LANGUAGE; LITERACY; CHILDREN|Communication; Linguistics; Language \& Linguistics|7|0|2
Reading and meditation in the Middle Ages: Lectio divina and books of hours|2008|This article offers a historical perspective on reading as a situated activity through an examination of the medieval devotional practice of reading the book of hours. My historical investigation opens with an analysis of key pedagogical treatises and religious essays popular in the Middle Ages, which provided instruction on reading, its sensori-motor enactment, its interpretive procedures, and its ultimate goal. These texts, which portray reading not as a self-contained and intrinsically motivating activity but rather as a necessary component of a broader spiritual project, offer precious clues about how medieval readers approached the reading activity, the ways they engaged with the book, and their expectations pertaining to the scope of the reading practice. In the second part of the article, the focus turns to the book of hours. We will leaf through folios of these devotional manuscripts and examine their format, semiotic configuration, and textual and visual content. This analysis will show how textual and illustrational features of the book of hours reflect and foster the ideology and practice of reading as mediative and prayerful activity.|reading practice; religious community; sacred text; medieval Christian tradition; book of hours; lectio divina|LITERACY|Communication; Linguistics; Language \& Linguistics|3|0|2
A multimedia system for temporally situated perceptual psycholinguistic analysis|2002|Perceptual analysis of video (analysis by unaided ear and eye) plays an important role in such disciplines as psychology, psycholinguistics, linguistics, anthropology, and neurology. In the specific domain of psycholinguistic analysis of gesture and speech, researchers micro-analyze videos of subjects using a high quality video cassette recorder that has a digital freeze capability down to the specific frame. Such analyses are very labor intensive and slow. We present a multimedia system for perceptual analysis of video data using a multiple, dynamically linked representation model. The system components are linked through a time portal with a current time focus. The system provides mechanisms to analyze overlapping hierarchical interpretations of the discourse, and integrates visual gesture analysis, speech analysis, video gaze analysis, and text transcription into a coordinated whole. The various interaction components facilitate accurate multi-point access to the data. While this system is currently used to analyze gesture, speech and gaze in human discourse, the system described may be applied to any other field where careful analysis of temporal synchronies in video is important.|multimedia data visualization; temporal analysis; user interface; multiple, linked representation; gesture coding; gesture, speech and gaze analysis|ATTENTION; DISCOURSE|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|6|0|2
A corpus-based connectionist architecture for large-scale natural language parsing|2002|We describe a deterministic shift-reduce parsing model that combines the advantages of connectionism with those of traditional symbolic models for parsing realistic sub-domains of natural language. It is a modular system that learns to annotate natural language texts with syntactic structure. The parser acquires its linguistic knowledge directly from pre-parsed sentence examples extracted from an annotated corpus. The connectionist modules enable the automatic learning of linguistic constraints and provide a distributed representation of linguistic information that exhibits tolerance to grammatical variation. The inputs and outputs of the connectionist modules represent symbolic information which can be easily manipulated and interpreted and provide the basis for organizing the parse. Performance is evaluated using labelled precision and recall. (For a test set of 4128 words, precision and recall of 75\% and 69\%, respectively, were achieved.) The work presented represents a significant step towards demonstrating that broad coverage parsing of natural language can be achieved with simple hybrid connectionist architectures which approximate shift-reduce parsing behaviours. Crucially, the model is adaptable to the grammatical framework of the training corpus used and so is not predisposed to a particular grammatical formalism.|connectionist networks; hybrid architectures; natural language processing; deterministic shift-reduce parsing; corpus linguistics; treebank grammar|DISTRIBUTED REPRESENTATIONS; VARIABLE BINDING; NETWORKS; MODEL|Computer Science, Artificial Intelligence; Computer Science, Theory \& Methods|5|1|2
Meeting medical terminology needs - The ontology-enhanced medical concept mapper|2001|This paper describes the development and testing of the Medical Concept Mapper, a tool designed to facilitate access to online medical information sources by providing users with appropriate medical search terms for their personal queries. Our system is valuable for patients whose knowledge of medical vocabularies is inadequate to find the desired information, and for medical experts who search for information outside their field of expertise. The Medical Concept Mapper maps synonyms and semantically related concepts to a user's query. The system is unique because it integrates our natural language processing tool, i.e., the Arizona (AZ) Noun Phraser, with human-created ontologies, the Unified Medical Language System (UMLS) and WordNet, and our computer generated Concept Space, into one system. Our unique contribution results from combining the UMLS Semantic Net with Concept Space in our deep semantic parsing (DSP) algorithm. This algorithm establishes a medical query context based on the UMLS Semantic Net, which allows Concept Space terms to be filtered so as to isolate related terms relevant to the query. We performed two user studies in which Medical Concept Mapper terms were compared against human experts' terms. We conclude that the AZ Noun Phraser is well suited to extract medical phrases from user queries, that WordNet is not well suited to provide strictly medical synonyms, that the UMLS Metathesaurus is well suited to provide medical synonyms, and that Concept Space is well suited to provide related medical terms, especially when these terms are limited by our DSP algorithm.|ontologies; parsing; query expansion; semantic parsing; terminology mapping; UMLS|INFORMATION; VOCABULARY; RETRIEVAL; SYSTEM|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical \& Computational Biology; Medical Informatics|37|0|2
Speech parts as Poisson processes|2001|This paper presents evidence that six of the seven parts of speech occur in written text as Poisson processes, simple or recurring. The six major parts are nouns, verbs, adjectives, adverbs, prepositions, and conjunctions, with the interjection occurring too infrequently to support a model. The data consist of more than the first 5000 words of works by four major authors coded to label the parts of speech, as well as periods (sentence terminators). Sentence length is measured via the period and found to be normally distributed with no stochastic model identified for its occurrence. The models for all six speech parts but the noun significantly distinguish some pairs of authors and likewise for the joint use of all words types. Any one author is significantly distinguished from any other by at least one word type and sentence length very significantly distinguishes each from all others. The variety of word type use, measured by Shannon entropy, builds to about 90\% of its maximum possible value. The rate constants for nouns are close to the fractions of maximum entropy achieved. This finding together with the stochastic models and the relations among them suggest that the noun may be a primitive organizer of written text.|speech; words; narrative; stochastic; Poisson; model|STOCHASTIC-ANALYSIS; SPEAKER ROLE; PSYCHOTHERAPY; DURATION|Linguistics; Psychology, Experimental|3|0|2
Representation, coherence and inference|2001|Approaches to story comprehension within several fields (computational linguistics, cognitive psychology, and artificial intelligence) are compared. Central to this comparison is an overview of much recent research in cognitive psychology, which is often not incorporated into simulations of comprehension (particularly in artificial intelligence). The theoretical core of this experimental work is the establishment of coherence via inference-making. The definitions of coherence and inference-making in this paper incorporate some of this work in cognitive psychology. Three major research methodologies are examined in the light of these definitions: scripts, spreading activation, and abduction. This analysis highlights several deficiencies in current models of comprehension. One deficiency of concern is the `one-track' behaviour of current systems, which pursue a monostratal representation of each story. In contrast, this paper emphasises a view of adaptive comprehension which produces a `variable-depth' representation. A representation is pursued to the extent specified by the comprehender's goals; these goals determine the amount of coherence sought by the system, and hence the `depth' of its representation. Coherence is generated incrementally via inferences which explain the co-occurrence of story elements.|cognitive modelling; coherence-driven processing; comprehension metrics; variable-depth representations; story comprehension|TEXT COMPREHENSION; STORY GRAMMARS; NARRATIVE TEXT; KNOWLEDGE; DISCOURSE; MEMORY; MODEL|Computer Science, Artificial Intelligence|4|0|2
Probability-based Chinese text processing and retrieval|2000|We discuss the use of probability-based natural language processing for Chinese text retrieval. We focus on comparing different text extraction methods and probabilistic weighting methods. Several document processing methods and probabilistic weighting functions are presented. A number of experiments have been conducted on large standard text collections. We present the experimental results that compare a word-based text processing method with a character-based method. The experimental results also compare a number of term-weighting functions including both single-unit weighting and compound-unit weighting functions.|information retrieval; word-based and character-based Chinese text processing; single-unit and compound-unit weighting|RELEVANCE INFORMATION|Computer Science, Artificial Intelligence|3|0|2
Patterns of prepositional attachments - Where dictionary semantics meets corpus statistics|2000|This paper presents a novel methodology of disambiguating prepositional phrase attachments. We create patterns of attachments by classifying a collection of prepositional relations derived from Treebank parses. As a by-product, the arguments of every prepositional relation are semantically disambiguated. Attachment decisions are generated as the result of a learning process, that builds upon some of the most popular current statistical and machine learning techniques. We have tested this methodology on (1) Wall Street Journal articles, (2) textual definitions of concepts from a dictionary and (3) an ad hoc corpus of Web documents, used for conceptual indexing and information extraction.|syntactic processing; natural language ambiguities|ALGORITHM|Computer Science, Artificial Intelligence|0|1|2
Choosing rhetorical structures to plan instructional texts|2000|This paper discusses a fundamental problem in natural language generation: how to organize the content of a text in a coherent and natural way. In this research, we set out to determine the semantic content and the rhetorical structure of texts and to develop heuristics to perform this process automatically within a text generation framework. The study was performed on a specific language and textual genre: French instructional texts. From a corpus analysis of these texts, we determined nine senses typically communicated in instructional texts and seven rhetorical relations used to present these senses. From this analysis, we then developed a set of presentation heuristics that determine how the senses to be communicated should be organized rhetorically in order to create a coherent and natural text. The heuristics are based on five types of constraints: conceptual, semantic, rhetorical, pragmatic, and intentional constraints. To verify the heuristics, we developed the SPIN natural language generation system, which performs all steps of text generation but focuses on the determination of the content and the rhetorical structure of the text.|natural language generation; text planning; rhetorical structure theory; instructional texts|WRITTEN DIRECTIONS; INFORMATION|Computer Science, Artificial Intelligence|11|0|2
Integrating case-based learning and cognitive biases for machine learning of natural language|1999|This paper shows that psychological constraints on human information processing can be used effectively to guide feature set selection for case-based learning of linguistic knowledge. Given as input a baseline case representation for a natural language learning task, our algorithm selects the relevant cognitive biases for the task and then automatically modifies the representation in response to those biases by changing, deleting, and weighting features appropriately. We apply the cognitive bias approach to feature set selection to four natural language learning problems and show that performance of the case-based learning algorithm improves significantly when relevant cognitive biases are incorporated into the baseline instance representation. We argue that the cognitive bias approach offers new possibilities for case-based learning of natural language: it simplifies the process of instance representation design and, in theory, obviates the need for separate instance representations for each linguistic knowledge acquisition task. More importantly, the approach offers a mechanism for explicitly combining the frequency information available from corpus-based techniques with cognitively-based preferences employed in traditional linguistic and knowledge-based approaches to natural language processing.|case-based learning; relative pronoun; disambiguation; lexical tagging; feature weighting|INDIVIDUAL-DIFFERENCES; INFORMATION EXTRACTION; SENTENCE COMPREHENSION; WORKING MEMORY; ALGORITHMS; CLASSIFICATION; CONTEXT; ADVANTAGE; SELECTION; MENTION|Computer Science, Artificial Intelligence|5|0|2
Symbolic connectionism in natural language disambiguation|1998|Natural language understanding involves the simultaneous consideration of a large number of different sources of information. Traditional methods employed in language analysis have focused on developing powerful formalisms to represent syntactic or semantic structures along with rules for transforming language into these formalisms, However, they make use of only small subsets of knowledge. This article will describe how to use the whole range of information through a neurosymbolic architecture which is a hybridization of a symbolic network and subsymbol vectors generated from a connectionist network. Besides initializing the symbolic network with prior knowledge, the subsymbol vectors are used to enhance the system's capability in disambiguation and provide flexibility in sentence understanding. The model captures a diversity of information including word associations, syntactic restrictions, case-role expectations, semantic rules and context. It attains highly interactive processing by representing knowledge in an associative network on which actual semantic inferences are performed. An integrated use of previously analyzed sentences in understanding is another important feature of our model. The model dynamically selects one hypothesis among multiple hypotheses. This notion is supported by three simulations which show the degree of disambiguation relies both on the amount of linguistic rules and the semantic-associative information available to support the inference processes in natural language understanding. Unlike many similar systems, our hybrid system is more sophisticated in tackling language disambiguation problems by using linguistic clues from disparate sources as well as modeling context effects into the sentence analysis. It is potentially more powerful than any systems relying on one processing paradigm.|Bayesian network; constraint satisfaction; hybrid systems; natural language understanding; neural network applications; semantic analysis|DISTRIBUTED REPRESENTATIONS; MODEL; COMPREHENSION; RULES|Computer Science, Artificial Intelligence; Computer Science, Hardware \& Architecture; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|9|0|2
Prosodic and lexical indications of discourse structure in human-machine interactions|1997|From a discourse perspective, utterances may vary in at least two important respects: (i) they can occupy a different hierarchical position in a larger-scale information unit and (ii) they can represent different types of speech acts. Spoken language systems will improve if they adequately take into account both discourse segmentation and utterance purpose. An important question then is how such discourse-structural features can be detected. Analyses of monologues and human-human dialogues have shown that a good indicator of these factors is prosody, defined as the set of suprasegmental speech features. This paper explores whether speakers also use prosody to highlight discourse structure in a particular type of human-machine interaction, viz., information query in a travel-planning domain. More specifically, it investigates if speakers signal (i) the start of a new topic by marking the initial utterance of a discourse segment, and (ii) whether an utterance is a normal request for information or part of a correction sub-dialogue. The study reveals that in human-machine interactions, both discourse segmentation and utterance purpose can have particular prosodic correlates, although speakers also mark this information through choice of wording. Therefore, it is useful to explore in the future the possibilities of incorporating prosody in spoken language systems as a cue to discourse structure. (C) 1997 Elsevier Science B.V.|prosody; discourse structure; human-machine interaction; spoken dialogue systems|SPEECH-ACT TYPE; INTONATION; DIALOG; TEXT|Acoustics; Computer Science, Interdisciplinary Applications|18|0|2
From communicative context to speech: Integrating dialogue processing, speech production and natural language generation|1997|The current article discusses the problem of appropriate intonation selection in Person-Machine dialogues, such as those expected in intelligent information systems when, for example, information retrieval is required. An approach is proposed which integrates the previously mostly separate paradigms of automatic natural language generation and speech synthesis in a Person-Machine dialogue scenario. The article introduces the two independent basis components adopted in the approach - a dialogue model for information retrieval (COR) and a text generation system for German (KOMET-PENMAN) - and develops from these a communicative-context-to-speech system architecture. This system provides for the flexible and context-appropriate selection of intonation patterns. The paper argues that such an approach removes some of the well-known gaps in both text-to-speech and concept-to-speech systems.|spoken language generation; text generation; dialogue models; intonation; information system interfaces; system-functional linguistics|TEXT|Acoustics; Computer Science, Interdisciplinary Applications|4|0|2
Oral reading and story retelling of students with specific language impairment|1997|Students with specific language impairment (SLI) and students matched for single-word reading ability read and retold stories that were approximately one grade level above their reading level. Children with SLI produced a significantly greater percentage of oral reading discrepancies (miscues) between printed and read words. Their miscues were less graphophonemically, synactically, semantically, and pragmatically consistent with the original texts than the miscues produced by their reading-matched peers. Despite these differences in oral reading, story retellings by students in the two groups were similar in terms of percentages of recalled vocabulary, story elements, and problem-resolution pairs. Holistic analysis of the retellings indicated that fewer retellings by students in the SLI group were complete, and more of their retellings were confusing. Lack of prior knowledge regarding the topics of the stories that were read, slowed language processing, and/or working memory deficiencies could account for these results.|specific language impairment; reading; narration; information processing; print cues|SCHOOL-AGE-CHILDREN; WORKING-MEMORY; COMPREHENSION; PRESCHOOLERS; NARRATIVES; SPOKEN|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|23|0|2
USEFULNESS OF THE LPC-RESIDUE IN TEXT-INDEPENDENT SPEAKER VERIFICATION|1995|This paper is a contribution to automatic speaker recognition. It considers speech analysis by linear prediction and investigates the recognition contribution of its two main resulting components, namely the synthesis filter on one hand and the residue on the other hand. This investigation is motivated by the orthogonality property and the physiological significance of these two components, which suggest the possibility of an improvement over current speaker recognition approaches based on nothing but the usual synthesis filter features. Specifically, we propose a new representation of the residue and we analyse its corresponding recognition performance by issuing experiments in the context of text-independent speaker verification. Experiments involving both known and new methods allow us to compare the recognition performance of the two components. First we consider separate methods, then we combine them. Each method is tested on the same database and according to the same methodology, with strictly disjoint training and test data sets. The results show the usefulness of the residue when used alone, even if it proves to be less efficient than the synthesis filter. However, when both are combined, the residue shows its true relevance. It achieves a reduction of the error rate which, in our case, went down from 5.7\% to 4.0\%.|SPEECH PROCESSING; SPEAKER RECOGNITION; SPEAKER VERIFICATION; TEXT-INDEPENDENCE; OPEN-TEST METHODOLOGY; NATURAL SPEECH DATABASE; MULTI-SESSION DATABASE; LINEAR PREDICTION ANALYSIS; SYNTHESIS FILTER; RESIDUE; COMPLEMENTARY FEATURES|VOCAL QUALITY; RECOGNITION; PERCEPTION; FEATURES|Acoustics; Computer Science, Interdisciplinary Applications|33|0|2
Concept coupling learning for improving concept lattice-based document retrieval|2018|The semantic information in any document collection is critical for query understanding in information retrieval. Existing concept lattice-based retrieval systems mainly rely on the partial order relation of formal concepts to index documents. However, the methods used by these systems often ignore the explicit semantic information between the formal concepts extracted from the collection. In this paper, a concept coupling relationship analysis model is proposed to learn and aggregate the intra- and inter-concept coupling relationships. The intra-concept coupling relationship employs the common terms of formal concepts to describe the explicit semantics of formal concepts. The inter-concept coupling relationship adopts the partial order relation of formal concepts to capture the implicit dependency of formal concepts. Based on the concept coupling relationship analysis model, we propose a concept lattice-based retrieval framework. This framework represents user queries and documents in a concept space based on fuzzy formal concept analysis, utilizes a concept lattice as a semantic index to organize documents, and ranks documents with respect to the learned concept coupling relationships. Experiments are performed on the text collections acquired from the SMART information retrieval system. Compared with classic concept lattice-based retrieval methods, our proposed method achieves at least 9\%, 8\% and 15\% improvement in terms of average MAP, IAP@11 and P@10 respectively on all the collections. (C) 2017 Elsevier Ltd. All rights reserved.|Fuzzy formal concept analysis; Lattice-based document retrieval; Coupling relationship|FORMAL CONCEPT ANALYSIS; INFORMATION-RETRIEVAL; CONCEPT SIMILARITY; SEMANTIC WEB; FUZZY|Automation \& Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical \& Electronic|0|1|1
The corpus of Basque simplified texts (CBST)|2018|In this paper we present the corpus of Basque simplified texts. This corpus compiles 227 original sentences of science popularisation domain and two simplified versions of each sentence. The simplified versions have been created following different approaches: the structural, by a court translator who considers easy-to-read guidelines and the intuitive, by a teacher based on her experience. The aim of this corpus is to make a comparative analysis of simplified text. To that end, we also present the annotation scheme we have created to annotate the corpus. The annotation scheme is divided into eight macro-operations: delete, merge, split, transformation, insert, reordering, no operation and other. These macro-operations can be classified into different operations. We also relate our work and results to other languages. This corpus will be used to corroborate the decisions taken and to improve the design of the automatic text simplification system for Basque.|Text simplification; Monolingual parallel corpora; Annotation scheme; Basque|SENTENCE COMPLEXITY; SPANISH|Computer Science, Interdisciplinary Applications|0|1|1
Exploring convolutional neural networks and topic models for user profiling from drug reviews|2018|Pharmacovigilance, and generally applications of natural language processing models to healthcare, have attracted growing attention over the recent years. In particular, drug reactions can be extracted from user reviews posted on the Web, and automated processing of this information represents a novel and exciting approach to personalized medicine and wide-scale drug tests. In medical applications, demographic information regarding the authors of these reviews such as age and gender is of primary importance; however, existing studies usually either assume that this information is available or overlook the issue entirely. In this work, we propose and compare several approaches to automated mining of demographic information from user-generated texts. We compare modern natural language processing techniques, including extensions of topic models and convolutional neural networks (CNN). We apply single-task and multi-task learning approaches to this problem. Based on a real-world dataset mined from a health-related web site, we conclude that while CNNs perform best in terms of predicting demographic information by jointly learning different user attributes, topic models provide additional information and reflect gender-specific and age-specific symptom profiles that may be of interest for a researcher.|Text mining; Natural language processing; Topic modeling; Deep learning; Convolutional neural networks; Multi-task learning; Single-task learning; User reviews; Demographic prediction; Demographic attributes; Social media; Mental health|ONLINE SOCIAL NETWORKS; AGE; TOOL|Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|0|1|1
What is the primordial reference for ...?-Redux|2018|Eugene Garfield's quest of the primordial reference for the familiar and ubiquitous phrase `Publish or Perish' led him to a 1942 monograph (The Scientist, 10(12):11, 1996). This quest is resumed two decades later here. Text mining applied to a sample of the mainstream and academic literature ever published, as well as crowdsourcing, yielded earlier references dating from 1934 and 1927. This search experiment suggests that `primordial reference chasing' in full-text corpora remains an open problem for the community intersecting bibliometrics and information retrieval. Addressing it has the potential to rejuvenate Garfield's work on historio-bibliography to improve our understanding of the genesis and diffusion of ideas, concepts, and associated metaphors.|Primordial reference chasing; Publish or Perish; Eugene Garfield|GOOGLE-SCHOLAR; SCIENCE; ARTICLES; SCOPUS; JSTOR; WEB|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|1|1
Beyond Garfield's Citation Index: an assessment of some issues in building a personal name Acknowledgments Index|2018|To study patterns of personal acknowledgments in life sciences research and assess the feasibility of a formal Personal Acknowledgments Index, two successive 5-year (1995-1999, 2000-2004) sets of original research articles on zebrafish (Danio rerio) were scanned for acknowledgment statements thanking individuals for various ``gifts{''} of research materials, services, and interpersonal communication. Text areas mined included ``Materials and Methods{''} (M\&M) and various text locations of ``Acknowledgments{''} (ACK). Acknowledgment statements were coded using a detailed Personal Acknowledgments Classification. Including the M\&M sections increased the number of unique personal names, primarily in classes 1a (experimental animals) and 1b (research materials)-with a few highly acknowledged researchers adding substantially to their tallies. The challenges of locating personal acknowledgment statements, harvesting and disambiguating personal names, determining the level of detail useful in characterizing the nature of the ``gifts,{''} and assessing the level of interest in the potential user community are discussed.|Acknowledgments; Personal Acknowledgments Index; Zebrafish; Peer interactive communication; Subauthorship; Paratext|COLLABORATION; COMMUNICATION; 20TH-CENTURY; INFORMATION; PARATEXT; PATTERNS; RESOURCE|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|1|1
Emoticons in informal text communication: a new window on bilingual alignment|2018|The study of emoticon use in text communication is in its early stages (Aragon, Feldman, Chen \& Kroll, 2014), with even less known about how emoticons function in multilingual environments. We describe a preliminary longitudinal analysis of text communication in an online bilingual scientific work environment and demonstrate how patterns of emoticon use constitute a novel yet systematic nonverbal aspect of communication. Specifically, coordination over bilingual speakers entails reductions in emoticon diversity over time that are greater for those who communicate in their L2 than in their L1. An analogous but weaker pattern is evident for lexical diversity in L2 but not L1. We hypothesize that reductions in emoticon diversity in the L2 are likely to reflect social contributions to alignment rather than purely proficiency.|alignment; bilingualism; emoticons; gesture; multilingualism|COMPUTER-MEDIATED COMMUNICATION; SPANISH-ENGLISH BILINGUALS; MESSAGE INTERPRETATION; NATIVE LANGUAGE; CONVERSATION; 2ND-LANGUAGE; GESTURES; DIALOGUE; SPEECH; WORDS|Linguistics; Psychology, Experimental|0|1|1
Filtered collocations as features in verbal polysemy disambiguation A case study of the Chinese verb kao `bake'|2018|In Generative Lexicon Theory (glt) (Pustejovsky 1995), co-composition is one of the generative devices proposed to explain the cases of verbal polysemous behavior where more than one function application is allowed. The English baking verbs were used as examples to illustrate how their arguments co-specify the verb with qualia unification. Some studies (Blutner 2002; Carston 2002; Falkum 2007) stated that the information of pragmatics and world knowledge need to be considered as well. Therefore, this study would like to examine whether glt could be practiced in a real-world Natural Language Processing (nlp) application using collocations. We have conducted a fine-grained logical polysemy disambiguation task, taking the open-sourced Leiden Weibo Corpus as resource and computing with Support Vector Machine (svm) classifier. Within the classifier, we have taken collocated verbs under glt as main features. In addition, measure words and syntactic patterns are extracted as additional features for comparison. Our study investigates the logical polysemy of the Chinese verb kao `bake'. We find that glt could help in identifying logically polysemous cases; additional features would help the classifier achieve a higher performance.|Generative Lexicon Theory; co-composition; baking verb; logical polysemy; collocation|LEXICON|Linguistics; Language \& Linguistics|0|1|1
Distance crossing and alignment in online humanitarian discourse|2018|This article analyzes multimodal genres of current online humanitarian discourse such as mission statements, annual reports and photo galleries to find how the construals of beneficiaries and humanitarian organizations align with the motives, values and emotional dispositions of prospective donors. The discursive reduction of distance between the donor and the beneficiary is likely to produce solicitation effects and enable self-legitimization. First, based on extant literature, the article develops a method to account for the pragmatic operations of textual `proximization' and visually simulated `co-presence' in humanitarian communication. Then it applies it to a sample of multimodal online messages issued by a prominent Polish humanitarian organization that distributes aid to communities in Africa or Asia. Analysis shows that Polish Humanitarian Action's mission statements and annual reports include strategic construals of space, quantity and transfer of aid that legitimize the organization's activities and their underlying axiological motivations. The texts also reproduce us/them differences to proximize the other that has been `Westernized.' Meanwhile, the photo-galleries manufacture co-presence to enhance the axiological and affective investments in solidarity with the distant beneficiary. The case study offers a preliminary insight into alignment and distance-crossing maneuvers in online appeals that seek to project `proper distance' between the donors and beneficiaries. (C) 2017 Elsevier B.V. All rights reserved.|Proximization; Alignment; Construal; Multimodality; Humanitarian discourse; Rhetoric|NEWS|Linguistics; Language \& Linguistics|0|1|1
Interactive natural language acquisition in a multi-modal recurrent neural architecture|2018|For the complex human brain that enables us to communicate in natural language, we gathered good understandings of principles underlying language acquisition and processing, knowledge about sociocultural conditions, and insights into activity patterns in the brain. However, we were not yet able to understand the behavioural and mechanistic characteristics for natural language and how mechanisms in the brain allow to acquire and process language. In bridging the insights from behavioural psychology and neuroscience, the goal of this paper is to contribute a computational understanding of appropriate characteristics that favour language acquisition. Accordingly, we provide concepts and refinements in cognitive modelling regarding principles and mechanisms in the brain and propose a neurocognitively plausible model for embodied language acquisition from real-world interaction of a humanoid robot with its environment. In particular, the architecture consists of a continuous time recurrent neural network, where parts have different leakage characteristics and thus operate on multiple timescales for every modality and the association of the higher level nodes of all modalities into cell assemblies. The model is capable of learning language production grounded in both, temporal dynamic somatosensation and vision, and features hierarchical concept abstraction, concept decomposition, multi-modal integration, and self-organisation of latent representations.|Language acquisition; recurrent neural networks; embodied cognition; multi-modal integration; developmental robotics|AUDITORY-CORTEX; SENTENCE COMPREHENSION; WORD PRODUCTION; LEXICAL ACCESS; VISUAL-CORTEX; TIME-COURSE; MODEL; ORGANIZATION; PERCEPTION; SYSTEMS|Computer Science, Artificial Intelligence; Computer Science, Theory \& Methods|0|1|1
Negotiating Voice Construction Between Writers and Readers in College Writing: A Case Study of an L2 Writer|2018|Voice is co-constructed, a result of the text-mediated interaction between the writer and the reader. The present study, using the context of U.S. college writing, explores the complicated process by which an L2 novice writerone who has a growing awareness of, yet peripheral access to, discourse practicesconstructs a voice. Through interviews and a close analysis of a text, a comparison is made between the voice the L2 writer wished to project in an assigned paper and the voice constructed by two readers in the course of their anonymous readings of the paper. The significant gap between the L2 writer's aims and the readers' responses suggests that a writer's view of her voice stems from the ways in which she conceptualizes discourse conventions, in association with her particular linguistic, social, and cultural background. The pedagogical implications of the L2 writer's process of negotiating identity, and her struggles to learn discourse expectations, are discussed.|College writing; ESL; second language writing; writer identity; writer-reader interaction; voice|IDENTITY; LITERACY|Education \& Educational Research; Linguistics; Language \& Linguistics|0|1|1
The overweight female body in Malaysian slimming advertisements: problem and solution|2018|This study analyses image and text to investigate the way slimming advertising exploits women's fear of being overweight to the extent that they feel obliged to do something about their own bodies. We show how Malaysian slimming advertisements construct certain types of female body which reinforce cultural stereotypes, namely the overweight body that exceeds culturally acceptable limits of desirable body size, and the desirable and attainable slim body with no excess fat. Three sample advertisements were selected from a Malaysian English newspaper and analysed using Jewitt and Oyama's framework to identify the way images and text are used to give specific meanings relating to the female body. The images were examined in terms of representational, interactional and compositional meanings, and the analysis provides evidence of how the extremely overweight female body is pathologised, making it the focus of critical scrutiny. The advertisements use body images to illustrate the problem of being very overweight and the desirability of being slim, and the consumption of slimming services as a quick and easy solution to the problem.|Slimming advertisements; female body image; overweight body; visual social semiotics; critical discourse analysis|GIRLS; DISSATISFACTION; MAGAZINE; CULTURE|Humanities, Multidisciplinary; Communication; Linguistics|0|1|1
Mining 100 million notes to find homelessness and adverse childhood experiences: 2 case studies of rare and severe social determinants of health in electronic health records|2018|Understanding how to identify the social determinants of health from electronic health records (EHRs) could provide important insights to understand health or disease outcomes. We developed a methodology to capture 2 rare and severe social determinants of health, homelessness and adverse childhood experiences (ACEs), from a large EHR repository. We first constructed lexicons to capture homelessness and ACE phenotypic profiles. We employed word2vec and lexical associations to mine homelessness-related words. Next, using relevance feedback, we refined the 2 profiles with iterative searches over 100 million notes from the Vanderbilt EHR. Seven assessors manually reviewed the top-ranked results of 2544 patient visits relevant for homelessness and 1000 patients relevant for ACE. word2vec yielded better performance (area under the precision-recall curve {[}AUPRC] of 0.94) than lexical associations (AUPRC = 0.83) for extracting homelessness-related words. A comparative study of searches for the 2 phenotypes revealed a higher performance achieved for homelessness (AUPRC = 0.95) than ACE (AUPRC = 0.79). A temporal analysis of the homeless population showed that the majority experienced chronic homelessness. Most ACE patients suffered sexual (70\%) and/or physical (50.6\%) abuse, with the top-ranked abuser keywords being ``father{''} (21.8\%) and ``mother{''} (15.4\%). Top prevalent associated conditions for homeless patients were lack of housing (62.8\%) and tobacco use disorder (61.5\%), while for ACE patients it was mental disorders (36.6\%-47.6\%). We provide an efficient solution for mining homelessness and ACE information from EHRs, which can facilitate large clinical and genetic studies of these social determinants of health.|text mining; homelessness; adverse childhood experiences; social determinants of health; EHR|PHENOTYPE ALGORITHMS; CLINICAL TEXT; CARE; IDENTIFICATION; DISORDERS; SELECTION; ADULTS; DEATH|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|1|1
Segment convolutional neural networks (Seg-CNNs) for classifying relations in clinical notes|2018|We propose Segment Convolutional Neural Networks (Seg-CNNs) for classifying relations from clinical notes. Seg-CNNs use only word-embedding features without manual feature engineering. Unlike typical CNN models, relations between 2 concepts are identified by simultaneously learning separate representations for text segments in a sentence: preceding, concept(1), middle, concept(2), and succeeding. We evaluate Seg-CNN on the i2b2/VA relation classification challenge dataset. We show that Seg-CNN achieves a state-of-the-art micro-average F-measure of 0.742 for overall evaluation, 0.686 for classifying medical problem-treatment relations, 0.820 for medical problem-test relations, and 0.702 for medical problem-medical problem relations. We demonstrate the benefits of learning segment-level representations. We show that medical domain word embeddings help improve relation classification. Seg-CNNs can be trained quickly for the i2b2/VA dataset on a graphics processing unit (GPU) platform. These results support the use of CNNs computed over segments of text for classifying medical relations, as they show state-of-the-art performance while requiring no manual feature engineering.|natural language processing; medical relation classification; convolutional neural network; machine learning|OF-THE-ART; ADVERSE DRUG-REACTIONS; TEXT; EXTRACTION; DESIDERATA; SEMANTICS; KNOWLEDGE|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|1|1
`You've just got to walk away': Mixed viewpoints in radio call-in trauma narratives|2017|Starting from the idea that multiplicity of viewpoint is the norm in discourse (Mey, 1999; Verhagen, 2005; Dancygier, 2012b), this paper presents an analysis of viewpoint in radio narratives in terms of Mental Spaces and Conceptual Integration Theory (MSCIT). More specifically, it studies the linguistic and cognitive strategies used by narrators of late night call-in radio programmes to disclose intimate experiences; that is, the strategies used to solve the tension between the need to share their traumatic experiences and the need to protect themselves from strangers, between what they want to say and how they can say it within this specific medial setting. A thorough integration of MSCIT theoretical and analytical tools, based on the notion of mixed viewpoint discourse (Dancygier, 2012b; Dancygier and Vandelanotte, 2016), helps to better understand the fragmented and complex structure of the text under study, the idiosyncratic features of the communicative medium, as well as how the narrator manages to turn an individual, intimate experience into a global story shared by the community. (C) 2017 Elsevier B.V. All rights reserved.|Radio narratives; Emotion; Self-disclosure; Viewpoint; Mental Spaces and Conceptual Integration Theory|DISCOURSE; COMPREHENSION; PERSPECTIVES|Linguistics; Language \& Linguistics|0|1|1
All dissimilation is computationally subsequential|2017|This article presents a computational analysis of the 185 dissimilation patterns in the typological surveys by Suzuki (1998) and Bennett (2013), and shows that dissimilation is computationally less complex than has been previously shown. Dissimilation patterns are grouped into three general types (basic, blocking, and polarity), each of which can be modeled with a subsequential finite-state transducer. This lends support to the claim that phonological patterns are not only regular, but in fact subsequential, which is a more restrictive class of patterns computationally and provides a stronger bound on the types of processes expected in natural language phonology.|dissimilation; Chomsky hierarchy; complexity; subsequentiality; subregular hypothesis|LANGUAGE; TRANSDUCERS|Linguistics; Language \& Linguistics|0|1|1
Periphrastic Progressive Constructions in Dutch and Afrikaans: A Contrastive Analysis|2017|Given the common ancestry of Dutch and Afrikaans, it is not surprising that they use similar periphrastic constructions to express progressive meaning: aan het (Dutch) and aan die/'t (Afrikaans) lit. `at the'; bezig met/(om) te (Dutch) lit. `busy with/to' and besig om te lit. `busy to' (Afrikaans); and so-called cardinal posture verb constructions (zitten/sit `sit', staan `stand', liggen/le `lie' and lopen/loop `walk'), CPV te ('to' Dutch) and CPV en ('and' Afrikaans). However, these cognate constructions have grammaticalized to different extents. To assess the exact nature of these differences, we analyzed the constructions with respect to overall frequency, collocational range, and transitivity (compatibility with transitive predicates and passivizability). We used two corpora that are equal in size (both about 57 million words) and contain roughly the same types of written text. It turns out that the use of periphrastic progressives is generally more widespread in Afrikaans than in Dutch. As far as grammaticalization is concerned, we found that the Afrikaans aan die- and CPV-constructions, as well as the Dutch bezig- and CPV-constructions, are semantically restricted. In addition, only the Afrikaans besig- and CPV en-constructions allow passivization, which is remarkable for such periphrastic expressions.|Afrikaans; cardinal postular verb; Dutch; periphrastic construction; progressive aspect|BUSY|Linguistics; Language \& Linguistics|0|1|1
A Case Study of Negative Affixes in Sadegh Hedayat's Letters: The Effect of Bipolar Mood Disorder|2017|This research studies the morphological features found in Sadegh Hedayat's letters, who, based on linguistic and psychological studies, may have had bipolar disorder. It aims to assess the impact of various types of moods on the frequency of negative affixes through qualitative analysis of the letters' text. The letters are written in Persian, and include six negative derivational affixes. As bipolar disorder includes four episodes, all letters are analyzed on the basis of six negative affixes concerning the episodes using SPSS. The results indicate that each episode shows totally different characteristics in using negative affixes. In fact, Hedayat mostly used negative affixes in depression, confirming psychological studies, and it is revealed that he mostly used negative affixes in hypomania when he experienced an irritated mood. Moreover, the frequency of negative affixes in mixed episode shows a combination of hypomania and depression, which is in agreement with previous studies. Additionally, euthymia shows few negative affixes.|Bipolar mood disorder; Hypomania; Morphology; Negative affixes|VERBAL FLUENCY; DEPRESSION; MEMORY; DEFICITS; UNIPOLAR|Linguistics; Psychology, Experimental|0|1|1
Language ideologies, intervarietal conflict and their repercussions on language and society: the case of the Hispanic dialect complex|2017|In this paper, a phase of language divinisation is posited as the deeply-rooted origin of the standard language/variety ideology, which devalues the nonstandard dialects thus causing a permanent sociolinguistic conflict. Present linguistic standardisation is seen as the form divinisation has taken in the course of the history of humankind and it is justified by the search of stability and functionality for organised speech communities, which is not objectionable as such for some aspects of social life. The sociolinguistic conflict emerges because the first stage of the process requires the selection of usually one variety (or more than one in some cases) out of the dialectal complex of any natural language, generally responding to class-related interests allied to power and prestige. It is evidently, an ideological issue. Our approach to this problem is based on data from the Spanish-speaking world, analysed mainly on a minimal unitary phonetological approach (MUPA) in search of different dialectal dimensions and parameters. MUPA is justified and possible because of the great cohesiveness of Spanish varieties. When attention is paid to this extensive linguistic dominion, one finds that the notion of the inevitability of the weakening of regional varieties has to be revised.|Language ideology; language divinisation; nonstandardness; Spanish; regional standards; historiography|PHONOLOGY; SPANISH|Linguistics; Language \& Linguistics|0|1|1
Automated Domain Bias Correction and Its Application in Text-Based Personality Analysis|2017|Personality prediction based on textual data is one topic gaining attention recently for its potential in large-scale personalized applications such as social media-based marketing. However, when applying this technology in real-world applications, users often encounter situations in which the personality traits derived from different sources (e.g., social media posts versus emails) are inconsistent. Varying results for the same individual renders the technology ineffective and untrustworthy. In this paper, we demonstrate the impact of domain differences in automated text-based personality prediction. We also propose different approaches for domain error correction to meet different needs: (a) single or multi-domain correction and (b) outcome-based or input feature-based error correction. We conduct comprehensive experiments to evaluate the effectiveness of these methods. Our findings demonstrate a significant improvement of prediction accuracy with the proposed methods. (e.g., 20-30\% relative error reduction using outcome-based error correction or 48\% increase of F1 score using feature-based error correction).|Personality analysis; domain bias; text-based personality prediction; artificial intelligence|LANGUAGE USE; TRAITS|Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications|0|1|1
NegAIT: A new parser for medical text simplification using morphological, sentential and double negation|2017|Many different text features influence text readability and content comprehension. Negation is commonly suggested as one such feature, but few general-purpose tools exist to discover negation and studies of the impact of negation on text readability are rare. In this paper, we introduce a new negation parser (NegAIT) for detecting morphological, sentential, and double negation. We evaluated the parser using a human annotated gold standard containing 500 Wikipedia sentences and achieved 95\%, 89\% and 67\% precision with 100\%, 80\%, and 67\% recall, respectively. We also investigate two applications of this new negation parser. First, we performed a corpus statistics study to demonstrate different negation usage in easy and difficult text. Negation usage was compared in six corpora: patient blogs (4 K sentences), Cochrane reviews (91 K sentences), PubMed abstracts (20 K sentences), clinical trial texts (48 K sentences), and English and Simple English Wikipedia articles for different medical topics (60 K and 6 K sentences). The most difficult text contained the least negation. However, when comparing negation types, difficult texts (i.e., Cochrane, PubMed, English Wikipedia and clinical trials) contained significantly (p < 0.01) more morphological negations. Second, we conducted a predictive analytics study to show the importance of negation in distinguishing between easy and difficulty text. Five binary classifiers (Naive Bayes, SVM, decision tree, logistic regression and linear regression) were trained using only negation information. All classifiers achieved better performance than the majority baseline. The Naive Bayes' classifier achieved the highest accuracy at 77\% (9\% higher than the majority baseline). (C) 2017 Elsevier Inc. All rights reserved.|NLP; Health literacy; Negation; Text simplification; Readability|HEALTH LITERACY; GRAMMATICAL TRANSFORMATIONS; PHYSICIAN COMMUNICATION; PATIENT ADHERENCE; INFORMATION; SENTENCES; ACCESSIBILITY; ACTIVATION; KNOWLEDGE; ALGORITHM|Computer Science, Interdisciplinary Applications; Medical Informatics|0|1|1
Unsupervised ensemble ranking of terms in electronic health record notes based on their importance to patients|2017|Background: Allowing patients to access their own electronic health record (EHR) notes through online patient portals has the potential to improve patient-centered care. However, EHR notes contain abundant medical jargon that can be difficult for patients to comprehend. One way to help patients is to reduce information overload and help them focus on medical terms that matter most to them. Targeted education can then be developed to improve patient EHR comprehension and the quality of care. Objective: The aim of this work was to develop FIT (Finding Important Terms for patients), an unsupervised natural language processing (NLP) system that ranks medical terms in EHR notes based on their importance to patients. Methods: We built FIT on a new unsupervised ensemble ranking model derived from the biased random walk algorithm to combine heterogeneous information resources for ranking candidate terms from each EHR note. Specifically, FIT integrates four single views (rankers) for term importance: patient use of medical concepts, document-level term salience, word co-occurrence based term relatedness, and topic coherence. It also incorporates partial information of term importance as conveyed by terms' unfamiliarity levels and semantic types. We evaluated FIT on 90 expert-annotated EHR notes and used the four single-view rankers as baselines. In addition, we implemented three benchmark unsupervised ensemble ranking methods as strong baselines. Results: FIT achieved 0.885 AUC-ROC for ranking candidate terms from EHR notes to identify important terms. When including term identification, the performance of FIT for identifying important terms from EHR notes was 0.813 AUC-ROC. Both performance scores significantly exceeded the corresponding scores from the four single rankers (P < 0.001). FIT also outperformed the three ensemble rankers for most metrics. Its performance is relatively insensitive to its parameter. Conclusions: FIT can automatically identify EHR terms important to patients. It may help develop future interventions to improve quality of care. By using unsupervised learning as well as a robust and flexible framework for information fusion, FIT can be readily applied to other domains and applications. (C) 2017 Elsevier Inc. All rights reserved.|Electronic health record; Natural language processing; Information extraction; Unsupervised ensemble ranking|INFORMATION; READABILITY; CARE; COMPREHENSION; TERMINOLOGY; PERCEPTIONS; RETRIEVAL; CLINICIAN; LITERACY; ACCESS|Computer Science, Interdisciplinary Applications; Medical Informatics|1|1|1
Interpreters - experts in careful listening and efficient encoding? Findings of a prose recall test|2017|Research Questions: The purpose of the present experiment was to study interpreters' recall of spoken prose. Design: The prose recall of simultaneous and consecutive interpreters was compared to that of foreign language teachers and non-linguistic experts. The professional experience of participants (21-24 participants in each group) was 10 years as a aminimum. The auditory presentation of the prose passage to be recalled, divided into eleven speech sequences, resembled the working conditions of interpreters. Data: Transcripted prose recall recordings were analysed quantitatively through an idea unit measure and qualitatively through meaning-based expressions. Findings: The foreign language expert groups outperformed the non-linguistic experts in both quantitative and qualitative measures. Additionally, compared to foreign language teachers, interpreters indicated a better recall of time expressions and topic sentences, as well as of complicated emotional and causal expressions. The explanation for these findings could indicate expertise-dependent tendencies: possibly a continuous practising of careful listening and the demand for a quick comprehension of the source text under the extreme time pressure of interpreters' work leads to better results in prose recall. However, the findings can only be generalized to a limited extent because the prose passage used contained only one or two expressions of each type studied in the qualitative analysis. Originality: The study differs from previous studies in that the memory of interpreters, and especially of consecutive interpreters, was studied for the first time with a prose recall measure. Significance: The prose recall test revealed that the abilities of careful listening and effective comprehension of coherence and causality seem to play a significant role in explaining memory functions of simultaneous and consecutive interpreters compared to those of foreign language teachers and non-linguistic experts.|Careful listening; consecutive interpreter; foreign language teacher; prose recall; simultaneous interpreter|WORKING-MEMORY; LONG-TERM; LANGUAGE COMPREHENSION; COGNITIVE-ABILITIES; PERFORMANCE; TEXT; INFORMATION; INFERENCES; RETENTION; DISCOURSE|Linguistics; Language \& Linguistics|0|1|1
Calibrating complexity: How complex is a gender system?|2017|Grammatical gender is a many-sided phenomenon, involving complex relations between semantics, morphology, phonology, and syntax. Yet, not all gender systems across the world are equally complex. This paper presents a way to assess the complexity of gender systems in natural languages, building on the typological data collected in Corbett (1991, 2013) and applying the insights from Canonical Typology (chiefly Corbett, 2006, 2012; Corbett and Fedden, 2015). The result is a typologically responsible evaluation of the ways in which grammatical gender can be more or less complex. The analysis provides a descriptive basis for the assessment of difficulty in acquisition and processing, avoiding the a priori assumption that ``complex{''} should always equal ``difficult{''}. Moreover, the article is intended as a methodological contribution by demonstrating the set-up and use of a calibration tool for the complexity of a grammatical subsystem. (C) 2016 Elsevier Ltd. All rights reserved.|Complexity; Gender; Canonical typology; Difficulty|AGREEMENT|Linguistics; Language \& Linguistics|0|1|1
Professional translations of non-native English: `before and after' texts from the European Parliament's Editing Unit|2017|Since English has become the dominant global language, research efforts have mostly concentrated on spoken English as a lingua franca (ELF). Written ELF is largely under-researched both in relation to translation and otherwise. This study examines before and after' texts made available by the European Parliament's Editing Unit. The original texts were written by non-native English speakers (before) and subsequently revised by native English editors (after) with a view to delivering consistent edited source texts as a basis for translation into different EU languages. In a pre-study, 12 texts (and their edited versions) were scrutinised for potential translation problems. In the main study, three of the 12 originals and their three edited counterparts were translated by six professional translators. A mixed-method approach was adopted: product-based analysis of the translations for actual translation problems combined with screen-recording-prompted retrospective translator comments and screen-recording-based indicators for the time taken to translate edited and non-edited segments. The results suggest that there is a sufficiently large number of challenges arising from non-standard source segments to prolong translational decision-making and provoke inadequate solutions.|English as a lingua franca; written ELF; translation; EU translation; editing unit; `before and after' texts|LINGUA-FRANCA; COMMUNICATION; LANGUAGE|Communication; Linguistics; Language \& Linguistics|0|1|1
Critical multimodal literacy with moving-image texts|2017|Purpose - This paper aims to examine language learners' critical multimodal literacy practices with a moving-image text, focusing on text comprehension and interpretation rather than text production. It takes a critical perspective towards multimodality and proposes the simultaneous emphasis on critical and multimodal literacies. Design/methodology/approach - This qualitative teacher-inquiry adopts critical multimodal literacy as the framework for understanding learners' literacy practices. The course implementation highlights images, sounds and words as encompassing the five modes of visual, aural, linguistic, gestural and spatial (Arola et al., 2014) in emphasizing the multimodal in critical multimodal literacy, and the purposeful organization of the images, sounds and words as reflecting the critical in critical multimodal literacy. The analysis also adopts Serafini's (2010) concentric perceptual, structural and ideological perspectives as the tenets of critical multimodal literacy. Findings - The findings show that focusing on images, sounds, words and their purposeful organization enabled the students to critically examine a moving-image text through considerations for the multiple modes and arriving at the structural and ideological interpretive perspectives. Originality/value - This study fills a gap in the literature, as very little research has been done to investigate the ways in which language learners engage with, that is, comprehend and interpret, movingimage multimodal texts. In addition, it presents a critical multimodal literacy framework based on Serafini's (2010) tripartite perspectives and offers pedagogical suggestions for incorporating critical multimodal literacy in language classrooms.|Critical literacy; English and media|LANGUAGE; STUDENTS|Education \& Educational Research; Linguistics; Language \& Linguistics|0|1|1
Enhancing a Role and Reference Grammar approach to English motion constructions in a Natural Language Processing environment|2017|This paper puts forward a finer-grained computational treatment of the English caused-motion construction (e.g. He kicked the ball into the net) within a knowledge base for natural language processing systems called FunGramKB. This computational project is largely based on Role and Reference Grammar (RRG), which is a functional projectionist theory of language. We argue that the RRG-based characterization of the caused-motion construction in FunGramKB is insufficient to account for the semantic and syntactic complexity of realizations such as He walked the dog to the park, I will show you out, or Mac flew Continental to Bush International Airport. Thus, drawing on insights from Constructions Grammars, three minimally distinct transitive motion sub-constructions are formalized within FunGramKB. It is through the inclusion of additional constructional schemas that the machine will be able to capture the various ways in which verbs and constructions interact to yield different input texts.|Natural Language Processing; Role and Reference Grammar; Construction Grammars; English motion constructions|RESULTATIVES|Linguistics; Language \& Linguistics|0|1|1
Register variation in malicious forensic texts|2017|The study reported here examines a corpus of 104 authentic malicious forensic texts for register variation. A malicious forensic text is defined in this article as a text that is threatening, abusive or defaming and that constitutes evidence for a forensic case. This corpus was firstly tagged with a set of situational parameters and then analysed using the same multidimensional model introduced in Biber (1988, 1989). The results of the study indicate that malicious forensic texts, similarly to non-malicious professional letters, are on average instances of the Involved Persuasion text type, which is characterised by linguistic features overtly expressing modality. The results also confirm that threatening texts tend to use more modal verbs than non-threatening texts. Furthermore, the personal knowledge between interactants was found to highly influence the level of information density of the texts, while the narrativity level of malicious texts was found to be affected by whether the text contains harmful content directed to the addressee or to a third party. These findings can inform and improve the authorship analysis of malicious texts and increase our understanding of the creation of language crimes.|THREATENING LANGUAGE; MULTIDIMENSIONAL ANALYSIS; REGISTER VARIATION; STYLISTICS|AUTHORSHIP ANALYSIS; LANGUAGE; STANCE|Criminology \& Penology; Linguistics|0|1|1
Five turns of the screw A CADS analysis of the European Parliament|2017|The present paper proposes a CADS-based analysis of European Parliament speeches, by merging (C)DA theoretical constructs (inspired by Laclau and Mouffe 1985) and CL tools. In this fashion, the European Comparable and Parallel Corpus of Parliamentary Speeches Archive (ECPC) is examined along synchronic and diachronic, quantitative and qualitative lines, in an inductive study that commutes from the micro-text to the macro-context.|European Parliament; Corpus-Assisted Discourse Studies (CADS); ECPC|CORPUS LINGUISTICS; DISCOURSE|Linguistics; Language \& Linguistics|0|1|1
A phonotactic analysis of the content of syllables on word boundaries in spoken and written Czech texts|2017|This study aims to provide and analyze a representative list of Czech initial syllable onsets and final codas along with their frequencies of occurrence in running text (token frequencies) and in the vocabulary of unique word forms extracted from it (type frequencies). The frequency data are important because many experiments have demonstrated that phonotactics is not categorical, but rather gradient in nature. Importantly, the study analyzes and compares both spoken and written texts, using the Czech National Corpus, and the two modalities are hypothesized to yield different outcomes. All words in the sample were transcribed phonemically and analyzed. A general preference was found for phonotactic structures that are simple in the context of the attested inventory, and the two corpora differed most in the repertoire of complex onsets/codas (some sequences being unique to one modality) as well as in their respective frequencies. The results are discussed in relation to previous studies of Czech phonotactics, and evaluated with respect to implications for phonological theory, focusing on spoken/written and type/token comparisons.|phonotactics; syllable; corpus; spoken language; written language|FREQUENCY|Linguistics; Language \& Linguistics|0|0|1
Can multilinguality improve Biomedical Word Sense Disambiguation?|2016|Ambiguity in the biomedical domain represents a major issue when performing Natural Language Processing tasks over the huge amount of available information in the field. For this reason, Word Sense Disambiguation is critical for achieving accurate systems able to tackle complex tasks such as information extraction, summarization or document classification. In this work we explore whether multilinguality can help to solve the problem of ambiguity, and the conditions required for a system to improve the results obtained by monolingual approaches. Also, we analyze the best ways to generate those useful multilingual resources, and study different languages and sources of knowledge. The proposed system, based on co-occurrence graphs containing biomedical concepts and textual information, is evaluated on a test dataset frequently used in biomedicine. We can conclude that multilingual resources are able to provide a clear improvement of more than 7\% compared to monolingual approaches, for graphs built from a small number of documents. Also, empirical results show that automatically translated resources are a useful source of information for this particular task. (C) 2016 Elsevier Inc. All rights reserved.|Biomedical Word Sense Disambiguation; Multilinguality; Graph-based systems; Unified Medical Language System; Unsupervised systems; Parallel and comparable corpora|MEDLINE; DOMAIN; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|0|1|1
Systematicity, a missing term in historical metrics|2016|This essay identifies two persistent problems in the historical study of meternonconformant metrical patterns and metrical changeand offers a new term as a conceptual tool for understanding their interdependence. The term systematic' denotes metrical patterns that conform to synchronically operant metrical principles. The corresponding term asystematic' denotes the minority of actually occurring metrical patterns that fall outside the metrical system as such for historical reasons. All systematic patterns are necessarily metrical, but not all metrical patterns are systematic. It is argued that the systematicity/metricality distinction in historical metrics is analogous to the regularity/grammaticality distinction in historical linguistics and similarly fundamental to historical analysis. By introducing a new technical term, this essay seeks to shift the metrist's object of study from the metrical system qua system to meter as a complex historical experience. The value of the concept of systematicity is illustrated through three case studies in asystematic metrical patterns from early English poetic traditions: verses with three metrical positions in Beowulf, lines with masculine ending in Middle English alliterative verse, and the infamous broken-backed lines' in the pentameter of John Lydgate. In each case, it is argued that the contrast between systematic and asystematic metrical patterns illuminates the diverse historical and perceptual negotiations that inevitably lie behind metered texts.|Alliterative verse; Beowulf; Chaucer; historical metrics; linguistics; Lydgate; meter; Middle English; Old English; textual criticism|ENGLISH ALLITERATIVE POETRY; B-VERSE; CHAUCER|Linguistics; Language \& Linguistics|1|0|1
Doing equality and difference: Representation and alignment in Finnish identification|2016|Using tools from critical discourse analytic approaches informed by systemic functional linguistics, this paper is an examination of how social values - specifically equality values in Finland - are given meaning by differently socially positioned Finnish citizens, and how those meanings are positioned in constructions of identities. The focus of my examination is on how respondents align with different meanings of equality using linguistic resources of ENGAGEMENT and GRADUATION (James R. Martin and Peter R. R. White {[}2005], The language of evaluation. Hampshire: Palgrave Macmillan). I conduct my analyses on written texts that were elicited in response to open items on a questionnaire. Respondents include individuals recruited through a national random sample, and individuals with transgendered life experiences and/or Asperger's diagnoses. I consider how being positioned in the margins by institutionalized norms may interact with representation and alignment of Finnish equality in identification. I also pay attention to how individuals strategically reconcile meanings of equality with other important yet potentially conflicting values, such as national identity, sameness and moderation. I discuss the implications of the study in relation to the historical path of equality, and in terms of how particular formulations of equality may contribute to building and maintaining relations of domination.|social values; appraisal; resistance discourse; new racism; identity; positioning|VALUES|Communication; Linguistics; Language \& Linguistics|0|0|1
Non-native scientists, research dissemination and English neologisms: What happens in the early stages of reception and re-production?|2016|That the English language is the prevailing language in international scientific discourse is an undeniable fact for research professionals who are non-native speakers of English (NNSE). An exploratory, survey-based study of scientists in the experimental disciplines of neuroscience and medicine seeks to reveal, on the one hand, the habits of scientists who in their research practice come across neologisms in English and need to use them in oral and written scientific discourse in their own languages, and, on the other hand, their attitudes towards these neologisms and towards English as the language of international science. We found that all scientists write and publish their research articles (RAs) in English and most submit them unrevised by native speakers of English. When first encountering a neologism in English, scientists tend to pay close attention to these new concepts, ideas or terms and very early in the reception process attempt to coin acceptable, natural-sounding Spanish equivalents for use in the laboratory and in their Spanish texts. In conjunction with the naturalized Spanish term, they often use the English neologism verbatim in a coexistent bilingual form, but they avoid using only the English term and very literal translations. These behaviors show an ambivalent attitude towards English (the language of both new knowledge reception and dissemination of their RAs) and Spanish (used for local professional purposes and for popularization): while accepting to write in their acquired non-native language, they simultaneously recognize that their native language needs to preserve its specificity as a language of science.|English for specific purposes; neologism; neuroscience; research article; Spanish|SPANISH; COMMUNICATION; PUBLICATION; JOURNALS|Linguistics; Language \& Linguistics|0|0|1
A Novel Methodology for Automatically Measuring Psychological Dimensions in Textual Data|2016|The processing of textual data to obtain psychological measures is becoming prevalent. However, the problem is that in most cases, tagged corpora are unavailable and therefore conventional classification methods cannot be easily applied. We present a novel solution for measuring psychological dimensions in textual data. The solution is based on (i) the construction of patterns from validated psychological questionnaires measuring the target dimension and (ii) similarity measurements of some of the text's sentences to the pre-defined patterns. Our proposed methodology was tested on (i) the identification of the five personality dimensions in a gold standard corpus, (ii) the measurement of depression and (iii) the screening of civilian mass murderers, gaining preliminary support for its validity.|computational psychology; computational personality; NLP|PERSONALITY-INVENTORY; DEPRESSION; VALIDITY; TRAITS; MODEL|Computer Science, Hardware \& Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory \& Methods|0|0|1
Substitute infinitives and Oberfeld placement of auxiliaries in German subordinate clauses: A synchronic and diachronic corpus study using the CLARIN research infrastructure|2016|The historical development and the linguistic triggering environments for Oberfeld formation in German subordinate clauses represent long-standing research questions in Germanic Linguistics, dating at least as far back as Jacob Grimm's famous Deutsche Grammatik. The present corpus study traces this historical development back to the 17th century. The study is based on three text corpora. For contemporary German, two syntactically annotated newspaper corpora were consulted: the TuBa-D/Z and TOPP-D/Z treebanks,(1) which provide linguistic annotations for articles published in the daily newspaper die tageszeitung (taz). For diachronic data, the corpus collection Deutsches Textarchiv (DTA)(2) was utilized. The DTA contains texts ranging from 1610 to 1900. All three corpus collections are part of the Common Language Resources and Technology Infrastructure (CLARIN) initiative(3) and will be developed further as part of the CLARIN research infrastructure. The study demonstrates the added value that annotated corpora can provide for in-depth studies in historical syntax. At the same time it showcases the added value of interoperable language resources for linguistic investigations that require access to and analysis of multiple linguistic resources. (C) 2016 The Author. Published by Elsevier B.V. This is an open access article under the CC BY license.|Oberfeld formation; German; Historical syntax; Corpus analysis; CLARIN research infrastructure|LANGUAGE|Linguistics; Language \& Linguistics|0|0|1
Intonation patterns in news headlines in the Spanish television channels|2016|The aim of this article is to describe the intonation trends in the headlines of the main Spanish television channels. For this, a discursive-perspective of analysis is taken. First, the prosodic features of the three prosodic patterns identified for the news reading discourse in different media and contents are described: the singsong, the emphatic and the natural. Secondly, an acoustic analysis is carried out to identify the pitch peaks and intonation contours by using percentages on a 79 corpus of contours, classified in anacrusis, body and final inflexion, which belong to the beginning, development and end of the headline. Results show a general tendency to use the natural pattern, although there are two sensationalist-driven channels that still use the singsong and the emphatic patterns. Finally, it is proposed that a comprehensive structure of news be modeled with margins for variability depending on text content.|emphasis accent; melodic pattern; news broadcast; communication efficacy|INFORMATION-STRUCTURE; PROMINENCE; PERCEPTION; PROSODY; SPEECH|Linguistics; Language \& Linguistics|0|1|1
Neighbour unpredictability measure in multiword expression extraction|2016|In all natural languages, due to the strong cohesive ties between the composing words, some recurrent combinations of words generate multiword expressions (MWEs). The extraction of MWEs in a text has an important role in natural language processing applications and information retrieval. In this study, we introduce a method of MWE extraction that ranks the candidates by the weakness of outer ties between the candidate and the neighbouring words in the text. The method presents a measure for the weakness of outer ties based on the degree of unpredictability of surrounding words in order to distinguish MWEs from other recurrent groups of consecutive words. Simply in the method, if the words following and preceding a MWE candidate are unpredictable due to the relatively excessive number of different neighbouring words, the candidate is accepted to have a strong evidence to be a real MWE. The method generates a single normalized score of unpredictability, which enables not only the comparison of MWE candidates of different occurrence frequency but also the comparison of MWE candidates with different number of composing words (such as the comparison of two-word candidates with three-word candidates). Comparisons with different groups of well-known methods; statistical measures of association and term hood, vector space models of composition and supervised learning methods; illustrate the effectiveness of the proposed method on two-word MWE candidates and in the merged set of two- and three-word candidates.|Multiword expression; predictability; association measures; term hood measures; compositionality; supervised learning|AUTOMATIC EXTRACTION|Computer Science, Hardware \& Architecture; Computer Science, Theory \& Methods|1|0|1
Participation frameworks in multiparty video chats cross-modal exchanges in public Google Hangouts|2016|Drawing on literature on interaction and participation in computer-mediated communication (CMC) and video-mediated communication (VMC), this study explores cross-modal exchanges with regards to participation in public video chats. By cross-modal, we wish to characterize interactions in which the production modality is different from the interlocutor's feedback modality, in the same communicative event and in synchronous fashion. Early research on recreational text-based CMC, especially Internet Relay Chat (IRC), has shown that initiating and maintaining interactions with strangers can be challenging. Our observations indicate that public video chats not only present these same challenges, but also that the availability of video and audio adds yet another level of complexity to issues of participation. Based on synchronous and naturally occurring interactions from public Google Hangouts, our analysis indicates that cross-modal exchanges are a means for participation mobility. Furthermore, this analysis brings attention to issues of visibility and noticeability in video chats. (C) 2016 Elsevier B.V. All rights reserved.|Video-mediated communication; Participation mobility; Cross-modal interaction; Google Hangouts|TURN-TAKING; COMMUNICATION; ORGANIZATION; RESOURCES|Linguistics; Language \& Linguistics|5|0|1
Generalization of Phonetic Detail: Cross-Segmental, Within-Category Priming of VOT|2015|The current study examined whether fine-grained phonetic detail (voice onset time (VOT)) of one segment (/p/ or /k/) generalizes to a different segment (/t/) within the same natural class. Two primes were constructed to exploit the natural variation of VOT: a velar stop followed by a high vowel (keen) resulting in a naturally long VOT and a labial stop followed by a low vowel (pan) resulting in a naturally shorter VOT. Two experiments were conducted, one in which the speakers produced both the prime and the target, and a second in which the speakers heard the primes and then produced the targets. In Experiment 1, VOTs for initial /t/ were shorter following pan than following keen. In Experiment 2 where participants heard the primes, priming was found only when the primes had unexpected relative VOT values (short for keen and long for pan). These results provide evidence for cross-segmental generalization of phonetic detail and also suggest that natural, within-category variability is encoded during language processing.|Speech production; speech perception; voice onset time; gradience|VOICE-ONSET TIME; TRAINING JAPANESE LISTENERS; LEXICAL ACCESS; TALKER VARIABILITY; PERCEPTION; SPEECH; INFORMATION; CONSONANTS; ACTIVATION; ALIGNMENT|Audiology \& Speech-Language Pathology; Linguistics; Psychology, Experimental|1|0|1
Register and artefact: Enregistering authenticity in an engagement with Ovdalsk descriptivist texts|2015|This article deals with the symbolic and material formation of an authenticated register of Ovdalsk - a Scandinavian local language - unfolding in a situated engagement with grammatical artefacts. Seeking to refine the often underspecified category of the indexically `pre-shift,' traditional,' `old' or, in some other way, temporally authenticated register, it intercalates an analysis of linguistic exchanges with histories of production of authoritative discourse. Through a stepwise analysis of the production of metapragmatic discourse, it explores the indexically presupposing and entailing relationship between artefactual objectivation and novel registers of language. Thus examining the enregistering interpretation of genred regimentations of language-as-form, it argues that such focus is apt for creating a reflexive and less essentializing understanding of linguistic authenticity. (C) 2015 Elsevier Ltd. All rights reserved.|Authenticity; Indexicality; Enregisterment; Metapragmatics; Descriptivism; Engagement|SOCIAL-LIFE; LANGUAGE; IDENTITY; ENTEXTUALIZATION; POLITICS|Communication; Linguistics|1|0|1
Understanding readers' differing understandings|2015|This research examines the characteristics of reader understandings that vary from those stated in the text. Eighty-seven fourth graders orally read complex academic literary and scientific texts, followed by probed retellings. Retold ideas not directly supported by, or reflective of, the texts were identified. These differing understandings served as a foundation for the development of a taxonomy that classified them by type: conflation, conceptual knowledge, text/rhetorical structure, lexical knowledge, cause/effect, extension, association and misremembering. Approximately 60\% of the differing understandings across the texts were conflations and extensions. However, particular texts did reflect particular types of differing understandings. In general, differing understandings were found to be reflective of the very active nature of the comprehension process. These meanings serve as a challenge to the current emphasis on close reading and the generation of text-based meanings because the natural consequence of such activity are differing understandings.|comprehension; discourse analysis; reading|ACADEMIC VOCABULARY|Education \& Educational Research; Linguistics; Language \& Linguistics|0|1|1
The agency of things: how spaces and artefacts organize the moral order of an intensive care unit|2015|This article focuses on the constitutive role of space and artefacts in delineating the moral order of a specific context. Building on the premises of a post-humanistic phenomenology, it proposes a theoretical contribution to a critical understanding of communication as a complex phenomenon distributed between human and non-human semiotic agents. Drawing on ethnographic research in an Intensive Care Unit (ICU), the article empirically illustrates this point. It analyses how the interior architecture and some ordinary objects (e.g. the glove box and the alcoholic dispenser, the monitors and the handwritten clinical record) delineate the range of the right things to do and participate in telling which philosophy of medicine is at play in this ICU.|agency of things; affordances; artefacts; ethnography; materiality; methodology; phenomenology of space; philosophy of care|COMMUNICATION; ETHNOGRAPHY; OBJECTS; TEXTS|Humanities, Multidisciplinary; Communication; Linguistics|1|1|1
Evidential al parecer: Between the physical and the cognitive meaning in Spanish scientific prose of the 18th, 19th and early 20th centuries|2015|Some of the evidential particles and adverbs in Spanish are believed to have developed during the 18th and 19th centuries. This also coincides with the consolidation of scientific writing in Spanish, a genre that holds a special relation with the expression of sources of information. Against this background, the aim of this paper is to study the evolution of the Spanish evidential discourse particle al parecer ('seemingly, apparently') in scientific texts of the 18th, 19th and early 20th centuries. Our analysis shows that in the period under review the occurrences of the evidential particle al parecer were dominant, but they were not the only uses of this construction. It coexisted with two other constructions: a two-member construction al parecer x, pero en realidad y (It appears to be x, but in reality is y') with inferential interpretation and with a construction al parecer with physical meaning (es al parecer rombico; `it looks rhombic'). Our data suggests that only the occurrences of the grammaticalized discourse particle al parecer were purely evidential. Furthermore, it shows that the evidential meaning of the particle developed toward more indirect evidentiality during the process of fixation. In the context of the genre analyzed, all three constructions of al parecer reflect the changes in the scientific writing practices: from basing the evidences on personal observation to relying on the experiment and reporting from the common knowledge. (C) 2015 Elsevier B.V. All rights reserved.|Evidentiality; Discourse particles; Scientific writing; Grammaticalization; al parecer|ENGLISH|Linguistics; Language \& Linguistics|2|0|1
Foundational considerations for the development of the Globalcrimeterm subontology: A research project based on FunGramKB|2015|This paper describes the theoretical foundations, the general methodological guidelines and the specific tasks for the development of the Global-crimeterm project, a domain-specific subontology based on a specific area of criminal law (international cooperation against terrorism and organized crime) within the architecture of FunGramKB, which is a multipurpose lexico-conceptual knowledge base for natural language processing (NLP) systems. One of the features of this subontology is, firstly, its commitment to structure its concepts under the postulates of deep semantics, unlike the more traditional approach only oriented towards surface semantics, and, secondly, to orientate the tasks of terminologists and knowledge engineers who wish to expand the general knowledge of FunGramKB Core Ontology and, at the same time, integrate the specialized knowledge through its representation in a domain-specific subontology such as Globalcrimeterm.|FunGramKB; legal ontology; terminology; Globalcrimeterm; NLP|KNOWLEDGE; REUSE|Linguistics; Language \& Linguistics|1|0|1
``THE DOCTOR SAID I SUFFER FROM VITAMIN (sic) DEFICIENCY{''}: INVESTIGATING THE MULTIPLE SOCIAL FUNCTIONS OF GREEK CRISIS JOKES|2015|Research on political jokes has more often than not concentrated on their content, which is related to, and interpreted in view of, the sociopolitical events and contexts that have given rise to the jokes investigated each time. The present study intends to suggest that there are other aspects of political joke-telling that could be taken into consideration when exploring its social functions and goals: First, the subgenres employed by speakers to convey their humorous perspectives on political issues; and, second, speakers' spontaneous comments on the jokes under scrutiny. The variety of subgenres could be related to the diverse ways joke-tellers perceive and encode their everyday problems and political views. Speakers' spontaneous comments on the content and effects of jokes could reveal why they consider such texts tellable and recyclable, as well as how they evaluate them. The political jokes analyzed here come from a large corpus of humorous material about the current Greek debt crisis and its sociopolitical effects on the Greek society. The analysis reveals the multifunctionality of such jokes: They convey a critical perspective on the current sociopolitical conditions in Greece, strengthen the solidarity bonds among Greek speakers, entertain them, and bolster their morale.|Political jokes; Humorous (sub)genres; Greek financial crisis; Content analysis; Social functions of jokes; Comments on humor|POLITICAL HUMOR; PROTEST; WAR|Linguistics; Language \& Linguistics|0|0|1
Latino(a) and Burmese elementary school students reading scientific informational texts: The interrelationship of the language of the texts, students' talk, and conceptual change theory|2015|This article is the result of an investigation examining 17 multilingual students transacting with scientific informational texts during miscue analysis. Students' retellings scores were generally found to be low despite high semantic acceptability during read alouds. Further investigation involving the use of social semiotics and discourse analysis revealed that the language patterns found in the scientific texts had similar social purposes to the language patterns in many students' retellings. Conceptual change theory was also applied to examine segments of students' retellings that differed from the retelling rubrics. As a result multilingual Latino(a) and Burmese students in this study were found to possess resources as readers during the assessment process that were not initially measured through retelling scores. (C) 2015 Elsevier Inc. All rights reserved.|Social semiotic; Discourse analysis; Conceptual change theory; Miscue analysis; Multilingual learner|SCIENCE-EDUCATION; PERSPECTIVE; CLASSROOM; INTERTEXTUALITY; KNOWLEDGE; TEACHERS; BELIEFS; ALOUDS|Education \& Educational Research; Linguistics; Language \& Linguistics|2|0|1
Making sense of immigration processes Overcoming narrative disruption|2015|This article analyses the narrative disruption processes and quality of life of adolescent immigrants in Spain. Furthermore, it also provides a new methodological approach to assess meta-subjective and narrative quality of life. Participants were 30 adolescents (15 immigrant and 15 autochthons) selected form a sample of 884 adolescents (from which 204 were immigrants). Data regarding quality of life was collected applying the Friendship Quality Scale and the Vancouver Index of Acculturation to all the participants (n = 884). According to the punctuation of the questionnaires a subsample was chosen, the Biographical Grid was applied to 30 participants; the immigrants group was also asked to write a text. Results indicate that both perceived quality of life and self-esteem of immigrant's group are lower than the autochthons' while narrative disruption is higher. A deeply explanation about some of the causes of these results is provided by the narratives' analysis.|narrative disruption; immigration processes; biographical grid; quality of life; self-esteem|EARLY ADOLESCENCE; SOCIAL SUPPORT; SELF; ACCULTURATION; PSYCHOTHERAPY; ELABORATION; TRAUMA; LIFE; RECONSTRUCTION; PERSONALITY|Communication; Linguistics; Language \& Linguistics|0|0|1
Beyond compare Similes in interaction|2015|This paper deals with the formal properties and discourse features of ``A es com B{''} ({''}A is like B{''}) similes in Catalan. In contrast with most previous approaches, the examples are naturally-occurring and the whole text has been analyzed so that their context, and not only the similes, is considered. The analysis of similes in interaction puts forward that: (i) a simile is a three-slot comparative construction, including a target and a source belonging to different conceptual domains, and an optional but frequent and highly significant elaboration; (ii) a simile is a figurative comparison between a source and a target (grammatically expressed by noun phrases or clauses) generally thought as completely distinct or non-comparable; (iii) similes are powerful mechanisms to catch the addressee's attention and put in a nutshell someone's opinion, and (iv) they tend to have a prominent text status and are often found as headlines.|similes; construction; comparison; metaphor; interaction|SIMILARITY; METAPHORS; ANALOGY|Linguistics; Language \& Linguistics|1|0|1
Rapid Publication An application of answer set programming to the field of second language acquisition|2015|This paper explores the contributions of Answer Set Programming ( ASP) to the study of an established theory from the field of Second Language Acquisition: Input Processing. The theory describes default strategies that learners of a second language use in extracting meaning out of a text based on their knowledge of the second language and their background knowledge about the world. We formalized this theory in ASP, and as a result we were able to determine opportunities for refining its natural language description, as well as directions for future theory development. We applied our model to automating the prediction of how learners of English would interpret sentences containing the passive voice. We present a system, PIas, that uses these predictions to assist language instructors in designing teaching materials.|answer set programming; second language acquisition; qualitative scientific theories; natural language|PROCESSING INSTRUCTION; DICTOGLOSS; KNOWLEDGE|Computer Science, Software Engineering; Computer Science, Theory \& Methods; Logic|0|0|1
Reformulation in bilingual speech: Italian cioe in German and Ladin|2014|This paper deals with the borrowing of the Italian reformulation marker doe in the German and Ladin linguistic minorities in Italy. A corpus of bi- and multilingual conversations is analyzed in order to verify the sociolinguistic distribution and the functional scope of borrowed markers in bilingual and monolingual discourse. Our hypothesis is that the metalinguistic processes involved in reformulation are particularly relevant for bilingual speakers who are constantly dealing with bilingual texts and other bilingual interlocutors. The analysis reveals that, unlike other well studied discourse markers, reformulation markers are borrowed only when contact languages are employed in every-day informal domains by actual bilingual speakers who are used to engaging in language alternation practices. (C) 2014 Elsevier B.V. All rights reserved.|Reformulation markers; Borrowing; Language contact|DISCOURSE MARKERS|Linguistics; Language \& Linguistics|1|0|1
On the relation between labilizations and neuter gender: Evidence from the Greek diachrony|2014|This paper considers labile verbs, i.e., verbs that use the same morphology for the causative and the anticausative reading, and how this lability pattern has evolved and spread in relation to case alignment and, specifically, to the lack of case distinctions between the nominative and the accusative with neuter DPs. In the first part of the study, we examine the voice distinctions in the history of the Greek language, showing that the use of the same voice morphology (i.e., active) for causative and anticausative readings increases in Hellenistic Greek and spreads progressively until Early Modern Greek, as indicated by empirical evidence in dialectal texts. The second part of the study attributes this pattern to the lack of the nominative-accusative case distinction in neuter nouns that in turn can be interpreted as either objects of a transitive (causative) verb or subjects of an intransitive verb (anticausative). In this aspect, neuter nouns demonstrate a type of split ergativity in the Greek labile alternations which thus require a split ergativity analysis based on DP features.|labile verbs; labilization; gender; case; split ergativity; history of Greek; Early Modern Greek dialects|SPLIT ERGATIVITY|Linguistics; Language \& Linguistics|2|0|1
Reformulation and recontextualization in popularization discourse|2014|The paper takes into consideration the evolution of the concept of popularization and of its main techniques of realization in the last few decades. At first, the use of definitions in popularization discourse is investigated and compared to the practices followed in argumentative and pedagogical texts. Special attention is then devoted to the strategies of reformulation and of recontextualization that are often adopted in this process, and exemplifications are provided to highlight the main functions fulfilled by the use of these rhetorical tools. The social importance of popularization is subsequently highlighted together with a discussion of the possible manipulative risks that may be encountered, particularly for argumentative or promotional purposes. The analysis carried out shows the great complexity of the popularization system, which implies therefore the adoption of an integrated approach in order to clearly identify and carefully describe the various aspects involved in this process.|popularization; reformulation; recontextualization|SCIENCE; KNOWLEDGE|Linguistics; Language \& Linguistics|3|0|1
Differential Object Marking in Corsican: Regularities and triggering factors|2014|The paper deals with Differential Object Marking in Corsican. After a short introduction, it gives an overview of the main local triggering factors for marking direct objects in general (animacy, referentiality). It then presents the few main assumptions about Corsican DOM in the literature as well as findings of a new corpus study, based on written Corsican texts. Strong personal pronouns and proper names for human referents are consistently marked by the DOM marker a, but toponyms and metonymically used proper names are marked as well. Universal and negative quantifiers with a human denotation are also DOM-marked, whereas all other pronouns are not; thus animacy plays only a minor role in Corsican. The presence of determiners, quantifiers or numerals within nominals excludes the presence of a, irrespective of the nominals' denotation. Non-specific bare nominals are never DOM-marked, also irrespective of the nominals' denotation. The discussion then explains that the Corsican DOM is triggered much more by syntactic definiteness than animacy, a hypothesis strengthened by the most prominent morphosyntactic regularity at work in Corsican: nominals in combination with determiners and quantifiers cannot be marked by the DOM-marker a, even if they denote human beings. The complementary distribution of a and prenominal functional elements requires a further detailed syntactic analysis.|Differential Object Marking; Nominal determination; Corsican; Italo-Romance languages|GRAMMAR|Linguistics; Language \& Linguistics|0|0|1
Multi-voiced assessment in a mental health final statement|2014|The focus of this article is on the records written during an intensive assessment and rehabilitation course targeted at young adults suffering from severe mental health issues. The ability of the clients to cope with everyday life is assessed during the rehabilitation course and the final statement compiled by the keyworker includes the combined results of the assessments of each client. Using intertextual analysis, I examine these final statements and utilize the concepts of voice and direct and indirect reported speech. I ask how and what kinds of voices are used in final statement to assess the clients' progress during the course and to define the future development tasks for them. Firstly, it is shown that the final statements are multi-voiced texts. They are persuasive statements about the clients' development stories and descriptions of how the rehabilitation course practitioners have helped the client. Secondly, the analysis shows how voice and client knowledge are present in the final statement. The voices of assessment build the argument dialogically and highlight temporality, and in this way they produce a convincing description of the mental health client's current ability to function and progress on the rehabilitation course.|intertextuality; voice; reported speech; records; assessment; mental health|INTERTEXTUALITY; DISCOURSE|Communication; Linguistics; Language \& Linguistics|0|1|1
The realization of pitch reset in Finnish print interpreting data|2014|Speakers use intonation in order to group spoken sentences together into larger units. One such grouping is often referred to as ``paragraph intonation.{''} One of its principal characteristics is that the beginning of a new speech paragraph is marked with a high pitch level at the beginning of the first spoken sentence. This phenomenon is called ``pitch reset.{''} The present article discusses the role of the pitch reset in Finnish data coming from two situations where conference-like monologous presentations are being interpreted by professional print interpreters. ``Print interpreting{''} is a mode of communication where the speech is being simultaneously transferred into written form so that deaf and hard-of-hearing people can have access to it. The study shows, on the one hand, that the pitch reset phenomenon can be found also in Finnish data. On the other hand, the results show that the pitch reset constitutes a prosodic sign that almost always leads to a paragraph division in the written target text. This implies that the print interpreters treat speech paragraphs as topical units, and that the pitch reset plays an important role in the structuring of discourse. The study is mainly based on Wichmann's (2000) approach, which constitutes an interface between discourse analysis and intonation studies.|pitch reset; intonation; Finnish prosody; phonetics; print interpreting; discourse analysis|INTONATION|Communication; Linguistics; Language \& Linguistics|0|0|1
Comprehension difficulties of over-the-counter pharmaceutical products leaflets. The case of paracetamol in Argentina|2014|The aim of this study is to determine the comprehension difficulties adults have regarding the information provided by over-the-counter pharmaceutical products leaflets that contain paracetamol as an active principle. For this purpose, 20 adults were interviewed with a survey especially designed for this research. Following important linguistic comprehension studies, comprehension difficulties were recognized and analyzed. The analysis shows difficulties with lexical, propositional, and micro-structural strategies. However, it is necessary to continue carrying out studies on comprehension to identify difficulties that over-the-counter drug users have to understand information pamphlets.|nonprescription drugs; medicine package inserts; comprehension; discursive strategies|TEXT COMPREHENSION; MODEL|Linguistics; Language \& Linguistics|1|1|1
Direct and indirect speech in Spanish language news reports|2014|This work uses data from two Spanish language newspapers: Granma from Cuba and El Nuevo Herald from Miami to analyze pragmatic and social factors that underlie the use of reported speech in news texts. This study examines pragmatic and social constraints on journalists' choice of reporting speech structures. Journalists use direct speech to provide a literal quotation of another's voice, whereas indirect speech is presents the journalists' own rendition of the quoted words. The qualitative and quantitative analyses reveal that Granma and El Nuevo Herald exhibit different patterns of use of direct and indirect speech, which are motivated by the two newspapers' ideological perspectives and the level of political and social power of the news actors.|direct speech; indirect speech; pragmatic; ideology; political power|ENGLISH; QUOTATION|Linguistics; Language \& Linguistics|0|0|1
Summary of Product Characteristics content extraction for a safe drugs usage|2012|The use of medications has a central role in health care provision, yet on occasion, it may injure the person taking them as result of adverse drug events. A correct drug choice must be modulated to acknowledge both patients' status and drug-specific information. However, this information is locked in free-text and, as such, cannot be actively accessed and elaborated by computerized applications. The goal of this work lies in extracting content (active ingredient, interaction effects, etc.) from the Summary of Product Characteristics, focusing mainly on drug-related interactions, following a machine learning based approach. We compare two state of the art classifiers: conditional random fields with support vector machines. To this end, we introduce a corpus of 100 interaction sections, hand annotated with 13 labels that have been derived from a previously developed conceptual model. The results of our empirical analysis demonstrate that the two models perform well. They exhibit similar overall performance, with an overall accuracy of about 91\%. (C) 2011 Elsevier Inc. All rights reserved.|Information extraction; Conditional random fields; Support vector machines; Adverse drug events; Medication errors; Summary of Product Characteristics|CLINICAL DECISION-SUPPORT; PHYSICIAN ORDER ENTRY; MEDICATION INFORMATION; TEXT; SYSTEMS; EVENTS; ALGORITHM; MEDICINE; ERRORS|Computer Science, Interdisciplinary Applications; Medical Informatics|11|0|1
Finding the arc A story about a search for narratives|2012|Powerful narratives exist about the nature, practice and validity of narrative inquiry. It is storied, for example, as complex, time-consuming and unappreciated by the conservative sociology academe. As a new PhD candidate I planned to undertake a straight thematic analysis. However, it became evident that an alternative approach was required. This paper tells a story about my struggle to comprehend narrative analysis and find the arc of my participant's stories. Because writing `my sexual story' provided a particular turning point in this journey I also recount this here, in addition to an outline of the analytical framework I developed to interpret my data. I argue that narrative analysis is not easily learned through traditional scholarship: texts, journal articles, supervisors and conferences. Rather, a lingering, challenging - but ultimately highly rewarding journey may be required. It is my hope that this paper will provide insight and assistance to the novice narrative researcher.|narrative analysis; self-story; analytical framework; journey|INTERVIEWS; INQUIRY; POWER; LIFE|Communication; Linguistics; Language \& Linguistics|2|0|1
Reformulation and use of the neutral demonstrative pronoun `this' in the production of written synthesis by university students|2012|In this paper it is studied the use of the neutral demonstrative pronoun `this' in texts produced by psychology students during a curricular task. As part of the objectives, the occurrences of the neutral demonstrative pronoun (NDP) are described and analyzed, the source text and the produced text are compared and the psycholinguistic operations that include its use in this corpus are interpreted. As a result of the analysis, the categories proposed allow to show the functional role that the NDP adopts in similar types of texts or in reformulative segments of other texts. It is considered for its study the generic compositional dependence of the type of text and of the task in which it is produced. In the students' texts, the NDP reaches a high proportion in comparison with the other no-neutral pronouns. Beside, the occurrence is found in more of the 80\% of the text in the context of the reformulation of the source text and in direct correspondence with it. The findings presented here offer promising paths for educational applications, considering the difficulties of students in their writings.|Text; university students; reformulation; demonstrative pronoun; anaphora|BROAD REFERENCE CLEAR|Linguistics; Language \& Linguistics|1|0|1
Panoptical defragmentation of the Stalinist microcosm in post-war Poland|2012|The paper is a critical hermeneutics of space during the period of Stalinism in Poland (1949-1953). It utilizes qualitative research to analyze spatial relations in Stalinist-era press propaganda through a paradigm based on Michel Foucault's oeuvre on space and power, as well as Marcel Danesi's work on the ontology of metaphor. The analysis traces the manipulation of space by Stalinist propaganda, which I propose becomes circular and broken into a plethora of `sphericules' - a strategy called here panoptical defragmentation. In this way, the discussion engages the spatial turn in media studies. The database for the research was a representative selection of texts extracted from a leading journal and a leading periodical of the time: Trybuna Ludu and Przekroj. The concepts of struggle and competition are proposed to be ontological categories involving fictitious forces and entailing a discursive reification effectuated by Communist apparatchiks.|propaganda; Stalinism; post-war Poland; press discourse; spatiality; discourse analysis; cultural semiotics|PROPAGANDA|Linguistics; Language \& Linguistics|0|0|1
Grammaticalization through inherent variability The development of a progressive in Spanish|2012|With the goal of elucidating the diachronic trajectory of a progressive, multivariate analysis is used to track the linguistic factors conditioning variation between the Spanish Progressive and the simple Present, in 13th-15th, 17th, and 19th century texts. The Progressive begins as more of a locative construction, as shown by the early favoring effect of co-occurring locatives. The direction of this co-occurring locative effect is retained over time, but the magnitude weakens relative to aspectual constraints (limited vs. extended duration contexts, dynamic vs. stative verbs), and the Progressive is increasingly disfavored in negatives and interrogatives. Increasing frequency is accompanied by changes in linguistic conditioning. An aspectual opposition arises as, in the course of speakers' recurrent choices between variant forms, the variants develop functional differentiation.|variation; grammaticalization; progressive; linguistic conditioning; frequency|FUTURE; CONVERSATION; DISCOURSE; ORIGINS|Linguistics; Language \& Linguistics|7|0|1
Mapping the information structure in Early Modern Bulgarian clauses with the particle TA|2011|Bulgarian texts from the 17th century display the particle ta that seems to behave as some kind of complementizer, topic and information focus marker, all at once. This is different from Modern Bulgarian, where the same particle behaves either as a complementizer or as a narrative connector. We argue that intra-clausal ta in these texts spells out the cluster of features {[}topic], {[}force], and acts as a syncretic head that inherits the features of C. This analysis has empirical and theoretical advantages in accounting for diachronic changes in the computation of the left periphery. Notably, two representations were at work in Early Modern Bulgarian: one in which Top/ta inherits the features of C, and one in which null Top is associated with {[}topic] only and is irrelevant to the C-to-T feature transfer. Modern Bulgarian has only the latter, due to the loss of the {[}topic] feature of to. Crown Copyright (C) 2011 Published by Elsevier B,V. All rights reserved.|Left periphery; Cartography; Feature transfer/inheritance; Topic; Information structure; Bulgarian|QUESTIONS; SYNTAX; LI|Linguistics; Language \& Linguistics|3|0|1
Getting the whole story: an experience report on analyzing data elicited using the war stories procedure|2011|When analyzing data elicited using the ``war stories{''} technique, previously introduced by Lutters and Seaman (Inf Softw Technol 49(6):576-587, 2007), we encountered unexpected challenges in applying standard qualitative analysis techniques. After reviewing the literature on stories and storytelling, we realized that a richer analysis would be possible if we accorded more respect to the data's structure and nature as stories, rather than treating our participants' utterances simply as textual data. We report on five lessons learned regarding how we can better analyze war stories as stories: 1) war stories tend to be about exceptional situations; 2) war stories tend to be diverse and resistant to being combined into a single grand narrative; 3) the humanities can be a valuable resource for analyzing war stories; 4) war stories are not just text, they are also performances; and 5) war stories are not just data, they are also instructive and evocative.|Qualitative data analysis; Figuration; Methodical; Amethodical|CRITICAL INCIDENT TECHNIQUE; PERFORMANCE|Computer Science, Software Engineering|0|0|1
Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models|2011|Standard statistical models of language fail to capture one of the most striking properties of natural languages: the power-law distribution in the frequencies of word tokens. We present a framework for developing statistical models that can generically produce power laws, breaking generative models into two stages. The first stage, the generator, can be any standard probabilistic model, while the second stage, the adaptor, transforms the word frequencies of this model to provide a closer match to natural language. We show that two commonly used Bayesian models, the Dirichlet-multinomial model and the Dirichlet process, can be viewed as special cases of our framework. We discuss two stochastic processes-the Chinese restaurant process and its two-parameter generalization based on the Pitman-Yor process-that can be used as adaptors in our framework to produce power-law distributions over word frequencies. We show that these adaptors justify common estimation procedures based on logarithmic or inverse-power transformations of empirical frequencies. In addition, taking the Pitman-Yor Chinese restaurant process as an adaptor justifies the appearance of type frequencies in formal analyses of natural language and improves the performance of a model for unsupervised learning of morphology.|nonparametric Bayes; Pitman-Yor process; language model; unsupervised|NONPARAMETRIC PROBLEMS; MORPHOLOGY; MIXTURES|Automation \& Control Systems; Computer Science, Artificial Intelligence|11|0|1
FINNIC STOP GRADATION AS AN EFFECT OF MORA SHARING|2011|Finnic radical stop gradation affected stop consonants in the onset position of unstressed syllables. The stops were weakened before closed syllables, and remained unweakened before open syllables. Stop gradation, conditioned by whether the following syllable was open or closed, is cross-linguistically extremely rare. In this paper, gradation is argued to be a phonetically natural intervocalic weakening process, which was blocked only in the onsets of open unstressed syllables due to restrictions on moraic structure. Under the proposed account, differences between Finnic languages in terms of gradation depend on the extent to which a specific language tolerated heavy unstressed syllables.|Finnic; gradation; stops; geminate gradation; single stop gradation; Optimality Theory; mora sharing|TYPOLOGY; WEIGHT|Linguistics; Language \& Linguistics|0|0|1
The functions carried out by the first person plural in Vera Linhartova's prose|2011|This paper presents an analysis of the ``rhetorical plural{''} as used in the prose of Vera Linhartova, namely in her Povidka nesouvisla (An incoherent story), included in the prose collection Prostor k rozliseni (Space to Discriminate, 1964), and in two texts from the collection Mezipruzkum nejbliz uplynuleho (Interim Research into the Most Recent Past, 1964), entitled Totez pozdeji and Raci kanon na besovske tema (The same thing later, A crab canon on a fiendish theme, respectively). The first part of the study devotes attention to different types of text subjects and their involvement in the process of (literary) communication. The theoretical definition of various types of the first person plural presented by grammar and style handbooks or other specialised works is also the subject of brief examination. The second part of the paper focuses on the functions carried out by the first person plural in Vera Linhartova's prose. Our aim is to show that the authorial plural in artistic texts need not serve the function assigned to this grammatical device in specialised texts and that the authorial plural must be distinguished from the inclusive plural, as these types not only perform different functions, but also refer to different referents.|authorial plural; exclusive plural; inclusive plural - incorporative form; inclusive plural - objective/adjunctive form; inclusive plural - subjective/adjunctive form; majestic plural; speaking subject; producer's communicative perspective; artistic text|SPEECH|Linguistics; Language \& Linguistics|0|0|1
Meta-communicative signals and humorous verbal interchanges: A case study|2010|The aim of this article is to provide a system for analysis of verbal humorous interactions that incorporates both the General Theory of Verbal Humor and the meta-communicative level. The integration will be accomplished using a two-pronged analytical model of humorous interactions. According to the General Theory of Verbal Humor, the first phase will trace the humor in the text with particular attention given to the Script Opposition and to the Logical Mechanism; the second will monitor the meta-communicative level, focusing on meta-communicative signals. Information about the humorous frame constitutes a seventh Knowledge Resource, called Meta-Knowledge Resource. Applying this model to an Italian film starring the comic actor Tot produced two results: 1) the definition of two kinds of humor on- and off-stage depending on the presence of Meta-Knowledge Resource and 2) a description of the ``ideal author{''} postulated by the text. The second result is achieved by an analysis that combines on- and off-stage humor with verbal and referential humor.|General Theory of Verbal Humor; humor on and off-stage; meta-knowledge resource; verbal humor; referential humor|JOKES|Language \& Linguistics; Psychology, Multidisciplinary|0|0|1
Directional Complements in Taiwan Mandarin Natural Speech|2010|This paper is concerned with a specific kind of resultative verb complement construction in Mandarin Chinese, the directional complement construction. Instead of using texts or controlled laboratory data, we utilized a corpus of Taiwan Mandarin natural speech annotated with three types of directional constructions and investigated their usage in conversation. Some of the structures of directional complement constructions predicted by theories or observations were empirically confirmed in our frequency analysis, but some were not. In particular, we conducted statistical screening tests to explore relevant acoustic-prosodic features which may reflect the acoustic representation of directional components. The analysis was carried out by using residuals calculated by fitting a linear model of effects of speakers and syllables on the measurements of duration and intensity. The results suggest that duration is the most reliable acoustic-prosodic feature signifying phonetic reduction. Specifically speaking, the metaphorical use of directional constructions is prosodically less prominent than their original counterparts. Potentiality terms are more reduced than the neighbouring directional components. Phonetic reduction associated with syntactic prominence and semantic loss is also found in the use of directional components in contrast with the use of other grammatical categories such as verbs and prepositions. This paper not only gives a comprehensive overview of the authentic use of directional constructions in natural speech. It also provides a new piece of acoustic-prosodic evidence suggesting that the more grammaticalized the lexical items are, the more reduced they would appear in speech production.|directional complements; natural speech; statistical analysis; acoustic-prosodic features; grammaticalization|CHINESE|Linguistics; Language \& Linguistics|0|0|1
Biologically Plausible Connectionist Prediction of Natural Language Thematic Relations|2010|In Natural Language Processing (NLP) symbolic systems, several linguistic phenomena, for instance, the thematic role relationships between sentence constituents, such as AGENT, PATIENT, and LOCATION, can be accounted for by the employment of a rule-based grammar. Another approach to NLP concerns the use of the connectionist model, which has the benefits of learning, generalization and fault tolerance, among others. A third option merges the two previous approaches into a hybrid one: a symbolic thematic theory is used to supply the connectionist network with initial knowledge. Inspired on neuroscience, it is proposed a symbolic-connectionist hybrid system called BIO theta PRED (BIOlogically plausible thematic (theta) symbolic-connectionist PREDictor), designed to reveal the thematic grid assigned to a sentence. Its connectionist architecture comprises, as input, a featural representation of the words (based on the verb/noun WordNet classification and on the classical semantic microfeature representation), and, as output, the thematic grid assigned to the sentence. BIO theta PRED is designed to ``predict{''} thematic (semantic) roles assigned to words in a sentence context, employing biologically inspired training algorithm and architecture, and adopting a psycholinguistic view of thematic theory.|thematic (semantic) role labeling; natural language processing; biologically plausible connectionist models|RECURRENT NEURAL-NETWORKS; SEMANTIC ROLES; STARTING SMALL; MODEL; PROCESSOR|Computer Science, Software Engineering; Computer Science, Theory \& Methods|0|0|1
Transitivity, mood and theme in Spanish: A first analysis in terms of Cardiff Grammar|2010|Systemic-Functional Linguistics posits that the linguistic system is structured as it is because of the functions people have it serve. Needless to say, speakers from different communities do not use language for the same specific ends. For instance, not every human group plans and goes on fishing excursions on yellow boats. However, all human communities use language to organize their experience, to establish and maintain social bonds with the others, and to produce texts (to name but a few purposes). These three uses are respectively defined as the `experiential', `interpersonal' and `textual' functions (or, more precisely, `metafunctions'). In this context, Fawcett (2008) emphasizes the `multifunctional principle' of language proposed by Halliday (1967a, 1967b): Every clause fulfills several functions at the same time. This paper will try to prove that the Cardiff Grammar provides a framework by reference to which it is possible to explain `how' the experiential, interpersonal and textual metafunctions manifest themselves in the structure of the Spanish clause.|Systemic-Functional Grammar; Cardiff; multifunctional; clause; Spanish|HALLIDAY VERBAL GROUP; IN-PLACE; PART 2; ENGLISH|Linguistics; Language \& Linguistics|1|1|1
COMPARING AND CONTRASTING NATURAL PHONOLOGY, OPTIMALITY THEORY AND THE THEORY OF PHONOLOGY AS HUMAN BEHAVIOR|2009|This paper compares and contrasts the theories of Natural Phonology, Optimality Theory and Phonology as Human Behavior from diverse theoretical and methodological aspects including: the interaction between the opposing forces of markedness (the human factor) and faithfulness (the communication factor); the sentence-oriented versus sign-oriented approaches; and the concepts of naturalistic versus generative research paradigms. Despite these basic differences, similarities are also found in their shared functional basis which is discussed in the context of the natural phonological processes of Natural Phonology. I will further show how each theory views the notion of language universals. The concepts of combinatory phonology, phonotactics, and diachronic, developmental and clinical phonology will be discussed as measures of defining and determining the concept of language universals. The author maintains that biological, physiological, cognitive, psychological, sociological and other universals of human behavior are merely reflected in language rather than being specific ``language universals{''} per se.|Natural Phonology; Optimality Theory; Phonology as Human Behavior|SIGN-LANGUAGE|Linguistics; Language \& Linguistics|3|0|1
Rhetorical variation in Arabic academic discourse: Humanities versus law|2009|The study adopts a genre analysis approach in order to investigate rhetorical variation in introductions of Arabic research articles from the fields of law and humanities. Fifty introductions from each discipline are analyzed in terms of the kinds of research justification and reader orientation they provide. The results show that law introductions exhibit more exponents of both functions; but neither discipline has utilized challenges to previous scholarship as a means of justifying the research proposed. These findings are accounted for through cultural, sociolinguistic, and educational factors that characterize the context of production of the texts considered. (C) 2008 Elsevier B.V. All rights reserved.|Arabic rhetoric; Academic discourse; Genre analysis; Contrastive rhetoric; Legal language|EDUCATION|Linguistics; Language \& Linguistics|7|0|1
``Be steady then, my countrymen, be firm, united and determined{''} Expressions of stance in the 1798-1800 Irish paper war|2009|This paper examines the linguistic resources adopted by pamphlet writers to express their stance and engage their readers during the so-called Irish paper war that preceded the 1800 Union between Great Britain and Ireland. The data (about 100,000 words) consists of 23 pamphlets divided, according to their position in the debate, into two sub-corpora of approximately the same number of words. My purpose in this paper is to investigate the communicative and rhetorical functionality of the linguistic features writers use to express their stance towards the union, with a view to determining how writers establish themselves as morally and intellectually authoritative in their texts. The analysis brings out the crucial role lexico-grammatical patterns play, but also demonstrates the need for a broader interactive perspective, in order to fully account for the dynamics of persuasive discourse.|Irish paper war; Union; stance; heteroglossic/monoglossic engagement; affect; judgement; authorial persona|DISCOURSE; ENGLISH|Linguistics; Language \& Linguistics|0|0|1
About the Position and Perspectives of General Lexicography with regard to German and Slovenian.|2009|About the Position and Perspectives of General Lexicography With regard to German and Slovenian. A brief overview of general bilingual dictionaries with German and Slovenian is followed by,a closer investigation of the following dictionaries: Plet, DebN, DebS, PonsN and PonsS. In the first part of the dictionary analysis the user reference, the dictionary basis, the primary recorded lexical items, as well as outer texts and phased-in inner texts are investigated. Only in Plet the user reference is relatively clearly recognisable. In the other dictionaries it-remains quite unclear. In all four more recent dictionaries all the components that have been investigated display serious shortcomings, e:g: lacking mediostructural linking of outer texts and central word list, the lack of data accessivity in the pleased-in inner texts;inappropriate selection,of the dictionary basis and the,unbalanced lemma selection: In the second part of the dictionary analysis selected aspects of the dictionary subject matter and the dictionary form of :the mentioned dictionaries are investigated by means of dictionary articles. In addition the typical article microstructures of each dictionary are given,and proposals. are made to change the article structures to produce a more user-friendly presentation, also when the data :presentation is expanded. This reveals some perspectives for the improvement of the lexicographic treatment in the language pair German and Slovenian.|BASIC DICTIONARY ARTICLE; BILINGUAL LEXICOGRAPHY; HYBRID MICROSTRUCTURE; ITEM ADDRESSING; MICROARCHITECTURE; MONOALPHABETIC MACROSTRUCTURE; OUTER TEXT; PURE MICROSTRUCTURE; SHORT ARTICLE; STRAIGHT ALPHABETICAL MAIN ACCESS STRUCTURE; USER REFERENCE|PRINTED DICTIONARIES; FORM|Linguistics; Language \& Linguistics|1|0|1
A contribution to the lexis of construction engineering textbooks: the case of building and construction|2008|The integration of a genre-based and a corpus-based instruction in ESP learning (Swales, 1990; Tribble, 2000; Ferguson, 2001; Flowerdew, 2005) has proved to be a suitable theoretical framework for describing the lexis of construction and architecture university textbooks, such as the sample compiled in the Construction Textbooks Corpus (CTC). This paper is a contribution to the study of the formal and semantic profiles of the lexis of this particular genre type and, by way of illustration, focuses on the case study of the lemmas build and construct. From a formal standpoint, the CTC reveals that the noun building (the first content word in the CTC) is six times more frequent than the verb build and the noun construction (third in frequency) is eleven times more frequent than the verb construct. Semantically, the corpus displays a prevalence of technical meanings which refer to building and construction as the activity or business of erecting edifices or structures. By observing the lexical profile of construction textbooks, this paper will finally consider possible teaching/learning implications.|ESP; genre analysis; lexis; textbooks; construction engineering|GENRE; PERSPECTIVE; ENGLISH; TEXT|Linguistics; Language \& Linguistics|0|0|1
Prosody and function of English comment clauses|2008|This paper investigates the use of 830 instances of spoken comment clauses (e.g. I think, I suppose) in the British component of the International Corpus of English and shows that their communicative functions depend to a large extent on prosodic realisation of the comment clause (CC). Four different prosodic patterns are identified, via. left-bound, right-bound, left-right bound, and prosodic independence. It is shown that prosodic binding to the left or right, together with positioning in the host, can narrow the scope of CCs to phrasal rather than clausal constituents. Unlike clausal CCs, which function as epistemic shields (Prince et al. 1982), phrasal CCs typically have approximative function. On the other hand, prosodic integration (especially left-right binding) is linked to high-frequency CCs and semantic weakening to the extent that they are used mainly as pleonastic elements for the structuring of text. Prosodic independence, finally, may give the CC an assertive or boosting function. It is argued that the wide range of communicative uses is the result of an ongoing grammaticalisation (pragmaticalisation) process, which involves semantic bleaching and a development from epistemic shield to approximator and, finally, structural device.|comment clauses; prosody; pragmatic function; corpus analysis; grammaticalisation|COMPLEMENTIZER|Linguistics; Language \& Linguistics|13|0|1
Unsettled facts: On the transformational dynamism of evidence in legal discourse|2008|In this article I conduct an examination of discursive identity of a legal `object' in the course of its treatment by various figures in the legal process. The need for this examination arises from a widespread concern about the effects of creating `records', i.e., transforming spoken discourse by way of documentation into `evidence'. After a brief review of the current discussion about this phenomenon, I argue that the identity of textualized evidence is upheld by way of references to other texts, all of which create afield of signification within which an object under discussion (evidence) shows different facets without however losing its identity. In order to support my argument, I offer an analysis of ethnographic data pertaining to a specific criminal case. My objective for the analysis is to trace the status of a specific discursive identity after its enunciation during an attorney-client conference. My findings indicate that textualization should be understood not as a form of fixity for discourse, but rather as semantic pivot that provides for different `argumentation figures' within the referential grid of the legal case.|discursive identity; legal discourse; textualization; transformation; figure; arguable|TALK; TEXT|Communication; Linguistics; Language \& Linguistics|5|0|1
Voicing folk for the academy: Interdiscursivity and collective identity in a north Dalmatian ethnography, 1899-1900|2007|This paper examines the specific discursive realizations of `folk identities' in a north Dalmatian ethnographic account from the end of the nineteenth century in the context of early Croatian institutional-ethnographic practice. By treating the text in question as a site for the dialogic-interactive mediation and production of `authentic' collective identities between local/folk (dialectal) and centralized, academic-institutional (standard) discourses, it also aims at reassessing its value as a historical and philological source for the study of ethno-cultural identity formation in the region. Adopting a pragmatic/discourse-analytic perspective, and devoting particular attention to dialogic aspects of the entextualization and contextualization process, our investigation seeks to elucidate latent and overt ideologies, categories and `performances' of identity in the ethnographic text-as-interdiscursive-construction. The analysis reveals the different levels/orders and strategies/processes of discursive identity formation that emerge from the text, as indexed e.g. by stereotypical predications and attributions. It concludes - and confirms - that systematic and methodic attention for dialogism and polyphony is indispensable to a reliable historical pragmatics of `ethnographic reality', `identities' included. (C) 2007 Elsevier B.V. All rights reserved.|identity; performance; dialogism; ethnographic discourse; Croatian (Bosnian, Serbian)|LANGUAGE; POETICS; LIFE|Linguistics; Language \& Linguistics|2|0|1
Why are computational models of text comprehension useful?|2007|Computational models have played an important role in unraveling and understanding the psychological complexity of text comprehension. They have done so for three major reasons. First, the process of transforming verbally described theories of text comprehension (conceptual theories) into computational models of text comprehension promotes the development and evolution of the conceptual theories by showing where the models accord with behavioral data and where they do not. Second, computational models can be applied to behavioral data to better understand and test alternative explanatory constructs; especially in cases where patterns of behavioral data are not as expected a priori. In such cases, researchers provide post-hoc explanations, many of which are quite reasonable. Computational models can provide a way to test or enact such explanations. Finally, and partly as a result of the first two benefits, computational models promote communication among researchers within and across research areas. These claims are illustrated in specific examples of computational models.|computational models; text comprehension|LATENT SEMANTIC ANALYSIS; CONSTRUCTION-INTEGRATION MODEL; SITUATIONAL REPRESENTATIONS; THEORETICAL-ANALYSIS; MEMORY; INFORMATION; RETRIEVAL; KNOWLEDGE; RECOGNITION; RECALL|Linguistics; Language \& Linguistics|1|0|1
Towards strategies for processing relationships between multiple relation participants in knowledge patterns - An analysis in English and French|2007|Knowledge patterns are an effective tool for automatically or semi-automatically locating specific types of information - such as conceptual relations - in text corpora. However, pattern-based approaches are vulnerable to a number of types of variation; one of these is the expression of multiple participants in a single occurrence of a relation. Despite the challenges posed by this phenomenon, however, such cases may be particularly rich in useful information about the principal relation expressed and/or others involving the relation participants. Strategies that allow for formal evaluation and processing of such cases can enable pattern-based applications to capitalize on this information. This article will present a description, in English and French, of the types of relation occurrences in which multiple participants in CAUSE-EFFECT and ASSOCIATION relations are named, and the information that each can offer in addition to these primary relations. Moreover, some strategies and challenges for processing these cases automatically will be discussed, and the phenomena as observed in the two languages will be briefly compared.|knowledge patterns; conceptual relations; multiple participants in relationships; semi-automatic knowledge extraction|CARDIOVASCULAR-DISEASE; BREAST-CANCER; VASCULAR BIOLOGY; PROTEIN; EXPRESSION; METASTASES; PLACEBO; MARKERS|Linguistics; Language \& Linguistics|6|0|1
Verification of text ideas during reading|2006|This study inspected the processes of verifying the current discourse constituent against the referents that it passively cues during reading. It seemed plausible that, after understanding The customer ate pancakes, the processes of fully understanding The waiter implied that the customer ate eggs might resemble those of intentionally verifying The customer ate eggs ({''}false{''}). Therefore, one working hypothesis was that existing analyses of intentional sentence verification might bear on tacit verification during reading. Second, discourse pragmatics are likely to influence and regulate those verification processes. To explore this analysis, experiments implemented a reading time analogue of familiar sentence verification tasks. Story target sentences varied in their truth and use of negation with reference to antecedent text. Experiment I suggested that sentence reading time varies systematically with truth and negation, a result that was proposed to reflect the joint impact of discourse pragmatics and of verification operations akin to intentional ones. Experiment 2 denied that the latter results were appreciably affected by violations of the pragmatics of negation. Experiment 3 provided evidence that, when readers adopt an intentional verification strategy, reading times resemble those of intentional sentence verification. These results were interpreted to support the central assumptions of the study. (c) 2005 Elsevier Inc. All rights reserved.|comprehension : text, comprehension monitoring; memory, memory-based text processing; negation; pragmatics : negation, factive verbs; text, memory-based processing; verbs : factive, nonfactive|LONG-TERM-MEMORY; BRIDGING INFERENCES; COMPREHENSION; INFORMATION; MODEL; RETRIEVAL; NEGATION; QUESTION; PICTURE; ACTIVATION|Linguistics; Psychology; Psychology, Experimental|49|0|1
Paving the way to literary analysis through TV commercials|2006|This article presents an approach to introducing literature to high school and college students in their second or third year of French. The aim is to reconcile the goals of literature courses with the backgrounds and motivations of students, by taking advantage of the popularity of TV commercials. After showing the close connection between advertising and literature, the authors present a detailed lesson structure, both student- and text-centered, that helps students analyze commercials and their effects on TV viewers. This procedure, based on the work of Compte (1993), is then applied to the analysis of a literary selection.|bridge between language and literature; high school and college language learning; task-based instruction; teaching of literature; TV commercials|FRENCH|Education \& Educational Research; Linguistics|8|0|1
Communicating affect in news stories: The case of the lead sentence|2006|The phenomenon of affect in language has recently received some attention from researchers who have focused primarily on its lexical expression. This article examines syntactic manifestations of affect in the lead sentence of Arabic news stories. It addresses the question of the pragmatic motivation for the occasional occurrence of spatiotemporal structures in text-initial position. Empirical analysis reveals that marking affect is one pragmatic function that the text-initial spatiotemporal structure serves in Arabic news stories. The importance of certain sociopolitical events is a crucial factor. The lead sentence acquires an emotive value or interpretation as it exhibits the writer's affective stance toward reported events. Although spatiotemporal structures are used sparingly in text-initial position, they manifest variation in their composition-a possible indication of varying degrees of emotional involvement or intensity. Illustrative examples of this phenomenon explain implications for the communication of affect.|affect; cross-cultural communication; grammar; news discourse; perspective|LANGUAGE|Communication; Linguistics; Language \& Linguistics|4|0|1
Tests of a theory of communicative responsibility|2005|Two studies are presented that provide the first empirical tests of a theory of communicative responsibility. The theory posits that individuals in communicative situations make systematic judgments of the extent to which each party is responsible for contributing to the process of creating understanding in a communicative event. These judgments affect the extent to which communicators engage in implicature and inference-making during the communicative event. The first study demonstrates that judgments of communicative responsibility affect communicative performance. Respondents' judgments of their personal communicative responsibility in a direction-giving task were positively associated with the length of their directions. The second study showed that a communicator's failure to behave in a communicatively responsible manner was associated with negative perceptions of the communicative behavior Communicative responsibility theory would be useful in a number of areas of communication research, including natural language processing, relational communication, misunderstandings and conversational repair communication competence, and deception.|conversational implicature; inference; understanding; collaboration; common ground; discourse|INFORMATION MANIPULATION THEORY; MISUNDERSTANDINGS; INFERENCE; KNOWLEDGE|Communication; Linguistics; Psychology, Social|6|0|1
Understanding text after severe closed-head injury: Assessing inferences and memory operations with a think-aloud procedure|2005|A think-aloud method was used to examine. the content of information available to working memory during narrative comprehension in a CHI population. Twenty severe CHI participants (> 1 year post-injury) and 20 controls talked aloud after they read each sentence of story narratives. Trabasso and Magliano's (1996a) verbal protocol analysis was then used to code for the production of inferential and non-inferential clauses and the memory operations that supported inferential clause, production. We found that CHI and control groups produced a comparable number of clauses, that inferences dominated narrative comprehension, and that both groups produced more, explanatory inferences than predictive or associative inferences. Despite these qualitative similarities, the CHI group demonstrated poorer comprehension, generated proportionately fewer inferences, relied less on retrieval as a memory source for explanatory inferences, and produced more non-inferential clauses and associative inferences. (c) 2005 Elsevier Inc. All rights reserved.|traumatic brain injury; closed-head injury; think-aloud; protocol analysis; language; discourse; comprehension; inferences; memory; working memory|TRAUMATIC BRAIN-INJURY; DIFFUSE AXONAL INJURY; COMPREHENSION SKILL; RIGHT-HEMISPHERE; DAMAGED PATIENTS; WORKING-MEMORY; DISCOURSE; DEFICITS; ADULTS; ABILITIES|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|15|0|1
Ambiguity resolution analysis in incremental parsing of natural language|2005|Incremental parsing gains its importance in natural language processing and psycholinguistics because of its cognitive plausibility. Modeling the associated cognitive data structures, and their dynamics, can lead to a better understanding of the human parser. In earlier work, we have introduced a recursive neural network (RNN) capable of performing syntactic ambiguity resolution in incremental parsing. In this paper, we report a systematic analysis of the behavior of the network that allows us to gain important insights about the kind of information that is exploited to resolve different forms of ambiguity. In attachment ambiguities, in which a new phrase can be attached at more than one point in the syntactic left context, we found that learning from examples allows us to predict the location of the attachment point with high accuracy, while the discrimination amongst alternative syntactic structures with the same attachment point is slightly better than making a decision purely based on frequencies. We also introduce several new ideas to enhance the architectural design, obtaining significant improvements of prediction accuracy, up to 25\% error reduction on the same dataset used in previous work. Finally, we report large scale experiments on the entire Wall Street Journal section of the Penn Treebank. The best prediction accuracy of the model on this large dataset is 87.6\%, a relative error reduction larger than 50\% compared to previous results.|first-pass attachment; incremental parsing; learning preferences; recursive neural networks (RNNs); structured data|RECURSIVE NEURAL-NETWORKS; ATTACHMENT; MODEL|Computer Science, Artificial Intelligence; Computer Science, Hardware \& Architecture; Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic|4|0|1
A psycholinguistically and neurolinguistically plausible system-level model of natural-language syntax processing|2005|We describe a psycholinguistically and neurolinguistically plausible model of natural-language processing by the human brain. This model is based on the work of Gerard Kempen and coworkers at Leiden and Nijmegen who have developed computational models of language generation and of language recognition. We show how to use our own brain modeling approach to develop a neurolinguistically plausible model based on the Kempen psycholinguistic model. Our model is implemented as a set of inter-communicating brain modules that run in parallel. These brain modules have the same structure and control regime as other nonlinguistic brain modules. They approximately correspond to Broca's and temporal lobe areas. (c) 2004 Elsevier B.V. All rights reserved.|psycholinguistics; lexical; unification; agrammatism|PRIMATE NEOCORTEX; FUNCTIONAL ARCHITECTURE; COMPUTATIONAL MODEL|Computer Science, Artificial Intelligence|4|0|1
To take a stance: a developmental study of the use of pronouns and passives in spoken and written narrative and expository texts in Dutch|2005|Discourse stance as expressed by the use of pronouns and passive-voice constructions is examined in two different text genres, narrative and expository text, produced in speech and writing by four groups of Dutch speakers: 9-10 year olds, 11-12 year olds, 15-16 year olds, and adults. In the pronoun analyses, the distribution and use of personal, impersonal, indefinite impersonal (pro)nominals, and demonstrative pronouns were examined. These quantitative analyses were supplemented with qualitative, functional analyses of the use of men (like German `man'), generic je `you', as well as ik `I' in expository text. In the passive analyses, the distribution and use of five types of passives were examined: present, past, infinitival, impersonal, and pseudo passives. The qualitative analyses of passives focused on the semantics of the verb, the presence of the agent, and the nature of the patient noun phrase, i.e., its degree of topicalization and animacy. In general, the results showed that children and adults use pronouns and passives systematically to express discourse stance in narrative and expository texts. In specific cases, grade school children use pronoun and passive forms in rhetorically less sophisticated ways, indicating that the expression of discourse stance is part of later language development. (C) 2004 Elsevier B.V. All rights reserved.|discourse stance; language development; spoken; written; pronouns; passive|TERM WORKING-MEMORY; ANIMACY; ENGLISH; VERBS; LANGUAGE; CHILDREN; SUBJECT; HEBREW; VOICE|Linguistics; Language \& Linguistics|12|0|1
Pragmatics and quantificational dependencies|2004|The dependency relation in quantificational dependencies (QDs) is analyzed here as a non-assertive DP defining relation that maps from given to new information, a form of D(iscourse)-linking (Pesetsky, D., 1987. Wh-in-situ: movement and unselective binding. In: Reuland, E.J., and ter Meulen, A.G.B. (Eds.), The Representation of (In)definiteness. MIT Press Cambridge, pp. 98-129). Given and new information are analyzed by means of their binding structures: Given information is bound, and hence fixed at text-level while new information is a local phenomenon. Every multiple DP, under this analysis new information, is linked by a dependency relation to a local given DP, such that the multiple DP is then necessarily specific under the D-linking relation. Drawing on Farkas (Farkas, D.F., 1997. Evaluation indices and scope. In: Szabolcsi, A. (Ed.), Ways of Scope Taking. Kluwer Academic Publishers Dordrecht, pp. 189-215), the D-linking dependency in QDs translates into a local dependency of functions that assign values to the variables contributed by DPs. Turkish data show that contrast and Focus operators may induce QDs, without the overt minimal partitioning elicited by a strong determiner on the given DP. This article proposes that the Only Effect that is associated with contrast and Focus operators instantiates a shift in the assertive force of the proposition by introducing a negative assertion of the relative alternatives to the focused element. The result is that the lexical predicate is demoted to non-assertive D-linking status. In this role it may sustain the dependency that defines QDs, and it does. (C) 2003 Elsevier B.V. All rights reserved.|locality/local {[}definition(s)]; text-level {[}definition(s)]; given/new information; binding/dependency; DP definition/define DP; quantificational dependencies (QDs); D-linking; assertion/assertive (force); attributive; contrast; only effect|SEMANTICS|Linguistics; Language \& Linguistics|2|0|1
Dipe-R: a knowledge representation language|2003|The paper reports the design of Dipe-R, a knowledge representation language. It meets two requirements: (1) Dipe-R should enable the appropriate expression of mental states and processes, viz. in line with basic insights on the nature of (human) communication and knowledge, and (2) Dipe-R should offer the possibility of identifying concepts by describing them by their features. The first requirement means that Dipe-R is capable of representing knowledge adequately. The second reflects a common way of exploring knowledge; this seems useful in various applications, e.g., in Information Retrieval. For meeting these requirements, Dipe-R has as main characteristics: (a) two types of expressions for representing thoughts (using binary relations), (b) for each expression Dipe-R creates at least one sentence in natural language, thus distinguishing language from `meaning', and (c) each expression in Dipe-R is provided with information on its origin. Some relation types are pre-represented, e.g., for creating type hierarchies. Experiments (in Information Retrieval) indicate that Dipe-R indeed meets its requirements. (C) 2002 Elsevier Science B.V. All rights reserved.|knowledge representation; reasoning; information retrieval|SYSTEM|Computer Science, Artificial Intelligence; Computer Science, Information Systems|2|0|1
Miscue analysis in school-age children|2002|It has been suggested that children who have trouble learning to read may use less effective decoding strategies than children who learn to read typically. The present investigation examined reading miscues (errors) made by typically developing children and children who demonstrated below-average language and reading abilities to answer the following questions: (a) Do typically developing children and children with below-average language and reading skills evidence similar types of miscues while reading aloud? (b) Do typically developing children make more grapho-phonernically similar errors (in which the error resembles the text word in two or more phonemes) and more nonsense-word errors than children with below-average language and reading ability and, (c) What is the relationship between the nature of reading miscues and comprehension performance? Results suggested that typically developing children made more miscues that preserved the meaning of the text than children with below-average language and reading abilities. Groups were equally likely to make errors that were grapho-phonernically similar and/or nonsense words. Comprehension performance for both groups was best predicted by omission of content words and phonologically similar real-word errors that maintained the meaning of the text. Analysis of oral-reading errors may be useful in prescribing specific intervention to improve automaticity and efficiency in reading for children with language-learning disorders.|reading; school-age; language impairment|LANGUAGE; MODEL; READ|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|10|0|1
An integrated, dual learner for grammars and ontologies|2002|We introduce a dual-use methodology for automating the maintenance and growth of two types of knowledge sources, which are crucial for natural language text understanding-background knowledge of the underlying domain and linguistic knowledge about the lexicon and the grammar of the underlying natural language. A particularity of this approach is that learning occurs simultaneously with the on-going text understanding process. The knowledge assimilation process is centered around the linguistic and conceptual `quality' of various forms of evidence underlying the generation, assessment and on-going refinement of lexical and concept hypotheses. On the basis of the strength of evidence, hypotheses are ranked according to qualitative plausibility criteria, and the most reasonable ones are selected for assimilation into the already given lexical class hierarchy and domain ontology. (C) 2002 Elsevier Science B.V. All rights reserved.|knowledge acquisition; natural language processing; ontology engineering; grammar learning; concept learning|INFORMATION EXTRACTION; MANAGEMENT|Computer Science, Artificial Intelligence; Computer Science, Information Systems|6|0|1
A child verb learning model based on syntactic bootstrapping|2002|This paper presents a child verb learning model mainly based on syntactic bootstrapping. The model automatically learns 4-5-year-old children's linguistic knowledge of verbs, including subcategorization frames and thematic roles, using a text in dialogue format. Subcategorization frame acquisition of verbs is guided by the assumption of the existence of nine verb prototypes. These verb prototypes are extracted based on syntactic bootstrapping and some psycholinguistic studies. Thematic roles are assigned by syntactic bootstrapping and other psycholinguistic hypotheses. The experiments are performed on the data from the CHILDES database. The results show that the learning model successfully acquires linguistic knowledge of verbs and also suggest that psycholinguistic studies of child verb learning may provide important hints for linguistic knowledge acquisition in natural language processing (NLP).|syntactic bootstrapping; subcategorization frame; thematic role; language acquisition; child verb learning|SUBCATEGORIZATION FRAMES; ACQUISITION; MEANINGS|Computer Science, Information Systems; Computer Science, Software Engineering|0|0|1
Grammatical morphology and perception of synthetic and natural speech in children with specific language impairments|2002|Studies investigating the relationship between the use of inflectional morphology and speech-perception abilities in children with SLI traditionally have employed synthetic speech stimuli. The purpose of this study was to replicate the findings reported in Leonard, McGregor, and Allen (1992) with an older group of children with SLI and to determine if the pattern of deficits seen for synthetic speech extends to perception of natural speech stimuli. The speech-perception abilities of 27 children between the ages of 6;11 and 8;11 (15 SLI and 12 NL) were compared using natural and synthetic versions of the {[}das]-{[}daf], {[}dabiba]-{[}dabuba], and {[}i]-{[}u] contrast pairs originally used in Leonard et al. The findings reported by Leonard et al. were replicated with synthetic speech but not for the natural speech. Use of inflectional morphology in obligatory contexts by the children with SLI was not significantly correlated with their perception abilities for any of the natural or synthetic speech-contrast pairs. Further, although both groups' ability to maintain the target contrast in memory declined over the span of the trials for all target contrasts for both natural and synthetic speech, the rate of decline did not differ significantly between the SLI and NL groups. Findings are discussed with respect to possible deficits in linking phonological representations to grammatical representations in children with SLI.|specific language impairment; grammatical morphology; speech perception; limited processing capacity; surface account of SLI|DEVELOPMENTAL APHASIA; IMPAIRED CHILDREN; STOP CONSONANTS; DEFICITS; SYSTEM; MEMORY|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|19|0|1
Selective automated indexing of findings and diagnoses in radiology reports|2001|The recent improvements in capabilities of desktop computers and communications networks give impetus for the development of clinical image repositories that can be used for patient care and medical education. A challenge in the use of these systems is the accurate indexing of images for retrieval performance acceptable to users. This paper describes a series of experiments aiming to adapt the SAPHIRE system, which matches text to concepts in the UMLS Metathesaurus, for the automated indexing of image reports. A series of enhancements to the baseline system resulted in a recall of 63\% but a precision of only 30\% in detecting concepts. At this level of performance, such a system might be problematic for users in a purely automated indexing environment. However, if the ability to retrieve images in repositories based on content in their reports, is desired by clinical users, and no other current systems offer this functionality, then follow-up research questions include whether these imperfect results would be useful in a completed or partially automated indexing environment and/or whether other approaches can improve upon them. (C) 2001 Elsevier Science (USA).|natural language processing; automated indexing; SAPHIRE; Unified Medical Language System (UMLS); Metathesaurus; evaluation|INFORMATION-RETRIEVAL; LANGUAGE; PERFORMANCE; COLLECTION; MULTIMEDIA; MEDICINE; SAPHIRE|Computer Science, Interdisciplinary Applications; Medical Informatics|29|0|1
Identification reaction times of voiced/voiceless continua: A right-ear advantage for VOT values near the phonetic boundary|2000|We explored the degree to which the duration of acoustic cues contributes to the respective involvement of the two hemispheres in the perception of speech. To this end, we recorded the reaction time needed to identify monaurally presented natural French plosives with varying VOT values. The results show that a right-ear advantage is significant only when the phonetic boundary is close to the release burst, i.e., when the identification of the two successive acoustical events (the onset of voicing and the release from closure) needed to perceive a phoneme as voiced or voiceless requires rapid information processing. These results are consistent with the recent hypothesis that the left hemisphere is superior in the processing of rapidly changing acoustical information. (C) 2000 Academic Press.|speech; hemispheric specialization; categorical perception; reaction time; VOT; temporal order|IMPAIRED CHILDREN; SPEECH-PERCEPTION; HEMISPHERIC-SPECIALIZATION; LANGUAGE COMPREHENSION; DEVELOPMENTAL APHASIA; AUDITORY-PERCEPTION; CONSONANTS; STIMULI|Audiology \& Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental|10|0|1
Pragmatic constraints on narrative processing: Actants and anaphora resolution in a corpus of North Carolina ghost stories|2000|Recent work on narrative has begun to rethink the functions of characters in stories. Research on life stories, for example, has shown that characters are not simply preexisting contents packaged in certain kinds of clauses, but rather complex, emergent products of the interplay between narrative design and narrative processing. Such wide-focus studies need to be complemented by finer-grained, microstructural investigations of character as a part of narrative discourse. Based on a corpus of fifteen natural-language narratives (specifically, ghost stories), this paper examines how stories encode mental representations of characters. Drawing on research in the field of narratology, the paper labels these character representations actants. Actants are models that encode narrative participants as agents and patients, thus allowing particular discourse entities to be inserted into global action structures like Pursuit of a goal. Analyzing sequences of referring expressions in the ghost stories, the paper shows that identifying and tracking agents in narratives requires that information about participant roles be encoded in the telling of the story. Further, insofar as they reconfigure objects and occurrences as agents and actions, ghost stories provide unique insights into the cognitive, linguistic, and interactional processes shaping discourse anaphora in narrative contexts. (C) 2000 Elsevier Science B.V, All rights reserved.|actants; character; discourse anaphora; mental models; narrative; reference|SELF|Linguistics; Language \& Linguistics|2|0|1
Building true understanding via apparent miscommunication: A case study|1999|The paper proposes an analysis of a sample text, which endeavours to show how apparent miscommunication is exploited by the speakers to build up towards an implicit mutual understanding between them. The conversation features in a short story in Hebrew, Sipur pashut ('A simple story') by the Nobel prize laureate, Shmuel Yossef Agnon. The theoretical approach underlying the analysis pertains to the distinction between individual speaker's meanings (I-level) on the one hand, and shared direction of the converstaion (We-level) on the other. It is shown how the very essence of miscommunication at I-level and of mutual understanding at We-level resides in a specific feature of the exchange, i.e. the validity of speakers' mutual assessments as to their respective familiarity with certain pieces of information. (C) 1999 Elsevier Science B.V. All rights reserved.|miscommunication; conversation; collective purpose; given information; liteary analysis; Agnon|EYEWITNESS; DISCOURSE|Linguistics; Language \& Linguistics|2|0|1
Can prosody aid the automatic classification of dialog acts in conversational speech?|1998|Identifying whether an utterance is a statement, question, greeting, and so forth is integral to effective automatic understanding of natural dialog. Little is known, however, about how such dialog acts (DAs) can be automatically classified in truly natural conversation. This study asks whether current approaches, which use mainly word information, could be improved by adding prosodic information. The study is based on more than 1000 conversations from the Switchboard corpus. DAs were hand-annotated, and prosodic features (duration, pause, F0, energy, and speaking rate) were automatically extracted for each DA. In training, decision trees based on these features were inferred; trees were then applied to unseen test data to evaluate performance. performance was evaluated for prosody models alone, and after combining the prosody models with word information-either from true words or from the output of an automatic speech recognizer. For an overall classification task, as well as three subtasks, prosody made significant contributions to classification. Feature-specific analyses further revealed that although canonical features (such as F0 for questions) were important, less obvious features could compensate if canonical features were removed. Finally, in each task, integrating the prosodic model with a DA-specific statistical language model improved performance over that of the language model alone, especially for the case of recognized words. Results suggest that DAs are redundantly marked in natural conversation, and that a variety of automatically extractable prosodic features could aid dialog processing in speech applications.|automatic dialog act classification; discourse modeling; prosody; speech understanding; spontaneous speech recognition|DISCOURSE STRUCTURE|Audiology \& Speech-Language Pathology; Linguistics; Psychology, Experimental|49|0|1
Effects of GSS interface and task type on group interaction: An empirical study|1997|The effects of GSS interface and task type on group interaction are examined in this experimental study. A 2 X 2 factorial design is employed. Each treatment has eight groups. Two types of GSS interfaces are studied: icon-based and text-based. Two task types are investigated: intellective and preference. Three dependent variables are measured: efficiency of influence attempts, inequality of influence attempts, and dominance significance. Results of data analysis show that groups using icon-based interface achieve greater efficiency of influence attempts, greater equality of influence attempts, and less dominance significance than groups using text-based interface. Moreover, equality of influence attempts is greater for preference task groups than intellective task groups. These results suggest that an icon-based interface is a useful feature of a GSS, particularly when group members an novice computer users. GSS developers should, therefore, pay attention to interface design on top of the considerations for other GSS features. (C) 1997 Elsevier Science B.V.|group support systems; group interaction; user-interface; task types|DECISION SUPPORT SYSTEMS; COMPUTER-INTERFACE; DESIGN; GDSS|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research \& Management Science|4|0|1
The enemy within: Autocorrelation bias in content analysis of narratives|1996|Many content analysis studies involving temporal data are biased by some unknown dose of autocorrelation. The effect of autocorrelation is to inflate or deflate the significant differences that may exist among the different parts of texts being compared. The solution consists in removing effects due to autocorrelation, even if the latter is not statistically significant. Procedures such as Crosbie's (1993) ITSACORR remove the effect of at least first-order autocorrelations and can be used with small samples. The AREG procedure of SPSS (1994) and the AUTOREG procedure of SAS (1993) can be employed to detect and remove first-order autocorrelations, and higher-order ones too in the case of AUTOREG, while several methods specifically intended for small samples (Huitema and McKean, 1991, 1994) have been developed. Four examples of content analysis studies with and without autocorrelation are discussed.|autocorrelation; computer-aided content analysis; narratives; serial dependencies|SINGLE-SUBJECT DATA; TIME-SERIES; PSYCHOLOGY; WORDS|Computer Science, Interdisciplinary Applications|3|0|1
VISIBLE SPEECH IMPROVES HUMAN LANGUAGE UNDERSTANDING - IMPLICATIONS FOR SPEECH PROCESSING SYSTEMS|1995|Evidence from the study of human language understanding is presented suggesting that our ability to perceive visible speech can greatly influence our ability to understand and remember spoken language. A view of the speaker's face can greatly aid in the perception of ambiguous or noisy speech and can aid cognitive processing of speech leading to better understanding and recall. Some of these effects have been replicated using computer synthesized visual and auditory speech. Thus, it appears that when giving an interface a voice, it may be best to give it a face too.|VISIBLE SPEECH; HUMAN-COMPUTER INTERACTION; NATURAL LANGUAGE UNDERSTANDING|PERCEPTION; GESTURES; REPRESENTATION; INFORMATION; EXPERT; NOVICE|Computer Science, Artificial Intelligence|5|0|1
THE EXPLICIT-IMPLICIT DISTINCTION|1995|Much of traditional AI exemplifies the `'explicit representation'' paradigm, and during the late 1980's a heated debate arose between the classical and connectionist camps as to whether beliefs and rules receive an explicit or implicit representation in human cognition. In a recent paper, Kirsh (1990) questions the coherence of the fundamental distinction underlying this debate. He argues that our basic intuitions concerning `explicit' and `implicit' representations are not only confused but inconsistent. Ultimately, Kirsh proposes a new formulation of the distinction, based upon the criterion of constant time processing. The present paper examines Kirsh's claims. It is argued that Kirsh fails to demonstrate that our usage of `explicit' and `implicit' is seriously confused or inconsistent. Furthermore, it is argued that Kirsh's new formulation of the explicit-implicit distinction is excessively stringent, in that it banishes virtually all sentences of natural language from the realm of explicit representation. By contrast, the present paper proposes definitions for `explicit' and `implicit' which preserve most of our strong intuitions concerning straightforward uses of these terms. It is also argued that the distinction delineated here sustains the meaningfulness of the abovementioned debate between classicists and connectionists.|EXPLICIT; IMPLICIT; CONNECTIONISM; REPRESENTATION|CONNECTIONISM|Computer Science, Artificial Intelligence|16|0|1
SCRIPT-BASED INFERENCE AND MEMORY RETRIEVAL IN SUBSYMBOLIC STORY PROCESSING|1995|DISCERN is an integrated natural language processing system built entirely from distributed neural networks. It reads short narratives about stereotypical event sequences, stores them in episodic memory, generates fully expanded paraphrases of the narratives, and answers questions about them. Processing in DISCERN is based on hierarchically-organized backpropagation modules, communicating through a central lexicon of word representations. The lexicon is a double feature map system that transforms each orthographic word symbol into its semantic representation and vice versa. The episodic memory is a hierarchy of feature maps, where memories are stored `'one-shot'' at different locations. Several high-level phenomena emerge automatically from the special properties of distributed neural networks in this model. DISCERN learns to infer unmentioned events and unspecified role fillers, generates expectations and defaults, and exhibits plausible lexical access errors and memory interference behavior. Word semantics, memory organization, and appropriate script inferences are automatically extracted from examples. DISCERN shows that high-level natural language processing is feasible through integrated subsymbolic systems. Subsymbolic control of high-level behavior and representing and learning abstractions are the two main challenges in scaling up the approach to more open-ended tasks.|NEURAL NETWORK ARCHITECTURES; NATURAL LANGUAGE PROCESSING; REASONING; COGNITIVE MODELING|KNOWLEDGE; NETWORKS; MODEL; TEXT; MAP|Computer Science, Artificial Intelligence|3|0|1
NATURAL-LANGUAGE PROCESSING USING A PROPOSITIONAL SEMANTIC NETWORK WITH STRUCTURED VARIABLES|1993|We describe a knowledge representation and inference formalism, based on an intensional propositional semantic network, in which variables are structures terms consisting of quantifier, type, and other information. This has three important consequences for natural language processing. First, this leads to an extended, more `'natural'' formalism whose use and representations are consistent with the use of variables in natural language in two ways: the structure of representations mirrors the structure of the language and allows re-use phenomena such as pronouns and ellipsis. Second, the formalism allows the specification of description subsumption as a partial ordering on related concepts (variable nodes in a semantic network) that relates more general concepts to more specific instances of that concept, as is done in language. Finally, this structured variable representation simplifies the resolution of some representational difficulties with certain classes of natural language sentences, namely, donkey sentences and sentences involving branching quantifiers. The implementation of this formalism is called ANALOG (A NAtural LOGIC) and its utility for natural language processing tasks is illustrated.|NATURAL LANGUAGE PROCESSING; KNOWLEDGE REPRESENTATION AND REASONING; SEMANTIC NETWORKS; SUBSUMPTION; QUANTIFIER SCOPING; LOGIC; ANALOG|FAMILY; QUANTIFIERS|Computer Science, Artificial Intelligence|8|0|1
SEGMENTAL INTELLIGIBILITY AND SPEECH INTERFERENCE THRESHOLDS OF HIGH-QUALITY SYNTHETIC SPEECH IN PRESENCE OF NOISE|1993|Technological advancement in the area of synthetic speech has made it increasingly difficult to distinguish quality of speech based solely on intelligibility scores obtained in benign laboratory conditions. Intelligibility scores obtained for natural speech and a high-quality text-to-speech system (DECtalk) are not substantially different. This study examined the perceived intelligibility and speech interference thresholds of DECtalk male and female voices and compared them with data obtained for natural speech. Results revealed that decreasing signal-to-noise levels had more deleterious effects on the perception of DECtalk male and female voices than on the perception of natural speech. Analysis of pattern of phoneme errors revealed that similar general patterns of errors tended to occur in DECtalk and in natural speech. The speech interference test did not demonstrate any significant difference between the DECtalk male and female voices. These results were supported by the absence of a significant difference between DECtalk male and female voices during intelligibility testing at different signal-to-noise ratios.|SYNTHETIC SPEECH; PERCEIVED INTELLIGIBILITY; SPEECH INTERFERENCE TEST; SPEECH IN NOISE; AUGMENTATIVE AND ALTERNATIVE COMMUNICATION|RULE; PERCEPTION|Language \& Linguistics; Rehabilitation|29|0|1
THE MULTIDIMENSIONAL APPROACH TO LINGUISTIC ANALYSES OF GENRE VARIATION - AN OVERVIEW OF METHODOLOGY AND FINDINGS|1992|The present paper summarizes the major methods and results of the multi-dimensional approach to genre variation. The approach combines the resources of computational tools, large text corpora, and multivariate statistical tools (such as factor analysis and cluster analysis). It has been used to address issues such as the relations among spoken and written genres in English, and the historical development of genres and styles. The approach has also been applied to other languages; in this regard it has been used to address broader theoretical issues, such as the extent to which genre and style variation are comparable cross-linguistically, and the linguistic consequences of literacy.|LINGUISTIC VARIATION; GENRE; STYLE; REGISTER; DIMENSION; FACTOR ANALYSIS; CLUSTER ANALYSIS; HISTORICAL CHANGE; ENGLISH; SOMALI|ENGLISH|Computer Science, Interdisciplinary Applications|15|0|1
Supervised and Unsupervised Aspect Category Detection for Sentiment Analysis with Co-occurrence Data|2018|Using online consumer reviews as electronic word of mouth to assist purchase-decision making has become increasingly popular. The Web provides an extensive source of consumer reviews, but one can hardly read all reviews to obtain a fair evaluation of a product or service. A text processing framework that can summarize reviews, would therefore be desirable. A sub-task to be performed by such a framework would be to find the general aspect categories addressed in review sentences, for which this paper presents two methods. In contrast to most existing approaches, the first method presented is an unsupervised method that applies association rule mining on co-occurrence frequency data obtained from a corpus to find these aspect categories. While not on par with state-of-the-art supervised methods, the proposed unsupervised method performs better than several simple baselines, a similar but supervised method, and a supervised baseline, with an F-1-score of 67\%. The second method is a supervised variant that outperforms existing methods with an F-1-score of 84\%.|Aspect category detection; consumer reviews; co-occurrence data; sentiment analysis; spreading activation|WORD-OF-MOUTH; IDENTIFICATION; INFORMATION|Automation \& Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics|0|0|0
Web of Science use in published research and review papers 1997-2017: a selective, dynamic, cross-domain, content-based analysis|2018|Clarivate Analytics's Web of Science (WoS) is the world's leading scientific citation search and analytical information platform. It is used as both a research tool supporting a broad array of scientific tasks across diverse knowledge domains as well as a dataset for large-scale data-intensive studies. WoS has been used in thousands of published academic studies over the past 20 years. It is also the most enduring commercial legacy of Eugene Garfield. Despite the central position WoS holds in contemporary research, the quantitative impact of WoS has not been previously examined by rigorous scientific studies. To better understand how this key piece of Eugene Garfield's heritage has contributed to science, we investigated the ways in which WoS (and associated products and features) is mentioned in a sample of 19,478 English-language research and review papers published between 1997 and 2017, as indexed in WoS databases. We offered descriptive analyses of the distribution of the papers across countries, institutions and knowledge domains. We also used natural language processingtechniques to identify the verbs and nouns in the abstracts of these papers that are grammatically connected to WoS-related phrases. This is the first study to empirically investigate the documentation of the use of the WoS platform in published academic papers in both scientometric and linguistic terms.|Web of Science; Scientometrics; Natural language processing; Eugene Garfield|IMPACT FACTOR; CITATION ANALYSIS; SCIENTOMETRICS; BIBLIOMETRICS; INFORMETRICS; JOURNALS; QUALITY; TRENDS; MISUSE; INDEX|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|0|0
The contribution of the lexical component in hybrid clustering, the case of four decades of ``Scientometrics{''|2018|The introduction of textual analysis and the use of lexical similarities already proved an important asset in science mapping. Earlier research showed the added value of hybrid document networks over link-based ones through the reduction of the extreme sparseness. However, it was only after the application of Natural Language Processing and phrase extraction that networks purely based on lexical similarities could be used as input for topic detection in quantitative science studies. This study investigates the contribution of the lexical component in hybrid cluster on a set of articles published in the journal Scientometrics since its foundation during four decades. Shifting the weight of the lexical components generates changes in the structure of the underlying hybrid network, which can be detected through clustering techniques. We show that these changes are not moving documents randomly, but in fact identify small groups of papers either at the borderline between different topics or combining those. In addition, the analysis substantiates that the lexical component adopts the structure of the network rather than amplifies hidden structures of the link-based network.|Science mapping; Lexical similarity; Hybrid clustering; Natural Language Processing; Scientometrics|INFORMATION|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|0|0
An indicator of technical emergence|2018|Developing useful intelligence on scientific and technological emergence challenges those who would manage R\&D portfolios, assess research programs, or manage innovation. Recently, the U.S. Intelligence Advanced Research Projects Activity Foresight and Understanding from Scientific Exposition Program has explored means to detect emergence via text analyses. We have been involved in positing conceptual bases for emergence, framing candidate indicators, and devising implementations. We now present a software script to generate a family of Emergence Indicators for a topic of interest. This paper offers some background, then discusses the development of this script through iterative rounds of testing, and then offers example findings. Results point to promising and actionable intelligence for R\&D decision-makers.|Emergence indicators; Technological emergence; Scientific emergence; Tech mining|SENSITIZED SOLAR-CELLS; EMERGING TECHNOLOGY; INNOVATION; SCIENCE; CHINA; MODEL|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|0|0
Functional structure identification of scientific documents in computer science|2018|The increasing number of open-access full-text scientific documents promotes the transformation from metadata- to content-based studies, which is more detailed and semantic. Along with the benefits of ample data, the confused internal structure introduces great difficulties to data organization and analysis. Each unit in scientific documents has its own function in expressing authors' research ideas, such as introducing motivations, describing methods, stating related work, and drawing conclusions; these could be used to identify functional structure of scientific documents. This paper firstly proposes a clustering method to generate domain-specific structures based on high-frequency section headers in scientific documents of a domain. To automatically identify the structure of scientific documents, we categorize scientific documents into three types: (1) strong-structure documents; (2) weak-structure documents; and (3) no-structure documents. We further divide the identification into three levels-section header-based identification, section content-based identification, and paragraph-based identification-corresponding to the three types of documents. Our experiments on documents in the field of computer science show that: (1) section header-based identification is the most direct and simplest method, but its accuracy is limited by unknown words in section headers; (2) section content-based identification is more stable and obtains good performance; and (3) paragraph-based identification is promising in identifying functions of no-structure documents. Additionally, we apply our methods to two tasks: academic search and keyword extraction. Both tasks demonstrate the effectiveness of functional structure.|Functional structure; Text categorization; Academic retrieval; Keyword extraction|AUTHOR COCITATION ANALYSIS; ARTICLES; CITATIONS; NETWORKS|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|0|0
Evaluating the nursing academicians in Turkey in the scope of Web of Science: scientometrics of original articles|2018|Scientometrics, bibliometrics, webometrics, and informetrics are specific research fields that cover statistical analyses of a particular research field which summarize the information related to topics handled during a particular time period; authors, citations and their demographic characteristics; network relationships among the authors. This study, which can be classified in both scientometrics and webometrics, aims at revealing the current situation and the performance of academicians working in the nursing field in Turkey through basic and advanced data analyses conducted on their published original articles in a Web of Science. The raw data including the details of the publications were first parsed into a novel database where the authors' affiliations were stored with respect to the data obtained from the website of the Turkish Higher Education Council. Over the integrated database, particular tables were generated to show the summary of the academic and demographic distributions of the publications. Specific statistical tests were applied to reveal the relationships and differences. Furthermore, analyses were carried out within text mining on authors, titles, keywords, abstracts, and references in order to examine the contents and references of the articles included in the data set to reveal keyword densities, particular topics, and co-authorship and citation networks. One of the challenging part of this research was the dataset collection and cleansing process, because of the special letters of Turkish Language, e.g. double dagger, AY, o, u. This issue was resolved when the representation pattern of the letters were discovered and queries were executed with respect to those patterns. This study has provided meaningful findings to both the field of nursing the scientometrics, since it reveals the academic performance in a particular field and systematically presents the current situation by examining the relevant studies in an analytical perspective.|Nursing research; Scientometrics; Turkish nursing academicians; Publication performance; Web of Science; Text analytics; Citation mining|BIBLIOMETRIC ANALYSIS; IMPACT FACTORS; JOURNALS; INFORMETRICS; HISTORY; TRENDS; FIELD|Computer Science, Interdisciplinary Applications; Information Science \& Library Science|0|0|0
Reporting Verbs as a Stylistic Device in the Creation of Fictional Personalities in Literary Texts|2017|This article presents an analysis of how reporting verbs can contribute to the creation of fictional personalities in literary texts. The examination of verbs was carried out using Caldas-Coulthard's (1987) taxonomy, in which verbs are classified in self-contained categories according to the reporter's level of mediation on the words glossed. The examples under analysis were all taken from Charles Dickens's Nicholas Nickleby (1839). For the sake of consistency, I focused on one character, Ralph Nickleby, whose words are reported using twenty-six verbs a total of 501 times throughout the story. As will be shown, Dickens's choice of verbs projects a specific way of speaking that triggers information about the villain's personality, thereby contributing to shaping his well-known evil character. The analysis will also illustrate how reporting verbs can influence the way in which readers form an impression of characters on the basis of their ways of speaking during the course of a story.|reporting verbs; fictional personalities; characterisation; Charles Dickens; Nicholas Nickleby; Ralph Nickleby|SPEECH|Linguistics; Language \& Linguistics; Literature|0|0|0
NLP-Based Approach to Semantic Classification of Heterogeneous Transportation Asset Data Terminology|2017|The inconsistency of data terminology has imposed big challenges on integrating transportation project data from distinct sources. Differences in meaning of data elements may lead to miscommunication between data senders and receivers. Semantic relations between terms in digital dictionaries, such as ontologies, can enable the semantics of a data element to be transparent and unambiguous to computer systems. However, because of the lack of effective automated methods, identifying these relations is labor intensive and time consuming. This paper presents a novel integrated methodology that leverages multiple computational techniques to extract heterogeneous American-English data terms used in different highway agencies and their semantic relations from design manuals and other technical specifications. The proposed method implements natural language processing (NLP) to detect data elements from text documents and uses machine learning to determine the semantic relatedness among terms using their occurrence statistics in a corpus. The study also consists of developing an algorithm that classifies semantically related terms into three different lexical groups including synonymy, hyponymy, and meronymy. The key merit in this technique is that the detection of semantic relations uses only linguistic information in texts and does not depend on other existing hand-coded semantic resources. A case study was undertaken that implemented the proposed method on a 16-million-word corpus of roadway design manuals to extract and classify roadway data items. The developed classifier was evaluated using a human-encoded test set, and the results show an overall performance of 92.76\% in precision and 81.02\% recall. (C) 2017 American Society of Civil Engineers.|Heterogeneous data terminology; Data sharing; Semantic interoperability; Semantic relation; Natural language processing; Vector space model; Transportation data|ONTOLOGY; RETRIEVAL; KNOWLEDGE; CONSTRUCTION; MODELS; TRENDS|Computer Science, Interdisciplinary Applications; Engineering, Civil|0|0|0
`So yo creo que es un proceso evolutivo': Language ideologies among Puerto Ricans in southeastern Pennsylvania|2017|This article examines the perspectives of Puerto Ricans living in the United States in response to a publicity campaign that focuses on the correction of linguistic features that appear in some Puerto Ricans' spoken Spanish. The campaign addresses phonetic, morphological, lexical, and syntactic features, including a specific set of words or phrases that are named as lexical and semantic borrowings from English. Participants were invited to respond to the content and ideologies present in the campaign by means of semi-structured interviews. Through a framework of Critical Discourse Analysis and language (de) legitimation, the article analyzes the ways in which interviewees (de) legitimize loanwords in Puerto Rican Spanish. A Critical Discourse Analytical framework allows for the mapping of spoken and written texts (e.g. the campaign texts) onto discourses about those texts (e.g. Puerto Ricans' perspectives). On a broader level, the article contributes to current research on dialectal diversity by analyzing speakers' ideologies in response to prescriptivist discourses that are present within and/or outside of their own speech networks and communities.|language contact; legitimation; loanwords; Puerto Rico; United States|UNITED-STATES; SPANISH; DISCOURSE; ENGLISH|Linguistics; Language \& Linguistics|0|0|0
Selecting relevant features from the electronic health record for clinical code prediction|2017|A multitude of information sources is present in the electronic health record (EHR), each of which can contain clues to automatically assign diagnosis and procedure codes. These sources however show information overlap and quality differences, which complicates the retrieval of these clues. Through feature selection, a denser representation with a consistent quality and less information overlap can be obtained. We introduce and compare coverage-based feature selection methods, based on confidence and information gain. These approaches were evaluated over a range of medical specialties, with seven different medical specialties for ICD-9-CM code prediction (six at the Antwerp University Hospital and one in the MIMIC-III dataset) and two different medical specialties for ICD-10-CM code prediction. Using confidence coverage to integrate all sources in an EHR shows a consistent improvement in F-measure (49.83\% for diagnosis codes on average), both compared with the baseline (44.25\% for diagnosis codes on average) and with using the best standalone source (44.41\% for diagnosis codes on average). Confidence coverage creates a concise patient stay representation independent of a rigid framework such as UMLS, and contains easily interpretable features. Confidence coverage has several advantages to a baseline setup. In our baseline setup, feature selection was limited to a filter removing features with less than five total occurrences in the trainingset. Prediction results improved consistently when using multiple heterogeneous sources to predict clinical codes, while reducing the number of features and the processing time. (C) 2017 Elsevier Inc. All rights reserved.|Feature selection; Data integration; EHR mining; Clinical coding; Data representation|PATIENT; REPRESENTATION; ASSIGNMENT; TEXT|Computer Science, Interdisciplinary Applications; Medical Informatics|0|0|0
Finding the Semantic Relationship Between Wikipedia Articles Based on a Useful Entry Relationship|2017|Wikipedia is the largest online Internet encyclopedia, and everyone can create and edit different articles. On the one hand, because it contains huge amounts of articles and there are many different language versions, it often faces synonymous and polysemy problems. On the other hand, since some of the similar Wikipedia articles may have the same topic of discussion, it needs a suitable way to identify effectively the semantic relationships between articles. This paper first uses three well-known semantic analysis models LSA, PLSA, and LDA as evaluation benchmarks. Then, it uses the entry relationship between Wikipedia articles to design its model. According to the experimental results and analysis, its model has high performance and low cost characteristics compared with other models. The advantages of its model are as follows: (1) it is a good model for finding the semantic relationships between Wikipedia articles; (2) it is suitable for dealing with huge amounts of documentation.|Aspect Model; Big Data Environment; Entry Relationship; Online Internet Encyclopedia; Semantic Analysis Model; Wikipedia Article|TEXT; KNOWLEDGE; MODELS; VIDEO|Computer Science, Software Engineering|1|0|0
What does corpus linguistics have to offer to language assessment?|2017|In recent years, continuing advances in technology have increased the capacity to automate the extraction of a range of linguistic features of texts and thus have provided the impetus for the substantial growth of corpus linguistics. While corpus linguistic tools and methods have been used extensively in second language learning research, they have also been used increasingly in the design and validation of language assessments (Callies \& Gotz, 2015; Deshors, Gotz, \& Laporte, 2016; Park, 2014). The collection of papers in this special issue represents an intentional and systematic effort to encourage the cross-pollination of corpus linguistics and language assessment. The research foci of these papers take this cross-disciplinary area in exciting, new directions. At the same time, the papers also point to some important gaps and provide inspiration for additional research. In this commentary, I offer some perspectives on how the papers contribute to this cross-disciplinary research area and then share my reflections on some of the gaps that need to be narrowed or closed if language testing researchers and practitioners are to take full advantage of the potential of corpus linguistics for language assessment.|Assessment design; assessment validation; automated linguistic analysis; corpus linguistics; language assessment|SYNTACTIC COMPLEXITY-MEASURES; ENGLISH; TEXTS|Linguistics; Language \& Linguistics|0|0|0
Incongruity-resolution cases in jokes|2017|The incongruity-resolution model is one of the most popular theories that propose an explanation for the strategies underlying humorous texts. In this paper, a taxonomy of incongruity-resolution Cases is proposed according to a relevance-theoretic stance. Then, the extent to which these Cases are exhaustive enough to cover the whole range of possible incongruity-resolution patterns is checked with a corpus of jokes. Furthermore, an analysis is carried out concerning the implications of matching certain kinds of jokes with specific Cases of the taxonomy. Some conclusions on their pragmatic quality and their overall humorous effects are also drawn.(C) 2017 Elsevier B.V. All rights reserved.|Incongruity; Resolution; Jokes; Humor; Relevance theory; Frame|HUMOR|Linguistics; Language \& Linguistics|0|0|0
Strength in Numbers: Using Big Data to Simplify Sentiment Classification|2017|Sentiment classification, the task of assigning a positive or negative label to a text segment, is a key component of mainstream applications such as reputation monitoring, sentiment summarization, and item recommendation. Even though the performance of sentiment classification methods has steadily improved over time, their ever-increasing complexity renders them comprehensible by only a shrinking minority of expert practitioners. For all others, such highly complex methods are black-box predictors that are hard to tune and even harder to justify to decision makers. Motivated by these shortcomings, we introduce BigCounter: a new algorithm for sentiment classification that substitutes algorithmic complexity with Big Data. Our algorithm combines standard data structures with statistical testing to deliver accurate and interpretable predictions. It is also parameter free and suitable for use virtually out of the box, which makes it appealing for organizations wanting to leverage their troves of unstructured data without incurring the significant expense of creating in-house teams of data scientists. Finally, BigCounter's efficient and parallelizable design makes it applicable to very large data sets. We apply our method on such data sets toward a study on the limits of Big Data for sentiment classification. Our study finds that, after a certain point, predictive performance tends to converge and additional data have little benefit. Our algorithmic design and findings provide the foundations for future research on the data-over-computation paradigm for classification problems.|sentiment analysis; big data; classification; opinion mining|SUPPORT VECTOR MACHINE; NEURAL-NETWORKS; FORMULAIC SEQUENCES; PRODUCT REVIEWS; LANGUAGE; WORD|Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods|0|0|0
The bothersome crow people and the silent princess: exploring the orientations of children as they play a digital narrative game|2017|This study builds on and extends our understanding of literacy through exploring children's encounters with a digital narrative game. The research analyses different stances or orientations that children take as they progress through the game and how they draw on schematic understandings about narratives and digital gaming to support their game-play. The study extends previous research exploring how children make meaning from visual texts and how we draw on resources across and between modes to understand narratives. Taking a socio-cultural approach, the research suggests a framework of possible orientations that children take as they engage with the storyworld of the game, showing how this is at times strategic and critical, and at other times immersive and reactive.|Digital games; reading; gaming literacy; multimodal; reading orientations; storyworlds|COMPREHENSION|Education \& Educational Research; Linguistics; Language \& Linguistics|0|0|0
Interpretation of Care Guidelines for Obese Women in Labor: Intergroup Language and Social Identity|2017|The hospital-based care of pregnant women who are obese is complex. Current guidelines recommend early epidural analgesia, but there is disagreement about the guidelines and their implementation by anesthesiologists. In this study, we conducted semistructured interviews with 42 specialist anesthesiologists about their experiences implementing the early epidural recommendation. We examined the impact of intergroup identity and system factors on the language used by anesthesiologists to express their experiences, framing the work by social identity and communication accommodation theory. Leximancer text mining was used to elicit the dominant theme epidural in the interviews, and discourse analysis aided in exploring selected extracts. Findings indicated that anesthesiologists expressed their role primarily as technical experts, along with the core value of accommodating patients' wishes. Furthermore, the extent to which they were prepared to accommodate the perspective of other health professionals was a key indicator of the intergroup climate.|communication accommodation theory; intergroup language; health communication; maternity care; anesthesiology|OBSTETRIC ANESTHESIA; NONTECHNICAL SKILLS; OPERATING-ROOM; COMMUNICATION; OUTCOMES; PARTURIENTS; PREGNANCY; RISK; METAANALYSIS; LEXIMANCER|Communication; Linguistics; Psychology, Social|0|0|0
Similarities and differences in constructs represented by US States' middle school writing tests and the 2007 National Assessment of Educational Progress writing assessment{*|2017|Little is known regarding the underlying constructs of writing tests used by U.S. state education authorities and national governments to evaluate the writing performance of their students, especially in middle school grades. Through a content analysis of 78 prompts and 35 rubrics from 27 states' middle school writing assessments from 2001 to 2007, and three representative prompts and rubrics from the United States' 2007 National Assessment of Educational Progress (NAEP) writing test, this study illuminates the writing constructs underlying large-scale writing assessments through examination of features in prompts and rubrics and investigation of the connections between prompts and rubrics in terms of genre demands. We found the content of state writing assessments and the NAEP align with respect to measurement parameters associated with (a) emphasis on writing process, audience awareness, and topic knowledge, (b) availability of procedural facilitators (e.g., checklists, rubrics, dictionaries) to assist students in their writing, and (c) inclusion of assessment criteria focused on organization, structure, content, details, sentence fluency, semantics, and general conventions. However, the NAEP's writing assessment differs from many state tests of writing by including explicit directions for students to review their writing, giving students two timed writing tasks rather than one, making informational text production one of the three genres assessed, and including genre-specific evaluative components in rubrics. This study contributes to our understanding of the direction and path that large-scale writing assessments in the US are taking and how writing assessments are continually evolving.|NAEP; Writing; Large-scale assessment|STUDENTS; KNOWLEDGE; INSTRUCTION; STRATEGIES; VALIDITY; AUDIENCE; GENRE|Education \& Educational Research; Linguistics|0|0|0
Automated classification of eligibility criteria in clinical trials to facilitate patient-trial matching for specific patient populations|2017|Objective:To develop automated classification methods for eligibility criteria in ClinicalTrials.gov to facilitate patient-trial matching for specific populations such as persons living with HIV or pregnant women. Materials and Methods:We annotated 891 interventional cancer trials from ClinicalTrials.gov based on their eligibility for human immunodeficiency virus (HIV)-positive patients using their eligibility criteria. These annotations were used to develop classifiers based on regular expressions and machine learning (ML). After evaluating classification of cancer trials for eligibility of HIV-positive patients, we sought to evaluate the generalizability of our approach to more general diseases and conditions. We annotated the eligibility criteria for 1570 of the most recent interventional trials from ClinicalTrials.gov for HIV-positive and pregnancy eligibility, and the classifiers were retrained and reevaluated using these data. Results:On the cancer-HIV dataset, the baseline regex model, the bag-of-words ML classifier, and the ML classifier with named entity recognition (NER) achieved macro-averaged F2 scores of 0.77, 0.87, and 0.87, respectively; the addition of NER did not result in a significant performance improvement. On the general dataset, ML + NER achieved macro-averaged F2 scores of 0.91 and 0.85 for HIV and pregnancy, respectively. Discussion and Conclusion:The eligibility status of specific patient populations, such as persons living with HIV and pregnant women, for clinical trials is of interest to both patients and clinicians. We show that it is feasible to develop a high-performing, automated trial classification system for eligibility status that can be integrated into consumer-facing search engines as well as patient-trial matching systems.|clinical trial screening; eligibility determination; machine learning; natural language processing; patient-trial matching|EFFICIENCY|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|0|0
MetaMap Lite: an evaluation of a new Java implementation of MetaMap|2017|MetaMap is a widely used named entity recognition tool that identifies concepts from the Unified Medical Language System Metathesaurus in text. This study presents MetaMap Lite, an implementation of some of the basic MetaMap functions in Java. On several collections of biomedical literature and clinical text, MetaMap Lite demonstrated real-time speed and precision, recall, and F-1 scores comparable to or exceeding those of MetaMap and other popular biomedical text processing tools, clinical Text Analysis and Knowledge Extraction System (cTAKES) and DNorm.|natural language processing; algorithms; software design; software validation; unified medical language system|CLINICAL TEXT; NORMALIZATION; ARCHITECTURE; RECOGNITION; CORPUS; SYSTEM|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|0|0
Recruiting Frontstage Entextualization: drafting, artifactuality and written-ness as resources in police - witness interviews|2017|This paper examines the complex literacy event through which police witness statements are produced in England and Wales. Witness statements are constructed through interviews which archetypally consist of a trajectory from the witness of the crime, through a police officer and onto a written page with the officer taking most control of the writing. This paper examines how this ostensibly inevitable trajectory materializes in practice. It identifies a distinctive way of traversing the trajectory through which the inner workings of the trajectory itself are put on display by the interviewing officer and through this display recursively influence the trajectory. This display of the trajectory draws on four discursive means: writing aloud, proposing wordings, reading back text just written and referring explicitly to the artifactuality of writing, which I label, collectively, ``Frontstage Entextualization.{''} Through Frontstage Entextualization, the writing process comes to be used as a resource for both producing text and involving the witness in text production. The paper identifies three forms of activity which are accomplished through Frontstage Entextualization: First, frontstage drafting which allows words and phrases for possible inclusion to be weighed-up; secondly, frontstage scribing which foregrounds the technology of pen and paper which allows the witness to be appraised of writing processes; and finally, frontstaging the sequentiality of written-ness to textually resolve difficulties of witness memory. The paper concludes by suggesting that the analysis has shown how text trajectories can be made accessible to lay participants by institutional actors.|Frontstage Entextualization; police interview; witness; text trajectories; writing|TALK; ORGANIZATION; ASYLUM; SCHOOL; TEXT|Communication; Linguistics; Language \& Linguistics|0|0|0
The metaphor at the service of melodrama in journalistic story in the Spanish transition to democracy|2017|This paper analyses different discourse strategies used by the journalist Jesus Duva in his report ``Los siete dias que hicieron temblar la Transicion{''} (The week the Spanish Democratic Transition trembled), in which features typically associated with melodrama are used to narrate the concatenation of events that culminated in the tragedies of 23rd and 24th January 1977, when Spain was immersed in the process of transforming the structures of a dictatorship into those of a democracy. The specific nature of political journalism in the construction of the discursive identity of a social group plays an important role here, as Duva's text not only aims to retrieve the historic memory of the Transition period, but it also mythologizes it. The passing of time contributes to this effect, as it has put the account of this political process into perspective, while also charting the schematic narration of a crucial event in the future that awaited that Spanish people. Specifically, one of the formulae adopted by the narration is melodrama, a fictitious system used to imbue the experience with meaning that explains how and why the episodes took place and that also presents a polarized world vision. One of the mechanisms used to enhance this melodramatic representation is, in fact, metaphor, which lends shape and substance to a narrative that brings a social group cohesion. Its capacity for simplification makes metaphor an extremely efficient tool in the sphere of politics, constituting an ideal resource for the transmitting of large amounts of information in a simple fashion. In our case, this means of conceptualization is an essential mechanism for the shaping of melodrama. As our analysis will show, several conceptual domains metaphorically shape a melodramatic account that moves the reader, provoking feelings of admiration and fear. These domains lend coherence to the text, working together and showing that melodramatic narration is an example of metaphorical systematization.|metaphor; political discourse; narrative; melodrama|LANGUAGE; IMMIGRATION|Linguistics; Language \& Linguistics|0|0|0
Towards generalizable entity-centric clinical coreference resolution|2017|Objective: This work investigates the problem of clinical coreference resolution in a model that explicitly tracks entities, and aims to measure the performance of that model in both traditional in-domain train/test splits and cross-domain experiments that measure the generalizability of learned models. Methods: The two methods we compare are a baseline mention-pair coreference system that operates over pairs of mentions with best-first conflict resolution and a mention-synchronous system that incrementally builds coreference chains. We develop new features that incorporate distributional semantics, discourse features, and entity attributes. We use two new coreference datasets with similar annotation guidelines the THYME colon cancer dataset and the DeepPhe breast cancer dataset. Results: The mention-synchronous system performs similarly on in-domain data but performs much better on new data. Part of speech tag features prove superior in feature generalizability experiments over other word representations. Our methods show generalization improvement but there is still a performance gap when testing in new domains. Discussion: Generalizability of clinical NLP systems is important and under-studied, so future work should attempt to perform cross-domain and cross-institution evaluations and explicitly develop features and training regimens that favor generalizability. A performance-optimized version of the mention synchronous system will be included in the open source Apache cTAKES software. (C) 2017 Elsevier Inc. All rights reserved.|Coreference; Clinical NLP; Portability; Generalizability; Machine learning|CLASSIFICATION; RECORDS|Computer Science, Interdisciplinary Applications; Medical Informatics|0|0|0
Ubiquitous clinic recommendation by predicting a patient's preferences|2017|Accurately identifying users' preferences for different service locations is sometimes difficult for a mobile application because of the limited options that can be provided by a cell phone in addition to the users' unwillingness or inability to conveniently express their preferences. However, such information, if precisely determined, can considerably enhance the effectiveness of the mobile application. On the basis of this concept, this study modified the existing fuzzy weighted average (FWA) nonlinear programming (NLP) approach by incorporating a mechanism of predicting a patient's unknown preferences for different nearby clinics to improve the performance of ubiquitous clinic recommendation. The proposed methodology was applied to a small region in Taiwan, and the experimental results confirmed its superiority over four existing methods in effectively improving the successful recommendation rates for patients in both training and testing groups. Comparing the results of the proposed methodology with those of the original FWA-NLP approach revealed that the proposed methodology has an advantage because of the mechanism of predicting patients' unknown preferences. (C) 2017 Elsevier B.V. All rights reserved.|Clinic recommendation; Fuzzy weighted average; Location-aware service; Nonlinear programming; Ubiquitous|LOCATION-AWARE SERVICE; HEALTH-CARE; SYSTEM; SATISFACTION; OPERATOR|Business; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications|0|0|0
A developmental study of prepositional phrases in Hebrew written text construction|2017|Prepositional phrases (PPs) are considered an important feature of mature written expression. However, little is known about the development of PPs during the school years. The study examined the use of PPs in 160 narrative and expository texts, written by Hebrew-users in grades 4, 7, and 11, and adults. PPs were identified, counted, and classified according to their syntactic roles. Statistical analyses were carried out to probe the effects of age and genre on the overall prevalence of PPs, and the prevalence of each role. Results show that PPs become more prevalent and functionally more diversified with age: PP prevalence increased significantly after grade 7 in both genres, and continued to rise after grade 11 in expositories. Grade 4 PPs had a limited set of roles, the majority serving as arguments. In the older age groups the proportion of arguments decreased, concomitantly with an increase in the prevalence of other roles - most markedly verb-adjuncts and noun-modifiers - and the emergence of new PP roles.|Expository; Hebrew; later language development; narrative; prepositional phrases; syntax; writing|DISCOURSE; ACQUISITION; GRAMMAR; USAGE|Psychology, Developmental; Linguistics; Language \& Linguistics|0|0|0
Talking grammatically: L1 adolescent metalinguistic reflection on writing|2017|This study investigated the metalinguistic reflections of 12 students, aged 14-15 years, undertaking a unit of work focused on reading and writing non-fiction. The unit embedded contextualised grammar teaching into preparation for English Language examinations. Students were interviewed twice, with prompts to discuss a sample of argument text in interview one, and a sample of their own writing in interview two. The interviews and subsequent analysis drew on Gombert's taxonomy of metalinguistic understanding, focusing on metasemantic, metasyntactic and metatextual reflections, and probing students' ability to link these to metapragmatic concerns. Similarly to previous studies, the findings suggest that students struggle to articulate the impact of metasyntactic choices; however, here it is suggested that this may be a particular artefact of the need for a specialised metalanguage for discussing syntax. Results also indicate a tendency to reify form-function relationships, and signal the potential benefit of using students' own writing as a platform for exploring authorial choices. Finally, the study contributes to the theorisation of metalinguistic understanding by suggesting how declarative knowledge may emerge from procedural activity, with interviews scaffolding students' ability to articulate what had initially been tacit language choices.|Writing; metalinguistic reflection; metalanguage; grammar; school|TEACHING GRAMMAR; ENGLISH; AWARENESS; SCHOOL; KNOWLEDGE; TEACHERS|Linguistics; Language \& Linguistics|0|0|0
The acquisition of Spanish and English as two first languages through the analysis of natural interpreting in bilingual children|2017|Research on the acquisition of two first languages from birth (2L1A) has focused, among other issues, on how the grammars of the two languages being acquired interact (e.g. Bhatia \& Ritchie, 2012; De Houwer, 2009; Deuchar \& Quay, 2000; Dopke, 2000; Koppe \& Meisel, 1995). A case in point is natural interpreting which evidences how bilingual children exposed to two languages from birth deal with the grammatical properties of the two languages and how this leads them to potentially convey the same message in either (or both) of these languages. More specifically, as part of the simultaneous processing of their two L1s, 2L1 bilingual children have been reported to often translate between their two L1s (Alvarez de la Fuente \& Fernondez Fuertes, 2012, 2015; Cossato, 2008; Harris, 1980a, 1980b; Harris \& Sherwood, 1978), a phenomenon that has been called natural interpreting (Harris, 1977, 2003). In this respect, natural interpreting can be included with other language contact phenomena, such as interlinguistic influence or code-switching, as a typical defining property of 2L1A. Therefore, in this study we aim to offer an analysis of the way in which Spanish-English bilingual children use natural interpreting in their 2L1A process by focusing on the Spanish-English bilingual corpora freely available through the CHILDES project (MacWhinney, 2000).|L1 bilingual acquisition; natural interpreting; Spanish-English; translation pairings|GENDER|Linguistics; Language \& Linguistics|0|0|0
Constructing `the French people' - On Sarkozy's populism|2017|Election campaigns represent a particular moment of political practice in democracies where political strategy and political discourse become one activity. Campaigns take effect through the speeches of candidates communicated to the electorate. This article analyses speeches of Nicolas Sarkozy's presidential campaigns in 2007 and 2012. Based on text statistical methods developed in French discourse analysis it examines his political position and his rhetorical techniques. In comparison to other presidents of the Fifth Republic, Sarkozy's discourse seems to be freed from typical party political positions. Whilst favouring direct encounters with the audience and pretending to speak to the whole nation he is embodying a form of populism which bestows his image of a charismatic leader.|Political discourse; election campaign; Sarkozy; logometry; populism|DISCOURSE|Linguistics; Language \& Linguistics|0|0|0
How words for sensory experiences become terms A cognitive approach|2017|Given the double nature of experiencing food as individual as well as shared experience and knowledge, the question is how to connect the observed variability of expressing such a sensory experience with a normalized requirement for developing (food) terminology. On the basis of descriptions of food experiences in actual practices involving the way food is consumed, evaluated and expressed by individuals - experts or not - in all their diversity, we propose to contribute cognitive (psychological and linguistic) expertise to terminology research. We analyze terms as cognitive units, defined within a psychological theory of natural categories as acts of meaning. In tracking the processes of terminological meaning construction in discourse we find intersubjective experience within the complex process of terminologization.|sensory experience; situated cognition; lexical resources; cognitive categories; word meaning constitution|WINE EXPERTISE; MEMORY; TERMINOLOGY; GUIDELINES; PERCEPTION; LANGUAGE; TASTERS; NOVICE; TALK|Linguistics; Language \& Linguistics|0|0|0
Making sense of events in literature and life through collaboration|2017|Purpose - The purpose of this conceptual paper is to make the case for the value of fostering collaborative sensemaking in responding to literature. Drawing on examples of classroom interactions in 6th-, 8th-, 11th-and 12th-grade classrooms, it proposes methods for teachers to foster collaborative sensemaking. Design/methodology/approach - Drawing on theories of ``participatory sensemaking{''} (Fuchs and De Jaegher, 2009), transactional literary response (Rosenblatt, 1994) and `` comprehension-as-sensemaking{''} pedagogy (Aukerman, 2013), this paper conceptualizes collaborative sensemaking to illustrate how teachers foster making sense of texts through sharing responses based on lived-world experiences, understanding the use of literary techniques and understanding events in students' own lives. Findings - Given that this is not an empirical study, there are no findings. The discussion of students' sensemaking practices in responding to classroom texts, suggests the importance of teachers creating open-ended response events in which students collaboratively support each other in making sense of characters' actions and events, as opposed to having to conform to teachers' predetermined agendas. Practical implications - Analysis of the classroom discussions suggests the importance of building students' trust in the process of sensemaking itself, fostering adoption of alternative perspectives as central to sensemaking and using activities for students' translating or rewriting events in texts to co-create texts with authors. Originality/value - This paper explores the importance of teachers engaging students in open-ended, sensemaking response events based on attending to `` n-between,{''} dialogic meanings through sharing emotions,|Teaching literature; English teaching; Curriculum English; Literacy teaching|LANGUAGE; ACCOUNT; SELF|Education \& Educational Research; Linguistics; Language \& Linguistics|0|0|0
Using word n-grams to identify authors and idiolects A corpus approach to a forensic linguistic problem|2017|Forensic authorship attribution is concerned with identifying the writers of anonymous criminal documents. Over the last twenty years, computer scientists have developed a wide range of statistical procedures using a number of different linguistic features to measure similarity between texts. However, much of this work is not of practical use to forensic linguists who need to explain in reports or in court why a particular method of identifying potential authors works. This paper sets out to address this problem using a corpus linguistic approach and the 176-author 2.5 million-word Enron Email Corpus. Drawing on literature positing the idiolectal nature of collocations, phrases and word sequences, this paper tests the accuracy of word n-grams in identifying the authors of anonymised email samples. Moving beyond the statistical analysis, the usage-based concept of entrenchment is offered as a means by which to account for the recurring and distinctive production of idiolectal word n-grams.|forensic linguistics; idiolect; authorship attribution; entrenchment; Enron|COLLOCATIONS; ATTRIBUTION; METHODOLOGY; SET|Linguistics; Language \& Linguistics|0|0|0
Colloquialization in journalistic writing The case of inserts with a focus on well|2017|Recent analyses of written text types have discovered significant frequency increases of colloquial or conversational elements, such as contractions, personal pronouns, questions or the progressive. This trend is often referred to as colloquialization. This paper presents a new perspective on colloquialization, with a special focus on the discourse marker well. The paper is divided into two parts. In the first part, we present new evidence of colloquialization on the basis of the TIME Magazine Corpus (Davies 2007), which allows analyses of diachronic change in recent written American English. The focus of our analysis is on highly frequent ``inserts{''} (Biber et al. 1999: 56), which are elements such as discourse markers (e.g., well and oh), backchannels (yeah, uh-huh, etc.), and hesitators (uh and um, etc.). We conclude that inserts significantly increase diachronically in TIME. In the second part of the paper, we focus on the element well in its function as a discourse marker. Through a combination of quantitative and qualitative analytical steps, we analyze its diachronic development in terms of its structural contexts and its pragmatic functions, fleshing out how the process of colloquialization has affected its usage in recent written American English. We argue that the integration of corpus linguistic and pragmatic methods in this case study represents a new step towards the field of corpus pragmatics, that is, ``the rapprochement between corpus linguistics and pragmatics and an integration of their key methodologies{''} (Ruhlemann and Aijmer 2014: 23).|colloquialization; inserts; discourse markers; well; Variability-based Neighbor Clustering (VNC); corpus pragmatics|FREQUENCY CHANGES; ACQUISITION; MARKERS; CORPUS|Linguistics; Language \& Linguistics|0|0|0
Processes of becoming-writer: thinking with a situated, relational and nomadic analysis to literacy research|2017|This paper arose out of a shared concern about how to explore young children's ways of becoming writers. A framework based on the nomad thought of French philosophers Gilles Deleuze and Felix Guattari was used to develop the analysis. A situated, relational and nomadic analysis offers insights into how processes of becomingwriters are produced, how they emerge and transform, as shown in this qualitative study of two Swedish early childhood classrooms. The analysis shows how social, cultural, linguistic, material and technological aspects interconnect and transform, and how this interrelatedness influences and forms six-year olds as writers. Young students constitute themselves as writers of classrooms through relating to the conventional norm of writing while simultaneously engaging in exploratory, creative and unpredictable processes of writing.|Nomadic analysis; becoming writers; early childhood writing classroom; Deleuze|PERSPECTIVES; ETHNOGRAPHY; CHILDHOOD; CLASSROOM; TEXTS; AGE|Education \& Educational Research; Linguistics; Language \& Linguistics|0|0|0
State contestations in constructions of 1Malaysia Saying it different to different people|2017|This article seeks to contribute to the existing body of knowledge about the relationship between political discourse and national identity. 1Malaysia, introduced in 2009 by Malaysia's then newly appointed 6th Prime Minister Najib Razak, was greeted with expectation and concern by various segments of the Malaysian population. For some, it signalled a new inclusiveness that was to change the discourse on belonging. For others, it raised concerns about changes to the status quo of ethnic issues. Given the varying responses of society to the concept of 1Malaysia, an examination of different texts through the critical paradigm of CDA provide useful insights into how the public sphere has attempted to construct this notion. Therefore, this paper critically examines the Prime Minister's early speeches as well as relevant chapters of the socioeconomic agenda, the 10th Malaysia Plan, to identify the referential and predicational strategies employed in characterising 1Malaysia. The findings suggest a notion of unity that appears to address varying issues.|1Malaysia; inclusiveness; referential strategies; predicational strategies; Critical Discourse Analysis|MALAYSIA|Linguistics; Language \& Linguistics|0|0|0
The linguistic expression of appraisal in judicial decisions: A contrastive study in French and Spanish|2017|This paper focuses on the linguistic mechanisms which reflect the speaker's subjective evaluation of textual contents, as well as on how different enunciative voices are intertwined in texts. In order to examine these evaluative mechanisms, Appraisal Theory (Halliday \& Mathiessen, 2004; Martin \& White, 2005) is applied to a bilingual corpus on liability in health care. The corpus is made up by twenty judicial decisions issued by both the first civil chamber of the French Tribunal de Cassation and the first civil chamber of the Spanish Tribunal Supremo during the first decade of the 21st century. The linguistic resources analysed in the study are those used by the speaker to convey subjective evaluation about the patient's initial condition, the medical intervention and the results of medical actions. The contrastive analysis has shed light on similarities and differences between French and Spanish related to evaluative linguistic mechanisms and core values that define healthcare responsibility in each culture.|Contrastive analysis; appraisal; judicial decisions; health care liability|HUMAN-RIGHTS; DISCOURSE|Linguistics; Language \& Linguistics|0|0|0
A computational implementation of idiomatic and non-idiomatic constructions|2017|Departing from a qualitative linguistic analysis based on corpus-attested examples, this paper provides a computational treatment of several construction-types, namely, argument-structure constructions, implicational constructions, and illocutionary constructions. Thus, our aim is to offer a formalized representation of constructions of varied nature and complexity. We do so through a lexico-conceptual knowledge base for natural language processing systems called FunGramKB, whose grammaticon is a computational implementation of the architecture of a usage-based constructionist model of language known as the Lexical Constructional Model.|Constructions; Lexical Constructional Model; FunGramKB; Natural Language Processing; COREL|GRAMMAR; LANGUAGE; FRAMENET|Linguistics; Language \& Linguistics|0|0|0
Strength of forensic text comparison evidence from stylometric features: a multivariate likelihood ratio-based analysis|2017|An experiment in forensic text comparison (FTC) within the likelihood ratio (LR) framework is described, in which authorship attribution was modelled with wordand character-based stylometric features. Chatlog messages of 115 authors were selected from a chatlog archive containing real pieces of chatlog evidence used to prosecute paedophiles. Four different text lengths (500, 1000, 1500 or 2500 words) were used for modelling in order to investigate how system performance is influenced by sample size. Strength of authorship attribution evidence (or LR) is estimated with the Multivariate Kernel Density formula. Performance was primarily assessed with the log-likelihood ratio cost (C-llr), but assessments of other metrics, e.g. credible interval and equal error rate, are also given. Taking into account the small number of features used for modelling authorship attribution, results are promising. Even with a small sample size of 500 words, the system achieved a discrimination accuracy of c. 76\% (C-llr = 0.68258). With a sample size of 2500 words, a discrimination accuracy of c. 94\% (C-llr = 0.21707) was obtained. Larger sample size is beneficial to FTC, resulting in an improvement in discriminability, an increase in the magnitude of the consistent-with-fact LRs and a decrease in the magnitude of the contrary-to-fact LRs. It was found that `Average character number per word token', `Punctuation character ratio', and vocabulary richness features are robust features, which work well regardless of sample sizes. The results demonstrate the efficacy of the LR framework for analysing authorship attribution evidence.|CHATLOG MESSAGES; FORENSIC TEXT COMPARISON; LIKELIHOOD RATIO; LOG-LIKELIHOOD RATIO COST; CREDIBLE INTERVAL; TIPPETT PLOT; STYLOMETRIC FEATURES; MULTIVARIATE KERNEL DENSITY MODEL|AUTHORSHIP ATTRIBUTION; HANDWRITING EVIDENCE; IDENTIFICATION; FRAMEWORK; MESSAGES; SCIENCE; DNA|Criminology \& Penology; Linguistics|0|0|0
Framework for Affective News Analysis of Arabic News: 2014 Gaza Attacks Case Study|2017|This paper aims at fostering the domain of Arabic affective news analysis through providing: (a) a benchmark annotated Arabic dataset of news for affective news analysis, (b) an aspect-based sentiment analysis (ABSA) approach for evaluating the sentimental affect of Arabic news posts on the reader, and (c) a baseline approach with a common evaluation framework to compare future research results with the baseline ones.|Affective News; Emotional Affect; Aspect Based Sentiment Analysis; Natural Language Processing; Arabic Dataset|SENTIMENT; MEDIA; TEXT|Computer Science, Software Engineering; Computer Science, Theory \& Methods|0|0|0
The instrumental case in the early language acquisition of Slovak-speaking children|2017|Using the frameworks of natural morphology and functional-semantic analysis, the paper deals with the polyfunctional instrumental case in early speech development (during the first 3 years of a child's life). Both a case study and a methodological study, it presents the results of research on grammatical forms, case meanings and the development of pragmatic functions. The key question is: which instrumental case structures do children acquire preferentially? The research is based on a combination of qualitative (audiovisual recordings of three children) and quantitative (1065 parental assessments) methods. Conclusions are reached on three levels: (a) form: maximal morphotactic transparency, regularity and simplicity are typical for preferentially acquired forms; (b) semantics: the preferentially acquired comitative and instrumental meanings can be interpreted as the linguistic representation of experience in social contact and in dealing with tools or means to accomplish one's goals; (c) pragmatics: children use the instrumental case in basic functions (to provide contextual information, for disagreements, answers, requests and commands). The research broadens the understanding of speech ontogenesis and contributes to a theory of language that is compatible with the process of its acquisition.|instrumental case; early childhood; Slovak; natural morphology|MORPHOLOGY; REGULARITY; GERMAN|Linguistics; Language \& Linguistics|0|0|0
Derivative creativity: the financialisation of the contemporary American novel|2017|This article offers a critical analysis of financialisation as a conceptual category for making sense of contemporary American fiction. Examining the rise of the figure of the creative entrepreneur as well as a range of contemporary fiction, the author argues that, to make sense of these developments and texts, we need to attend to how they reproduce the logic of finance, and in particular that of the financial instrument of the derivative. Like the financial derivative, the novels the author examines are future-oriented: they calculate and speculate on the ways they feed forward into new iterations and media. In addition, the texts and their authors are embedded within entrepreneurial networks within which different fields and competencies are brought into relation with one another. Through these conjunctures, the logic of finance becomes that of the contemporary novel.|Financialisation; derivative; entrepreneurship; creativity; contemporary novel|FINANCE|Cultural Studies; Linguistics; Language \& Linguistics; Literature|0|0|0
Syntactic Complexity in Narratives Written by Spanish Heritage Speakers|2017|The present study focuses on the analysis of syntactic complexity (SC) in written narratives produced by Spanish heritage language speakers, growing up in a multilingual context. In order to describe the level of syntactic complexity of a text, we considered traditional measures of SC (T-Units, mean length of T-Unit, syntactic complexity index, and percentage of error free clauses). Also, we assessed the type and frequency of subordinate clauses used in the children's written productions. Besides, we explored possible associations between syntactic complexity and different variables (such as age, Spanish input at home and time attending Spanish courses). Finally, we compared the SC performance of the heritage speakers (HS) with that of full Spanish speakers. Results showed that the groups do not differ greatly in the SC of their text productions. Findings are discussed considering the exposure to Spanish and the cognitive demands of writing.|Syntactic complexity; Heritage Speakers; Narratives; Written production; Subordinate Clauses|WRITING QUALITY; SPOKEN LANGUAGE; DISCOURSE; LEARNERS|Linguistics; Language \& Linguistics|0|0|0
Encountering the Posthuman Animal: Revisiting Dian Fossey's Gorillas in the Mist|2016|Posthumanist theory has rendered possible the rereading of texts that have until now been subjected to more traditional humanist critiques. By opening new exegetical dimensions through which to approach the literary artifact, we can not only challenge speciesist assumptions but also revisit the implications of both literary conventions and literary theory. The aim of this paper is to present an alternative, posthumanist interpretation of Dian Fossey's Gorillas in the Mist (1983) so as to analyze the manner by which the de-voiced nonhuman others are rendered as full biographical subjects that rise above the humanist emphasis on speech and reason. I begin with a critical overview of the posthumanist challenge and of the dialectical resistance imposed by humanist ideology. I then turn to an in-depth analysis of Gorillas in the Mist as an example of literary defiance of humanism. Through a series of rhetorical strategies, Fossey finds a way through which to speak the gorillas, at the same time as she relocates her own condition as a human within a space where a new form of encountering the other is possible.|posthumanism; Dian Fossey; primatology; (auto) biography; (animal)consciousness|PRIMATOLOGY; FIELD|Linguistics; Language \& Linguistics; Literature|0|0|0
Immune modulators in disease: integrating knowledge from the biomedical literature and gene expression|2016|Objective Cytokines play a central role in both health and disease, modulating immune responses and acting as diagnostic markers and therapeutic targets. This work takes a systems-level approach for integration and examination of immune patterns, such as cytokine gene expression with information from biomedical literature, and applies it in the context of disease, with the objective of identifying potentially useful relationships and areas for future research. Results We present herein the integration and analysis of immune-related knowledge, namely, information derived from biomedical literature and gene expression arrays. Cytokine-disease associations were captured from over 2.4 million PubMed records, in the form of Medical Subject Headings descriptor co-occurrences, as well as from gene expression arrays. Clustering of cytokine-disease co-occurrences from biomedical literature is shown to reflect current medical knowledge as well as potentially novel relationships between diseases. A correlation analysis of cytokine gene expression in a variety of diseases revealed compelling relationships. Finally, a novel analysis comparing cytokine gene expression in different diseases to parallel associations captured from the biomedical literature was used to examine which associations are interesting for further investigation. Discussion We demonstrate the usefulness of capturing Medical Subject Headings descriptor co-occurrences from biomedical publications in the generation of valid and potentially useful hypotheses. Furthermore, integrating and comparing descriptor co-occurrences with gene expression data was shown to be useful in detecting new, potentially fruitful, and unaddressed areas of research. Conclusion Using integrated large-scale data captured from the scientific literature and experimental data, a better understanding of the immune mechanisms underlying disease can be achieved and applied to research.|cytokines; disease; expression; MeSH; data integration|CYTOKINES; GRANULOMA; LANGUAGE; POLYMORPHISMS; SNAPSHOT; MEDLINE; HEALTH; FUTURE; CANCER; TEXT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|0|0|0
NEGOTIATING ALIGNMENT IN NEWSPAPER EDITORIALS: THE ROLE OF CONCUR-COUNTER PATTERNS|2016|Newspaper editorials are shaped by the need to negotiate alignment and rapport with a diverse readership. This is achieved partly through the resources of engagement (Martin and White 2005), that is, through the argumentative moves of disclaim, proclaim, entertain and attribute, by which dialogic relations with the reader are carefully modulated. One aspect of argumentation in editorials that has sometimes been overlooked is that of the concede-counter structure, by which the writer signals concurrence with the reader on a particular issue, only to counter this with a new argument that may wholly or partially refute the first one. Typically, leader writers signal this manoeuvre textually from the outset, indicating that they are setting up an argument in order to demolish it by means of specific lexical choices or patterns. Thus items such as ``of course{''} or ``naturally{''} are used to build up the first argument, with which the reader is understood to concur. This is generally followed by a turning point marked by ``but{''}, ``yet{''} or ``though{''}, after which the counter-argument is presented. Corpus linguists have pointed out that the presence of this type of lexical patterning makes it possible to research argumentation in large volumes of text using corpus tools. This study contains an analysis of concede-counter patterns in a corpus consisting of all the editorials published in the Guardian newspaper in 2011. The distinctive patterns that emerge are described, with particular attention paid to patterns of alignment and disalignment that emerge, as well as the related use of concurrence in asides to the reader. The role of such patterns in structuring discourse is analysed, with a particular focus on their ideological dimension as a means of subtly aligning readers with a particular set of opinions.|Editorials; Appraisal analysis; Discourse analysis; Concede-counter patterns; Adverbials|METADISCOURSE; DISCOURSE|Linguistics; Language \& Linguistics|0|0|0
Fuzzy Hindi WordNet and Word Sense Disambiguation Using Fuzzy Graph Connectivity Measures|2016|In this article, we propose Fuzzy Hindi WordNet, which is an extended version of Hindi WordNet. The proposed idea of fuzzy relations and their role in modeling Fuzzy Hindi WordNet is explained. We mathematically define fuzzy relations and the composition of these fuzzy relations for this extended version. We show that the concept of composition of fuzzy relations can be used to infer a relation between two words that otherwise are not directly related in Hindi WordNet. Then we propose fuzzy graph connectivity measures that include both local and global measures. These measures are used in determining the significance of a concept (which is represented as a vertex in the fuzzy graph) in a specific context. Finally, we show how these extended measures solve the problem of word sense disambiguation (WSD) effectively, which is useful in many natural language processing applications to improve their performance. Experiments on standard sense tagged corpus for WSD show better results when Fuzzy Hindi WordNet is used in place of Hindi WordNet.|Algorithms; Design; Languages; Centrality; fuzzy logic; fuzzy graph; Hindi WordNet; lexicon; word sense disambiguation|CONCEPT NETWORKS; SHORTEST PATHS; CENTRALITY; SETS|Computer Science, Artificial Intelligence|1|0|0
Nation-building and presidential rhetoric in Belarus|2016|This paper studies the Belarusian nation as envisioned by the president in his political speeches delivered on the country's Independence Day. The theoretical framework of the paper rests upon an understanding of the discursive construction of national identity. This analysis of the presidential speeches utilizes principles of the Discourse Historical Approach (DHA). As a special genre of texts, political speeches aim to offer normative guidance and a sense of societal consensus to the public. The paper reveals that in the construction of a national community in Belarus, the presidential speeches ambiguously refer to historical memory, socio-economic development, the political system and the country's foreign relations.|Belarus; nation-building; discourse; Discourse Historical Approach; political speeches; rhetoric|BELARUSIAN IDENTITY; MEMORY; HISTORY; NARRATIVES; CULTURE|Linguistics; Language \& Linguistics|0|0|0
How Many People Constitute a Crowd and What Do They Do? Quantitative Analyses of Revisions in the English and German Wiktionary Editions|2016|Wiktionary is increasingly gaining influence in a wide variety of linguistic fields such as NLP and lexicography, and has great potential to become a serious competitor for publisherbased and academic dictionaries. However, little is known about the ``crowd{''} that is responsible for the content of Wiktionary. In this article, we want to shed some light on selected questions concerning large-scale cooperative work in online dictionaries. To this end, we use quantitative analyses of the complete edit history files of the English and German Wiktionary language editions. Concerning the distribution of revisions over users, we show that - compared to the overall user base - only very few authors are responsible for the vast majority of revisions in the two Wiktionary editions. In the next step, we compare this distribution to the distribution of revisions over all the articles. The articles are subsequently analysed in terms of rigour and diversity, typical revision patterns through time, and novelty (the time since the last revision). We close with an examination of the relationship between corpus frequencies of headwords in articles, the number of article visits, and the number of revisions made to articles.|USER-GENERATED CONTENT; ONLINE DICTIONARY; WIKTIONARY; REVISION; EDIT; FREQUENCY; COLLABORATION; WISDOM OF THE CROWD|DICTIONARY|Linguistics; Language \& Linguistics|0|0|0
From possession to obligation via shifting distributions and particular constructions|2016|Studies of grammaticalization have identified a tendency for verbs of possession to develop modal meanings (Bybee et al. 1994, Heine \& Kuteva 2002). I present evidence of the mechanisms contributing to both semantic and structural change in one such instance, the Modern Spanish deontic modal construction {[}tener que + INF] ``to have to{''}. Quantitative analysis of a corpus of written texts confirms that this process is gradual and layered, exhibiting semantic changes measurable in the ratio of lexical infinitive types to total tokens of the constructions, changing tendencies in the construction's internal structure and the presence of highly frequent, lexically particular instances of tener que. This study presents quantifiable manifestations of grammaticalization processes that do not adhere to a linear, uniform cline and are consistently variable, even on a small scale.|Grammaticalization; modality; semantic change; Spanish; lexical diffusion|WORD-ORDER; ENGLISH|Linguistics; Language \& Linguistics|0|0|0
Language-specific information structure in German and Spanish route directions|2016|This paper investigates which linguistic resources speakers use to produce understandable and coherent route directions. These resources include how the information flows from one sentence to the next, how the information is mapped onto the topological route and how this information is encoded linguistically in order to be organized into a text. The aim of this paper is to show that syntactical differences between Spanish and German (the marking of subordination and the boundary crossing constraint) have consequences for the way the information is structured in route directions. The analyses are based on a corpus of 124 empirically collected route directions. The results include language-specific differences regarding information flow and information packaging.|route directions; language specificity; Spanish-German contrast; language relativity; linearization; information structure|SPACE|Linguistics; Language \& Linguistics|0|0|0
Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data|2016|Social media data with geotags can be used to track people's movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people's movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns.|Spatial temporal visual analytics; Geo-tagged social media; Sparsely sampling; Uncertainty. Movement|TRAJECTORY DATA; VISUALIZATION; AGGREGATION; EXPLORATION; ANALYTICS|Computer Science, Software Engineering|16|0|0
Discourse-driven V-to-C in Early Modern Romanian|2015|The Moldavian Chronicles of the 17th and 18th centuries are the first literary texts written directly in Romanian. In these Early Modern Romanian (EMR) texts, declarative clauses display an alternation between clitic > V(erb) and V(erb) > clitic orders, which reflects low verb movement (Verb-to-Tense/V-to-T) or high verb movement (Verb-to-Complementizer/V-to-C), respectively. The analysis concentrates on V-to-C, and demonstrates that, within a cartographic approach to the left periphery of the clause, V-to-C is actually V-to-Focus. Hence, the paper argues for discourse-driven (versus structure-preserving/formal) verb movement to C in EMR, and thus contributes to current studies that view V-to-C in Old Romance as an epiphenomenon of the information packaging at the left periphery of clauses.|Early Modern Romanian; Verb second; Long Head Movement; Wackernagel's law|CLITICS; SYNTAX; MOVEMENT; FOCUS|Linguistics; Language \& Linguistics|6|0|0
Automated Recognition of Russian Verse Meters: A Statistical and Corpus-Based Approach|2015|The aim of this paper is to discuss the theoretical grounds of, the arising problems in, and practical solutions for automated rhythmic-metrical and morphological-accentual analysis of Russian poetic texts. The metrical analysis of poetic texts written in a language with variable stress (such as Russian) should be based on the morphological analysis, from which we may proceed either using manual disambiguation, or applying the elements of syntactic analysis with automated disambiguation, or developing a probabilistic approach. The concluding section of the paper describes a statistical and corpus-based approach to the description of Russian classical ({''}explicit{''}) and non-classical ({''}implicit{''}) meters.|Russian metrics; automated meter recognition; probabilistic; statistical and corpus-based approach|ENGLISH|Linguistics; Language \& Linguistics|0|0|0
VERB-INITIAL ORDERS IN OLD ROMANCE: A COMPARATIVE ACCOUNT|2015|Against the backdrop of controversy over the correct analysis of Old Romance clausal structure, this article presents a comparative typology of the V1 orders found within seven Old Romance texts. Evidence is presented that all the languages under consideration feature V-to-C-Fin, movement and are thus types of verb-second (V2) grammar. The languages present a pattern of rich microvariation with regard to V1 phenomena however. The Old Sicilian, Old Occitan and Old Venetian varieties considered are argued to present widespread V1 which is employed as a discourse-marked word order alternative. In the later Old Spanish text presented V1 is attested as a marked word order, but is exceptionally rare. Old Sardinian contrasts with the other varieties is licensing generalised V1, derived via V-to-C-Fin movement. Later Old French makes use of the initial particle SI, in cases where the other varieties license V1 orders.|Old Romance; V1 order; V2 grammar; V-movement|LEFT PERIPHERY; ARGUMENT-DROP; MOVEMENT; PRO; FRENCH; V2; PRONOUNS; LANGUAGE; POSITION; YIDDISH|Linguistics; Language \& Linguistics|1|0|0
PRONOMINAL CLITICS IN OLD ROMANIAN: THE TOBLER-MUSSAFIA LAW|2015|This study analyzes the position occupied by pronominal clitics in the clause with respect to the verb in old Romanian (OR) on the basis of an extensive corpus analysis of 16th - 18th century texts. The corpus analysis shows that, from the earliest texts, OR pronominal clitics are attested in second, third, fourth, etc. position in the clause, and exceptionally also in first position. Therefore, they do not fully observe the Tobler-Mussafia Law, which was in function in old Romance languages. OR pronominal clitics are IP-clitics, which can be placed both in pre- and in postverbal position (proclisis and enclisis). Gradually, due to the going reduction of V-to-C movement, pronominal proclisis generalizes.|pronominal clitics; enclisis; proclisis; old Romanian; the Tobler-Mussafia Law; V-to-C movement|V2|Linguistics; Language \& Linguistics|1|0|0
TypingSuite: Integrated Software for Presenting Stimuli, and Collecting and Analyzing Typing Data|2015|Research into typing patterns has broad applications in both psycholinguistics and biometrics (i.e., improving security of computer access via each user's unique typing patterns). We present a new software package, TypingSuite, which can be used for presenting visual and auditory stimuli, collecting typing data, and summarizing and analyzing the data. TypingSuite is a Java-based software package that is platform-independent and open-source. To validate TypingSuite as a beneficial tool for researchers who are interested in keystroke dynamics, two studies were conducted. First, a behavioural experiment based on single word typing was conducted that replicated two well-known findings in typing research, namely the lexicality and frequency effects. The results confirmed that words are typed faster than pseudowords and that high frequency words are typed faster than low frequency words. Second, in regard to biometrics, it was also shown that typing data from the same user are more similar than data from different users. Because TypingSuite allows its users to easily implement an experiment and to collect and analyze data within a single software package, it holds promise for being a valuable educational and research tool in language-related sciences such as psycholinguistics and natural language processing.|Typing patterns; Keystroke dynamics; Psycholinguistics; Biometrics; Software|DYNAMICS IDENTITY VERIFICATION; KEYSTROKE DYNAMICS; MOTORIC ASPECTS; TEXT|Linguistics; Psychology, Experimental|0|0|0
Cross-Language Source Code Re-Use Detection Using Latent Semantic Analysis|2015|Nowadays, Internet is the main source to get information from blogs, encyclopedias, discussion forums, source code repositories, and more resources which are available just one click away. The temptation to re-use these materials is very high. Even source codes are easily available through a simple search on the Web. There is a need of detecting potential instances of source code re-use. Source code re-use detection has usually been approached comparing source codes in their compiled version. When dealing with cross-language source code re-use, traditional approaches can deal only with the programming languages supported by the compiler. We assume that a source code is a piece of text, with its syntax and structure, so we aim at applying models for free text re-use detection to source code. In this paper we compare a Latent Semantic Analysis (LSA) approach with previously used text re-use detection models for measuring cross-language similarity in source code. The LSA-based approach shows slightly better results than the other models, being able to distinguish between re-used and related source codes with a high performance.|Cross-Language Re-Use Detection; Source Code; Plagiarism; Latent Semantic Analysis|PLAGIARISM DETECTION; N-GRAMS; RETRIEVAL|Computer Science, Software Engineering; Computer Science, Theory \& Methods|2|0|0
On the categorization of seem and its Spanish renderings. Analysis of a parallel corpus|2015|The main objective of this paper is to categorize the values of seem in a parallel corpus of technical texts in English and Spanish. Considering syntactic and pragmatic issues, we offer a taxonomy of seem forms. This also includes the classification of this verb as an evidential or as an epistemic device. Data for analysis were taken from the Corpus of English-Spanish software localization at the University of Vigo (LOGALIZA), which is a compilation of technical texts in English with their corresponding translations into Spanish. The results of our analyses show that the translation of seem largely depends on the translator's own assumptions concerning the meaning of this form in the original texts during the process of translation. We conclude that seem has an evidential function in a high percentage of the analyzed samples.|Seem; evidentiality; modality; translation|EVIDENTIALITY|Linguistics; Language \& Linguistics|0|0|0
Czech intonation: A tonal approach|2014|In this article we describe a model of Czech intonation that is based on Danes's system of nuclear contours (1957), though, unlike Danes's system, it is formally inspired by autosegmental (tone-based) theory. After discussing the fundamental principles of the stylisation (prosodic phrase, types of tonal events, their scaling and their functions) we present and illustrate the inventories of prenuclear accents, boundary tones and nuclear contours. The findings of our analysis are based on two types of speech recordings (read newspaper texts and literary dialogues). Issues relating to the application of tonal events to prosodic phrases (alignment of nuclear contours, intonational homonymy and synonymy, structure of the phrase) are also discussed. We conclude the article by providing a general typological overview of Czech intonation.|intonation; Czech; autosegmental phonology; tonal stylisation; pitch accents; boundary tones; prosodic phrase|PITCH ACCENTS|Linguistics; Language \& Linguistics|0|0|0
IPLR: an online resource for Greek word-level and sublexical information|2012|We present a new online psycholinguistic resource for Greek based on analyses of written corpora combined with text processing technologies developed at the Institute for Language \& Speech Processing (ILSP), Greece. The ``ILSP PsychoLinguistic Resource{''} (IPLR) is a freely accessible service via a dedicated web page, at IPLR provides analyses of user-submitted letter strings (words and nonwords) as well as frequency tables for important units and conditions such as syllables, bigrams, and neighbors, calculated over two word lists based on printed text corpora and their phonetic transcription. Online tools allow retrieval of words matching user-specified orthographic or phonetic patterns. All results and processing code (in the Python programming language) are freely available for noncommercial educational or research use.|Online resources; Text corpora; Sublexical variables; Psycholinguistics; Greek; Syllabification; Bigrams|LEXICAL DATABASE; TRANSPARENCY; FREQUENCY; ENGLISH; MANULEX; UNITS|Computer Science, Interdisciplinary Applications|19|0|0
Spanish Heritage Language Learners' Allocation of Time to Writing Processes in English and Spanish|2011|This study brings together previous research on writing processes and Spanish heritage language (SHL) learners to obtain a clearer picture of these learners' writing behaviors in English and Spanish. Following a cognitive-oriented framework, the study explores planning time, execution time, monitoring time, accuracy, and fluency. Twelve SHL learners in a third-year Spanish class at a university in the US Southwest participated in the study. Screen-capture software recorded their behaviors while they responded to similar prompts in Spanish and English. Results indicated that participants spent significantly more time planning between sentences in their Spanish responses. Nevertheless, they showed more fluency (word output, mean sentence length, and words per minute) and accuracy in English than in Spanish. These findings, along with the participants' more limited experience with academic writing in Spanish, suggest that SHL curricula should draw upon any previous Spanish writing experience students may have had and move from informal to more academically oriented assignments.|accuracy; cognitive approach; execution; fluency; monitoring; planning; screen-capture software (Camtasia); Spanish heritage language learners; time allocation; writing processes|FORMULATION PROCESSES; TEMPORAL ANALYSIS; GENERATING TEXT; STUDENT WRITERS; FOREIGN; L1; L2; PROFICIENCY; PROFILES; ACCURACY|Linguistics; Language \& Linguistics; Literature, Romance|7|0|0
ANTONYMOUS FRAMEWORKS IN SERBIAN WRITTEN DISCOURSE: PHRASAL CONTEXTS OF ANTONYM CO-OCCURRENCE IN TEXT|2011|This paper presents the results of a study that analyzes antonym co-occurrence in written texts in a corpus of contemporary Serbian language. It adopts the metalexical approach to paradigmatic semantic relations, which posits that semantic relations among words are represented as part of what we know about the words. Antonymy is within this theoretical framework viewed as a conceptual relation, derivable by a single relational principle. Contexts of antonym use in the sentence seem to be structured and can be explained if conceptual approach to antonymy is adopted. Two major, and four minor, functions of antonyms have been identified in discourse, matching the results of similar analyses in other languages, such as English, Japanese, Swedish and Dutch. Antonyms in Serbian written discourse are predominantly used with an aim to either maximize contrast or annul its existence. This ``paradox{''} can be explained if we postulate that antonyms are minimally different (i.e. similar but for one relevant difference) which makes it possible for the language users to focus on either of these two properties when they use them in discourse. This paper describes the notion of antonymous framework and the roles that antonyms can have in these phrasal contexts. The conclusions provide support to conceptual approach to antonymy and contribute to investigations of antonyms from pragmatic perspective using corpus data.|Antonym; antonymous framework; contrast; written discourse|ENGLISH; ADJECTIVES; OPPOSITES|Linguistics; Language \& Linguistics|9|0|0
Semantic Space models for classification of consumer webpages on metadata attributes|2010|To deal with the quantity and quality issues with online healthcare resources, creating web portals centred on particular health topics and/or communities of users is a strategy to provide access to a reduced corpus of information resources that meet quality and relevance criteria. In this paper we use hyperspace analogue to language (HAL) to model the language use patterns of webpages as Semantic Spaces. We have applied machine learning methods, including support vector machine (SVM), decision forest, and a novel summed similarity measure (SSM) to automatically classify online webpages on their Semantic Space models. We find classification accuracy on metadata attributes to be over 93\% for `medical' versus `supportive' perspective, over 92\% for disease stage of `early' versus `advanced', and over 90\% for author credentials of `lay' versus `clinician' based on webpages of the Breast Cancer Knowledge Online portal. These results indicate that language use patterns can be used to automate such classification with useful levels of accuracy.(c) 2010 Elsevier Inc. All rights reserved.|Consumer health information; Internet; Metadata; Natural language processing; Breast cancer|WEB|Computer Science, Interdisciplinary Applications; Medical Informatics|8|0|0
Centering and noun phrase realization in Kaqchikel Mayan|2010|Centering Theory is applied to a narrated film retelling in Kaqchikel Mayan in Older to better understand discourse constraints on the form of referring expression It is shown that Backwards-Looking Centers are very often encoded by zero pronouns. and that center Shifts mole often employ full pronouns and full noun phrases than do center Continues and Retains Preverbal pronouns and full noun phrases as opposed to postverbal pronouns and full noun phrases correlate with center Shifts Morphological ergativity is seen to have no effect on the proper tanking of Forward-Looking Centers in that in morphologically creative languages. just as in morphologically accusative languages, subjects should be taken to outrank objects in transitive sentences A comparison of the Kaqchikel text with Du Bois' (1987) analysis of Sacapultec Mayan film-retelling narratives supports this ranking by showing that ergative subject arguments more often encode participants that are `given' in the discourse than do absolutive object arguments (c) 2009 Elsevier B.V. All rights reserved|Reference; Centering Theory; Pronoun; Zero pronoun; Eigativity; Mayan languages|DISCOURSE|Linguistics; Language \& Linguistics|1|0|0
Professional documents for a non-expert audience. The use of mechanisms of reference in the March 11 court sentence|2010|The aim of this paper is to analyze one of the court sentences that has had a great impact on Spanish History: the sentence on the case of the terrorist attacks of March 11, 2004, in Madrid. The linguistic interest of this sentence is that its author was especially aware that the text would be widely disseminated not only in the legal field but also in the mass media. Our hypothesis is that due to this exceptional context, the M11 court sentence is an example of a real attempt to write a legal text comprehensible to a non-expert audience. Our study of this court sentence focuses on the quantitative and qualitative analysis of a linguistic aspect that clearly shows the effort made by the judge pronouncing the sentence to ensure clarity: the use of anaphoric demonstrative expressions ('this', `this phenomenon' ...). The analysis of this mechanism of reference in the M11 court sentence is contrasted with the same mechanism in six other sentences passed by the same court, the Audiencia Nacional (The High Court). The findings shed light on how Professional Discourse Analysis could contribute to the modernization of Spanish judicial discourse.|Legal sentences; readability; professional discourse-optimization; demonstrative pronouns; anaphoric nouns|DISCOURSE; NOUNS|Linguistics; Language \& Linguistics|2|0|0
Porting a lexicalized-grammar parser to the biomedical domain|2009|This paper introduces a state-of-the-art, linguistically motivated statistical parser to the biomedical text mining community, and proposes a method of adapting it to the biomedical domain requiring only limited resources for data annotation. The parser was originally developed using the Penn Treebank and is therefore tuned to newspaper text. Our approach takes advantage of a lexicalized grammar formalism, Combinatory Categorial Grammar (CCG), to train the parser at a lower level of representation than full syntactic derivations. The CCG parser uses three levels of representation: a first level consisting of part-ofspeech (POS) tags; a second level consisting of more fine-grained CCG lexical categories: and a third, hierarchical level consisting of CCG; derivations. We find that simply retraining the POS tagger on biomedical data leads to a large improvement in parsing performance, and that using annotated data at the intermediate lexical category level of representation improves parsing accuracy further. We describe the procedure involved in evaluating the parser, and obtain accuracies for biomedical data in the same range as those reported for newspaper text, and higher than those previously reported for the biomedical resource on which we evaluate. Our conclusion is that porting newspaper parsers to the biomedical domain, at least for parsers which use lexicalized grammars, may not be as difficult as first thought. (C) 2008 Elsevier Inc. All rights reserved.|Statistical parsing; Tagging; CCG; Porting; Annotation; Evaluation|MODELS; CCG|Computer Science, Interdisciplinary Applications; Medical Informatics|18|0|0
A multi-modal ethnopoetic analysis (Part 1): Text, gesture, and environment in Japanese spatial narrative|2009|In this paper, I examine the interplay of language-specific factors and socio-cognitive motivations for the poetic construction of language and gesture in Japanese spatial narrative. By employing an ethnopoetic approach and analyzing the text, the body, and the environment in conjunction with the thematic cohesion via ``catchment{''} {[}McNeill, D., 2004. Gesture and Thought. The University of Chicago Press, Chicago], I argue that speakers coordinately cue subtle shifts of the narrative phases in terms of forms, referents, and shifts of hand gestures. Based on this argument, I claim that not only linguistic but also multi-modal semiotic resources can substantially contribute to the achievement of holistic poetic configuration and an inter-subjective schema for narrative comprehension. (C) 2009 Elsevier Ltd. All rights reserved.|Narrative; Gesture; Multi-modality; Ethnopoetics; Spatial description|DISCOURSE; COMMUNICATION; LANGUAGE|Communication; Linguistics|5|0|0
From ``textual{''} to ``interpersonal{''}: On the diachrony of the Italian particle mica|2009|This paper investigates the development of the Italian negative particle mica as an increase in ``intersubjectivity{''}, in the sense of an increasing coding of the speaker's awareness of the interlocutor' attitudes and beliefs (cf. e.g. Traugott, in press). Extending to a diachronic perspective Schwenter's (2003, 2005, 2006) hypotheses on the relationship between marked, or ``non-canonical{''}, negation and information structural constrains, the first part of the paper examines the relationship between the negated proposition and the preceding co-text in data from the XIII to the XX century. Two main trends are identified: (i) a decrease of the cases where the link with the preceding co-text is explicitly activated, as opposed to prompted by inferrable elements of the preceding co-text; (ii) an increase in ``dialogual{''} (dyadic) contexts. The combination of these trends identifies a cline, from a cluster of monologual contexts in which p is discourse-old by virtue of explicit textual evocation, to a cluster of dialogual contexts in which an increasing amount of inferencing on behalf of the interlocutors is required. Such a cline is argued to be indicative of a more general shift in the use of mica: from a ``textual{''} mode, pertaining to the level of text-construction, to an ``interpersonal{''} mode, centered on the locutor-interlocutor interaction. This trend is confirmed by analysis of Present Day Italian data in the second part of the paper, where mica is shown to acquire both a polyphonic and a mitigating function in interrogative contexts. The role of dialogual contexts is highlighted in favoring the development of such polyphonic and intersubjective polysemies. The investigation has bearing on three main issues: (i) the discursive function of negation; (ii) the notion of `discourse-old' and more in general the textual dimension of giveness; (iii) the methodological importance of an interactional approach to change, in the identification of dialogual vs. monologual contexts as a locus for the acquisition of salient properties in the evolution of the particle. (C) 2008 Elsevier B.V. All rights reserved.|Negation; Non-canonical; Intersubjectification|NEGATION|Linguistics; Language \& Linguistics|8|0|0
Categorization of web pages - Performance enhancement to search engine|2009|With the advent of technology man is endeavoring for relevant and optimal results from the web through search engines. Retrieval performance can often be improved using several algorithms and methods. Abundance in web has impelled to exert better search systems. Categorization of the web pages abet fairly in addressing this issue. The anatomy of the web pages, links, categorization of text and their relations are empathized with time. Search engines perform critical analysis using several inputs for a keyword(s) to obtain quality results in shortest possible time. Categorization is mostly done with separating the content using the web link structure, We estimated two different page weights (a) Page Retaining Weight (PRW) and (b) Page Forwarding Weight (PFW) for a web page and grouped for categorization. Using these experimental results we classified the web pages into four different groups i.e. (A) Simple type (B) Axis shifted (c) Fluctuated and ((I) Oscillating types. Implication in development of such categorization alleviates the performance of search engines and also delves into study of web modeling studies. (C) 2008 Elsevier B.V. All rights reserved.|Categorization; Web pages; Link analysis; Information Retrieval|INFORMATION-RETRIEVAL; SYSTEMS; DESIGN|Computer Science, Artificial Intelligence|5|0|0
Scientizing Bangladeshi psychiatry: Parallelism, enregisterment, and the cure for a magic complex|2008|This article combines textual, videotape, historical, and ethnographic evidence to describe the Bangla psychiatric register and its enregisterment. Enregisterment is a process ``through which a linguistic repertoire becomes differentiable {[}and] ... socially recognized{''} (Agha 2003:231). The emergence of psychiatric registers in Europe and, later, Bangladesh bore the particular burden of psychiatry's ``magic complex{''} - its need to convince a skeptical public that its perceived associations with magic and religion were finished, vanquished in part by discursive measures, focused on a scientizing drive. Psychiatric Bangla appears to involve the sort of pervasive use of parallelism normally associated with ritual texts. This indicates a profound hybridity that may contribute to the psychiatric unease epitomized in the magic complex.|enregisterment; linguistic anthropology; psychiatry; poetics; parallelism; classification; natural kinds; Bangladesh|LANGUAGE; CULTURE; FEAR|Linguistics; Sociology|13|0|0
WHAT DO WORD-INTERNAL PAUSES, CUT-OFFS, AND RETRACINGS TELL ABOUT INFLECTIONAL PROCESS?|2008|The oral processing of inflectional forms, in comparison with writing, is characterized by shorter processing times. The pauses, cut-offs, and retracings are a natural part of the oral producing process of native speakers and language learners alike. The paper argues that the occurrence, frequency and location of pauses, cut-offs and retracings within inflectional forms are not coincidental, but give valuable information about psycholinguistics; processes. The argument is based on a study of morphological production of Finnish plural nominals by Estonian and Russian learners. The paper discusses the production in oral inflection tests of context-free words. The second data-type consists of the learners comments on how they process the same words in a written test, and the retrospective interviews with the learners. Both data-types were used to explore the following questions: 1. How do the learners perceive the morphological formatives? 2. Is the notion of the inflectional paradigm psycholinguistically real for the learners? 3. Are the inflectional processes of the learners always linear? 4. How does the learners' first language influence the use of the pauses, cutoffs and retracings? The study concludes that the borders of the morphological formatives are quite indistinct in the minds of the learners and that the perception and production of formatives depends mostly on the syllabic structure of the formative. The data also seems to confirm the assumption that the inflectional paradigms are psycholinguistically real in the learners' perceptions, but there are individual differences and variance by the L-2 proficiency. The inflectional process is not necessarily always linear, and the interaction between stem and suffix allomorphs has an important role in processing inflectional forms. The use of the pauses, cut-offs and retracings is more determined by the personal characteristics of learners than by the first language influence.|psycholinguistics; morphological processing; oral production; inflection test; context-free words; Finnish as a foreign language; Estonian and Russian learners|MORPHOLOGY; FINNISH|Linguistics; Language \& Linguistics|1|0|0
The interaction of cartoonist's gender and formal features of cartoons|2007|The present study investigates gender differences in the use of formal features of cartoons, like the amount of text, the number of panels, or the application of color. For the analysis, 300 cartoons (150 each by female and male cartoonists) were selected randomly from the works of 1519 cartoonists. Twenty-one formal features were analyzed. On average, female cartoonists use more text, include text more frequently, and also draw more panels. These differences were expected, because Differential Psychology has shown for a long time in a variety of cultures that, on average, women tend to perform better in tasks testing verbal intelligence whereas men perform significantly better in tasks that require spatial intelligence. We also found a difference in the type of joke: Women more frequently draw cartoons with incongruity-resolution humor, whereas men prefer to draw cartoons with nonsense humor. The results are discussed in relation to gender differences in humor processing and gender differences in general.|cartoon; humor; gender; formal features|CAPTIONED CARTOONS; HUMOR; APPRECIATION; RATINGS|Language \& Linguistics; Psychology, Multidisciplinary|8|0|0
Theme analysis of narratives produced by children with and without Specific Language Impairment|2005|Theme is defined within the Systemic-Functional Linguistics framework as the point of the departure for the clause and therefore important for text organisation. Aspects of theme are examined in the elicited narratives and story retells from a group of 25 5-8 year-old children with Specific Language Impairment (SLI) and a group of 25 age-matched children with Typically Developing Language. The analysis indicated that subjects with SLI used less variety and complexity in themes with more than one element but this is suggested to reflect localised lexicogrammatical problems. Analysis of the aspects of theme which are more reliant on text-level resources, namely marked theme and theme progression patterns, yielded equivocal results. No significant inter-group difference was found in the subjects' representation of marked Theme and only one of the two progression patterns showed a significant difference. These findings are discussed in relation to the theoretical implications for the description of narrative abilities in SLI.|narrative analysis; theme; Specific Language Impairment|4-YEAR-OLDS; DISCOURSE|Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation|6|0|0
From representational to scopal `distancing indirect speech or thought': A cline of subjectification|2004|`Distancing indirect speech or thought' (DIST) is defined as a noncanonical form of speech or thought representation which is characterized by the singleness of deictic center across both component clauses: Contrary to direct, indirect, or free indirect speech/thought, no truly separate consciousness ('sayer/cognizant') is represented by the current speaker ('speaker'), even though the grammar of speech or thought representation is used. In this way, a `corrective', distancing effect vis-a-vis the main proposition is obtained. Examples include He mailed you earlier today, he said and Did I want that? (she asked). In this article, I will argue that two structurally distinct subtypes of DIST have to be recognized, viz. `representational' and `scopal' DIST I will discuss these as they manifest themselves in different registers (academic discourse, news reports, literary texts), and will associate them on the basis of this text analysis with distinct contextual usage types. Finally, I will relate representational and scopal DIST in terms of a cline of increasing subjectification.|reported speech; distancing indirect speech/thought; deixis; scope; subjectification; grammaticalization|DISCOURSE; OBJECT|Communication; Linguistics; Language \& Linguistics|13|0|0
Experimental evaluation of hypertext access structures|2002|Transient hypertextual access structures (THASs) are temporary graphs formed automatically on the basis of the situation-dependent information needs of software engineers. The approach is implemented in the HyperSoft system, which is a hypertext-based software maintenance support tool. THASs highlight the relevant parts of the program and enable nonlinear browsing between them. The system also supports various graphical views whose elements are linked to the program text. This paper describes the effects of using these hypertextual structures in two separate experiments. The subjects of both experiments were computer science students (total N = 70). In both experiments, the subjects performed a series of sample information accesses from a C program. HyperSoft and conventional text browsing and searching were compared. The results from the two experiments are well in line with our hypothesis of the usefulness of the approach and with each other. The results indicate better task performance while using THASs as compared to using the information seeking capabilities of a conventional compiler environment. The difference is statistically significant (p < 0.001). Copyright (C) 2002 John Wiley \& Sons, Ltd.|reverse engineering; program comprehension; program analysis|SOFTWARE MAINTENANCE; COMPREHENSION; SUPPORT; SYSTEMS; ENVIRONMENT; DATABASES; TOOLS; MODEL; TEXT|Computer Science, Software Engineering|8|0|0
Forensic speaker identification based on spectral moments|2002|A new method for doing text-independent speaker identification geared to forensic situations is presented. By analysing `isolexemic' sequences, the method addresses the issues of very short criminal exemplars and the need for open-set identification. An algorithm is given that computes an average spectral shape of the speech to be analysed for each glottal pulse period. Each such spectrum is converted to a probability density function and the first moment (i.e. the mean) and the second moment about the mean (i.e. the variance) are computed. Sequences of moment values are used as the basis for extracting variables that discriminate among speakers. Ten variables are presented all of which have sufficiently high inter- to intraspeaker variation to be effective discriminators. A case study comprising a ten-speaker database, and ten unknown speakers, is presented. A discriminant analysis is performed and the statistical measurements that result suggest that the method is potentially effective. The report represents work in progress.|speaker identification; spectral moments; isolexemic sequences; glottal pulse period|RECOGNITION|Criminology \& Penology; Linguistics|9|0|0
The hidden dimension: a paradigmatic view of data-driven NLP|1999|Many tasks in language analysis are described as the maximally economic mapping of one level of linguistic representation onto another such level, Over the past decade, many different machine-learning strategies have been developed to automatically induce such mappings directly from data. In this paper, we contend that the way most learning algorithms have been applied to problems of language analysis reflects a strong bias towards a compositional (or biunique) model of interlevel mapping. Although this is justified in some cases, we contend that biunique inter-level mapping is not a jack of all trades. A model of analogical learning, based on a paradigmatic reanalysis of memorized data,is presented here. The methodological pros and cons of this approach are discussed in relation to a number of germane linguistic issues and illustrated in the context of three case studies: word pronunciation, word analysis, and word sense disambiguation, The evidence produced here seems to suggest that the brain is not designed to carry out the logically simplest and maximally economic way of relating form and function in language. Rather we propose a radical shift of emphasis in language learning from syntagmatic inter-level mapping to paradigmatically-constrained intra-level mapping.|data-driven NLP; memory-based learning; analogical language learning|ENGLISH; MODEL|Computer Science, Artificial Intelligence|7|0|0
Dependency parsing for medical language and concept representation|1998|The theory of conceptual structures serves as a common basis for natural language processing and medical concept representation. We present a PROLOG-based formalization of dependency grammar that can accommodate conceptual structures in its dependency rules. First results indicate that this formalization provides an operational basis for the implementation of medical language parsers and for the design of medical concept representation languages. (C) 1998 Elsevier Science B.V.|dependency grammar; medical concept representation language; conceptual graphs; natural language processing; feature unification|UNIFICATION|Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics|2|0|0
SYMCON - A hybrid symbolic connectionist system for word sense disambiguation|1997|Connectionist methods and knowledge-based techniques are two largely complementary approaches to natural language processing (NLP). However, they both have some potential problems which preclude their being a general purpose processing method. Research reveals that a hybrid processing approach that combines connectionist with symbolic techniques may be able to use the strengths of one processing paradigm to address the weakness of the other one. Hence, a system that effectively combines the two different approaches can be superior to either one in isolation. This paper describes a hybrid system-SYMCON (SYMbolic and CONnectionist) which integrates symbolic and connectionist techniques in an attempt to solve the problem of word sense disambiguation (WSD), which is arguably one of the most fundamental and difficult issues in NLP. It consists of three sub-systems: first, a distributed simple recurrent network (SRN) is trained by using the standard back-propagation algorithm to learn the semantic relationships among concepts, thereby generating categorical constraints that are supplied to the other two sub-systems as the initial results of pre-processing. The second sub-system of SYMCON is a knowledge-based symbolic component consisting of a knowledge base containing general inferencing rules in a certain application domain. Third, a localist network is used to select the best interpretation among multiple alternatives and potentially ambiguous inference paths by spreading activation throughout the network. The structure, initial states, and connection weights of the network are determined by the processing outcome in the other two sub-systems. This localist network can be viewed as a medium between the distributed network and the symbolic sub-system. Such a hybrid symbolic/connectionist system combines information from all three sources to select the most plausible interpretation for ambiguous words.|natural language processing; word sense disambiguation; connectionist system; knowledge-based system; hybrid system; microfeature|MODEL; REPRESENTATION; NETWORKS|Computer Science, Artificial Intelligence|0|0|0
The sensitive interface|1996|One of the most important problems in human-computer interaction is that of maximising communication between the user and the computer. We claim that optimum communication will be facilitated when the computer can analyse and respond to the intentions of the computer user. We propose a philosophy for computer interface design in which the computer analyses the intentions of users through verbal and nonverbal media. With respect to verbal media we describe a computer program called Operating System CONsultant (OSCON) which can analyse users' intentions from English in the domain of computer operating systems. With respect to nonverbal media we argue that computers will be better able to analyse people's intentions when recognising the media of facial expression, touch, and sound. Some results and implications from a recent experiment on cross-cultural emotions in faces are discussed. We describe the IDIOMS (Intelligent Decision-making In On-line Management Systems) project which implements a design philosophy for capturing users' concepts and intentions. We argue that this approach will ensure the computers will become more understanding of their users and this will result in a more sensitive human-computer interface.|anthropocentrism; emotion; face recognition; human-centredness; human-computer interaction (HCI); IDIOMS; interfaces; natural-language processing; OSCON|DISCOURSE; ENGLISH|Computer Science, Artificial Intelligence|0|0|0
On the use of a hybrid harmonic/stochastic model for TTS synthesis-by-concatenation|1996|In this paper, we address the possibilities offered by hybrid harmonic/stochastic (H/S) models in the context of wide-band text-to-speech synthesis based on segment concatenation. After a brief recall of the hypotheses underlying such models and a comprehensive review of a well-known analysis algorithm, namely the one provided by the multi-band excited (MBE) analysis framework, we study how H/S models allow to modify the prosody of segments and how segment concatenation can be organized, in the purpose of minimizing mismatches at the border of segments. In this context, we introduce an original concatenation algorithm which takes advantage of some analysis errors. Speech synthesis algorithms are then described, including an original synthesis technique based on judiciously prepared IFFTs, and the final segmental quality(1) is detailed. More particularly, we examine the differences in the quality obtained when using the model in a narrow-band speech coding context and in a wide-band, concatenation based synthesis context. We study three possible causes for these differences: the choice of an analysis criterion, the inadequacy of the model due to pitch variatons, and the effect of coarticulation on phases.|TTS synthesis; hybrid harmonic/stochastic; overlap-add; concatenation; segmental quality|SPEECH|Acoustics; Computer Science, Interdisciplinary Applications|7|0|0
Register as a variable in prosodic analysis: The case of the English negative|1996|The next generation of text-to-speech systems will have to be more sensitive to sociolinguistic `style' variables. In order to assist in the adaptation of synthesis to a wider range of contexts, this article examines several sociolinguistic parameters which have been shown to influence the realization of negatives in actual discourse, analyzing their effects on the realization of negatives in English prose readings. Consistent with the results found in an earlier study, the analysis shows that pitch prominence on negatives is not common in read prose passages, and is even less common in read dialogue. Informational content (and consequently pitch prominence on negatives) is more important in prose addressed to children than in narrative reading for adults, while the more formal the prose for adults, the less likely prominence is to occur. The results show a surprising absence of conformity with `theoretical' linguistic expectations, highlighting the necessity for consideration of register as an important variable for speech synthesis.|Spontaneous speech; Read speech; Speaking style; Discourse variables; Focus|SPEECH SYNTHESIS; SPEAKING STYLES; WORDS|Acoustics; Computer Science, Interdisciplinary Applications|8|0|0
STOCHASTIC MODELING IN SPOKEN DIALOG SYSTEM-DESIGN|1994|In this paper, we review the current state of the art in stochastic modeling for spoken dialogue system design. We discuss acoustic modeling of speech units for automatic speech recognition and language modeling of linguistic units for natural language processing. We point out some of the emerging stochastic modeling techniques and show the similarity between language modeling and acoustic modeling. Finally, we address search and decision issues related to the integration of knowledge sources for automatic speech recognition and natural language processing.|AUTOMATIC SPEECH RECOGNITION; NATURAL LANGUAGE PROCESSING; STOCHASTIC MODELING; ACOUSTIC MODELING; LANGUAGE MODELING; HIDDEN MARKOV MODEL; SPOKEN DIALOG SYSTEM|SPEECH RECOGNITION; LANGUAGE MODEL|Acoustics; Computer Science, Interdisciplinary Applications|1|0|0
AN EXPECTATION-DRIVEN RESPONSE UNDERSTANDING PARADIGM|1994|This paper describes a model that can account for ad hoc user-responses to argument interrogative type of system-initiated questions. Successful implementation of the model can provide an alternative solution that is more effective than the menu-driven approach that has been proposed as a meager solution to enable the system to ask a question to the user. The proposed model assumes that when the system asks a question, it maintains an expectation of the potential answers. The system then uses the expectation as the focus to perform the most likely interpretation of the user's response. Without using such a focus the interpretation process could be unbounded. The interpretation process is mapped into a heuristic search problem. `rhe interpretation process results in identifying a particular expectation-response relationship type, which the system can use to tailor its response strategy with respect to the given user-response. A prototype has been constructed to demonstrate the soundness of the proposed model.|EXPECTATION-DRIVEN APPROACH; MIXED-INITIATIVE SYSTEM; MAN-MACHINE DIALOG; 2-WAY COMMUNICATION; NATURAL LANGUAGE INTERFACE|SYSTEM|Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical \& Electronic|0|0|0
ANALYSIS OF PROMINENCE IN SPOKEN JAPANESE SENTENCES AND APPLICATION TO TEXT-TO-SPEECH SYNTHESIS|1994|This paper focuses on the partial emphasis or `'prominence'' of parts of Japanese sentences. Four sets of 43 read sentences uttered by two speakers including various types of prominence (172 sentences in total) are analyzed. This analysis shows that in 88\% of the sentences prominence is produced by enhancing F0 and increasing power. No examples of lengthening of phoneme duration are observed in the emphasized parts of the sentences except for some special cases. One exception is lengthening accompanied by pause insertion as a mark of prominence, and another slowing total speech rate. The prosodic features of read natural speech are then used to develop rules for changing a reference sentence to produce prominence for rule-based speech synthesis. Listening test results using 10 subjects do not show any significant difference in expressibility between prominence synthesized by rule (rate of correct expression: 76.9\%) and prominence in natural speech (79.9\%) at the 5\% level. To further improve prominence expressibility, listening tests for 10 subjects are used to clarify the conditions under which prominence expressibility becomes optimal. These tests show that the prosodic control parameters increase the expressibility of prominence by about 20\%. Finally, prosodic features of spontaneous conversational speech are analyzed and compared with those of read sentence speech. Speech-rate reduction in parts where prominence is placed is more conspicuous in spontaneous conversational speech.|JAPANESE; TEXT-TO-SPEECH; FUJISAKIS MODEL; PROMINENCE; PROSODY; PROMINENCE-PRODUCTION RULE|PERCEPTION; INTONATION; DANISH|Acoustics; Computer Science, Interdisciplinary Applications|4|0|0
ACOUSTICS AND PERCEPTION OF DYNAMIC VOWEL SEGMENTS|1993|Some 550 vowel segments have been excised from a text read by a Dutch speaker, both at normal rate and at fast rate. The duration of each segment is measured, as well as static and dynamic formant characteristics, such as midpoint formant frequencies, and descriptions of the formant tracks in terms of 16 equidistant points per segment, or Legendre polynomial functions. We examined these formant characteristics as a function of vowel duration, but found no indication for duration-dependent undershoot. Instead, this speaker showed very consistent consonant-specific coarticulatory behavior and adapted his speaking style to the speaking rate in order to reach the same midpoint formant frequencies. Various (parabolically stylized) formant tracks, at various durations, in isolation or in CVC contexts, were synthesized and presented to listeners for identification. Net shifts in vowel responses, compared to stationary stimuli, showed no indication of perceptual overshoot. A weighted averaging method with the greatest weight to formant frequencies in the final part of the vowel tokens, explained the results best.|ACOUSTICS OF VOWELS; VOWELS IN READ SPEECH; DUTCH; PERCEPTION OF VOWELS; (DYNAMIC) FORMANT ANALYSIS; VOWEL IDENTIFICATION; VOWEL MODELS|DUTCH VOWELS; FORMANT; CONTEXT; TEXT; READ|Acoustics; Computer Science, Interdisciplinary Applications|13|0|0
EXPERIMENTS WITH VOICE MODELING IN SPEECH SYNTHESIS|1991|Some experiments with voice modelling using recent developments of the KTH speech synthesis system will be presented. A new synthesizer, GLOVE, an extended version of OVE III has been implemented in the system. It contains an improved glottal source built on the LF voice source model, some extra control parameters for the voiced and noise sources and an extra pole/zero-pair in the nasal branch. Furthermore, the present research versions of the KTH text-to-speech system include possibilities for interactive manipulations at the parameter level with on-screen reference to natural speech. The synthesis system constitutes a flexible environment for voice modelling experiments. The new synthesis tools and models were used for synthesis-by-analysis experiments. A sentence uttered by a female speaker was analysed and a stylized copy was made using both the old and the new synthesis system. With the new system the synthetic copy sounded very similar to the natural utterance.|SPEECH SYNTHESIS; VOICE MODELING; VOICE SOURCE MODELS; TEXT-TO-SPEECH CONVERSION; FEMALE VOICE|QUALITY|Acoustics; Computer Science, Interdisciplinary Applications|27|0|0
A survey on opinion mining and sentiment analysis: Tasks, approaches and applications|2015|With the advent of Web 2.0, people became more eager to express and share their opinions on web regarding day-to-day activities and global issues as well. Evolution of social media has also contributed immensely to these activities, thereby providing us a transparent platform to share views across the world. These electronic Word of Mouth (eWOM) statements expressed on the web are much prevalent in business and service industry to enable customer to share his/her point of view. In the last one and half decades, research communities, academia, public and service industries are working rigorously on sentiment analysis, also known as, opinion mining, to extract and analyze public mood and views. In this regard, this paper presents a rigorous survey on sentiment analysis, which portrays views presented by over one hundred articles published in the last decade regarding necessary tasks, approaches, and applications of sentiment analysis. Several sub-tasks need to be performed for sentiment analysis which in turn can be accomplished using various approaches and techniques. This survey covering published literature during 2002-2015, is organized on the basis of sub-tasks to be performed, machine learning and natural language processing techniques used and applications of sentiment analysis. The paper also presents open issues and along with a summary table of a hundred and sixty-one articles. (C) 2015 Elsevier B.V. All rights reserved.|Opinion mining; Sentiment analysis; Social media; Micro blog; Lexica creation; Machine learning; Ontology|PRODUCT FEATURE-EXTRACTION; ONLINE CONSUMER REVIEWS; CUSTOMER REVIEWS; POLARITY CLASSIFICATION; PERCEIVED USEFULNESS; RESTAURANT REVIEWS; STRENGTH DETECTION; FEATURE-SELECTION; SOCIAL NETWORKS; SPANISH REVIEWS|Computer Science, Artificial Intelligence|100|78|228
Pharmacovigilance from social media: mining adverse drug reaction mentions using sequence labeling with word embedding cluster features|2015|Objective Social media is becoming increasingly popular as a platform for sharing personal health-related information. This information can be utilized for public health monitoring tasks, particularly for pharmacovigilance, via the use of natural language processing (NLP) techniques. However, the language in social media is highly informal, and user-expressed medical concepts are often nontechnical, descriptive, and challenging to extract. There has been limited progress in addressing these challenges, and thus far, advanced machine learning-based NLP techniques have been underutilized. Our objective is to design a machine learning-based approach to extract mentions of adverse drug reactions (ADRs) from highly informal text in social media. Methods We introduce ADRMine, a machine learning-based concept extraction system that uses conditional random fields (CRFs). ADRMine utilizes a variety of features, including a novel feature for modeling words' semantic similarities. The similarities are modeled by clustering words based on unsupervised, pretrained word representation vectors (embeddings) generated from unlabeled user posts in social media using a deep learning technique. Results ADRMine outperforms several strong baseline systems in the ADR extraction task by achieving an F-measure of 0.82. Feature analysis demonstrates that the proposed word cluster features significantly improve extraction performance. Conclusion It is possible to extract complex medical concepts, with relatively high performance, from informal, user-generated content. Our approach is particularly scalable, suitable for social media mining, as it relies on large volumes of unlabeled data, thus diminishing the need for large, annotated training data sets.|adverse drug reaction; ADR; social media mining; pharmacovigilance; natural language processing; machine learning; deep learning word embeddings|WEB; EXTRACTION; DISCOVERY; AGREEMENT; DATABASE; TEXT|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|48|15|79
A review of approaches to identifying patient phenotype cohorts using electronic health records|2014|Objective To summarize literature describing approaches aimed at automatically identifying patients with a common phenotype. Materials and methods We performed a review of studies describing systems or reporting techniques developed for identifying cohorts of patients with specific phenotypes. Every full text article published in (1) Journal of American Medical Informatics Association, (2) Journal of Biomedical Informatics, (3) Proceedings of the Annual American Medical Informatics Association Symposium, and (4) Proceedings of Clinical Research Informatics Conference within the past 3years was assessed for inclusion in the review. Only articles using automated techniques were included. Results Ninety-seven articles met our inclusion criteria. Forty-six used natural language processing (NLP)-based techniques, 24 described rule-based systems, 41 used statistical analyses, data mining, or machine learning techniques, while 22 described hybrid systems. Nine articles described the architecture of large-scale systems developed for determining cohort eligibility of patients. Discussion We observe that there is a rise in the number of studies associated with cohort identification using electronic medical records. Statistical analyses or machine learning, followed by NLP techniques, are gaining popularity over the years in comparison with rule-based systems. Conclusions There are a variety of approaches for classifying patients into a particular phenotype. Different techniques and data sources are used, and good performance is reported on datasets at respective institutions. However, no system makes comprehensive use of electronic medical records addressing all of their known weaknesses.|Review; Electronic Health Records; Cohort Identification; Phenotyping|X-RAY REPORTS; MEDICAL-RECORDS; RHEUMATOID-ARTHRITIS; CLINICAL-TRIALS; HEART-FAILURE; DECISION-MAKING; CANCER-RISK; EHR DATA; CLASSIFICATION; IDENTIFICATION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|57|12|77
A feature selection model based on genetic rank aggregation for text sentiment classification|2017|Sentiment analysis is an important research direction of natural language processing, text mining and web mining which aims to extract subjective information in source materials. The main challenge encountered in machine learning method-based sentiment classification is the abundant amount of data available. This amount makes it difficult to train the learning algorithms in a feasible time and degrades the classification accuracy of the built model. Hence, feature selection becomes an essential task in developing robust and efficient classification models whilst reducing the training time. In text mining applications, individual filter-based feature selection methods have been widely utilized owing to their simplicity and relatively high performance. This paper presents an ensemble approach for feature selection, which aggregates the several individual feature lists obtained by the different feature selection methods so that a more robust and efficient feature subset can be obtained. In order to aggregate the individual feature lists, a genetic algorithm has been utilized. Experimental evaluations indicated that the proposed aggregation model is an efficient method and it outperforms individual filter-based feature selection methods on sentiment classification.|Feature selection; rank aggregation; sentiment classification|TRAVELING SALESMAN PROBLEM; ALGORITHMS|Computer Science, Information Systems; Information Science \& Library Science|7|38|50
A comprehensive text analysis of lecture slides to generate concept maps|2017|Current instructional methods widely support verbal learning through linear and sequential teaching materials, focusing on isolated pieces of information. However, an important aspect of learning design is to facilitate students in identifying relationships between information. The transformation of linearity in teaching resources into integrated network models such as concept maps facilitates effective knowledge organisation by constructing relationships between new and existing knowledge. However, the manual construction of concept maps from teaching materials places an additional workload on the academics involved. Consequently, this research investigates the effectiveness of automated approaches in extracting concept maps from lecture slides and the suitability of auto-generated concept maps as a pedagogical tool. We develop a set of Natural Language Processing (NLP) algorithms to support concept-relation-concept triple extraction to form concept maps. Structural and graph-based features are utilised to rank the triples according to their importance. The natural layout of the lecture slides is incorporated to organise the triples in a hierarchy, facilitating highly integrated structure. Our evaluation studies identify promising results, with several case studies demonstrating a statistically significant correlation (r(s) > 0.455) between auto-generated concept maps and human experts' judgment. Auto-generated concept maps were rated from `good' to `very good' by the academics on evaluation factors such as coverage, accuracy, and suitability as a pedagogical tool. Thus, auto-generated concept maps from this research can be utilised as a positive alternative to the manual construction of expert concept maps and further, it is possible to utilise these maps for a wider range of applications including knowledge organisation and reflective visualisation of course contents. Our research contributes to bridging the gap between linearity in teaching materials and the necessity of creating integrated network models from teaching resources. (C) 2017 Elsevier Ltd. All rights reserved.|improving classroom teaching; Media in education; Pedagogical issues; Teaching/learning strategies|KNOWLEDGE MAPS; POWERPOINT|Computer Science, Interdisciplinary Applications; Education \& Educational Research|6|48|48
What can natural language processing do for clinical decision support?|2009|Computerized clinical decision support (CDS) aims to aid decision making of health care providers and the public by providing easily accessible health-related information at the point and time it is needed. natural language processing (NLP) is instrumental in using free-text information to drive CDS, representing clinical knowledge and CDS interventions in standardized formats, and leveraging clinical narrative. The early innovative NLP research of clinical narrative was followed by a period of stable research conducted at the major clinical centers and a shift of mainstream interest to biomedical NLP. This review primarily focuses on the recently renewed interest in development of fundamental NLP methods and advances in the NLP systems for CDS. The current solutions to challenges posed by distinct sublanguages, intended user groups, and support goals are discussed. Published by Elsevier Inc.|Natural language processing; Decision support techniques; Clinical decision support systems; Review|PART-OF-SPEECH; ELECTRONIC MEDICAL-RECORD; NAMED-ENTITY RECOGNITION; PATIENT SAFETY RESEARCH; BIOMEDICAL LITERATURE; INFORMATION; DOCUMENTS; TEXT; PERFORMANCE; EXTRACTION|Computer Science, Interdisciplinary Applications; Medical Informatics|140|10|37
Validating drug repurposing signals using electronic health records: a case study of metformin associated with reduced cancer mortality|2015|Objectives Drug repurposing, which finds new indications for existing drugs, has received great attention recently. The goal of our work is to assess the feasibility of using electronic health records (EHRs) and automated informatics methods to efficiently validate a recent drug repurposing association of metformin with reduced cancer mortality. Methods By linking two large EHRs from Vanderbilt University Medical Center and Mayo Clinic to their tumor registries, we constructed a cohort including 32 415 adults with a cancer diagnosis at Vanderbilt and 79 258 cancer patients at Mayo from 1995 to 2010. Using automated informatics methods, we further identified type 2 diabetes patients within the cancer cohort and determined their drug exposure information, as well as other covariates such as smoking status. We then estimated HRs for all-cause mortality and their associated 95\% CIs using stratified Cox proportional hazard models. HRs were estimated according to metformin exposure, adjusted for age at diagnosis, sex, race, body mass index, tobacco use, insulin use, cancer type, and non-cancer Charlson comorbidity index. Results Among all Vanderbilt cancer patients, metformin was associated with a 22\% decrease in overall mortality compared to other oral hypoglycemic medications (HR 0.78; 95\% CI 0.69 to 0.88) and with a 39\% decrease compared to type 2 diabetes patients on insulin only (HR 0.61; 95\% CI 0.50 to 0.73). Diabetic patients on metformin also had a 23\% improved survival compared with non-diabetic patients (HR 0.77; 95\% CI 0.71 to 0.85). These associations were replicated using the Mayo Clinic EHR data. Many site-specific cancers including breast, colorectal, lung, and prostate demonstrated reduced mortality with metformin use in at least one EHR. Conclusions EHR data suggested that the use of metformin was associated with decreased mortality after a cancer diagnosis compared with diabetic and non-diabetic cancer patients not on metformin, indicating its potential as a chemotherapeutic regimen. This study serves as a model for robust and inexpensive validation studies for drug repurposing signals using EHR data.|drug repurposing; electronic health records; natural language processing; metformin|GENOME-WIDE ASSOCIATION; DISCHARGE SUMMARIES; PANCREATIC-CANCER; DIABETIC-PATIENTS; INCIDENT CANCER; RISK; THERAPEUTICS; SURVIVAL; GLUCOSE; IDENTIFICATION|Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences \& Services; Information Science \& Library Science; Medical Informatics|43|5|24
